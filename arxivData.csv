id,title,categories,abstract,doi,created,updated,authors
1301.3535,"airport gate scheduling for passengers, aircraft, and operation",cs.sy cs.ai,"passengers' experience is becoming a key metric to evaluate the air transportation system's performance. efficient and robust tools to handle airport operations are needed along with a better understanding of passengers' interests and concerns. among various airport operations, this paper studies airport gate scheduling for improved passengers' experience. three objectives accounting for passengers, aircraft, and operation are presented. trade-offs between these objectives are analyzed, and a balancing objective function is proposed. the results show that the balanced objective can improve the efficiency of traffic flow in passenger terminals and on ramps, as well as the robustness of gate operations.",10.2514/1.d0079,2013-01-15,,"['sang hyun kim', 'eric feron', 'john-paul clarke', 'aude marzuoli', 'daniel delahaye']"
1805.10672,a note on belief structures and s-approximation spaces,cs.ai math.lo,"we study relations between evidence theory and s-approximation spaces. both theories have their roots in the analysis of dempster's multivalued mappings and lower and upper probabilities and have close relations to rough sets. we show that an s-approximation space, satisfying a monotonicity condition, can induce a natural belief structure which is a fundamental block in evidence theory. we also demonstrate that one can induce a natural belief structure on one set, given a belief structure on another set if those sets are related by a partial monotone s-approximation space.",,2018-05-27,2020-03-28,"['ali shakiba', 'amir kafshdar goharshady', 'mohammadreza hooshmandasl', 'mohsen alambardar meybodi']"
1808.08079,under the hood: using diagnostic classifiers to investigate and improve   how language models track agreement information,cs.cl cs.ai,"how do neural language models keep track of number agreement between subject and verb? we show that `diagnostic classifiers', trained to predict number from the internal states of a language model, provide a detailed understanding of how, when, and where this information is represented. moreover, they give us insight into when and where number information is corrupted in cases where the language model ends up making agreement errors. to demonstrate the causal role played by the representations we find, we then use agreement information to influence the course of the lstm during the processing of difficult sentences. results from such an intervention reveal a large increase in the language model's accuracy. together, these results show that diagnostic classifiers give us an unrivalled detailed look into the representation of linguistic information in neural models, and demonstrate that this knowledge can be used to improve their performance.",,2018-08-24,2021-11-18,"['mario giulianelli', 'jacqueline harding', 'florian mohnert', 'dieuwke hupkes', 'willem zuidema']"
1810.04879,generating shared latent variables for robots to imitate human movements   and understand their physical limitations,cs.ro cs.ai cs.cv cs.hc cs.lg,"assistive robotics and particularly robot coaches may be very helpful for rehabilitation healthcare. in this context, we propose a method based on gaussian process latent variable model (gp-lvm) to transfer knowledge between a physiotherapist, a robot coach and a patient. our model is able to map visual human body features to robot data in order to facilitate the robot learning and imitation. in addition , we propose to extend the model to adapt robots' understanding to patient's physical limitations during the assessment of rehabilitation exercises. experimental evaluation demonstrates promising results for both robot imitation and model adaptation according to the patients' limitations.",10.1007/978-3-030-11012-3_15,2018-10-11,2021-11-03,"['maxime devanne', 'sao mai nguyen']"
1812.04082,visual depth mapping from monocular images using recurrent convolutional   neural networks,cs.cv cs.ai,"a reliable sense-and-avoid system is critical to enabling safe autonomous operation of unmanned aircraft. existing sense-and-avoid methods often require specialized sensors that are too large or power intensive for use on small unmanned vehicles. this paper presents a method to estimate object distances based on visual image sequences, allowing for the use of low-cost, on-board monocular cameras as simple collision avoidance sensors. we present a deep recurrent convolutional neural network and training method to generate depth maps from video sequences. our network is trained using simulated camera and depth data generated with microsoft's airsim simulator. empirically, we show that our model achieves superior performance compared to models generated using prior methods.we further demonstrate that the method can be used for sense-and-avoid of obstacles in simulation.",10.2514/6.2019-1189,2018-12-10,,"['john mern', 'kyle julian', 'rachael e. tompa', 'mykel j. kochenderfer']"
1812.10487,early prediction of post-acute care discharge disposition using   predictive analytics: preponing prior health insurance authorization thus   reducing the inpatient length of stay,cs.cy cs.ai,"objective: a patient medical insurance coverage plays an essential role in determining the post-acute care (pac) discharge disposition. the prior health insurance authorization process postpones the pac discharge disposition, increases the inpatient length of stay, and effects patient health. our study implements predictive analytics for the early prediction of the pac discharge disposition to reduce the deferments caused by prior health insurance authorization, the inpatient length of stay and inpatient stay expenses. methodology: we conducted a group discussion involving 25 patient care facilitators (pcfs) and two registered nurses (rns) and retrieved 1600 patient data records from the initial nursing assessment and discharge notes to conduct a retrospective analysis of pac discharge dispositions using predictive analytics. results: the chi-squared automatic interaction detector (chaid) algorithm enabled the early prediction of the pac discharge disposition, accelerated the prior health insurance process, decreased the inpatient length of stay by an average of 22.22%, and reduced inpatient stay expenses by \$1,974 for state government hospitals, \$2,346 for non-profit hospitals and \$1,798 for for-profit hospitals per day. the chaid algorithm produced an overall accuracy of 84.16% and an area under the receiver operating characteristic (roc) curve value of 0.81. conclusion: the early prediction of pac discharge dispositions can condense the pac deferment caused by the prior health insurance authorization process and simultaneously minimize the inpatient length of stay and related expenses incurred by the hospital.",,2018-12-28,,['avishek choudhury']
1903.00715,efficient reinforcement learning for starcraft by abstract forward   models and transfer learning,cs.lg cs.ai stat.ml,"injecting human knowledge is an effective way to accelerate reinforcement learning (rl). however, these methods are underexplored. this paper presents our discovery that an abstract forward model (thought-game (tg)) combined with transfer learning (tl) is an effective way. we take starcraft ii as our study environment. with the help of a designed tg, the agent can learn a 99% win-rate on a 64x64 map against the level-7 built-in ai, using only 1.08 hours in a single commercial machine. we also show that the tg method is not as restrictive as it was thought to be. it can work with roughly designed tgs, and can also be useful when the environment changes. comparing with previous model-based rl, we show tg is more effective. we also present a tg hypothesis that gives the influence of different fidelity levels of tg. for real games that have unequal state and action spaces, we proposed a novel xfrnet of which usefulness is validated while achieving a 90% win-rate against the cheating level-10 ai. we argue that the tg method might shed light on further studies of efficient rl with human knowledge.",,2019-03-02,2021-11-02,"['ruo-ze liu', 'haifeng guo', 'xiaozhong ji', 'yang yu', 'zhen-jia pang', 'zitai xiao', 'yuzhou wu', 'tong lu']"
1904.00326,medication recommendation and lab test imputation via graph   convolutional networks,cs.lg cs.ai stat.ml,"laboratory testing and medication prescription are two of the most important routines in daily clinical practice. developing an artificial intelligence system that can automatically make lab test imputations and medication recommendations can save costs on potentially redundant lab tests and inform physicians of a more effective prescription. we present an intelligent medical system (named medgcn) that can automatically recommend the patients' medications based on their incomplete lab tests, and can even accurately estimate the lab values that have not been taken. in our system, we integrate the complex relations between multiple types of medical entities with their inherent features in a heterogeneous graph. then we model the graph to learn a distributed representation for each entity in the graph based on graph convolutional networks (gcn). by the propagation of graph convolutional networks, the entity representations can incorporate multiple types of medical information that can benefit multiple medical tasks. moreover, we introduce a cross regularization strategy to reduce overfitting for multi-task training by the interaction between the multiple tasks. in this study, we construct a graph to associate 4 types of medical entities, i.e., patients, encounters, lab tests, and medications, and applied a graph neural network to learn node embeddings for medication recommendation and lab test imputation. we validate our medgcn model on two real-world datasets: nmedw and mimic-iii. the experimental results on both datasets demonstrate that our model can outperform the state-of-the-art in both tasks. we believe that our innovative system can provide a promising and reliable way to assist physicians to make medication prescriptions and to save costs on potentially redundant lab tests.",,2019-03-30,2021-10-31,"['chengsheng mao', 'liang yao', 'yuan luo']"
1905.08088,graph mining meets crowdsourcing: extracting experts for answer   aggregation,cs.si cs.ai cs.hc cs.lg,"aggregating responses from crowd workers is a fundamental task in the process of crowdsourcing. in cases where a few experts are overwhelmed by a large number of non-experts, most answer aggregation algorithms such as the majority voting fail to identify the correct answers. therefore, it is crucial to extract reliable experts from the crowd workers. in this study, we introduce the notion of ""expert core"", which is a set of workers that is very unlikely to contain a non-expert. we design a graph-mining-based efficient algorithm that exactly computes the expert core. to answer the aggregation task, we propose two types of algorithms. the first one incorporates the expert core into existing answer aggregation algorithms such as the majority voting, whereas the second one utilizes information provided by the expert core extraction algorithm pertaining to the reliability of workers. we then give a theoretical justification for the first type of algorithm. computational experiments using synthetic and real-world datasets demonstrate that our proposed answer aggregation algorithms outperform state-of-the-art algorithms.",10.24963/ijcai.2019/177,2019-05-17,,"['yasushi kawase', 'yuko kuroki', 'atsushi miyauchi']"
1906.05799,deep reinforcement learning for cyber security,cs.cr cs.ai cs.lg stat.ml,"the scale of internet-connected systems has increased considerably, and these systems are being exposed to cyber attacks more than ever. the complexity and dynamics of cyber attacks require protecting mechanisms to be responsive, adaptive, and scalable. machine learning, or more specifically deep reinforcement learning (drl), methods have been proposed widely to address these issues. by incorporating deep learning into traditional rl, drl is highly capable of solving complex, dynamic, and especially high-dimensional cyber defense problems. this paper presents a survey of drl approaches developed for cyber security. we touch on different vital aspects, including drl-based security methods for cyber-physical systems, autonomous intrusion detection techniques, and multiagent drl-based game theory simulations for defense strategies against cyber attacks. extensive discussions and future research directions on drl-based cyber security are also given. we expect that this comprehensive review provides the foundations for and facilitates future studies on exploring the potential of emerging drl to cope with increasingly complex cyber security problems.",10.1109/tnnls.2021.3121870,2019-06-13,2021-11-01,"['thanh thi nguyen', 'vijay janapa reddi']"
1908.07822,a multi-level neural network for implicit causality detection in web   texts,cs.cl cs.ai cs.lg,"mining causality from text is a complex and crucial natural language understanding task corresponding to the human cognition. existing studies at its solution can be grouped into two primary categories: feature engineering based and neural model based methods. in this paper, we find that the former has incomplete coverage and inherent errors but provide prior knowledge; while the latter leverages context information but causal inference of which is insufficiency. to handle the limitations, we propose a novel causality detection model named mcdn to explicitly model causal reasoning process, and furthermore, to exploit the advantages of both methods. specifically, we adopt multi-head self-attention to acquire semantic feature at word level and develop the scrn to infer causality at segment level. to the best of our knowledge, with regards to the causality tasks, this is the first time that the relation network is applied. the experimental results show that: 1) the proposed approach performs prominent performance on causality detection; 2) further analysis manifests the effectiveness and robustness of mcdn.",,2019-08-18,2021-11-03,"['shining liang', 'wanli zuo', 'zhenkun shi', 'sen wang', 'junhu wang', 'xianglin zuo']"
1909.12425,a re-classification of information seeking tasks and their computational   solutions,cs.ai cs.ir,"this article presents a re-classification of information seeking (is) tasks, concepts, and algorithms. the proposed taxonomy provides new dimensions to look into information seeking tasks and methods. the new dimensions include the number of search iterations, search goal types, and procedures to reach these goals. differences along these dimensions for the information seeking tasks call for suitable computational solutions. the article then reviews machine learning solutions that match each new category. the paper ends with a review of evaluation campaigns for is systems.",10.1145/3497875,2019-09-26,2021-11-09,"['zhiwen tang', 'grace hui yang']"
1910.05065,a theory of relation learning and cross-domain generalization,cs.ai cs.lg cs.ne,"people readily generalize knowledge to novel domains and stimuli. we present a theory, instantiated in a computational model, based on the idea that cross-domain generalization in humans is a case of analogical inference over structured (i.e., symbolic) relational representations. the model is an extension of the lisa and dora models of relational inference and learning. the resulting model learns both the content and format (i.e., structure) of relational representations from non-relational inputs without supervision, when augmented with the capacity for reinforcement learning, leverages these representations to learn individual domains, and then generalizes to new domains on the first exposure (i.e., zero-shot learning) via analogical inference. we demonstrate the capacity of the model to learn structured relational representations from a variety of simple visual stimuli, and to perform cross-domain generalization between video games (breakout and pong) and between several psychological tasks. we demonstrate that the model's trajectory closely mirrors the trajectory of children as they learn about relations, accounting for phenomena from the literature on the development of children's reasoning and analogy making. the model's ability to generalize between domains demonstrates the flexibility afforded by representing domains in terms of their underlying relational structure, rather than simply in terms of the statistical relations between their inputs and outputs.",,2019-10-11,2021-11-09,"['leonidas a. a. doumas', 'guillermo puebla', 'andrea e. martin', 'john e. hummel']"
1910.07294,reinforcement learning for robotic manipulation using simulated   locomotion demonstrations,cs.lg cs.ai cs.ro stat.ml,"mastering robotic manipulation skills through reinforcement learning (rl) typically requires the design of shaped reward functions. recent developments in this area have demonstrated that using sparse rewards, i.e. rewarding the agent only when the task has been successfully completed, can lead to better policies. however, state-action space exploration is more difficult in this case. recent rl approaches to learning with sparse rewards have leveraged high-quality human demonstrations for the task, but these can be costly, time consuming or even impossible to obtain. in this paper, we propose a novel and effective approach that does not require human demonstrations. we observe that every robotic manipulation task could be seen as involving a locomotion task from the perspective of the object being manipulated, i.e. the object could learn how to reach a target state on its own. in order to exploit this idea, we introduce a framework whereby an object locomotion policy is initially obtained using a realistic physics simulator. this policy is then used to generate auxiliary rewards, called simulated locomotion demonstration rewards (sldrs), which enable us to learn the robot manipulation policy. the proposed approach has been evaluated on 13 tasks of increasing complexity, and can achieve higher success rate and faster learning rates compared to alternative algorithms. sldrs are especially beneficial for tasks like multi-object stacking and non-rigid object manipulation.",10.1007/s10994-021-06116-1,2019-10-16,2021-11-11,"['ozsel kilinc', 'giovanni montana']"
1911.07605,commit2vec: learning distributed representations of code changes,cs.se cs.ai cs.lg,"deep learning methods, which have found successful applications in fields like image classification and natural language processing, have recently been applied to source code analysis too, due to the enormous amount of freely available source code (e.g., from open-source software repositories).   in this work, we elaborate upon a state-of-the-art approach to the representation of source code that uses information about its syntactic structure, and we adapt it to represent source changes (i.e., commits). we use this representation to classify security-relevant commits.   because our method uses transfer learning (that is, we train a network on a ""pretext task"" for which abundant labeled data is available, and then we use such network for the target task of commit classification, for which fewer labeled instances are available), we studied the impact of pre-training the network using two different pretext tasks versus a randomly initialized model.   our results indicate that representations that leverage the structural information obtained through code syntax outperform token-based representations. furthermore, the performance metrics obtained when pre-training on a loosely related pretext task with a very large dataset ($>10^6$ samples) were surpassed when pretraining on a smaller dataset ($>10^4$ samples) but for a pretext task that is more closely related to the target task.",10.1007/s42979-021-00566-z,2019-11-18,2021-11-17,"['rocìo cabrera lozoya', 'arnaud baumann', 'antonino sabetta', 'michele bezzi']"
1911.09315,rule extraction in unsupervised anomaly detection for model   explainability: application to oneclass svm,cs.lg cs.ai,"oneclass svm is a popular method for unsupervised anomaly detection. as many other methods, it suffers from the black box problem: it is difficult to justify, in an intuitive and simple manner, why the decision frontier is identifying data points as anomalous or non anomalous. such type of problem is being widely addressed for supervised models. however, it is still an uncharted area for unsupervised learning. in this paper, we evaluate several rule extraction techniques over oneclass svm models, as well as present alternative designs for some of those algorithms. together with that, we propose algorithms to compute metrics related with explainable artificial intelligence (xai) regarding the ""comprehensibility"", ""representativeness"", ""stability"" and ""diversity"" of the extracted rules. we evaluate our proposals with different datasets, including real-world data coming from industry. with this, our proposal contributes to extend xai techniques to unsupervised machine learning models.",10.1016/j.eswa.2021.116100,2019-11-21,2021-04-01,"['alberto barbado', 'óscar corcho', 'richard benjamins']"
1912.02368,inter-level cooperation in hierarchical reinforcement learning,cs.lg cs.ai stat.ml,"hierarchies of temporally decoupled policies present a promising approach for enabling structured exploration in complex long-term planning problems. to fully achieve this approach an end-to-end training paradigm is needed. however, training these multi-level policies has had limited success due to challenges arising from interactions between the goal-assigning and goal-achieving levels within a hierarchy. in this article, we consider the policy optimization process as a multi-agent process. this allows us to draw on connections between communication and cooperation in multi-agent rl, and demonstrate the benefits of increased cooperation between sub-policies on the training performance of the overall policy. we introduce a simple yet effective technique for inducing inter-level cooperation by modifying the objective function and subsequent gradients of higher-level policies. experimental results on a wide variety of simulated robotics and traffic control tasks demonstrate that inducing cooperation results in stronger performing policies and increased sample efficiency on a set of difficult long time horizon tasks. we also find that goal-conditioned policies trained using our method display better transfer to new tasks, highlighting the benefits of our method in learning task-agnostic lower-level behaviors. videos and code are available at: https://sites.google.com/berkeley.edu/cooperative-hrl.",,2019-12-04,2021-11-17,"['abdul rahman kreidieh', 'glen berseth', 'brandon trabucco', 'samyak parajuli', 'sergey levine', 'alexandre m. bayen']"
1912.02906,scalable reinforcement learning for multi-agent networked systems,math.oc cs.ai cs.lg,"we study reinforcement learning (rl) in a setting with a network of agents whose states and actions interact in a local manner where the objective is to find localized policies such that the (discounted) global reward is maximized. a fundamental challenge in this setting is that the state-action space size scales exponentially in the number of agents, rendering the problem intractable for large networks. in this paper, we propose a scalable actor critic (sac) framework that exploits the network structure and finds a localized policy that is an $o(\rho^{\kappa})$-approximation of a stationary point of the objective for some $\rho\in(0,1)$, with complexity that scales with the local state-action space size of the largest $\kappa$-hop neighborhood of the network. we illustrate our model and approach using examples from wireless communication, epidemics and traffic.",,2019-12-05,2021-10-31,"['guannan qu', 'adam wierman', 'na li']"
1912.10514,tag-less back-translation,cs.cl cs.ai cs.lg,"an effective method to generate a large number of parallel sentences for training improved neural machine translation (nmt) systems is the use of the back-translations of the target-side monolingual data. the standard back-translation method has been shown to be unable to efficiently utilize the available huge amount of existing monolingual data because of the inability of translation models to differentiate between the authentic and synthetic parallel data during training. tagging, or using gates, has been used to enable translation models to distinguish between synthetic and authentic data, improving standard back-translation and also enabling the use of iterative back-translation on language pairs that underperformed using standard back-translation. in this work, we approach back-translation as a domain adaptation problem, eliminating the need for explicit tagging. in the approach -- \emph{tag-less back-translation} -- the synthetic and authentic parallel data are treated as out-of-domain and in-domain data respectively and, through pre-training and fine-tuning, the translation model is shown to be able to learn more efficiently from them during training. experimental results have shown that the approach outperforms the standard and tagged back-translation approaches on low resource english-vietnamese and english-german neural machine translation.",10.1007/s10590-021-09284-y,2019-12-22,2021-02-09,"['idris abdulmumin', 'bashir shehu galadanci', 'aliyu garba']"
2003.03917,bittensor: a peer-to-peer intelligence market,cs.ai cs.lg cs.ma,"as with other commodities, markets could help us efficiently produce machine intelligence. we propose a market where intelligence is priced by other intelligence systems peer-to-peer across the internet. peers rank each other by training neural networks which learn the value of their neighbors. scores accumulate on a digital ledger where high ranking peers are monetarily rewarded with additional weight in the network. however, this form of peer-ranking is not resistant to collusion, which could disrupt the accuracy of the mechanism. the solution is a connectivity-based regularization which exponentially rewards trusted peers, making the system resistant to collusion of up to 50 percent of the network weight. the result is a collectively run intelligence market which continual produces newly trained models and pays contributors who create information theoretic value.",,2020-03-09,2021-11-09,"['yuma rao', 'jacob steeves', 'ala shaabana', 'daniel attevelt', 'matthew mcateer']"
2003.06507,the conflict between people's urge to punish ai and legal systems,cs.cy cs.ai,"regulating artificial intelligence (ai) has become necessary in light of its deployment in high-risk scenarios. this paper explores the proposal to extend legal personhood to ai and robots, which had not yet been examined through the lens of the general public. we present two studies (n = 3,559) to obtain people's views of electronic legal personhood vis-\`a-vis existing liability models. our study reveals people's desire to punish automated agents even though these entities are not recognized any mental state. furthermore, people did not believe automated agents' punishment would fulfill deterrence nor retribution and were unwilling to grant them legal punishment preconditions, namely physical independence and assets. collectively, these findings suggest a conflict between the desire to punish automated agents and its perceived impracticability. we conclude by discussing how future design and legal decisions may influence how the public reacts to automated agents' wrongdoings.",10.3389/frobt.2021.756242,2020-03-13,2021-11-10,"['gabriel lima', 'meeyoung cha', 'chihyung jeon', 'kyungsin park']"
2004.01274,does comma selection help to cope with local optima,cs.ne cs.ai cs.ds,"one hope when using non-elitism in evolutionary computation is that the ability to abandon the current-best solution aids leaving local optima. to improve our understanding of this mechanism, we perform a rigorous runtime analysis of a basic non-elitist evolutionary algorithm (ea), the $(\mu,\lambda)$ ea, on the most basic benchmark function with a local optimum, the jump function. we prove that for all reasonable values of the parameters and the problem, the expected runtime of the $(\mu,\lambda)$~ea is, apart from lower order terms, at least as large as the expected runtime of its elitist counterpart, the $(\mu+\lambda)$~ea (for which we conduct the first runtime analysis on jump functions to allow this comparison). consequently, the ability of the $(\mu,\lambda)$~ea to leave local optima to inferior solutions does not lead to a runtime advantage.   we complement this lower bound with an upper bound that, for broad ranges of the parameters, is identical to our lower bound apart from lower order terms. this is the first runtime result for a non-elitist algorithm on a multi-modal problem that is tight apart from lower order terms.",10.1145/3377930.3389823,2020-04-02,2021-11-10,['benjamin doerr']
2004.09705,explainable goal-driven agents and robots -- a comprehensive review,cs.ro cs.ai,"recent applications of autonomous agents and robots, such as self-driving cars, scenario-based trainers, exploration robots, and service robots have brought attention to crucial trust-related challenges associated with the current generation of artificial intelligence (ai) systems. ai systems based on the connectionist deep learning neural network approach lack capabilities of explaining their decisions and actions to others, despite their great successes. without symbolic interpretation capabilities, they are black boxes, which renders their decisions or actions opaque, making it difficult to trust them in safety-critical applications. the recent stance on the explainability of ai systems has witnessed several approaches on explainable artificial intelligence (xai); however, most of the studies have focused on data-driven xai systems applied in computational sciences. studies addressing the increasingly pervasive goal-driven agents and robots are still missing. this paper reviews approaches on explainable goal-driven intelligent agents and robots, focusing on techniques for explaining and communicating agents perceptual functions (example, senses, and vision) and cognitive reasoning (example, beliefs, desires, intention, plans, and goals) with humans in the loop. the review highlights key strategies that emphasize transparency, understandability, and continual learning for explainability. finally, the paper presents requirements for explainability and suggests a roadmap for the possible realization of effective goal-driven explainable agents and robots.",,2020-04-20,2021-11-05,"['fatai sado', 'chu kiong loo', 'wei shiung liew', 'matthias kerzel', 'stefan wermter']"
2005.13625,revisiting parameter sharing in multi-agent deep reinforcement learning,cs.lg cs.ai cs.ma stat.ml,"""nonstationarity"" is a fundamental problem in cooperative multi-agent reinforcement learning (marl). it results from every agent's policy changing during learning, while being part of the environment from the perspective of other agents. this causes information to inherently oscillate between agents during learning, greatly slowing convergence. we use the mailp model of information transfer during multi-agent learning to show that increasing centralization during learning arbitrarily mitigates the slowing of convergence due to nonstationarity. the most centralized case of learning is parameter sharing, an uncommonly used marl method, specific to environments with homogeneous agents. it bootstraps single-agent reinforcement learning (rl) methods and learns an identical policy for each agent. we experimentally replicate our theoretical result of increased learning centralization leading to better performance. we further apply parameter sharing to 8 more modern single-agent deep rl methods for the first time, achieving up to 44 times more average reward in 16% as many episodes compared to previous parameter sharing experiments. we finally give a formal proof of a set of methods that allow parameter sharing to serve in environments with heterogeneous agents.",,2020-05-27,2021-02-25,"['j. k. terry', 'nathaniel grammel', 'ananth hari', 'luis santos', 'benjamin black']"
2006.00587,towards understanding cooperative multi-agent q-learning with value   factorization,cs.lg cs.ai cs.ma stat.ml,"value factorization is a popular and promising approach to scaling up multi-agent reinforcement learning in cooperative settings, which balances the learning scalability and the representational capacity of value functions. however, the theoretical understanding of such methods is limited. in this paper, we formalize a multi-agent fitted q-iteration framework for analyzing factorized multi-agent q-learning. based on this framework, we investigate linear value factorization and reveal that multi-agent q-learning with this simple decomposition implicitly realizes a powerful counterfactual credit assignment, but may not converge in some settings. through further analysis, we find that on-policy training or richer joint value function classes can improve its local or global convergence properties, respectively. finally, to support our theoretical implications in practical realization, we conduct an empirical analysis of state-of-the-art deep multi-agent q-learning algorithms on didactic examples and a broad set of starcraft ii unit micromanagement tasks.",,2020-05-31,2021-10-31,"['jianhao wang', 'zhizhou ren', 'beining han', 'jianing ye', 'chongjie zhang']"
2006.03950,valnorm quantifies semantics to reveal consistent valence biases across   languages and over centuries,cs.cy cs.ai cs.cl cs.lg,"word embeddings learn implicit biases from linguistic regularities captured by word co-occurrence statistics. by extending methods that quantify human-like biases in word embeddings, we introducevalnorm, a novel intrinsic evaluation task and method to quantify the valence dimension of affect in human-rated word sets from social psychology. we apply valnorm on static word embeddings from seven languages (chinese, english, german, polish, portuguese, spanish, and turkish) and from historical english text spanning 200 years. valnorm achieves consistently high accuracy in quantifying the valence of non-discriminatory, non-social group word sets. specifically, valnorm achieves a pearson correlation of r=0.88 for human judgment scores of valence for 399 words collected to establish pleasantness norms in english. in contrast, we measure gender stereotypes using the same set of word embeddings and find that social biases vary across languages. our results indicate that valence associations of non-discriminatory, non-social group words represent widely-shared associations, in seven languages and over 200 years.",,2020-06-06,2021-11-07,"['autumn toney-wails', 'aylin caliskan']"
2006.06870,multi-agent informational learning processes,cs.ma cs.ai cs.lg,"we introduce a new mathematical model of multi-agent reinforcement learning, the multi-agent informational learning processor ""mailp"" model. the model is based on the notion that agents have policies for a certain amount of information, models how this information iteratively evolves and propagates through many agents. this model is very general, and the only meaningful assumption made is that learning for individual agents progressively slows over time.",,2020-06-11,2021-02-25,"['j. k. terry', 'nathaniel grammel']"
2006.07869,benchmarking multi-agent deep reinforcement learning algorithms in   cooperative tasks,cs.lg cs.ai cs.ma stat.ml,"multi-agent deep reinforcement learning (marl) suffers from a lack of commonly-used evaluation tasks and criteria, making comparisons between approaches difficult. in this work, we provide a systematic evaluation and comparison of three different classes of marl algorithms (independent learning, centralised multi-agent policy gradient, value decomposition) in a diverse range of cooperative multi-agent learning tasks. our experiments serve as a reference for the expected performance of algorithms across different learning tasks, and we provide insights regarding the effectiveness of different learning approaches. we open-source epymarl, which extends the pymarl codebase to include additional algorithms and allow for flexible configuration of algorithm implementation details such as parameter sharing. finally, we open-source two environments for multi-agent research which focus on coordination under sparse rewards.",,2020-06-14,2021-11-09,"['georgios papoudakis', 'filippos christianos', 'lukas schäfer', 'stefano v. albrecht']"
2006.08170,metacure: meta reinforcement learning with empowerment-driven   exploration,cs.ai cs.lg,"meta reinforcement learning (meta-rl) extracts knowledge from previous tasks and achieves fast adaptation to new tasks. despite recent progress, efficient exploration in meta-rl remains a key challenge in sparse-reward tasks, as it requires quickly finding informative task-relevant experiences in both meta-training and adaptation. to address this challenge, we explicitly model an exploration policy learning problem for meta-rl, which is separated from exploitation policy learning, and introduce a novel empowerment-driven exploration objective, which aims to maximize information gain for task identification. we derive a corresponding intrinsic reward and develop a new off-policy meta-rl framework, which efficiently learns separate context-aware exploration and exploitation policies by sharing the knowledge of task inference. experimental evaluation shows that our meta-rl method significantly outperforms state-of-the-art baselines on various sparse-reward mujoco locomotion tasks and more complex sparse-reward meta-world tasks.",,2020-06-15,2021-11-11,"['jin zhang', 'jianhao wang', 'hao hu', 'tong chen', 'yingfeng chen', 'changjie fan', 'chongjie zhang']"
2006.10424,an investigation of the weight space to monitor the training progress of   neural networks,cs.lg cs.ai stat.ml,"safe use of deep neural networks (dnns) requires careful testing. however, deployed models are often trained further to improve in performance. as rigorous testing and evaluation is expensive, triggers are in need to determine the degree of change of a model. in this paper we investigate the weight space of dnn models for structure that can be exploited to that end. our results show that dnn models evolve on unique, smooth trajectories in weight space which can be used to track dnn training progress. we hypothesize that curvature and smoothness of the trajectories as well as step length along it may contain information on the state of training as well as potential domain shifts. we show that the model trajectories can be separated and the order of checkpoints on the trajectories recovered, which may serve as a first step towards dnn model versioning.",,2020-06-18,2021-03-17,"['konstantin schürholt', 'damian borth']"
2006.10916,probabilistic fair clustering,cs.lg cs.ai cs.ds stat.ml,"in clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some objective function. in fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the features of a valid clustering might also include the representation of colors in that clustering. prior work in fair clustering assumes complete knowledge of group membership. in this paper, we generalize prior work by assuming imperfect knowledge of group membership through probabilistic assignments. we present clustering algorithms in this more general setting with approximation ratio guarantees. we also address the problem of ""metric membership"", where different groups have a notion of order and distance. experiments are conducted using our proposed algorithms as well as baselines to validate our approach and also surface nuanced concerns when group membership is not known deterministically.",,2020-06-18,2021-11-04,"['seyed a. esmaeili', 'brian brubach', 'leonidas tsepenekas', 'john p. dickerson']"
2006.13365,bringing light into the dark: a large-scale evaluation of knowledge   graph embedding models under a unified framework,cs.lg cs.ai stat.ml,"the heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. in order to assess the reproducibility of previously published results, we re-implemented and evaluated 21 interaction models in the pykeen software package. here, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all as well as provide insight as to why this might be the case.   we then performed a large-scale benchmarking on four datasets with several thousands of experiments and 24,804 gpu hours of computation time. we present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performances, and not only determined by the model architecture. we provide evidence that several architectures can obtain results competitive to the state-of-the-art when configured carefully. we have made all code, experimental configurations, results, and analyses that lead to our interpretations available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking",10.1109/tpami.2021.3124805,2020-06-23,2021-11-01,"['mehdi ali', 'max berrendorf', 'charles tapley hoyt', 'laurent vermue', 'mikhail galkin', 'sahand sharifzadeh', 'asja fischer', 'volker tresp', 'jens lehmann']"
2006.16709,a survey on recent progress in the theory of evolutionary algorithms for   discrete optimization,cs.ne cs.ai,"the theory of evolutionary computation for discrete search spaces has made significant progress in the last ten years. this survey summarizes some of the most important recent results in this research area. it discusses fine-grained models of runtime analysis of evolutionary algorithms, highlights recent theoretical insights on parameter tuning and parameter control, and summarizes the latest advances for stochastic and dynamic problems. we regard how evolutionary algorithms optimize submodular functions and we give an overview over the large body of recent results on estimation of distribution algorithms. finally, we present the state of the art of drift analysis, one of the most powerful analysis technique developed in this field.",10.1145/3472304,2020-06-30,2021-07-08,"['benjamin doerr', 'frank neumann']"
2007.06796,evaluation toolkit for robustness testing of automatic essay scoring   systems,cs.cl cs.ai,"automatic scoring engines have been used for scoring approximately fifteen million test-takers in just the last three years. this number is increasing further due to covid-19 and the associated automation of education and testing. despite such wide usage, the ai-based testing literature of these ""intelligent"" models is highly lacking. most of the papers proposing new models rely only on quadratic weighted kappa (qwk) based agreement with human raters for showing model efficacy. however, this effectively ignores the highly multi-feature nature of essay scoring. essay scoring depends on features like coherence, grammar, relevance, sufficiency and, vocabulary. to date, there has been no study testing automated essay scoring: aes systems holistically on all these features. with this motivation, we propose a model agnostic adversarial evaluation scheme and associated metrics for aes systems to test their natural language understanding capabilities and overall robustness. we evaluate the current state-of-the-art aes models using the proposed scheme and report the results on five recent models. these models range from feature-engineering-based approaches to the latest deep learning algorithms. we find that aes models are highly overstable. even heavy modifications(as much as 25%) with content unrelated to the topic of the questions do not decrease the score produced by the models. on the other hand, irrelevant content, on average, increases the scores, thus showing that the model evaluation strategy and rubrics should be reconsidered. we also ask 200 human raters to score both an original and adversarial response to seeing if humans can detect differences between the two and whether they agree with the scores assigned by auto scores.",,2020-07-13,2021-11-14,"['anubha kabra', 'mehar bhatia', 'yaman kumar', 'junyi jessy li', 'rajiv ratn shah']"
2007.14490,on accuracy and coherence with infinite opinion sets,math.st cs.ai stat.th,"there is a well-known equivalence between avoiding accuracy dominance and having probabilistically coherent credences (see, e.g., de finetti 1974, joyce 2009, predd et al. 2009, schervish et al. 2009, pettigrew 2016). however, this equivalence has been established only when the set of propositions on which credence functions are defined is finite. in this paper, we establish connections between accuracy dominance and coherence when credence functions are defined on an infinite set of propositions. in particular, we establish the necessary results to extend the classic accuracy argument for probabilism originally due to joyce (1998) to certain classes of infinite sets of propositions including countably infinite partitions.",,2020-07-28,2021-11-07,['mikayla kelley']
2008.01976,robust deep reinforcement learning through adversarial loss,cs.lg cs.ai cs.cr stat.ml,"recent studies have shown that deep reinforcement learning agents are vulnerable to small adversarial perturbations on the agent's inputs, which raises concerns about deploying such agents in the real world. to address this issue, we propose radial-rl, a principled framework to train reinforcement learning agents with improved robustness against $l_p$-norm bounded adversarial attacks. our framework is compatible with popular deep reinforcement learning algorithms and we demonstrate its performance with deep q-learning, a3c and ppo. we experiment on three deep rl benchmarks (atari, mujoco and procgen) to show the effectiveness of our robust training algorithm. our radial-rl agents consistently outperform prior methods when tested against attacks of varying strength and are more computationally efficient to train. in addition, we propose a new evaluation method called greedy worst-case reward (gwc) to measure attack agnostic robustness of deep rl agents. we show that gwc can be evaluated efficiently and is a good estimate of the reward under the worst possible sequence of adversarial attacks. all code used for our experiments is available at https://github.com/tuomaso/radial_rl_v2.",,2020-08-05,2021-11-10,"['tuomas oikarinen', 'wang zhang', 'alexandre megretski', 'luca daniel', 'tsui-wei weng']"
2008.02066,follow the object: curriculum learning for manipulation tasks with   imagined goals,cs.lg cs.ai cs.ro stat.ml,"learning robot manipulation through deep reinforcement learning in environments with sparse rewards is a challenging task. in this paper we address this problem by introducing a notion of imaginary object goals. for a given manipulation task, the object of interest is first trained to reach a desired target position on its own, without being manipulated, through physically realistic simulations. the object policy is then leveraged to build a predictive model of plausible object trajectories providing the robot with a curriculum of incrementally more difficult object goals to reach during training. the proposed algorithm, follow the object (fo), has been evaluated on 7 mujoco environments requiring increasing degree of exploration, and has achieved higher success rates compared to alternative algorithms. in particularly challenging learning scenarios, e.g. where the object's initial and target positions are far apart, our approach can still learn a policy whereas competing methods currently fail.",,2020-08-05,2021-11-11,"['ozsel kilinc', 'giovanni montana']"
2008.02577,a critical analysis of metrics used for measuring progress in artificial   intelligence,cs.ai cs.lg,"comparing model performances on benchmark datasets is an integral part of measuring and driving progress in artificial intelligence. a model's performance on a benchmark dataset is commonly assessed based on a single or a small set of performance metrics. while this enables quick comparisons, it may entail the risk of inadequately reflecting model performance if the metric does not sufficiently cover all performance characteristics. it is unknown to what extent this might impact benchmarking efforts.   to address this question, we analysed the current landscape of performance metrics based on data covering 3867 machine learning model performance results from the open repository 'papers with code'. our results suggest that the large majority of metrics currently used have properties that may result in an inadequate reflection of a models' performance. while alternative metrics that address problematic properties have been proposed, they are currently rarely used.   furthermore, we describe ambiguities in reported metrics, which may lead to difficulties in interpreting and comparing model performances.",,2020-08-06,2021-11-08,"['kathrin blagec', 'georg dorffner', 'milad moradi', 'matthias samwald']"
2008.02790,decoupling exploration and exploitation for meta-reinforcement learning   without sacrifices,cs.lg cs.ai stat.ml,"the goal of meta-reinforcement learning (meta-rl) is to build agents that can quickly learn new tasks by leveraging prior experience on related tasks. learning a new task often requires both exploring to gather task-relevant information and exploiting this information to solve the task. in principle, optimal exploration and exploitation can be learned end-to-end by simply maximizing task performance. however, such meta-rl approaches struggle with local optima due to a chicken-and-egg problem: learning to explore requires good exploitation to gauge the exploration's utility, but learning to exploit requires information gathered via exploration. optimizing separate objectives for exploration and exploitation can avoid this problem, but prior meta-rl exploration objectives yield suboptimal policies that gather information irrelevant to the task. we alleviate both concerns by constructing an exploitation objective that automatically identifies task-relevant information and an exploration objective to recover only this information. this avoids local optima in end-to-end training, without sacrificing optimal exploration. empirically, dream substantially outperforms existing approaches on complex meta-rl problems, such as sparse-reward 3d visual navigation. videos of dream: https://ezliu.github.io/dream/",,2020-08-06,2021-11-11,"['evan zheran liu', 'aditi raghunathan', 'percy liang', 'chelsea finn']"
2008.04213,boosting ant colony optimization via solution prediction and machine   learning,cs.ne cs.ai cs.lg,"this paper introduces an enhanced meta-heuristic (ml-aco) that combines machine learning (ml) and ant colony optimization (aco) to solve combinatorial optimization problems. to illustrate the underlying mechanism of our ml-aco algorithm, we start by describing a test problem, the orienteering problem. in this problem, the objective is to find a route that visits a subset of vertices in a graph within a time budget to maximize the collected score. in the first phase of our ml-aco algorithm, an ml model is trained using a set of small problem instances where the optimal solution is known. specifically, classification models are used to classify an edge as being part of the optimal route, or not, using problem-specific features and statistical measures. the trained model is then used to predict the probability that an edge in the graph of a test problem instance belongs to the corresponding optimal route. in the second phase, we incorporate the predicted probabilities into the aco component of our algorithm, i.e., using the probability values as heuristic weights or to warm start the pheromone matrix. here, the probability values bias sampling towards favoring those predicted high-quality edges when constructing feasible routes. we have tested multiple classification models including graph neural networks, logistic regression and support vector machines, and the experimental results show that our solution prediction approach consistently boosts the performance of aco. further, we empirically show that our ml model trained on small synthetic instances generalizes well to large synthetic and real-world instances. our approach integrating ml with a meta-heuristic is generic and can be applied to a wide range of optimization problems.",,2020-07-29,2021-11-07,"['yuan sun', 'sheng wang', 'yunzhuang shen', 'xiaodong li', 'andreas t. ernst', 'michael kirley']"
2008.06595,decision-making at unsignalized intersection for autonomous vehicles:   left-turn maneuver with deep reinforcement learning,cs.ai cs.lg,"decision-making module enables autonomous vehicles to reach appropriate maneuvers in the complex urban environments, especially the intersection situations. this work proposes a deep reinforcement learning (drl) based left-turn decision-making framework at unsignalized intersection for autonomous vehicles. the objective of the studied automated vehicle is to make an efficient and safe left-turn maneuver at a four-way unsignalized intersection. the exploited drl methods include deep q-learning (dql) and double dql. simulation results indicate that the presented decision-making strategy could efficaciously reduce the collision rate and improve transport efficiency. this work also reveals that the constructed left-turn control structure has a great potential to be applied in real-time.",,2020-08-14,2021-11-12,"['teng liu', 'xingyu mu', 'bing huang', 'xiaolin tang', 'fuqing zhao', 'xiao wang', 'dongpu cao']"
2008.06692,how to build your own asp-based system?!,cs.ai cs.pl,"answer set programming (asp) has become a popular and quite sophisticated approach to declarative problem solving. this is arguably due to its attractive modeling-grounding-solving workflow that provides an easy approach to problem solving, even for laypersons outside computer science. unlike this, the high degree of sophistication of the underlying technology makes it increasingly hard for asp experts to put ideas into practice.   for addressing this issue, this tutorial aims at enabling users to build their own asp-based systems. more precisely, we show how the asp system clingo can be used for extending asp and for implementing customized special-purpose systems. to this end, we propose two alternatives. we begin with a traditional ai technique and show how meta programming can be used for extending asp. this is a rather light approach that relies on clingo's reification feature to use asp itself for expressing new functionalities. unlike this, the major part of this tutorial uses traditional programming (in python) for manipulating clingo via its application programming interface. this approach allows for changing and controlling the entire model-ground-solve workflow of asp. central to this is clingo's new application class that allows us to draw on clingo's infrastructure by customizing processes similar to the one in clingo. for instance, we may engage manipulations to programs' abstract syntax trees, control various forms of multi-shot solving, and set up theory propagators for foreign inferences. another cross-sectional structure, spanning meta as well as application programming, is clingo's intermediate format, aspif, that specifies the interface among the underlying grounder and solver. we illustrate the aforementioned concepts and techniques throughout this tutorial by means of examples and several non-trivial case-studies.",,2020-08-15,2021-11-05,"['roland kaminski', 'javier romero', 'torsten schaub', 'philipp wanko']"
2008.06727,a review on drivers red light running behaviour predictions and   technology based countermeasures,cs.ai cs.cy cs.ne,"red light running at signalised intersections is a growing road safety issue worldwide, leading to the rapid development of advanced intelligent transportation technologies and countermeasures. however, existing studies have yet to summarise and present the effect of these technology-based innovations in improving safety. this paper represents a comprehensive review of red-light running behaviour prediction methodologies and technology-based countermeasures. specifically, the major focus of this study is to provide a comprehensive review on two streams of literature targeting red-light running and stop-and-go behaviour at signalised intersection (1) studies focusing on modelling and predicting the red-light running and stop-and-go related driver behaviour and (2) studies focusing on the effectiveness of different technology-based countermeasures which combat such unsafe behaviour. the study provides a systematic guide to assist researchers and stakeholders in understanding how to best identify red-light running and stop-and-go associated driving behaviour and subsequently implement countermeasures to combat such risky behaviour and improve the associated safety.",,2020-08-15,2021-11-04,"['md mostafizur rahman komol', 'mohammed elhenawy', 'shamsunnahar yasmin', 'mahmoud masoud', 'sebastien glaser', 'andry rakotonirainy']"
2008.08932,supersuit: simple microwrappers for reinforcement learning environments,cs.lg cs.ai,"in reinforcement learning, wrappers are universally used to transform the information that passes between a model and an environment. despite their ubiquity, no library exists with reasonable implementations of all popular preprocessing methods. this leads to unnecessary bugs, code inefficiencies, and wasted developer time. accordingly we introduce supersuit, a python library that includes all popular wrappers, and wrappers that can easily apply lambda functions to the observations/actions/reward. it's compatible with the standard gym environment specification, as well as the pettingzoo specification for multi-agent environments. the library is available at https://github.com/pettingzoo-team/supersuit,and can be installed via pip.",,2020-08-16,,"['j. k. terry', 'benjamin black', 'ananth hari']"
2009.04521,how good is your explanation? algorithmic stability measures to assess   the quality of explanations for deep neural networks,cs.lg cs.ai,"a plethora of methods have been proposed to explain how deep neural networks reach their decisions but comparatively, little effort has been made to ensure that the explanations produced by these methods are objectively relevant. while several desirable properties for trustworthy explanations have been formulated, objective measures have been harder to derive. here, we propose two new measures to evaluate explanations borrowed from the field of algorithmic stability: mean generalizability mege and relative consistency reco. we conduct extensive experiments on different network architectures, common explainability methods, and several image datasets to demonstrate the benefits of the proposed measures.in comparison to ours, popular fidelity measures are not sufficient to guarantee trustworthy explanations.finally, we found that 1-lipschitz networks produce explanations with higher mege and reco than common neural networks while reaching similar accuracy. this suggests that 1-lipschitz networks are a relevant direction towards predictors that are more explainable and trustworthy.",,2020-09-07,2021-11-09,"['thomas fel', 'david vigouroux', 'rémi cadène', 'thomas serre']"
2009.04547,optimal inspection and maintenance planning for deteriorating structures   through dynamic bayesian networks and markov decision processes,cs.ai cs.sy eess.sy stat.ap,"civil and maritime engineering systems, among others, from bridges to offshore platforms and wind turbines, must be efficiently managed as they are exposed to deterioration mechanisms throughout their operational life, such as fatigue or corrosion. identifying optimal inspection and maintenance policies demands the solution of a complex sequential decision-making problem under uncertainty, with the main objective of efficiently controlling the risk associated with structural failures. addressing this complexity, risk-based inspection planning methodologies, supported often by dynamic bayesian networks, evaluate a set of pre-defined heuristic decision rules to reasonably simplify the decision problem. however, the resulting policies may be compromised by the limited space considered in the definition of the decision rules. avoiding this limitation, partially observable markov decision processes (pomdps) provide a principled mathematical methodology for stochastic optimal control under uncertain action outcomes and observations, in which the optimal actions are prescribed as a function of the entire, dynamically updated, state probability distribution. in this paper, we combine dynamic bayesian networks with pomdps in a joint framework for optimal inspection and maintenance planning, and we provide the formulation for developing both infinite and finite horizon pomdps in a structural reliability context. the proposed methodology is implemented and tested for the case of a structural component subject to fatigue deterioration, demonstrating the capability of state-of-the-art point-based pomdp solvers for solving the underlying planning optimization problem. within the numerical experiments, pomdp and heuristic-based policies are thoroughly compared, and results showcase that pomdps achieve substantially lower costs as compared to their counterparts, even for traditional problem settings.",10.1016/j.strusafe.2021.102140,2020-09-09,,"['p. g. morato', 'k. g. papakonstantinou', 'c. p. andriotis', 'j. s. nielsen', 'p. rigo']"
2009.05283,fair and accurate age prediction using distribution aware data curation   and augmentation,cs.cv cs.ai cs.lg,"deep learning-based facial recognition systems have experienced increased media attention due to exhibiting unfair behavior. large enterprises, such as ibm, shut down their facial recognition and age prediction systems as a consequence. age prediction is an especially difficult application with the issue of fairness remaining an open research problem (e.g., predicting age for different ethnicity equally accurate). one of the main causes of unfair behavior in age prediction methods lies in the distribution and diversity of the training data. in this work, we present two novel approaches for dataset curation and data augmentation in order to increase fairness through balanced feature curation and increase diversity through distribution aware augmentation. to achieve this, we introduce out-of-distribution detection to the facial recognition domain which is used to select the data most relevant to the deep neural network's (dnn) task when balancing the data among age, ethnicity, and gender. our approach shows promising results. our best-trained dnn model outperformed all academic and industrial baselines in terms of fairness by up to 4.92 times and also enhanced the dnn's ability to generalize outperforming amazon aws and microsoft azure public cloud systems by 31.88% and 10.95%, respectively.",,2020-09-11,2021-11-16,"['yushi cao', 'david berend', 'palina tolmach', 'guy amit', 'moshe levy', 'yang liu', 'asaf shabtai', 'yuval elovici']"
2009.05487,the intriguing relation between counterfactual explanations and   adversarial examples,cs.ai cs.lg,"the same method that creates adversarial examples (aes) to fool image-classifiers can be used to generate counterfactual explanations (ces) that explain algorithmic decisions. this observation has led researchers to consider ces as aes by another name. we argue that the relationship to the true label and the tolerance with respect to proximity are two properties that formally distinguish ces and aes. based on these arguments, we introduce ces, aes, and related concepts mathematically in a common framework. furthermore, we show connections between current methods for generating ces and aes, and estimate that the fields will merge more and more as the number of common use-cases grows.",10.1007/s11023-021-09580-9,2020-09-11,2021-08-26,['timo freiesleben']
2009.06429,into the unknown: active monitoring of neural networks,cs.lg cs.ai cs.lo,"neural-network classifiers achieve high accuracy when predicting the class of an input that they were trained to identify. maintaining this accuracy in dynamic environments, where inputs frequently fall outside the fixed set of initially known classes, remains a challenge. the typical approach is to detect inputs from novel classes and retrain the classifier on an augmented dataset. however, not only the classifier but also the detection mechanism needs to adapt in order to distinguish between newly learned and yet unknown input classes. to address this challenge, we introduce an algorithmic framework for active monitoring of a neural network. a monitor wrapped in our framework operates in parallel with the neural network and interacts with a human user via a series of interpretable labeling queries for incremental adaptation. in addition, we propose an adaptive quantitative monitor to improve precision. an experimental evaluation on a diverse set of benchmarks with varying numbers of classes confirms the benefits of our active monitoring framework in dynamic scenarios.",10.1007/978-3-030-88494-9_3,2020-09-14,2021-11-12,"['anna lukina', 'christian schilling', 'thomas a. henzinger']"
2009.09341,multiplayer support for the arcade learning environment,cs.lg cs.ai,"the arcade learning environment (""ale"") is a widely used library in the reinforcement learning community that allows easy programmatic interfacing with atari 2600 games, via the stella emulator. we introduce a publicly available extension to the ale that extends its support to multiplayer games and game modes. this interface is additionally integrated with pettingzoo to allow for a simple gym-like interface in python to interact with these games. we additionally introduce experimental baselines for all environments included.",,2020-09-19,2021-01-17,"['j. k. terry', 'benjamin black', 'luis santos']"
2009.11459,robust finite-state controllers for uncertain pomdps,cs.ai cs.lg cs.ro cs.sy eess.sy math.oc,"uncertain partially observable markov decision processes (upomdps) allow the probabilistic transition and observation functions of standard pomdps to belong to a so-called uncertainty set. such uncertainty, referred to as epistemic uncertainty, captures uncountable sets of probability distributions caused by, for instance, a lack of data available. we develop an algorithm to compute finite-memory policies for upomdps that robustly satisfy specifications against any admissible distribution. in general, computing such policies is theoretically and practically intractable. we provide an efficient solution to this problem in four steps. (1) we state the underlying problem as a nonconvex optimization problem with infinitely many constraints. (2) a dedicated dualization scheme yields a dual problem that is still nonconvex but has finitely many constraints. (3) we linearize this dual problem and (4) solve the resulting finite linear program to obtain locally optimal solutions to the original problem. the resulting problem formulation is exponentially smaller than those resulting from existing methods. we demonstrate the applicability of our algorithm using large instances of an aircraft collision-avoidance scenario and a novel spacecraft motion planning case study.",,2020-09-23,2021-03-04,"['murat cubuktepe', 'nils jansen', 'sebastian junges', 'ahmadreza marandi', 'marnix suilen', 'ufuk topcu']"
2009.13051,agent environment cycle games,cs.lg cs.ai cs.gt cs.ma stat.ml,"partially observable stochastic games (posgs) are the most general and common model of games used in multi-agent reinforcement learning (marl). we argue that the posg model is conceptually ill suited to software marl environments, and offer case studies from the literature where this mismatch has led to severely unexpected behavior. in response to this, we introduce the agent environment cycle games (aec games) model, which is more representative of software implementation. we then prove it's as an equivalent model to posgs. the aec games model is also uniquely useful in that it can elegantly represent both all forms of marl environments, whereas for example posgs cannot elegantly represent strictly turn based games like chess.",,2020-09-28,2021-05-01,"['justin k terry', 'nathaniel grammel', 'benjamin black', 'ananth hari', 'caroline horsch', 'luis santos']"
2009.13251,deep learning for predictive business process monitoring: review and   benchmark,cs.lg cs.ai,"predictive monitoring of business processes is concerned with the prediction of ongoing cases on a business process. lately, the popularity of deep learning techniques has propitiated an ever-growing set of approaches focused on predictive monitoring based on these techniques. however, the high disparity of process logs and experimental setups used to evaluate these approaches makes it especially difficult to make a fair comparison. furthermore, it also difficults the selection of the most suitable approach to solve a specific problem. in this paper, we provide both a systematic literature review of approaches that use deep learning to tackle the predictive monitoring tasks. in addition, we performed an exhaustive experimental evaluation of 10 different approaches over 12 publicly available process logs.",,2020-09-24,2021-10-29,"['efrén rama-maneiro', 'juan c. vidal', 'manuel lama']"
2010.01729,revisiting batch normalization for training low-latency deep spiking   neural networks from scratch,cs.cv cs.ai cs.ne,"spiking neural networks (snns) have recently emerged as an alternative to deep learning owing to sparse, asynchronous and binary event (or spike) driven processing, that can yield huge energy efficiency benefits on neuromorphic hardware. however, training high-accuracy and low-latency snns from scratch suffers from non-differentiable nature of a spiking neuron. to address this training issue in snns, we revisit batch normalization and propose a temporal batch normalization through time (bntt) technique. most prior snn works till now have disregarded batch normalization deeming it ineffective for training temporal snns. different from previous works, our proposed bntt decouples the parameters in a bntt layer along the time axis to capture the temporal dynamics of spikes. the temporally evolving learnable parameters in bntt allow a neuron to control its spike rate through different time-steps, enabling low-latency and low-energy training from scratch. we conduct experiments on cifar-10, cifar-100, tiny-imagenet and event-driven dvs-cifar10 datasets. bntt allows us to train deep snn architectures from scratch, for the first time, on complex datasets with just few 25-30 time-steps. we also propose an early exit algorithm using the distribution of parameters in bntt to reduce the latency at inference, that further improves the energy-efficiency.",,2020-10-04,2021-11-10,"['youngeun kim', 'priyadarshini panda']"
2010.01748,policy learning using weak supervision,cs.lg cs.ai stat.ml,"most existing policy learning solutions require the learning agents to receive high-quality supervision signals such as well-designed rewards in reinforcement learning (rl) or high-quality expert demonstrations in behavioral cloning (bc). these quality supervisions are usually infeasible or prohibitively expensive to obtain in practice. we aim for a unified framework that leverages the available cheap weak supervisions to perform policy learning efficiently. to handle this problem, we treat the ""weak supervision"" as imperfect information coming from a peer agent, and evaluate the learning agent's policy based on a ""correlated agreement"" with the peer agent's policy (instead of simple agreements). our approach explicitly punishes a policy for overfitting to the weak supervision. in addition to theoretical guarantees, extensive evaluations on tasks including rl with noisy rewards, bc with weak demonstrations, and standard policy co-training show that our method leads to substantial performance improvements, especially when the complexity or the noise of the learning environments is high.",,2020-10-04,2021-11-02,"['jingkang wang', 'hongyi guo', 'zhaowei zhu', 'yang liu']"
2010.01909,"deliberative acting, online planning and learning with hierarchical   operational models",cs.ai,"in ai research, synthesizing a plan of action has typically used descriptive models of the actions that abstractly specify what might happen as a result of an action, and are tailored for efficiently computing state transitions. however, executing the planned actions has needed operational models, in which rich computational control structures and closed-loop online decision-making are used to specify how to perform an action in a nondeterministic execution context, react to events and adapt to an unfolding situation. deliberative actors, which integrate acting and planning, have typically needed to use both of these models together -- which causes problems when attempting to develop the different models, verify their consistency, and smoothly interleave acting and planning.   as an alternative, we define and implement an integrated acting and planning system in which both planning and acting use the same operational models. these rely on hierarchical task-oriented refinement methods offering rich control structures. the acting component, called reactive acting engine (rae), is inspired by the well-known prs system. at each decision step, rae can get advice from a planner for a near-optimal choice with respect to a utility function. the anytime planner uses a uct-like monte carlo tree search procedure, called upom, whose rollouts are simulations of the actor's operational models. we also present learning strategies for use with rae and upom that acquire, from online acting experiences and/or simulated planning results, a mapping from decision contexts to method instances as well as a heuristic function to guide upom. we demonstrate the asymptotic convergence of upom towards optimal methods in static domains, and show experimentally that upom and the learning strategies significantly improve the acting efficiency and robustness.",10.1016/j.artint.2021.103523,2020-10-02,2021-11-15,"['sunandita patra', 'james mason', 'malik ghallab', 'dana nau', 'paolo traverso']"
2010.03597,bayesian optimized monte carlo planning,cs.ai,"online solvers for partially observable markov decision processes have difficulty scaling to problems with large action spaces. monte carlo tree search with progressive widening attempts to improve scaling by sampling from the action space to construct a policy search tree. the performance of progressive widening search is dependent upon the action sampling policy, often requiring problem-specific samplers. in this work, we present a general method for efficient action sampling based on bayesian optimization. the proposed method uses a gaussian process to model a belief over the action-value function and selects the action that will maximize the expected improvement in the optimal action value. we implement the proposed approach in a new online tree search algorithm called bayesian optimized monte carlo planning (bomcp). several experiments show that bomcp is better able to scale to large action space pomdps than existing state-of-the-art tree search solvers.",,2020-10-07,,"['john mern', 'anil yildiz', 'zachary sunberg', 'tapan mukerji', 'mykel j. kochenderfer']"
2010.03599,improved pomdp tree search planning with prioritized action branching,cs.lg cs.ai,online solvers for partially observable markov decision processes have difficulty scaling to problems with large action spaces. this paper proposes a method called pa-pomcpow to sample a subset of the action space that provides varying mixtures of exploitation and exploration for inclusion in a search tree. the proposed method first evaluates the action space according to a score function that is a linear combination of expected reward and expected information gain. the actions with the highest score are then added to the search tree during tree expansion. experiments show that pa-pomcpow is able to outperform existing state-of-the-art solvers on problems with large discrete action spaces.,,2020-10-07,,"['john mern', 'anil yildiz', 'larry bush', 'tapan mukerji', 'mykel j. kochenderfer']"
2010.04456,augmenting physical models with deep networks for complex dynamics   forecasting,stat.ml cs.ai cs.cv cs.lg,"forecasting complex dynamical phenomena in settings where only partial knowledge of their dynamics is available is a prevalent problem across various scientific fields. while purely data-driven approaches are arguably insufficient in this context, standard physical modeling based approaches tend to be over-simplistic, inducing non-negligible errors. in this work, we introduce the aphynity framework, a principled approach for augmenting incomplete physical dynamics described by differential equations with deep data-driven models. it consists in decomposing the dynamics into two components: a physical component accounting for the dynamics for which we have some prior knowledge, and a data-driven component accounting for errors of the physical model. the learning problem is carefully formulated such that the physical model explains as much of the data as possible, while the data-driven component only describes information that cannot be captured by the physical model, no more, no less. this not only provides the existence and uniqueness for this decomposition, but also ensures interpretability and benefits generalization. experiments made on three important use cases, each representative of a different family of phenomena, i.e. reaction-diffusion equations, wave equations and the non-linear damped pendulum, show that aphynity can efficiently leverage approximate physical models to accurately forecast the evolution of the system and correctly identify relevant physical parameters. code is available at https://github.com/yuan-yin/aphynity .",,2020-10-09,2021-11-14,"['yuan yin', 'vincent le guen', 'jérémie dona', 'emmanuel de bézenac', 'ibrahim ayed', 'nicolas thome', 'patrick gallinari']"
2010.05649,multivariate time series classification with hierarchical variational   graph pooling,cs.lg cs.ai,"with the advancement of sensing technology, multivariate time series classification (mtsc) has recently received considerable attention. existing deep learning-based mtsc techniques, which mostly rely on convolutional or recurrent neural networks, are primarily concerned with the temporal dependency of single time series. as a result, they struggle to express pairwise dependencies among multivariate variables directly. furthermore, current spatial-temporal modeling (e.g., graph classification) methodologies based on graph neural networks (gnns) are inherently flat and cannot aggregate hub data in a hierarchical manner. to address these limitations, we propose a novel graph pooling-based framework mtpool to obtain the expressive global representation of mts. we first convert mts slices to graphs by utilizing interactions of variables via graph structure learning module and attain the spatial-temporal graph node features via temporal convolutional module. to get global graph-level representation, we design an ""encoder-decoder"" based variational graph pooling module for creating adaptive centroids for cluster assignments. then we combine gnns and our proposed variational graph pooling layers for joint graph representation learning and graph coarsening, after which the graph is progressively coarsened to one node. at last, a differentiable classifier takes this coarsened representation to get the final predicted class. experiments on ten benchmark datasets exhibit mtpool outperforms state-of-the-art strategies in the mtsc task.",,2020-10-12,2021-11-05,"['ziheng duan', 'haoyan xu', 'yueyang wang', 'yida huang', 'anni ren', 'zhongbin xu', 'yizhou sun', 'wei wang']"
2010.05769,parameterized reinforcement learning for optical system optimization,cs.lg cs.ai physics.optics,"designing a multi-layer optical system with designated optical characteristics is an inverse design problem in which the resulting design is determined by several discrete and continuous parameters. in particular, we consider three design parameters to describe a multi-layer stack: each layer's dielectric material and thickness as well as the total number of layers. such a combination of both, discrete and continuous parameters is a challenging optimization problem that often requires a computationally expensive search for an optimal system design. hence, most methods merely determine the optimal thicknesses of the system's layers. to incorporate layer material and the total number of layers as well, we propose a method that considers the stacking of consecutive layers as parameterized actions in a markov decision process. we propose an exponentially transformed reward signal that eases policy optimization and adapt a recent variant of q-learning for inverse design optimization. we demonstrate that our method outperforms human experts and a naive reinforcement learning algorithm concerning the achieved optical characteristics. moreover, the learned q-values contain information about the optical properties of multi-layer optical systems, thereby allowing physical interpretation or what-if analysis.",10.1088/1361-6463/abfddb,2020-10-09,2020-11-25,"['heribert wankerl', 'maike l. stern', 'ali mahdavi', 'christoph eichler', 'elmar w. lang']"
2010.06797,reinforcement learning based temporal logic control with maximum   probabilistic satisfaction,cs.fl cs.ai cs.ro math.oc,"this paper presents a model-free reinforcement learning (rl) algorithm to synthesize a control policy that maximizes the satisfaction probability of linear temporal logic (ltl) specifications. due to the consideration of environment and motion uncertainties, we model the robot motion as a probabilistic labeled markov decision process with unknown transition probabilities and unknown probabilistic label functions. the ltl task specification is converted to a limit deterministic generalized b\""uchi automaton (ldgba) with several accepting sets to maintain dense rewards during learning. the novelty of applying ldgba is to construct an embedded ldgba (e-ldgba) by designing a synchronous tracking-frontier function, which enables the record of non-visited accepting sets without increasing dimensional and computational complexity. with appropriate dependent reward and discount functions, rigorous analysis shows that any method that optimizes the expected discount return of the rl-based approach is guaranteed to find the optimal policy that maximizes the satisfaction probability of the ltl specifications. a model-free rl-based motion planning strategy is developed to generate the optimal policy in this paper. the effectiveness of the rl-based control synthesis is demonstrated via simulation and experimental results.",,2020-10-13,2021-10-05,"['mingyu cai', 'shaoping xiao', 'baoluo li', 'zhiliang li', 'zhen kan']"
2010.10041,looking for clues of language in multilingual bert to improve   cross-lingual generalization,cs.cl cs.ai,"token embeddings in multilingual bert (m-bert) contain both language and semantic information. we find that the representation of a language can be obtained by simply averaging the embeddings of the tokens of the language. given this language representation, we control the output languages of multilingual bert by manipulating the token embeddings, thus achieving unsupervised token translation. we further propose a computationally cheap but effective approach to improve the cross-lingual ability of m-bert based on this observation.",,2020-10-20,2021-11-01,"['chi-liang liu', 'tsung-yuan hsu', 'yung-sung chuang', 'chung-yi li', 'hung-yi lee']"
2010.11003,unsupervised multiple choices question answering: start learning from   basic knowledge,cs.cl cs.ai,"in this paper, we study the possibility of almost unsupervised multiple choices question answering (mcqa). starting from very basic knowledge, mcqa model knows that some choices have higher probabilities of being correct than the others. the information, though very noisy, guides the training of an mcqa model. the proposed method is shown to outperform the baseline approaches on race and even comparable with some supervised learning approaches on mc500.",,2020-10-21,2021-11-01,"['chi-liang liu', 'hung-yi lee']"
2010.11413,predicting human decision making in psychological tasks with recurrent   neural networks,cs.lg cs.ai q-bio.nc,"unlike traditional time series, the action sequences of human decision making usually involve many cognitive processes such as beliefs, desires, intentions and theory of mind, i.e. what others are thinking. this makes predicting human decision making challenging to be treated agnostically to the underlying psychological mechanisms. we propose to use a recurrent neural network architecture based on long short-term memory networks (lstm) to predict the time series of the actions taken by the human subjects at each step of their decision making, the first application of such methods in this research domain. in this study, we collate the human data from 8 published literature of the iterated prisoner's dilemma comprising 168,386 individual decisions and postprocess them into 8,257 behavioral trajectories of 9 actions each for both players. similarly, we collate 617 trajectories of 95 actions from 10 different published studies of iowa gambling task experiments with healthy human subjects. we train our prediction networks on the behavioral data from these published psychological experiments of human decision making, and demonstrate a clear advantage over the state-of-the-art methods in predicting human decision making trajectories in both single-agent scenarios such as the iowa gambling task and multi-agent scenarios such as the iterated prisoner's dilemma. in the prediction, we observe that the weights of the top performers tends to have a wider distribution, and a bigger bias in the lstm networks, which suggests possible interpretations for the distribution of strategies adopted by each group.",,2020-10-21,2021-11-12,"['baihan lin', 'djallel bouneffouf', 'guillermo cecchi']"
2010.14685,parameterized neural ordinary differential equations: applications to   computational physics problems,physics.comp-ph cs.ai,"this work proposes an extension of neural ordinary differential equations (nodes) by introducing an additional set of ode input parameters to nodes. this extension allows nodes to learn multiple dynamics specified by the input parameter instances. our extension is inspired by the concept of parameterized ordinary differential equations, which are widely investigated in computational science and engineering contexts, where characteristics of the governing equations vary over the input parameters. we apply the proposed parameterized nodes (pnodes) for learning latent dynamics of complex dynamical processes that arise in computational physics, which is an essential component for enabling rapid numerical simulations for time-critical physics applications. for this, we propose an encoder-decoder-type framework, which models latent dynamics as pnodes. we demonstrate the effectiveness of pnodes with important benchmark problems from computational physics.",10.1098/rspa.2021.0162,2020-10-27,,"['kookjin lee', 'eric j. parish']"
2010.14746,continuous lyapunov controller and chaotic non-linear system   optimization using deep machine learning,eess.sy cs.ai cs.lg cs.sy,"the introduction of unexpected system disturbances and new system dynamics does not allow guaranteed continuous system stability. in this research we present a novel approach for detecting early failure indicators of non-linear highly chaotic system and accordingly predict the best parameter calibrations to offset such instability using deep machine learning regression model. the approach proposed continuously monitors the system and controller signals. the re-calibration of the system and controller parameters is triggered according to a set of conditions designed to maintain system stability without compromise to the system speed, intended outcome or required processing power. the deep neural model predicts the parameter values that would best counteract the expected system in-stability. to demonstrate the effectiveness of the proposed approach, it is applied to the non-linear complex combination of duffing van der pol oscillators. the approach is also tested under different scenarios the system and controller parameters are initially chosen incorrectly or the system parameters are changed while running or new system dynamics are introduced while running to measure effectiveness and reaction time.",10.5923/j.control.20201002.01,2020-10-28,2021-10-31,"['amr mahmoud', 'youmna ismaeil', 'mohamed zohdy']"
2011.00416,deep learning for text style transfer: a survey,cs.cl cs.ai cs.lg,"text style transfer is an important task in natural language generation, which aims to control certain attributes in the generated text, such as politeness, emotion, humor, and many others. it has a long history in the field of natural language processing, and recently has re-gained significant attention thanks to the promising performance brought by deep neural models. in this paper, we present a systematic survey of the research on neural text style transfer, spanning over 100 representative articles since the first neural text style transfer work in 2017. we discuss the task formulation, existing datasets and subtasks, evaluation, as well as the rich methodologies in the presence of parallel and non-parallel data. we also provide discussions on a variety of important topics regarding the future development of this task. our curated paper list is at https://github.com/zhijing-jin/text_style_transfer_survey",,2020-11-01,2021-11-01,"['di jin', 'zhijing jin', 'zhiting hu', 'olga vechtomova', 'rada mihalcea']"
2011.01681,learning causal semantic representation for out-of-distribution   prediction,stat.ml cs.ai cs.lg,"conventional supervised learning methods, especially deep ones, are found to be sensitive to out-of-distribution (ood) examples, largely because the learned representation mixes the semantic factor with the variation factor due to their domain-specific correlation, while only the semantic factor causes the output. to address the problem, we propose a causal semantic generative model (csg) based on a causal reasoning so that the two factors are modeled separately, and develop methods for ood prediction from a single training domain, which is common and challenging. the methods are based on the causal invariance principle, with a novel design in variational bayes for both efficient learning and easy prediction. theoretically, we prove that under certain conditions, csg can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of ood generalization error and the success of adaptation. empirical study shows improved ood performance over prevailing baselines.",,2020-11-03,2021-11-01,"['chang liu', 'xinwei sun', 'jindong wang', 'haoyue tang', 'tao li', 'tao qin', 'wei chen', 'tie-yan liu']"
2011.04218,automorphic equivalence-aware graph neural network,cs.lg cs.ai,"distinguishing the automorphic equivalence of nodes in a graph plays an essential role in many scientific domains, e.g., computational biologist and social network analysis. however, existing graph neural networks (gnns) fail to capture such an important property. to make gnn aware of automorphic equivalence, we first introduce a localized variant of this concept -- ego-centered automorphic equivalence (ego-ae). then, we design a novel variant of gnn, i.e., grape, that uses learnable ae-aware aggregators to explicitly differentiate the ego-ae of each node's neighbors with the aids of various subgraph templates. while the design of subgraph templates can be hard, we further propose a genetic algorithm to automatically search them from graph data. moreover, we theoretically prove that grape is expressive in terms of generating distinct representations for nodes with different ego-ae features, which fills in a fundamental gap of existing gnn variants. finally, we empirically validate our model on eight real-world graph data, including social network, e-commerce co-purchase network, and citation network, and show that it consistently outperforms existing gnns. the source code is public available at https://github.com/tsinghua-fib-lab/grape.",,2020-11-09,2021-11-08,"['fengli xu', 'quanming yao', 'pan hui', 'yong li']"
2011.06507,reinforcement learning with videos: combining offline observations with   interaction,cs.lg cs.ai cs.cv cs.ro,"reinforcement learning is a powerful framework for robots to acquire skills from experience, but often requires a substantial amount of online data collection. as a result, it is difficult to collect sufficiently diverse experiences that are needed for robots to generalize broadly. videos of humans, on the other hand, are a readily available source of broad and interesting experiences. in this paper, we consider the question: can we perform reinforcement learning directly on experience collected by humans? this problem is particularly difficult, as such videos are not annotated with actions and exhibit substantial visual domain shift relative to the robot's embodiment. to address these challenges, we propose a framework for reinforcement learning with videos (rlv). rlv learns a policy and value function using experience collected by humans in combination with data collected by robots. in our experiments, we find that rlv is able to leverage such videos to learn challenging vision-based skills with less than half as many samples as rl methods that learn from scratch.",,2020-11-12,2021-11-04,"['karl schmeckpeper', 'oleh rybkin', 'kostas daniilidis', 'sergey levine', 'chelsea finn']"
2011.07682,a large-scale database for graph representation learning,cs.lg cs.ai cs.cr cs.cv cs.si,"with the rapid emergence of graph representation learning, the construction of new large-scale datasets is necessary to distinguish model capabilities and accurately assess the strengths and weaknesses of each technique. by carefully analyzing existing graph databases, we identify 3 critical components important for advancing the field of graph representation learning: (1) large graphs, (2) many graphs, and (3) class diversity. to date, no single graph database offers all these desired properties. we introduce malnet, the largest public graph database ever constructed, representing a large-scale ontology of malicious software function call graphs. malnet contains over 1.2 million graphs, averaging over 15k nodes and 35k edges per graph, across a hierarchy of 47 types and 696 families. compared to the popular reddit-12k database, malnet offers 105x more graphs, 39x larger graphs on average, and 63x more classes. we provide a detailed analysis of malnet, discussing its properties and provenance, along with the evaluation of state-of-the-art machine learning and graph neural network techniques. the unprecedented scale and diversity of malnet offers exciting opportunities to advance the frontiers of graph representation learning--enabling new discoveries and research into imbalanced classification, explainability and the impact of class hardness. the database is publicly available at www.mal-net.org.",,2020-11-15,2021-11-06,"['scott freitas', 'yuxiao dong', 'joshua neil', 'duen horng chau']"
2011.08999,"passgoodpool: joint passengers and goods fleet management with   reinforcement learning aided pricing, matching, and route planning",cs.ai cs.sy eess.sy,"the ubiquitous growth of mobility-on-demand services for passenger and goods delivery has brought various challenges and opportunities within the realm of transportation systems. as a result, intelligent transportation systems are being developed to maximize operational profitability, user convenience, and environmental sustainability. the growth of last mile deliveries alongside ridesharing calls for an efficient and cohesive system that transports both passengers and goods. existing methods address this using static routing methods considering neither the demands of requests nor the transfer of goods between vehicles during route planning. in this paper, we present a dynamic and demand aware fleet management framework for combined goods and passenger transportation that is capable of (1) involving both passengers and drivers in the decision-making process by allowing drivers to negotiate to a mutually suitable price, and passengers to accept/reject, (2) matching of goods to vehicles, and the multi-hop transfer of goods, (3) dynamically generating optimal routes for each vehicle considering demand along their paths, based on the insertion cost which then determines the matching, (4) dispatching idle vehicles to areas of anticipated high passenger and goods demand using deep reinforcement learning (rl), (5) allowing for distributed inference at each vehicle while collectively optimizing fleet objectives. our proposed model is deployable independently within each vehicle as this minimizes computational costs associated with the growth of distributed systems and democratizes decision-making to each individual. simulations on a variety of vehicle types, goods, and passenger utility functions show the effectiveness of our approach as compared to other methods that do not consider combined load transportation or dynamic multi-hop route planning.",,2020-11-17,2021-11-11,"['kaushik manchella', 'marina haliem', 'vaneet aggarwal', 'bharat bhargava']"
2011.09719,adversarial examples for $k$-nearest neighbor classifiers based on   higher-order voronoi diagrams,cs.lg cs.ai cs.cr stat.ml,"adversarial examples are a widely studied phenomenon in machine learning models. while most of the attention has been focused on neural networks, other practical models also suffer from this issue. in this work, we propose an algorithm for evaluating the adversarial robustness of $k$-nearest neighbor classification, i.e., finding a minimum-norm adversarial example. diverging from previous proposals, we take a geometric approach by performing a search that expands outwards from a given input point. on a high level, the search radius expands to the nearby voronoi cells until we find a cell that classifies differently from the input point. to scale the algorithm to a large $k$, we introduce approximation steps that find perturbations with smaller norm, compared to the baselines, in a variety of datasets. furthermore, we analyze the structural properties of a dataset where our approach outperforms the competition.",,2020-11-19,2021-11-01,"['chawin sitawarin', 'evgenios m. kornaropoulos', 'dawn song', 'david wagner']"
2011.11201,modular action concept grounding in semantic video prediction,cs.cv cs.ai cs.lg,"recent works in video prediction have mainly focused on passive forecasting and low-level action-conditional prediction, which sidesteps the learning of interaction between agents and objects. we introduce the task of semantic action-conditional video prediction, which uses semantic action labels to describe those interactions and can be regarded as an inverse problem of action recognition. the challenge of this new task primarily lies in how to effectively inform the model of semantic action information. inspired by the idea of mixture of experts, we embody each abstract label by a structured combination of various visual concept learners and propose a novel video prediction model, modular action concept network (mac). our method is evaluated on two newly designed synthetic datasets, clevr-building-blocks and sapien-kitchen, and one real-world dataset called tower-creation. extensive experiments demonstrate that mac can correctly condition on given instructions and generate corresponding future frames without need of bounding boxes. we further show that the trained model can make out-of-distribution generalization, be quickly adapted to new object categories and exploit its learnt features for object detection, showing the progression towards higher-level cognitive abilities.",,2020-11-22,2021-11-02,"['wei yu', 'wenxin chen', 'songhenh yin', 'steve easterbrook', 'animesh garg']"
2011.11311,uncovering the bias in facial expressions,cs.cv cs.ai,"over the past decades the machine and deep learning community has celebrated great achievements in challenging tasks such as image classification. the deep architecture of artificial neural networks together with the plenitude of available data makes it possible to describe highly complex relations. yet, it is still impossible to fully capture what the deep learning model has learned and to verify that it operates fairly and without creating bias, especially in critical tasks, for instance those arising in the medical field. one example for such a task is the detection of distinct facial expressions, called action units, in facial images. considering this specific task, our research aims to provide transparency regarding bias, specifically in relation to gender and skin color. we train a neural network for action unit classification and analyze its performance quantitatively based on its accuracy and qualitatively based on heatmaps. a structured review of our results indicates that we are able to detect bias. even though we cannot conclude from our results that lower classification performance emerged solely from gender and skin color bias, these biases must be addressed, which is why we end by giving suggestions on how the detected bias can be avoided.",,2020-11-23,2021-11-16,"['jessica deuschel', 'bettina finzel', 'ines rieger']"
2012.00190,towards label-agnostic emotion embeddings,cs.cl cs.ai cs.lg,"research in emotion analysis is scattered across different label formats (e.g., polarity types, basic emotion categories, and affective dimensions), linguistic levels (word vs. sentence vs. discourse), and, of course, (few well-resourced but much more under-resourced) natural languages and text genres (e.g., product reviews, tweets, news). the resulting heterogeneity makes data and software developed under these conflicting constraints hard to compare and challenging to integrate. to resolve this unsatisfactory state of affairs we here propose a training scheme that learns a shared latent representation of emotion independent from different label formats, natural languages, and even disparate model architectures. experiments on a wide range of datasets indicate that this approach yields the desired interoperability without penalizing prediction quality. code and data are archived under doi 10.5281/zenodo.5466068.",,2020-11-30,2021-11-06,"['sven buechel', 'luise modersohn', 'udo hahn']"
2012.01608,obstacle avoidance using a monocular camera,cs.ro cs.ai,"a collision avoidance system based on simple digital cameras would help enable the safe integration of small uavs into crowded, low-altitude environments. in this work, we present an obstacle avoidance system for small uavs that uses a monocular camera with a hybrid neural network and path planner controller. the system is comprised of a vision network for estimating depth from camera images, a high-level control network, a collision prediction network, and a contingency policy. this system is evaluated on a simulated uav navigating an obstacle course in a constrained flight pattern. results show the proposed system achieves low collision rates while maintaining operationally relevant flight speeds.",10.2514/6.2021-0269,2020-12-02,2021-01-25,"['kyle hatch', 'john mern', 'mykel kochenderfer']"
2012.01935,backpropagation-free learning method for correlated fuzzy neural   networks,cs.lg cs.ai,"in this paper, a novel stepwise learning approach based on estimating desired premise parts' outputs by solving a constrained optimization problem is proposed. this learning approach does not require backpropagating the output error to learn the premise parts' parameters. instead, the near best output values of the rules premise parts are estimated and their parameters are changed to reduce the error between current premise parts' outputs and the estimated desired ones. therefore, the proposed learning method avoids error backpropagation, which lead to vanishing gradient and consequently getting stuck in a local optimum. the proposed method does not need any initialization method. this learning method is utilized to train a new takagi-sugeno-kang (tsk) fuzzy neural network with correlated fuzzy rules including many parameters in both premise and consequent parts, avoiding getting stuck in a local optimum due to vanishing gradient. to learn the proposed network parameters, first, a constrained optimization problem is introduced and solved to estimate the desired values of premise parts' output values. next, the error between these values and the current ones is utilized to adapt the premise parts' parameters based on the gradient-descent (gd) approach. afterward, the error between the desired and network's outputs is used to learn consequent parts' parameters by the gd method. the proposed paradigm is successfully applied to real-world time-series prediction and regression problems. according to experimental results, its performance outperforms other methods with a more parsimonious structure.",10.1016/j.neucom.2021.10.103,2020-11-25,,"['armin salimi-badr', 'mohammad mehdi ebadzadeh']"
2012.03612,lcs graph kernel based on wasserstein distance in longest common   subsequence metric space,cs.lg cs.ai cs.ds stat.ml,"for graph learning tasks, many existing methods utilize a message-passing mechanism where vertex features are updated iteratively by aggregation of neighbor information. this strategy provides an efficient means for graph features extraction, but obtained features after many iterations might contain too much information from other vertices, and tend to be similar to each other. this makes their representations less expressive. learning graphs using paths, on the other hand, can be less adversely affected by this problem because it does not involve all vertex neighbors. however, most of them can only compare paths with the same length, which might engender information loss. to resolve this difficulty, we propose a new graph kernel based on a longest common subsequence (lcs) similarity. moreover, we found that the widely-used r-convolution framework is unsuitable for path-based graph kernel because a huge number of comparisons between dissimilar paths might deteriorate graph distances calculation. therefore, we propose a novel metric space by exploiting the proposed lcs-based similarity, and compute a new wasserstein-based graph distance in this metric space, which emphasizes more the comparison between similar paths. furthermore, to reduce the computational cost, we propose an adjacent point merging operation to sparsify point clouds in the metric space.",10.1016/j.sigpro.2021.108281,2020-12-07,2021-10-29,"['jianming huang', 'zhongxi fang', 'hiroyuki kasai']"
2012.03774,learning to extrapolate using continued fractions: predicting the   critical temperature of superconductor materials,cs.lg cond-mat.supr-con cs.ai cs.ne,"in artificial intelligence we often seek to identify an unknown target function of many variables $y=f(\mathbf{x})$ giving a limited set of instances $s=\{(\mathbf{x^{(i)}},y^{(i)})\}$ with $\mathbf{x^{(i)}} \in d$ where $d$ is a domain of interest. we refer to $s$ as the training set and the final quest is to identify the mathematical model that approximates this target function for new $\mathbf{x}$; with the set $t=\{ \mathbf{x^{(j)}} \} \subset d$ with $t \neq s$ (i.e. thus testing the model generalisation). however, for some applications, the main interest is approximating well the unknown function on a larger domain $d'$ that contains $d$. in cases involving the design of new structures, for instance, we may be interested in maximizing $f$; thus, the model derived from $s$ alone should also generalize well in $d'$ for samples with values of $y$ larger than the largest observed in $s$. in that sense, the ai system would provide important information that could guide the design process, e.g., using the learned model as a surrogate function to design new lab experiments.   we introduce a method for multivariate regression based on iterative fitting of a continued fraction by incorporating additive spline models. we compared it with established methods such as adaboost, kernel ridge, linear regression, lasso lars, linear support vector regression, multi-layer perceptrons, random forests, stochastic gradient descent and xgboost. we tested the performance on the important problem of predicting the critical temperature of superconductors based on physical-chemical characteristics.",,2020-11-26,2021-11-07,"['pablo moscato', 'mohammad nazmul haque', 'kevin huang', 'julia sloan', 'jon c. de oliveira']"
2012.06047,knn classification with one-step computation,cs.lg cs.ai,"knn classification is a query triggered yet improvisational learning mode, in which they are carried out only when a test data is predicted that set a suitable k value and search the k nearest neighbors from the whole training sample space, referred them to the lazy part of knn classification. this lazy part has been the bottleneck problem of applying knn classification. in this paper, a one-step computation is proposed to replace the lazy part of knn classification. the one-step computation actually transforms the lazy part to a matrix computation as follows. given a test data, training samples are first applied to fit the test data with the least squares loss function. and then, a relationship matrix is generated by weighting all training samples according to their influence on the test data. finally, a group lasso is employed to perform sparse learning of the relationship matrix. in this way, setting k value and searching k nearest neighbors are both integrated to a unified computation. in addition, a new classification rule is proposed for improving the performance of one-step knn classification. the proposed approach is experimentally evaluated, and demonstrated that the one-step knn classification is efficient and promising.",10.1109/tkde.2021.3119140,2020-12-09,,"['shichao zhang', 'jiaye li']"
2012.06157,fairness in rating prediction by awareness of verbal and gesture quality   of public speeches,cs.ai,"the role of verbal and non-verbal cues towards great public speaking has been a topic of exploration for many decades. we identify a commonality across present theories, the element of ""variety or heterogeneity"" in channels or modes of communication (e.g. resorting to stories, scientific facts, emotional connections, facial expressions etc.) which is essential for effectively communicating information. we use this observation to formalize a novel heterogeneity metric, hem, that quantifies the quality of a talk both in the verbal and non-verbal domain (transcript and facial gestures). we use ted talks as an input repository of public speeches because it consists of speakers from a diverse community besides having a wide outreach. we show that there is an interesting relationship between hem and the ratings of ted talks given to speakers by viewers. it emphasizes that hem inherently and successfully represents the quality of a talk based on ""variety or heterogeneity"". further, we also discover that hem successfully captures the prevalent bias in ratings with respect to race and gender, that we call sensitive attributes (because prediction based on these might result in unfair outcome). we incorporate the hem metric into the loss function of a neural network with the goal to reduce unfairness in rating predictions with respect to race and gender. our results show that the modified loss function improves fairness in prediction without considerably affecting prediction accuracy of the neural network. our work ties together a novel metric for public speeches in both verbal and non-verbal domain with the computational power of a neural network to design a fair prediction system for speakers.",,2020-12-11,2021-11-15,"['ankani chattoraj', 'rupam acharyya', 'shouman das', 'md. iftekhar tanveer', 'ehsan hoque']"
2012.06405,attack agnostic detection of adversarial examples via random subspace   analysis,cs.cv cs.ai cs.cr cs.lg,"whilst adversarial attack detection has received considerable attention, it remains a fundamentally challenging problem from two perspectives. first, while threat models can be well-defined, attacker strategies may still vary widely within those constraints. therefore, detection should be considered as an open-set problem, standing in contrast to most current detection approaches. these methods take a closed-set view and train binary detectors, thus biasing detection toward attacks seen during detector training. second, limited information is available at test time and typically confounded by nuisance factors including the label and underlying content of the image. we address these challenges via a novel strategy based on random subspace analysis. we present a technique that utilizes properties of random projections to characterize the behavior of clean and adversarial examples across a diverse set of subspaces. the self-consistency (or inconsistency) of model activations is leveraged to discern clean from adversarial examples. performance evaluations demonstrate that our technique ($auc\in[0.92, 0.98]$) outperforms competing detection strategies ($auc\in[0.30,0.79]$), while remaining truly agnostic to the attack strategy (for both targeted/untargeted attacks). it also requires significantly less calibration data (composed only of clean examples) than competing approaches to achieve this performance.",,2020-12-11,2021-11-03,"['nathan drenkow', 'neil fendley', 'philippe burlina']"
2012.06968,multi-interactive attention network for fine-grained feature learning in   ctr prediction,cs.ir cs.ai,"in the click-through rate (ctr) prediction scenario, user's sequential behaviors are well utilized to capture the user interest in the recent literature. however, despite being extensively studied, these sequential methods still suffer from three limitations. first, existing methods mostly utilize attention on the behavior of users, which is not always suitable for ctr prediction, because users often click on new products that are irrelevant to any historical behaviors. second, in the real scenario, there exist numerous users that have operations a long time ago, but turn relatively inactive in recent times. thus, it is hard to precisely capture user's current preferences through early behaviors. third, multiple representations of user's historical behaviors in different feature subspaces are largely ignored. to remedy these issues, we propose a multi-interactive attention network (mian) to comprehensively extract the latent relationship among all kinds of fine-grained features (e.g., gender, age and occupation in user-profile). specifically, mian contains a multi-interactive layer (mil) that integrates three local interaction modules to capture multiple representations of user preference through sequential behaviors and simultaneously utilize the fine-grained user-specific as well as context information. in addition, we design a global interaction module (gim) to learn the high-order interactions and balance the different impacts of multiple features. finally, offline experiment results from three datasets, together with an online a/b test in a large-scale recommendation system, demonstrate the effectiveness of our proposed approach.",,2020-12-13,2021-11-03,"['kai zhang', 'hao qian', 'qing cui', 'qi liu', 'longfei li', 'jun zhou', 'jianhui ma', 'enhong chen']"
2012.07962,iterative label cleaning for transductive and semi-supervised few-shot   learning,cs.lg cs.ai cs.cv,"few-shot learning amounts to learning representations and acquiring knowledge such that novel tasks may be solved with both supervision and data being limited. improved performance is possible by transductive inference, where the entire test set is available concurrently, and semi-supervised learning, where more unlabeled data is available. focusing on these two settings, we introduce a new algorithm that leverages the manifold structure of the labeled and unlabeled data distribution to predict pseudo-labels, while balancing over classes and using the loss value distribution of a limited-capacity classifier to select the cleanest labels, iteratively improving the quality of pseudo-labels. our solution surpasses or matches the state of the art results on four benchmark datasets, namely miniimagenet, tieredimagenet, cub and cifar-fs, while being robust over feature space pre-processing and the quantity of available data. the publicly available source code can be found in https://github.com/michalislazarou/ilpc.",,2020-12-14,2021-10-31,"['michalis lazarou', 'tania stathaki', 'yannis avrithis']"
2012.08580,panther: pathway augmented nonnegative tensor factorization for   higher-order feature learning,q-bio.qm cs.ai cs.lg,"genetic pathways usually encode molecular mechanisms that can inform targeted interventions. it is often challenging for existing machine learning approaches to jointly model genetic pathways (higher-order features) and variants (atomic features), and present to clinicians interpretable models. in order to build more accurate and better interpretable machine learning models for genetic medicine, we introduce pathway augmented nonnegative tensor factorization for higher-order feature learning (panther). panther selects informative genetic pathways that directly encode molecular mechanisms. we apply genetically motivated constrained tensor factorization to group pathways in a way that reflects molecular mechanism interactions. we then train a softmax classifier for disease types using the identified pathway groups. we evaluated panther against multiple state-of-the-art constrained tensor/matrix factorization models, as well as group guided and bayesian hierarchical models. panther outperforms all state-of-the-art comparison models significantly (p<0.05). our experiments on large scale next generation sequencing (ngs) and whole-genome genotyping datasets also demonstrated wide applicability of panther. we performed feature analysis in predicting disease types, which suggested insights and benefits of the identified pathway groups.",,2020-12-15,,"['yuan luo', 'chengsheng mao']"
2012.09542,weakly-supervised action localization and action recognition using   global-local attention of 3d cnn,cs.cv cs.ai cs.ne,"3d convolutional neural network (3d cnn) captures spatial and temporal information on 3d data such as video sequences. however, due to the convolution and pooling mechanism, the information loss seems unavoidable. to improve the visual explanations and classification in 3d cnn, we propose two approaches; i) aggregate layer-wise global to local (global-local) discrete gradients using trained 3dresnext network, and ii) implement attention gating network to improve the accuracy of the action recognition. the proposed approach intends to show the usefulness of every layer termed as global-local attention in 3d cnn via visual attribution, weakly-supervised action localization, and action recognition. firstly, the 3dresnext is trained and applied for action classification using backpropagation concerning the maximum predicted class. the gradients and activations of every layer are then up-sampled. later, aggregation is used to produce more nuanced attention, which points out the most critical part of the predicted class's input videos. we use contour thresholding of final attention for final localization. we evaluate spatial and temporal action localization in trimmed videos using fine-grained visual explanation via 3dcam. experimental results show that the proposed approach produces informative visual explanations and discriminative attention. furthermore, the action recognition via attention gating on each layer produces better classification results than the baseline model.",,2020-12-17,2021-11-17,"['novanto yudistira', 'muthu subash kavitha', 'takio kurita']"
2012.10034,automatic detection of abnormal eeg signals using wavelet feature   extraction and gradient boosting decision tree,eess.sp cs.ai cs.lg,"electroencephalography is frequently used for diagnostic evaluation of various brain-related disorders due to its excellent resolution, non-invasive nature and low cost. however, manual analysis of eeg signals could be strenuous and a time-consuming process for experts. it requires long training time for physicians to develop expertise in it and additionally experts have low inter-rater agreement (ira) among themselves. therefore, many computer aided diagnostic (cad) based studies have considered the automation of interpreting eeg signals to alleviate the workload and support the final diagnosis. in this paper, we present an automatic binary classification framework for brain signals in multichannel eeg recordings. we propose to use wavelet packet decomposition (wpd) techniques to decompose the eeg signals into frequency sub-bands and extract a set of statistical features from each of the selected coefficients. moreover, we propose a novel method to reduce the dimension of the feature space without compromising the quality of the extracted features. the extracted features are classified using different gradient boosting decision tree (gbdt) based classification frameworks, which are catboost, xgboost and lightgbm. we used temple university hospital eeg abnormal corpus v2.0.0 to test our proposed technique. we found that catboost classifier achieves the binary classification accuracy of 87.68%, and outperforms state-of-the-art techniques on the same dataset by more than 1% in accuracy and more than 3% in sensitivity. the obtained results in this research provide important insights into the usefulness of wpd feature extraction and gbdt classifiers for eeg classification.",10.1016/j.bspc.2021.102957,2020-12-17,,"['hezam albaqami', 'ghulam mubashar hassan', 'abdulhamit subasi', 'amitava datta']"
2012.11517,a hybrid mga-msgd ann training approach for approximate solution of   linear elliptic pdes,math.na cs.ai cs.na,"we introduce a hybrid ""modified genetic algorithm-multilevel stochastic gradient descent"" (mga-msgd) training algorithm that considerably improves accuracy and efficiency of solving 3d mechanical problems described, in strong-form, by pdes via anns (artificial neural networks). this presented approach allows the selection of a number of locations of interest at which the state variables are expected to fulfil the governing equations associated with a physical problem. unlike classical pde approximation methods such as finite differences or the finite element method, there is no need to establish and reconstruct the physical field quantity throughout the computational domain in order to predict the mechanical response at specific locations of interest. the basic idea of mga-msgd is the manipulation of the learnable parameters' components responsible for the error explosion so that we can train the network with relatively larger learning rates which avoids trapping in local minima. the proposed training approach is less sensitive to the learning rate value, training points density and distribution, and the random initial parameters. the distance function to minimise is where we introduce the pdes including any physical laws and conditions (so-called, physics informed ann). the genetic algorithm is modified to be suitable for this type of ann in which a coarse-level stochastic gradient descent (csgd) is exploited to make the decision of the offspring qualification. employing the presented approach, a considerable improvement in both accuracy and efficiency, compared with standard training algorithms such as classical sgd and adam optimiser, is observed. the local displacement accuracy is studied and ensured by introducing the results of finite element method (fem) at sufficiently fine mesh as the reference displacements. a slightly more complex problem is solved ensuring its feasibility.",10.1016/j.matcom.2021.05.036,2020-12-18,,"['hamidreza dehghani', 'andreas zilian']"
2012.11867,intelligent resource allocation in dense lora networks using deep   reinforcement learning,cs.ni cs.ai,"the anticipated increase in the count of iot devices in the coming years motivates the development of efficient algorithms that can help in their effective management while keeping the power consumption low. in this paper, we propose an intelligent multi-channel resource allocation algorithm for dense lora networks termed loradrl and provide a detailed performance evaluation. our results demonstrate that the proposed algorithm not only significantly improves lorawan's packet delivery ratio (pdr) but is also able to support mobile end-devices (eds) while ensuring lower power consumption hence increasing both the lifetime and capacity of the network.} most previous works focus on proposing different mac protocols for improving the network capacity, i.e., lorawan, delay before transmit etc. we show that through the use of loradrl, we can achieve the same efficiency with aloha \textcolor{black}{compared to lorasim, and lora-mab while moving the complexity from eds to the gateway thus making the eds simpler and cheaper. furthermore, we test the performance of loradrl under large-scale frequency jamming attacks and show its adaptiveness to the changes in the environment. we show that loradrl's output improves the performance of state-of-the-art techniques resulting in some cases an improvement of more than 500\% in terms of pdr compared to learning-based techniques.",,2020-12-22,2021-11-01,"['inaam ilahi', 'muhammad usama', 'muhammad omer farooq', 'muhammad umar janjua', 'junaid qadir']"
2012.14905,meta learning backpropagation and improving it,cs.lg cs.ai cs.ne stat.ml,"many concepts have been proposed for meta learning with neural networks (nns), e.g., nns that learn to reprogram fast weights, hebbian plasticity, learned learning rules, and meta recurrent nns. our variable shared meta learning (vsml) unifies the above and demonstrates that simple weight-sharing and sparsity in an nn is sufficient to express powerful learning algorithms (las) in a reusable fashion. a simple implementation of vsml where the weights of a neural network are replaced by tiny lstms allows for implementing the backpropagation la solely by running in forward-mode. it can even meta learn new las that differ from online backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. introspection reveals that our meta learned las learn through fast association in a way that is qualitatively different from gradient descent.",,2020-12-29,2021-10-29,"['louis kirsch', 'jürgen schmidhuber']"
2012.15234,artificial intelligence development races in heterogeneous settings,cs.ai cs.gt,"regulation of advanced technologies such as artificial intelligence (ai) has become increasingly more important given their potential implications such as associated risks and ethical issues. with the great benefits promised from being able to first supply such technologies, safety precautions and societal consequences might be ignored or shortchanged in exchange for speeding up the development, therefore engendering a racing narrative among the developers. starting from a game-theoretical model describing an idealised technology race in a well-mixed world of players, here we investigate how different interaction structures among race participants can alter collective choices and requirements for regulatory actions. our findings indicate that, when participants portray a strong diversity in terms of connections and peer-influence (e.g., when scale-free networks shape interactions among parties), the conflicts that exist in homogeneous settings are significantly reduced, thereby lessening the need for regulatory actions. furthermore, our results suggest that technology governance and regulation may profit from the world's patent heterogeneity and inequality among firms and nations, so as to enable the design and implementation of meticulous interventions on a minority of participants, which is capable of influencing an entire population towards an ethical and sustainable use of advanced technologies.",,2020-12-30,2021-11-11,"['theodor cimpeanu', 'francisco c. santos', 'luis moniz pereira', 'tom lenaerts', 'the anh han']"
2101.00124,discourse-level relation extraction via graph pooling,cs.cl cs.ai cs.lg,"the ability to capture complex linguistic structures and long-term dependencies among words in the passage is essential for discourse-level relation extraction (dre) tasks. graph neural networks (gnns), one of the methods to encode dependency graphs, have been shown effective in prior works for dre. however, relatively little attention has been paid to receptive fields of gnns, which can be crucial for cases with extremely long text that requires discourse understanding. in this work, we leverage the idea of graph pooling and propose to use pooling-unpooling framework on dre tasks. the pooling branch reduces the graph size and enables the gnns to obtain larger receptive fields within fewer layers; the unpooling branch restores the pooled graph to its original resolution so that representations for entity mention can be extracted. we propose clause matching (cm), a novel linguistically inspired graph pooling method for nlp tasks. experiments on two dre datasets demonstrate that our models significantly improve over baselines when modeling long-term dependencies is required, which shows the effectiveness of the pooling-unpooling framework and our cm pooling method.",,2020-12-31,2021-11-12,"['i-hung hsu', 'xiao guo', 'premkumar natarajan', 'nanyun peng']"
2101.03163,slow manifolds in recurrent networks encode working memory efficiently   and robustly,q-bio.nc cs.ai,"working memory is a cognitive function involving the storage and manipulation of latent information over brief intervals of time, thus making it crucial for context-dependent computation. here, we use a top-down modeling approach to examine network-level mechanisms of working memory, an enigmatic issue and central topic of study in neuroscience and machine intelligence. we train thousands of recurrent neural networks on a working memory task and then perform dynamical systems analysis on the ensuing optimized networks, wherein we find that four distinct dynamical mechanisms can emerge. in particular, we show the prevalence of a mechanism in which memories are encoded along slow stable manifolds in the network state space, leading to a phasic neuronal activation profile during memory periods. in contrast to mechanisms in which memories are directly encoded at stable attractors, these networks naturally forget stimuli over time. despite this seeming functional disadvantage, they are more efficient in terms of how they leverage their attractor landscape and paradoxically, are considerably more robust to noise. our results provide new dynamical hypotheses regarding how working memory function is encoded in both natural and artificial neural networks.",10.1371/journal.pcbi.1009366,2021-01-08,,"['elham ghazizadeh', 'shinung ching']"
2101.03805,multi-objective conflict-based search for multi-agent path finding,cs.ai cs.ro,"conventional multi-agent path planners typically compute an ensemble of paths while optimizing a single objective, such as path length. however, many applications may require multiple objectives, say fuel consumption and completion time, to be simultaneously optimized during planning and these criteria may not be readily compared and sometimes lie in competition with each other. naively applying existing multi-objective search algorithms to multi-agent path finding may prove to be inefficient as the size of the space of possible solutions, i.e., the pareto-optimal set, can grow exponentially with the number of agents (the dimension of the search space). this article presents an approach named multi-objective conflict-based search (mo-cbs) that bypasses this so-called curse of dimensionality by leveraging prior conflict-based search (cbs), a well-known algorithm for single-objective multi-agent path finding, and principles of dominance from multi-objective optimization literature. we prove that mo-cbs is able to compute the entire pareto-optimal set. our results show that mo-cbs can solve problem instances with hundreds of pareto-optimal solutions which the standard multi-objective a* algorithms could not find within a bounded time.",10.1109/icra48506.2021.9560985,2021-01-11,2021-05-09,"['zhongqiang ren', 'sivakumar rathinam', 'howie choset']"
2101.07757,magnification generalization for histopathology image embedding,eess.iv cs.ai cs.cv,"histopathology image embedding is an active research area in computer vision. most of the embedding models exclusively concentrate on a specific magnification level. however, a useful task in histopathology embedding is to train an embedding space regardless of the magnification level. two main approaches for tackling this goal are domain adaptation and domain generalization, where the target magnification levels may or may not be introduced to the model in training, respectively. although magnification adaptation is a well-studied topic in the literature, this paper, to the best of our knowledge, is the first work on magnification generalization for histopathology image embedding. we use an episodic trainable domain generalization technique for magnification generalization, namely model agnostic learning of semantic features (masf), which works based on the model agnostic meta-learning (maml) concept. our experimental results on a breast cancer histopathology dataset with four different magnification levels show the proposed method's effectiveness for magnification generalization.",10.1109/isbi48211.2021.9433978,2021-01-17,,"['milad sikaroudi', 'benyamin ghojogh', 'fakhri karray', 'mark crowley', 'h. r. tizhoosh']"
2101.10841,pconv: simple yet effective convolutional layer for generative   adversarial network,cs.cv cs.ai cs.lg,"this paper presents a novel convolutional layer, called perturbed convolution (pconv), which focuses on achieving two goals simultaneously: improving the generative adversarial network (gan) performance and alleviating the memorization problem in which the discriminator memorizes all images from a given dataset as training progresses. in pconv, perturbed features are generated by randomly disturbing an input tensor before performing the convolution operation. this approach is simple but surprisingly effective. first, to produce a similar output even with the perturbed tensor, each layer in the discriminator should learn robust features having a small local lipschitz value. second, since the input tensor is randomly perturbed during the training procedure like the dropout in neural networks, the memorization problem could be alleviated. to show the generalization ability of the proposed method, we conducted extensive experiments with various loss functions and datasets including cifar-10, celeba, celeba-hq, lsun, and tiny-imagenet. the quantitative evaluations demonstrate that pconv effectively boosts the performance of gan and conditional gan in terms of frechet inception distance (fid).",,2021-01-19,2021-11-07,"['seung park', 'yoon-jae yeo', 'yong-goo shin']"
2101.11952,rethinking rotated object detection with gaussian wasserstein distance   loss,cs.cv cs.ai,"boundary discontinuity and its inconsistency to the final detection metric have been the bottleneck for rotating detection regression loss design. in this paper, we propose a novel regression loss based on gaussian wasserstein distance as a fundamental approach to solve the problem. specifically, the rotated bounding box is converted to a 2-d gaussian distribution, which enables to approximate the indifferentiable rotational iou induced loss by the gaussian wasserstein distance (gwd) which can be learned efficiently by gradient back-propagation. gwd can still be informative for learning even there is no overlapping between two rotating bounding boxes which is often the case for small object detection. thanks to its three unique properties, gwd can also elegantly solve the boundary discontinuity and square-like problem regardless how the bounding box is defined. experiments on five datasets using different detectors show the effectiveness of our approach. codes are available at https://github.com/yangxue0827/rotationdetection.",,2021-01-28,2021-11-16,"['xue yang', 'junchi yan', 'qi ming', 'wentao wang', 'xiaopeng zhang', 'qi tian']"
2101.12051,edge federated learning via unit-modulus over-the-air computation,cs.it cs.ai math.it,"edge federated learning (fl) is an emerging paradigm that trains a global parametric model from distributed datasets based on wireless communications. this paper proposes a unit-modulus over-the-air computation (umaircomp) framework to facilitate efficient edge federated learning, which simultaneously uploads local model parameters and updates global model parameters via analog beamforming. the proposed framework avoids sophisticated baseband signal processing, leading to low communication delays and implementation costs. training loss bounds of umaircomp fl systems are derived and two low-complexity large-scale optimization algorithms, termed penalty alternating minimization (pam) and accelerated gradient projection (agp), are proposed to minimize the nonconvex nonsmooth loss bound. simulation results show that the proposed umaircomp framework with pam algorithm achieves a smaller mean square error of model parameters' estimation, training loss, and test error compared with other benchmark schemes. moreover, the proposed umaircomp framework with agp algorithm achieves satisfactory performance while reduces the computational complexity by orders of magnitude compared with existing optimization algorithms. finally, we demonstrate the implementation of umaircomp in a vehicle-to-everything autonomous driving simulation platform. it is found that autonomous driving tasks are more sensitive to model parameter errors than other tasks since the neural networks for autonomous driving contain sparser model parameters.",,2021-01-28,2021-11-11,"['shuai wang', 'yuncong hong', 'rui wang', 'qi hao', 'yik-chung wu', 'derrick wing kwan ng']"
2102.01353,subdimensional expansion for multi-objective multi-agent path finding,cs.ro cs.ai,"conventional multi-agent path planners typically determine a path that optimizes a single objective, such as path length. many applications, however, may require multiple objectives, say time-to-completion and fuel use, to be simultaneously optimized in the planning process. often, these criteria may not be readily compared and sometimes lie in competition with each other. simply applying standard multi-objective search algorithms to multi-agent path finding may prove to be inefficient because the size of the space of possible solutions, i.e., the pareto-optimal set, can grow exponentially with the number of agents (the dimension of the search space). this paper presents an approach that bypasses this so-called curse of dimensionality by leveraging our prior multi-agent work with a framework called subdimensional expansion. one example of subdimensional expansion, when applied to a*, is called m* and m* was limited to a single objective function. we combine principles of dominance and subdimensional expansion to create a new algorithm named multi-objective m* (mom*), which dynamically couples agents for planning only when those agents have to ""interact"" with each other. mom* computes the complete pareto-optimal set for multiple agents efficiently and naturally trades off sub-optimal approximations of the pareto-optimal set and computational efficiency. our approach is able to find the complete pareto-optimal set for problem instances with hundreds of solutions which the standard multi-objective a* algorithms could not find within a bounded time.",10.1109/lra.2021.3096744,2021-02-02,2021-07-09,"['zhongqiang ren', 'sivakumar rathinam', 'howie choset']"
2102.02454,hybrid adversarial imitation learning,cs.lg cs.ai,"extrapolating beyond-demonstrator (bd) performance through the imitation learning (il) algorithm aims to learn from and outperform the demonstrator. most existing bdil algorithms are performed in two stages by first inferring a reward function before learning a policy via reinforcement learning (rl). however, such two-stage bdil algorithms suffer from high computational complexity, weak robustness, and large performance variations. in particular, a poor reward function derived in the first stage will inevitably incur severe performance loss in the second stage. in this work, we propose a hybrid adversarial imitation learning (hail) algorithm that is one-stage, model-free, generative-adversarial (ga) fashion and curiosity-driven. thanks to the one-stage design, the hail can integrate both the reward function learning and the policy optimization into one procedure, which leads to many advantages such as low computational complexity, high robustness, and strong adaptability. more specifically, hail simultaneously imitates the demonstrator and explores bd performance by utilizing hybrid rewards. extensive simulation results confirm that hail can achieve higher performance as compared to other similar bdil algorithms.",,2021-02-04,2021-10-28,['mingqi yuan']
2102.03479,rethinking the implementation tricks and monotonicity constraint in   cooperative multi-agent reinforcement learning,cs.lg cs.ai cs.ma,"many complex multi-agent systems such as robot swarms control and autonomous vehicle coordination can be modeled as multi-agent reinforcement learning (marl) tasks. qmix, a widely popular marl algorithm, has been used as a baseline for the benchmark environments, e.g., starcraft multi-agent challenge (smac), difficulty-enhanced predator-prey (depp). recent variants of qmix target relaxing the monotonicity constraint of qmix, allowing for performance improvement in smac. in this paper, we investigate the code-level optimizations of these variants and the monotonicity constraint. (1) we find that such improvements of the variants are significantly affected by various code-level optimizations. (2) the experiment results show that qmix with normalized optimizations outperforms other works in smac; (3) beyond the common wisdom from these works, the monotonicity constraint can improve sample efficiency in smac and depp. we also discuss why monotonicity constraints work well in purely cooperative tasks with a theoretical analysis. we open-source the code at \url{https://github.com/hijkzzz/pymarl2}.",,2021-02-05,2021-11-11,"['jian hu', 'siyang jiang', 'seth austin harding', 'haibin wu', 'shih-wei liao']"
2102.03988,ising model selection using $\ell_{1}$-regularized linear regression: a   statistical mechanics analysis,cs.lg cond-mat.dis-nn cs.ai stat.ml,"we theoretically analyze the typical learning performance of $\ell_{1}$-regularized linear regression ($\ell_1$-linr) for ising model selection using the replica method from statistical mechanics. for typical random regular graphs in the paramagnetic phase, an accurate estimate of the typical sample complexity of $\ell_1$-linr is obtained. remarkably, despite the model misspecification, $\ell_1$-linr is model selection consistent with the same order of sample complexity as $\ell_{1}$-regularized logistic regression ($\ell_1$-logr), i.e., $m=\mathcal{o}\left(\log n\right)$, where $n$ is the number of variables of the ising model. moreover, we provide an efficient method to accurately predict the non-asymptotic behavior of $\ell_1$-linr for moderate $m, n$, such as precision and recall. simulations show a fairly good agreement between theoretical predictions and experimental results, even for graphs with many loops, which supports our findings. although this paper mainly focuses on $\ell_1$-linr, our method is readily applicable for precisely characterizing the typical learning performances of a wide class of $\ell_{1}$-regularized $m$-estimators including $\ell_1$-logr and interaction screening.",,2021-02-07,2021-11-01,"['xiangming meng', 'tomoyuki obuchi', 'yoshiyuki kabashima']"
2102.04394,learning with density matrices and random features,cs.lg cs.ai quant-ph,"a density matrix describes the statistical state of a quantum system. it is a powerful formalism to represent both the quantum and classical uncertainty of quantum systems and to express different statistical operations such as measurement, system combination and expectations as linear algebra operations. this paper explores how density matrices can be used as a building block to build machine learning models exploiting their ability to straightforwardly combine linear algebra and probability. one of the main results of the paper is to show that density matrices coupled with random fourier features could approximate arbitrary probability distributions over $\mathbb{r}^n$. based on this finding the paper builds different models for density estimation, classification and regression. these models are differentiable, so it is possible to integrate them with other differentiable components, such as deep learning architectures and to learn their parameters using gradient-based optimization. in addition, the paper presents optimization-less training strategies based on estimation and model averaging. the models are evaluated in benchmark tasks and the results are reported and discussed.",,2021-02-08,2021-11-08,"['fabio a. gonzález', 'alejandro gallego', 'santiago toledo-cortés', 'vladimir vargas-calderón']"
2102.04897,learning state representations from random deep action-conditional   predictions,cs.lg cs.ai,"our main contribution in this work is an empirical finding that random general value functions (gvfs), i.e., deep action-conditional predictions -- random both in what feature of observations they predict as well as in the sequence of actions the predictions are conditioned upon -- form good auxiliary tasks for reinforcement learning (rl) problems. in particular, we show that random deep action-conditional predictions when used as auxiliary tasks yield state representations that produce control performance competitive with state-of-the-art hand-crafted auxiliary tasks like value prediction, pixel control, and curl in both atari and deepmind lab tasks. in another set of experiments we stop the gradients from the rl part of the network to the state representation learning part of the network and show, perhaps surprisingly, that the auxiliary tasks alone are sufficient to learn state representations good enough to outperform an end-to-end trained actor-critic baseline. we opensourced our code at https://github.com/hwhitetooth/random_gvfs.",,2021-02-09,2021-11-05,"['zeyu zheng', 'vivek veeriah', 'risto vuorio', 'richard lewis', 'satinder singh']"
2102.05034,slaps: self-supervision improves structure learning for graph neural   networks,cs.lg cs.ai,"graph neural networks (gnns) work well when the graph structure is provided. however, this structure may not always be available in real-world applications. one solution to this problem is to infer a task-specific latent structure and then apply a gnn to the inferred graph. unfortunately, the space of possible graph structures grows super-exponentially with the number of nodes and so the task-specific supervision may be insufficient for learning both the structure and the gnn parameters. in this work, we propose the simultaneous learning of adjacency and gnn parameters with self-supervision, or slaps, a method that provides more supervision for inferring a graph structure through self-supervision. a comprehensive experimental study demonstrates that slaps scales to large graphs with hundreds of thousands of nodes and outperforms several models that have been proposed to learn a task-specific graph structure on established benchmarks.",,2021-02-09,2021-10-31,"['bahare fatemi', 'layla el asri', 'seyed mehran kazemi']"
2102.05311,cifs: improving adversarial robustness of cnns via channel-wise   importance-based feature selection,cs.lg cs.ai,"we investigate the adversarial robustness of cnns from the perspective of channel-wise activations. by comparing \textit{non-robust} (normally trained) and \textit{robustified} (adversarially trained) models, we observe that adversarial training (at) robustifies cnns by aligning the channel-wise activations of adversarial data with those of their natural counterparts. however, the channels that are \textit{negatively-relevant} (nr) to predictions are still over-activated when processing adversarial data. besides, we also observe that at does not result in similar robustness for all classes. for the robust classes, channels with larger activation magnitudes are usually more \textit{positively-relevant} (pr) to predictions, but this alignment does not hold for the non-robust classes. given these observations, we hypothesize that suppressing nr channels and aligning pr ones with their relevances further enhances the robustness of cnns under at. to examine this hypothesis, we introduce a novel mechanism, i.e., \underline{c}hannel-wise \underline{i}mportance-based \underline{f}eature \underline{s}election (cifs). the cifs manipulates channels' activations of certain layers by generating non-negative multipliers to these channels based on their relevances to predictions. extensive experiments on benchmark datasets including cifar10 and svhn clearly verify the hypothesis and cifs's effectiveness of robustifying cnns. \url{https://github.com/hanshuyan/cifs}",,2021-02-10,2021-11-09,"['hanshu yan', 'jingfeng zhang', 'gang niu', 'jiashi feng', 'vincent y. f. tan', 'masashi sugiyama']"
2102.06794,extending lagrangian and hamiltonian neural networks with differentiable   contact models,cs.ro cs.ai cs.lg,"the incorporation of appropriate inductive bias plays a critical role in learning dynamics from data. a growing body of work has been exploring ways to enforce energy conservation in the learned dynamics by encoding lagrangian or hamiltonian dynamics into the neural network architecture. these existing approaches are based on differential equations, which do not allow discontinuity in the states and thereby limit the class of systems one can learn. however, in reality, most physical systems, such as legged robots and robotic manipulators, involve contacts and collisions, which introduce discontinuities in the states. in this paper, we introduce a differentiable contact model, which can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. this model can also accommodate inequality constraints, such as limits on the joint angles. the proposed contact model extends the scope of lagrangian and hamiltonian neural networks by allowing simultaneous learning of contact and system properties. we demonstrate this framework on a series of challenging 2d and 3d physical systems with different coefficients of restitution and friction. the learned dynamics can be used as a differentiable physics simulator for downstream gradient-based optimization tasks, such as planning and control.",,2021-02-12,2021-11-12,"['yaofeng desmond zhong', 'biswadip dey', 'amit chakraborty']"
2102.08026,edith :ecg biometrics aided by deep learning for reliable individual   authentication,cs.lg cs.ai cs.cr,"in recent years, physiological signal based authentication has shown great promises,for its inherent robustness against forgery. electrocardiogram (ecg) signal, being the most widely studied biosignal, has also received the highest level of attention in this regard. it has been proven with numerous studies that by analyzing ecg signals from different persons, it is possible to identify them, with acceptable accuracy. in this work, we present, edith, a deep learning-based framework for ecg biometrics authentication system. moreover, we hypothesize and demonstrate that siamese architectures can be used over typical distance metrics for improved performance. we have evaluated edith using 4 commonly used datasets and outperformed the prior works using less number of beats. edith performs competitively using just a single heartbeat (96-99.75% accuracy) and can be further enhanced by fusing multiple beats (100% accuracy from 3 to 6 beats). furthermore, the proposed siamese architecture manages to reduce the identity verification equal error rate (eer) to 1.29%. a limited case study of edith with real-world experimental data also suggests its potential as a practical authentication system.",,2021-02-16,2021-11-13,"['nabil ibtehaz', 'muhammad e. h. chowdhury', 'amith khandakar', 'serkan kiranyaz', 'm. sohel rahman', 'anas tahir', 'yazan qiblawey', 'tawsifur rahman']"
2102.09390,a machine learning approach for early detection of fish diseases by   analyzing water quality,cs.lg cs.ai,"early detection of fish diseases and identifying the underlying causes are crucial for farmers to take necessary steps to mitigate the potential outbreak and thus to avert financial losses with apparent negative implications to the national economy. typically, fish diseases are caused by viruses and bacteria; according to biochemical studies, the presence of certain bacteria and viruses may affect the level of ph, do, bod, cod, tss, tds, ec, po43-, no3-n, and nh3-n in water, resulting in the death of fishes. besides, natural processes, e.g., photosynthesis, respiration, and decomposition, also contribute to the alteration of water quality that adversely affects fish health. being motivated by the recent successes of machine learning techniques, a state-of-art machine learning algorithm has been adopted in this paper to detect and predict the degradation of water quality timely and accurately. thus, it helps to take preemptive steps against potential fish diseases. the experimental results show high accuracy in detecting fish diseases specific to water quality based on the algorithm with real datasets.",10.48048/tis.2021.351,2021-02-15,2021-11-11,"['al-akhir nayan', 'ahamad nokib mozumder', 'joyeta saha', 'khan raqib mahmud', 'abul kalam al azad', 'muhammad golam kibria']"
2102.10557,contrastive self-supervised neural architecture search,cs.cv cs.ai,"this paper proposes a novel cell-based neural architecture search algorithm (nas), which completely alleviates the expensive costs of data labeling inherited from supervised learning. our algorithm capitalizes on the effectiveness of self-supervised learning for image representations, which is an increasingly crucial topic of computer vision. first, using only a small amount of unlabeled train data under contrastive self-supervised learning allow us to search on a more extensive search space, discovering better neural architectures without surging the computational resources. second, we entirely relieve the cost for labeled data (by contrastive loss) in the search stage without compromising architectures' final performance in the evaluation phase. finally, we tackle the inherent discrete search space of the nas problem by sequential model-based optimization via the tree-parzen estimator (smbo-tpe), enabling us to reduce the computational expense response surface significantly. an extensive number of experiments empirically show that our search algorithm can achieve state-of-the-art results with better efficiency in data labeling cost, searching time, and accuracy in final validation.",10.1109/tai.2021.3121663,2021-02-21,2021-10-29,"['nam nguyen', 'j. morris chang']"
2102.11137,program synthesis guided reinforcement learning for partially observed   environments,cs.ai,"a key challenge for reinforcement learning is solving long-horizon planning problems. recent work has leveraged programs to guide reinforcement learning in these settings. however, these approaches impose a high manual burden on the user since they must provide a guiding program for every new task. partially observed environments further complicate the programming task because the program must implement a strategy that correctly, and ideally optimally, handles every possible configuration of the hidden regions of the environment. we propose a new approach, model predictive program synthesis (mpps), that uses program synthesis to automatically generate the guiding programs. it trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. in our experiments, we show that our approach significantly outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2d minecraft-inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent. our results demonstrate that our approach can obtain the benefits of program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task.",,2021-02-22,2021-11-01,"['yichen david yang', 'jeevana priya inala', 'osbert bastani', 'yewen pu', 'armando solar-lezama', 'martin rinard']"
2102.11436,model-based domain generalization,stat.ml cs.ai cs.lg,"despite remarkable success in a variety of applications, it is well-known that deep learning can fail catastrophically when presented with out-of-distribution data. toward addressing this challenge, we consider the domain generalization problem, wherein predictors are trained using data drawn from a family of related training domains and then evaluated on a distinct and unseen test domain. we show that under a natural model of data generation and a concomitant invariance condition, the domain generalization problem is equivalent to an infinite-dimensional constrained statistical learning problem; this problem forms the basis of our approach, which we call model-based domain generalization. due to the inherent challenges in solving constrained optimization problems in deep learning, we exploit nonconvex duality theory to develop unconstrained relaxations of this statistical problem with tight bounds on the duality gap. based on this theoretical motivation, we propose a novel domain generalization algorithm with convergence guarantees. in our experiments, we report improvements of up to 30 percentage points over state-of-the-art domain generalization baselines on several benchmarks including coloredmnist, camelyon17-wilds, fmow-wilds, and pacs.",,2021-02-22,2021-11-15,"['alexander robey', 'george j. pappas', 'hamed hassani']"
2102.11494,sample-efficient learning of stackelberg equilibria in general-sum games,cs.lg cs.ai cs.gt stat.ml,"real world applications such as economics and policy making often involve solving multi-agent games with two unique features: (1) the agents are inherently asymmetric and partitioned into leaders and followers; (2) the agents have different reward functions, thus the game is general-sum. the majority of existing results in this field focuses on either symmetric solution concepts (e.g. nash equilibrium) or zero-sum games. it remains open how to learn the stackelberg equilibrium -- an asymmetric analog of the nash equilibrium -- in general-sum games efficiently from noisy samples.   this paper initiates the theoretical study of sample-efficient learning of the stackelberg equilibrium, in the bandit feedback setting where we only observe noisy samples of the reward. we consider three representative two-player general-sum games: bandit games, bandit-reinforcement learning (bandit-rl) games, and linear bandit games. in all these games, we identify a fundamental gap between the exact value of the stackelberg equilibrium and its estimated version using finitely many noisy samples, which can not be closed information-theoretically regardless of the algorithm. we then establish sharp positive results on sample-efficient learning of stackelberg equilibrium with value optimal up to the gap identified above, with matching lower bounds in the dependency on the gap, error tolerance, and the size of the action spaces. overall, our results unveil unique challenges in learning stackelberg equilibria under noisy bandit feedback, which we hope could shed light on future research on this topic.",,2021-02-23,2021-11-03,"['yu bai', 'chi jin', 'huan wang', 'caiming xiong']"
2102.11764,quantum entropic causal inference,cs.et cs.ai cs.it math.it quant-ph,"the class of problems in causal inference which seeks to isolate causal correlations solely from observational data even without interventions has come to the forefront of machine learning, neuroscience and social sciences. as new large scale quantum systems go online, it opens interesting questions of whether a quantum framework exists on isolating causal correlations without any interventions on a quantum system. we put forth a theoretical framework for merging quantum information science and causal inference by exploiting entropic principles. at the root of our approach is the proposition that the true causal direction minimizes the entropy of exogenous variables in a non-local hidden variable theory. the proposed framework uses a quantum causal structural equation model to build the connection between two fields: entropic causal inference and the quantum marginal problem. first, inspired by the definition of geometric quantum discord, we fill the gap between classical and quantum conditional density matrices to define quantum causal models. subsequently, using a greedy approach, we develop a scalable algorithm for quantum entropic causal inference unifying classical and quantum causality in a principled way. we apply our proposed algorithm to an experimentally relevant scenario of identifying the subsystem impacted by noise starting from an entangled state. this successful inference on a synthetic quantum dataset can have practical applications in identifying originators of malicious activity on future multi-node quantum networks as well as quantum error correction. as quantum datasets and systems grow in complexity, our framework can play a foundational role in bringing observational causal inference from the classical to the quantum domain.",,2021-02-23,2021-10-29,"['mohammad ali javidian', 'vaneet aggarwal', 'fanglin bao', 'zubin jacob']"
2102.11938,"baby intuitions benchmark (bib): discerning the goals, preferences, and   actions of others",cs.ai cs.lg,"to achieve human-like common sense about everyday life, machine learning systems must understand and reason about the goals, preferences, and actions of other agents in the environment. by the end of their first year of life, human infants intuitively achieve such common sense, and these cognitive achievements lay the foundation for humans' rich and complex understanding of the mental states of others. can machines achieve generalizable, commonsense reasoning about other agents like human infants? the baby intuitions benchmark (bib) challenges machines to predict the plausibility of an agent's behavior based on the underlying causes of its actions. because bib's content and paradigm are adopted from developmental cognitive science, bib allows for direct comparison between human and machine performance. nevertheless, recently proposed, deep-learning-based agency reasoning models fail to show infant-like reasoning, leaving bib an open challenge.",,2021-02-23,2021-11-09,"['kanishk gandhi', 'gala stojnic', 'brenden m. lake', 'moira r. dillon']"
2102.12002,adversarial robustness with non-uniform perturbations,cs.lg cs.ai cs.cr stat.ml,"robustness of machine learning models is critical for security related applications, where real-world adversaries are uniquely focused on evading neural network based detectors. prior work mainly focus on crafting adversarial examples (aes) with small uniform norm-bounded perturbations across features to maintain the requirement of imperceptibility. however, uniform perturbations do not result in realistic aes in domains such as malware, finance, and social networks. for these types of applications, features typically have some semantically meaningful dependencies. the key idea of our proposed approach is to enable non-uniform perturbations that can adequately represent these feature dependencies during adversarial training. we propose using characteristics of the empirical data distribution, both on correlations between the features and the importance of the features themselves. using experimental datasets for malware classification, credit risk prediction, and spam detection, we show that our approach is more robust to real-world attacks. finally, we present robustness certification utilizing non-uniform perturbation bounds, and show that non-uniform bounds achieve better certification.",,2021-02-23,2021-10-29,"['ecenaz erdemir', 'jeffrey bickford', 'luca melis', 'sergul aydore']"
2102.12060,teach me to explain: a review of datasets for explainable nlp,cs.cl cs.ai cs.lg,"explainable nlp (exnlp) has increasingly focused on collecting human-annotated textual explanations. these explanations are used downstream in three ways: as data augmentation to improve performance on a predictive task, as supervision to train models to produce explanations for their predictions, and as a ground-truth to evaluate model-generated explanations. in this review, we identify 65 datasets with three predominant classes of textual explanations (highlights, free-text, and structured), organize the literature on annotating each type, identify strengths and shortcomings of existing collection methodologies, and give recommendations for collecting exnlp datasets in the future.",,2021-02-23,2021-11-04,"['sarah wiegreffe', 'ana marasović']"
2102.13128,an online learning approach to interpolation and extrapolation in domain   generalization,cs.lg cs.ai cs.gt stat.ml,"a popular assumption for out-of-distribution generalization is that the training data comprises sub-datasets, each drawn from a distinct distribution; the goal is then to ""interpolate"" these distributions and ""extrapolate"" beyond them -- this objective is broadly known as domain generalization. a common belief is that erm can interpolate but not extrapolate and that the latter is considerably more difficult, but these claims are vague and lack formal justification. in this work, we recast generalization over sub-groups as an online game between a player minimizing risk and an adversary presenting new test distributions. under an existing notion of inter- and extrapolation based on reweighting of sub-group likelihoods, we rigorously demonstrate that extrapolation is computationally much harder than interpolation, though their statistical complexity is not significantly different. furthermore, we show that erm -- or a noisy variant -- is provably minimax-optimal for both tasks. our framework presents a new avenue for the formal analysis of domain generalization algorithms which may be of independent interest.",,2021-02-25,2021-11-18,"['elan rosenfeld', 'pradeep ravikumar', 'andrej risteski']"
2102.13307,potential impacts of smart homes on human behavior: a reinforcement   learning approach,cs.ai,"we aim to investigate the potential impacts of smart homes on human behavior. to this end, we simulate a series of human models capable of performing various activities inside a reinforcement learning-based smart home. we then investigate the possibility of human behavior being altered as a result of the smart home and the human model adapting to one-another. we design a semi-markov decision process human task interleaving model based on hierarchical reinforcement learning that learns to make decisions to either pursue or leave an activity. we then integrate our human model in the smart home which is based on q-learning. we show that a smart home trained on a generic human model is able to anticipate and learn the thermal preferences of human models with intrinsic rewards similar to the generic model. the hierarchical human model learns to complete each activity and set optimal thermal settings for maximum comfort. with the smart home, the number of time steps required to change the thermal settings are reduced for the human models. interestingly, we observe that small variations in the human model reward structures can lead to the opposite behavior in the form of unexpected switching between activities which signals changes in human behavior due to the presence of the smart home.",,2021-02-26,2021-06-21,"['shashi suman', 'ali etemad', 'francois rivest']"
2103.00137,meta-learning with graph neural networks: methods and applications,cs.lg cs.ai,"graph neural networks (gnns), a generalization of deep neural networks on graph data have been widely used in various domains, ranging from drug discovery to recommender systems. however, gnns on such applications are limited when there are few available samples. meta-learning has been an important framework to address the lack of samples in machine learning, and in recent years, researchers have started to apply meta-learning to gnns. in this work, we provide a comprehensive survey of different meta-learning approaches involving gnns on various graph problems showing the power of using these two approaches together. we categorize the literature based on proposed architectures, shared representations, and applications. finally, we discuss several exciting future research directions and open problems.",,2021-02-27,2021-11-06,"['debmalya mandal', 'sourav medya', 'brian uzzi', 'charu aggarwal']"
2103.00255,expert decision support system for aeroacoustic source type   identification using clustering,cs.sd cs.ai cs.lg eess.as,"this paper presents an expert decision support system for the identification of time-invariant, aeroacoustic source types. the system comprises two steps: first, acoustic properties are calculated based on spectral and spatial information. second, clustering is performed based on these properties. the clustering aims at helping and guiding an expert for quick identification of different source types, providing an understanding of how sources differ. this supports the expert in determining similar or atypical behavior. a variety of features are proposed for capturing the characteristics of the sources. these features represent aeroacoustic properties that can be interpreted by both the machine and by experts. the features are independent of the absolute mach number which enables the proposed method to cluster data measured at different flow configurations. the method is evaluated on deconvolved beamforming data from two scaled airframe half-model measurements. for this exemplary data, the proposed support system method results in clusters that mostly correspond to the source types identified by the authors. the clustering also provides the mean feature values and the cluster hierarchy for each cluster and for each cluster member a clustering confidence. this additional information makes the results transparent and allows the expert to understand the clustering choices.",10.13140/rg.2.2.33496.42249,2021-02-27,2021-11-18,"['armin goudarzi', 'carsten spehr', 'steffen herbold']"
2103.00718,autonomous navigation of an ultrasound probe towards standard scan   planes with deep reinforcement learning,cs.ro cs.ai cs.lg,"autonomous ultrasound (us) acquisition is an important yet challenging task, as it involves interpretation of the highly complex and variable images and their spatial relationships. in this work, we propose a deep reinforcement learning framework to autonomously control the 6-d pose of a virtual us probe based on real-time image feedback to navigate towards the standard scan planes under the restrictions in real-world us scans. furthermore, we propose a confidence-based approach to encode the optimization of image quality in the learning process. we validate our method in a simulation environment built with real-world data collected in the us imaging of the spine. experimental results demonstrate that our method can perform reproducible us probe navigation towards the standard scan plane with an accuracy of $4.91mm/4.65^\circ$ in the intra-patient setting, and accomplish the task in the intra- and inter-patient settings with a success rate of $92\%$ and $46\%$, respectively. the results also show that the introduction of image quality optimization in our method can effectively improve the navigation performance.",10.1109/icra48506.2021.9561295,2021-02-28,2021-08-26,"['keyu li', 'jian wang', 'yangxin xu', 'hao qin', 'dongsheng liu', 'li liu', 'max q. -h. meng']"
2103.00845,a brief summary of interactions between meta-learning and   self-supervised learning,cs.lg cs.ai,"this paper briefly reviews the connections between meta-learning and self-supervised learning. meta-learning can be applied to improve model generalization capability and to construct general ai algorithms. self-supervised learning utilizes self-supervision from original data and extracts higher-level generalizable features through unsupervised pre-training or optimization of contrastive loss objectives. in self-supervised learning, data augmentation techniques are widely applied and data labels are not required since pseudo labels can be estimated from trained models on similar tasks. meta-learning aims to adapt trained deep models to solve diverse tasks and to develop general ai algorithms. we review the associations of meta-learning with both generative and contrastive self-supervised learning models. unlabeled data from multiple sources can be jointly considered even when data sources are vastly different. we show that an integration of meta-learning and self-supervised learning models can best contribute to the improvement of model generalization capability. self-supervised learning guided by meta-learner and general meta-learning algorithms under self-supervision are both examples of possible combinations.",,2021-03-01,2021-11-16,['huimin peng']
2103.01205,statistically significant stopping of neural network training,cs.lg cs.ai cs.cv cs.ne,"the general approach taken when training deep learning classifiers is to save the parameters after every few iterations, train until either a human observer or a simple metric-based heuristic decides the network isn't learning anymore, and then backtrack and pick the saved parameters with the best validation accuracy. simple methods are used to determine if a neural network isn't learning anymore because, as long as it's well after the optimal values are found, the condition doesn't impact the final accuracy of the model. however from a runtime perspective, this is of great significance to the many cases where numerous neural networks are trained simultaneously (e.g. hyper-parameter tuning). motivated by this, we introduce a statistical significance test to determine if a neural network has stopped learning. this stopping criterion appears to represent a happy medium compared to other popular stopping criterions, achieving comparable accuracy to the criterions that achieve the highest final accuracies in 77% or fewer epochs, while the criterions which stop sooner do so with an appreciable loss to final accuracy. additionally, we use this as the basis of a new learning rate scheduler, removing the need to manually choose learning rate schedules and acting as a quasi-line search, achieving superior or comparable empirical performance to existing methods.",,2021-03-01,2021-07-27,"['j. k. terry', 'mario jayakumar', 'kusal de alwis']"
2103.01242,cryptonite: a cryptic crossword benchmark for extreme ambiguity in   language,cs.cl cs.ai cs.lg stat.ml,"current nlp datasets targeting ambiguity can be solved by a native speaker with relative ease. we present cryptonite, a large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced. each example in cryptonite is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving requires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. cryptic clues pose a challenge even for experienced solvers, though top-tier experts can solve them with almost 100% accuracy. cryptonite is a challenging task for current models; fine-tuning t5-large on 470k cryptic clues achieves only 7.6% accuracy, on par with the accuracy of a rule-based clue solver (8.6%).",,2021-03-01,2021-11-01,"['avia efrat', 'uri shaham', 'dan kilman', 'omer levy']"
2103.02167,touchless palmprint recognition based on 3d gabor template and block   feature refinement,cs.cv cs.ai,"with the growing demand for hand hygiene and convenience of use, palmprint recognition with touchless manner made a great development recently, providing an effective solution for person identification. despite many efforts that have been devoted to this area, it is still uncertain about the discriminative ability of the contactless palmprint, especially for large-scale datasets. to tackle the problem, in this paper, we build a large-scale touchless palmprint dataset containing 2334 palms from 1167 individuals. to our best knowledge, it is the largest contactless palmprint image benchmark ever collected with regard to the number of individuals and palms. besides, we propose a novel deep learning framework for touchless palmprint recognition named 3dcpn (3d convolution palmprint recognition network) which leverages 3d convolution to dynamically integrate multiple gabor features. in 3dcpn, a novel variant of gabor filter is embedded into the first layer for enhancement of curve feature extraction. with a well-designed ensemble scheme,low-level 3d features are then convolved to extract high-level features. finally on the top, we set a region-based loss function to strengthen the discriminative ability of both global and local descriptors. to demonstrate the superiority of our method, extensive experiments are conducted on our dataset and other popular databases tongji and iitd, where the results show the proposed 3dcpn achieves state-of-the-art or comparable performances.",,2021-03-02,2021-10-31,"['zhaoqun li', 'xu liang', 'dandan fan', 'jinxing li', 'wei jia', 'david zhang']"
2103.02362,video sentiment analysis with bimodal information-augmented multi-head   attention,cs.ai,"humans express feelings or emotions via different channels. take language as an example, it entails different sentiments under different visual-acoustic contexts. to precisely understand human intentions as well as reduce the misunderstandings caused by ambiguity and sarcasm, we should consider multimodal signals including textual, visual and acoustic signals. the crucial challenge is to fuse different modalities of features for sentiment analysis. to effectively fuse the information carried by different modalities and better predict the sentiments, we design a novel multi-head attention based fusion network, which is inspired by the observations that the interactions between any two pair-wise modalities are different and they do not equally contribute to the final sentiment prediction. by assigning the acoustic-visual, acoustic-textual and visual-textual features with reasonable attention and exploiting a residual structure, we attend to attain the significant features. we conduct extensive experiments on four public multimodal datasets including one in chinese and three in english. the results show that our approach outperforms the existing methods and can explain the contributions of bimodal interaction in multiple modalities.",10.1016/j.knosys.2021.107676,2021-03-03,2021-11-16,"['ting wu', 'junjie peng', 'wenqiang zhang', 'huiran zhang', 'chuanshuai ma', 'yansong huang']"
2103.02398,filter-based abstractions with correctness guarantees for planning under   uncertainty,cs.ai cs.ro cs.se cs.sy eess.sy,"we study planning problems for continuous control systems with uncertainty caused by measurement and process noise. the goal is to find an optimal plan that guarantees that the system reaches a desired goal state within finite time. measurement noise causes limited observability of system states, and process noise causes uncertainty in the outcome of a given plan. these factors render the problem undecidable in general. our key contribution is a novel abstraction scheme that employs kalman filtering as a state estimator to obtain a finite-state model, which we formalize as a markov decision process (mdp). for this mdp, we employ state-of-the-art model checking techniques to efficiently compute plans that maximize the probability of reaching goal states. moreover, we account for numerical imprecision in computing the abstraction by extending the mdp with intervals of probabilities as a more robust model. we show the correctness of the abstraction and provide several optimizations that aim to balance the quality of the plan and the scalability of the approach. we demonstrate that our method can handle systems that result in mdps with thousands of states and millions of transitions.",,2021-03-03,2021-03-18,"['thom s. badings', 'nils jansen', 'hasan a. poonawala', 'marielle stoelinga']"
2103.02696,on the importance of sampling in training gcns: tighter analysis and   variance reduction,cs.lg cs.ai cs.cv,"graph convolutional networks (gcns) have achieved impressive empirical advancement across a wide variety of semi-supervised node classification tasks. despite their great success, training gcns on large graphs suffers from computational and memory issues. a potential path to circumvent these obstacles is sampling-based methods, where at each layer a subset of nodes is sampled. although recent studies have empirically demonstrated the effectiveness of sampling-based methods, these works lack theoretical convergence guarantees under realistic settings and cannot fully leverage the information of evolving parameters during optimization. in this paper, we describe and analyze a general doubly variance reduction schema that can accelerate any sampling method under the memory budget. the motivating impetus for the proposed schema is a careful analysis of the variance of sampling methods where it is shown that the induced variance can be decomposed into node embedding approximation variance (zeroth-order variance) during forward propagation and layerwise-gradient variance (first-order variance) during backward propagation. we theoretically analyze the convergence of the proposed schema and show that it enjoys an $\mathcal{o}(1/t)$ convergence rate. we complement our theoretical results by integrating the proposed schema in different sampling methods and applying them to different large real-world graphs.",,2021-03-03,2021-11-01,"['weilin cong', 'morteza ramezani', 'mehrdad mahdavi']"
2103.03874,measuring mathematical problem solving with the math dataset,cs.lg cs.ai cs.cl,"many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. to measure this ability in machine learning models, we introduce math, a new dataset of 12,500 challenging competition mathematics problems. each problem in math has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. to facilitate future research and increase accuracy on math, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. even though we are able to increase accuracy on math, our results show that accuracy remains relatively low, even with enormous transformer models. moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. while scaling transformers is automatically solving most other text-based tasks, scaling is not currently solving math. to have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.",,2021-03-05,2021-11-08,"['dan hendrycks', 'collin burns', 'saurav kadavath', 'akul arora', 'steven basart', 'eric tang', 'dawn song', 'jacob steinhardt']"
2103.03991,passing through narrow gaps with deep reinforcement learning,cs.ro cs.ai,"the u.s. defense advanced research projects agency (darpa) subterranean challenge requires teams of robots to traverse difficult and diverse underground environments. traversing small gaps is one of the challenging scenarios that robots encounter. imperfect sensor information makes it difficult for classical navigation methods, where behaviours require significant manual fine tuning. in this paper we present a deep reinforcement learning method for autonomously navigating through small gaps, where contact between the robot and the gap may be required. we first learn a gap behaviour policy to get through small gaps (only centimeters wider than the robot). we then learn a goal-conditioned behaviour selection policy that determines when to activate the gap behaviour policy. we train our policies in simulation and demonstrate their effectiveness with a large tracked robot in simulation and on the real platform. in simulation experiments, our approach achieves 93\% success rate when the gap behaviour is activated manually by an operator, and 63\% with autonomous activation using the behaviour selection policy. in real robot experiments, our approach achieves a success rate of 73\% with manual activation, and 40\% with autonomous behaviour selection. while we show the feasibility of our approach in simulation, the difference in performance between simulated and real world scenarios highlight the difficulty of direct sim-to-real transfer for deep reinforcement learning policies. in both the simulated and real world environments alternative methods were unable to traverse the gap.",,2021-03-05,2021-11-01,"['brendan tidd', 'akansel cosgun', 'jurgen leitner', 'nicolas hudson']"
2103.05147,model-free policy learning with reward gradients,cs.lg cs.ai,"despite the increasing popularity of policy gradient methods, they are yet to be widely utilized in sample-scarce applications, such as robotics. the sample efficiency could be improved by making best usage of available information. as a key component in reinforcement learning, the reward function is usually devised carefully to guide the agent. hence, the reward function is usually known, allowing access to not only scalar reward signals but also reward gradients. to benefit from reward gradients, previous works require the knowledge of environment dynamics, which are hard to obtain. in this work, we develop the \textit{reward policy gradient} estimator, a novel approach that integrates reward gradients without learning a model. bypassing the model dynamics allows our estimator to achieve a better bias-variance trade-off, which results in a higher sample efficiency, as shown in the empirical analysis. our method also boosts the performance of proximal policy optimization on different mujoco control tasks.",,2021-03-08,2021-11-02,"['qingfeng lan', 'samuele tosatto', 'homayoon farrahi', 'a. rupam mahmood']"
2103.05154,explanations in autonomous driving: a survey,cs.hc cs.ai cs.cy cs.lg cs.ro,"the automotive industry has witnessed an increasing level of development in the past decades; from manufacturing manually operated vehicles to manufacturing vehicles with a high level of automation. with the recent developments in artificial intelligence (ai), automotive companies now employ blackbox ai models to enable vehicles to perceive their environments and make driving decisions with little or no input from a human. with the hope to deploy autonomous vehicles (av) on a commercial scale, the acceptance of av by society becomes paramount and may largely depend on their degree of transparency, trustworthiness, and compliance with regulations. the assessment of the compliance of avs to these acceptance requirements can be facilitated through the provision of explanations for avs' behaviour. explainability is therefore seen as an important requirement for avs. avs should be able to explain what they have 'seen', done, and might do in environments in which they operate.   in this paper, we provide a comprehensive survey of the existing body of work around explainable autonomous driving. first, we open with a motivation for explanations by highlighting and emphasising the importance of transparency, accountability, and trust in avs; and examining existing regulations and standards related to avs. second, we identify and categorise the different stakeholders involved in the development, use, and regulation of avs and elicit their explanation requirements for av. third, we provide a rigorous review of previous work on explanations for the different av operations (i.e., perception, localisation, planning, control, and system management). finally, we identify pertinent challenges and provide recommendations, such as a conceptual framework for av explainability. this survey aims to provide the fundamental knowledge required of researchers who are interested in explainability in avs.",10.1109/tits.2021.3122865,2021-03-08,2021-11-09,"['daniel omeiza', 'helena webb', 'marina jirotka', 'lars kunze']"
2103.05825,ella: exploration through learned language abstraction,cs.cl cs.ai cs.lg cs.ro,"building agents capable of understanding language instructions is critical to effective and robust human-ai collaboration. recent work focuses on training these agents via reinforcement learning in environments with synthetic language; however, instructions often define long-horizon, sparse-reward tasks, and learning policies requires many episodes of experience. we introduce ella: exploration through learned language abstraction, a reward shaping approach geared towards boosting sample efficiency in sparse reward environments by correlating high-level instructions with simpler low-level constituents. ella has two key elements: 1) a termination classifier that identifies when agents complete low-level instructions, and 2) a relevance classifier that correlates low-level instructions with success on high-level tasks. we learn the termination classifier offline from pairs of instructions and terminal states. notably, in departure from prior work in language and abstraction, we learn the relevance classifier online, without relying on an explicit decomposition of high-level instructions to low-level instructions. on a suite of complex babyai environments with varying instruction complexities and reward sparsity, ella shows gains in sample efficiency relative to language-based shaping and traditional rl methods.",,2021-03-09,2021-10-30,"['suvir mirchandani', 'siddharth karamcheti', 'dorsa sadigh']"
2103.06443,"where is your place, visual place recognition?",cs.ro cs.ai cs.cv cs.ir cs.lg,"visual place recognition (vpr) is often characterized as being able to recognize the same place despite significant changes in appearance and viewpoint. vpr is a key component of spatial artificial intelligence, enabling robotic platforms and intelligent augmentation platforms such as augmented reality devices to perceive and understand the physical world. in this paper, we observe that there are three ""drivers"" that impose requirements on spatially intelligent agents and thus vpr systems: 1) the particular agent including its sensors and computational resources, 2) the operating environment of this agent, and 3) the specific task that the artificial agent carries out. in this paper, we characterize and survey key works in the vpr area considering those drivers, including their place representation and place matching choices. we also provide a new definition of vpr based on the visual overlap -- akin to spatial view cells in the brain -- that enables us to find similarities and differences to other research areas in the robotics and computer vision fields. we identify numerous open challenges and suggest areas that require more in-depth attention in future works.",10.24963/ijcai.2021/603,2021-03-10,2021-11-08,"['sourav garg', 'tobias fischer', 'michael milford']"
2103.06624,beta-crown: efficient bound propagation with per-neuron split   constraints for complete and incomplete neural network robustness   verification,cs.lg cs.ai cs.cr stat.ml,"bound propagation based incomplete neural network verifiers such as crown are very efficient and can significantly accelerate branch-and-bound (bab) based complete verification of neural networks. however, bound propagation cannot fully handle the neuron split constraints introduced by bab commonly handled by expensive linear programming (lp) solvers, leading to loose bounds and hurting verification efficiency. in this work, we develop $\beta$-crown, a new bound propagation based method that can fully encode neuron splits via optimizable parameters $\beta$ constructed from either primal or dual space. when jointly optimized in intermediate layers, $\beta$-crown generally produces better bounds than typical lp verifiers with neuron split constraints, while being as efficient and parallelizable as crown on gpus. applied to complete robustness verification benchmarks, $\beta$-crown with bab is up to three orders of magnitude faster than lp-based bab methods, and is notably faster than all existing approaches while producing lower timeout rates. by terminating bab early, our method can also be used for efficient incomplete verification. we consistently achieve higher verified accuracy in many settings compared to powerful incomplete verifiers, including those based on convex barrier breaking techniques. compared to the typically tightest but very costly semidefinite programming (sdp) based incomplete verifiers, we obtain higher verified accuracy with three orders of magnitudes less verification time. our algorithm empowered the $\alpha,\!\beta$-crown (alpha-beta-crown) verifier, the winning tool in vnn-comp 2021. our code is available at http://papercode.cc/betacrown",,2021-03-11,2021-10-31,"['shiqi wang', 'huan zhang', 'kaidi xu', 'xue lin', 'suman jana', 'cho-jui hsieh', 'j. zico kolter']"
2103.06859,understanding the origin of information-seeking exploration in   probabilistic objectives for control,cs.lg cs.ai,"the exploration-exploitation trade-off is central to the description of adaptive behaviour in fields ranging from machine learning, to biology, to economics. while many approaches have been taken, one approach to solving this trade-off has been to equip or propose that agents possess an intrinsic 'exploratory drive' which is often implemented in terms of maximizing the agents information gain about the world -- an approach which has been widely studied in machine learning and cognitive science. in this paper we mathematically investigate the nature and meaning of such approaches and demonstrate that this combination of utility maximizing and information-seeking behaviour arises from the minimization of an entirely difference class of objectives we call divergence objectives. we propose a dichotomy in the objective functions underlying adaptive behaviour between \emph{evidence} objectives, which correspond to well-known reward or utility maximizing objectives in the literature, and \emph{divergence} objectives which instead seek to minimize the divergence between the agent's expected and desired futures, and argue that this new class of divergence objectives could form the mathematical foundation for a much richer understanding of the exploratory components of adaptive and intelligent action, beyond simply greedy utility maximization.",,2021-03-11,2021-11-12,"['beren millidge', 'alexander tschantz', 'anil seth', 'christopher buckley']"
2103.07356,hippocampal formation-inspired probabilistic generative model,cs.ai cs.ne q-bio.nc,"we tackle the challenging task of bridging the gap between the neuroscientific knowledge of hippocampal formation (hpf) and the engineering knowledge of robotics and artificial intelligence. simultaneous localization and mapping (slam) has already been realized in robotics as a basic function for spatial cognition. in this study, we aim to investigate how the slam functionality corresponds to the hpf. to this end, a hypothesis based on a literature review is suggested and a direction for its verification is presented, without performing any new simulations. we survey hpf models and various computational ones, including brain-inspired slam, spatial concept formation, and deep generative models. furthermore, we discuss the relationship between the findings of hpf in neuroscience and slam in robotics. thereby, a hippocampal formation-inspired probabilistic generative model (pgm) was constructed using a methodology for constructing a brain reference architecture. we propose an hpf-pgm as a computational model based on a modification of the conventional slam model, which is designed to be highly consistent with the anatomical structure and functions of the hpf. by referencing the brain, we suggest the importance of the integration of egocentric/allocentric information from the entorhinal cortex to the hippocampus and the use of discrete-event queues.",,2021-03-12,2021-11-10,"['akira taniguchi', 'ayako fukawa', 'hiroshi yamakawa']"
2103.07364,a unified game-theoretic interpretation of adversarial robustness,cs.lg cs.ai cs.cv,"this paper provides a unified view to explain different adversarial attacks and defense methods, i.e. the view of multi-order interactions between input variables of dnns. based on the multi-order interaction, we discover that adversarial attacks mainly affect high-order interactions to fool the dnn. furthermore, we find that the robustness of adversarially trained dnns comes from category-specific low-order interactions. our findings provide a potential method to unify adversarial perturbations and robustness, which can explain the existing defense methods in a principle way. besides, our findings also make a revision of previous inaccurate understanding of the shape bias of adversarially learned features.",,2021-03-12,2021-11-09,"['jie ren', 'die zhang', 'yisen wang', 'lu chen', 'zhanpeng zhou', 'yiting chen', 'xu cheng', 'xin wang', 'meng zhou', 'jie shi', 'quanshi zhang']"
2103.08137,cloth manipulation planning on basis of mesh representations with   incomplete domain knowledge and voxel-to-mesh estimation,cs.ro cs.ai,"we consider the problem of open-goal planning for robotic cloth manipulation. core of our system is a neural network trained as a forward model of cloth behaviour under manipulation, with planning performed through backpropagation. we introduce a neural network-based routine for estimating mesh representations from voxel input, and perform planning in mesh format internally. we address the problem of planning with incomplete domain knowledge by means of an explicit epistemic uncertainty signal. this signal is calculated from prediction divergence between two instances of the forward model network and used to avoid epistemic uncertainty during planning. finally, we introduce logic for handling restriction of grasp points to a discrete set of candidates, in order to accommodate graspability constraints imposed by robotic hardware. we evaluate the system's mesh estimation, prediction, and planning ability on simulated cloth for sequences of one to three manipulations. comparative experiments confirm that planning on basis of estimated meshes improves accuracy compared to voxel-based planning, and that epistemic uncertainty avoidance improves performance under conditions of incomplete domain knowledge. planning time cost is a few seconds. we additionally present qualitative results on robot hardware.",,2021-03-15,2021-11-12,"['solvi arnold', 'daisuke tanaka', 'kimitoshi yamazaki']"
2103.09979,ms*: a new exact algorithm for multi-agent simultaneous multi-goal   sequencing and path finding,cs.ro cs.ai,"in multi-agent applications such as surveillance and logistics, fleets of mobile agents are often expected to coordinate and safely visit a large number of goal locations as efficiently as possible. the multi-agent planning problem in these applications involves allocating and sequencing goals for each agent while simultaneously producing conflict-free paths for the agents. in this article, we introduce a new algorithm called ms* which computes an optimal solution for this multi-agent problem by fusing and advancing state of the art solvers for multi-agent path finding (mapf) and multiple travelling salesman problem (mtsp). ms* leverages our prior subdimensional expansion approach for mapf and embeds the mtsp solvers to optimally allocate and sequence goals for agents. numerical results show that our new algorithm can solve the multi-agent problem with 20 agents and 50 goals in a minute of cpu time on a standard laptop.",10.1109/icra48506.2021.9561779,2021-03-17,,"['zhongqiang ren', 'sivakumar rathinam', 'howie choset']"
2103.10245,building safer autonomous agents by leveraging risky driving behavior   knowledge,cs.lg cs.ai,"simulation environments are good for learning different driving tasks like lane changing, parking or handling intersections etc. in an abstract manner. however, these simulation environments often restrict themselves to operate under conservative interaction behavior amongst different vehicles. but, as we know, real driving tasks often involve very high risk scenarios where other drivers often don't behave in the expected sense. there can be many reasons for this behavior like being tired or inexperienced. the simulation environment doesn't take this information into account while training the navigation agent. therefore, in this study we especially focus on systematically creating these risk prone scenarios with heavy traffic and unexpected random behavior for creating better model-free learning agents. we generate multiple autonomous driving scenarios by creating new custom markov decision process (mdp) environment iterations in the highway-env simulation package. the behavior policy is learnt by agents trained with the help from deep reinforcement learning models. our behavior policy is deliberated to handle collisions and risky randomized driver behavior. we train model free learning agents with supplement information of risk prone driving scenarios and compare their performance with baseline agents. finally, we casually measure the impact of adding these perturbations in the training process to precisely account for the performance improvement obtained from utilizing the learnings from these scenarios.",10.1109/ccci52664.2021.9583209,2021-03-16,2021-10-17,"['ashish rana', 'avleen malhi']"
2103.10685,controllable generation from pre-trained language models via inverse   prompting,cs.cl cs.ai cs.lg,"large-scale pre-trained language models have demonstrated strong capabilities of generating realistic text. however, it remains challenging to control the generation results. previous approaches such as prompting are far from sufficient, which limits the usage of language models. to tackle this challenge, we propose an innovative method, inverse prompting, to better control text generation. the core idea of inverse prompting is to use generated text to inversely predict the prompt during beam search, which enhances the relevance between the prompt and the generated text and provides better controllability. empirically, we pre-train a large-scale chinese language model to perform a systematic study using human evaluation on the tasks of open-domain poem generation and open-domain long-form question answering. our results show that our proposed method substantially outperforms the baselines and that our generation quality is close to human performance on some of the tasks.   narrators can try our poem generation demo at https://pretrain.aminer.cn/apps/poetry.html, while our qa demo can be found at https://pretrain.aminer.cn/app/qa. for researchers, the code is provided in https://github.com/thudm/inverseprompting.",10.1145/3447548.3467418,2021-03-19,2021-11-09,"['xu zou', 'da yin', 'qingyang zhong', 'ming ding', 'hongxia yang', 'zhilin yang', 'jie tang']"
2103.11909,identifying machine-paraphrased plagiarism,cs.cl cs.ai cs.dl,"employing paraphrasing tools to conceal plagiarized text is a severe threat to academic integrity. to enable the detection of machine-paraphrased text, we evaluate the effectiveness of five pre-trained word embedding models combined with machine learning classifiers and state-of-the-art neural language models. we analyze preprints of research papers, graduation theses, and wikipedia articles, which we paraphrased using different configurations of the tools spinbot and spinnerchief. the best performing technique, longformer, achieved an average f1 score of 80.99% (f1=99.68% for spinbot and f1=71.64% for spinnerchief cases), while human evaluators achieved f1=78.4% for spinbot and f1=65.6% for spinnerchief cases. we show that the automated classification alleviates shortcomings of widely-used text-matching systems, such as turnitin and plagscan. to facilitate future research, all data, code, and two web applications showcasing our contributions are openly available.",,2021-03-22,2021-11-15,"['jan philip wahle', 'terry ruas', 'tomáš foltýnek', 'norman meuschke', 'bela gipp']"
2103.12169,a pilot study for fragment identification using 2d nmr and deep learning,q-bio.qm cs.ai cs.lg,"this paper presents a method to identify substructures in nmr spectra of mixtures, specifically 2d spectra, using a bespoke image-based convolutional neural network application. this is done using hsqc and hmbc spectra separately and in combination. the application can reliably detect substructures in pure compounds, using a simple network. it can work for mixtures when trained on pure compounds only. hmbc data and the combination of hmbc and hsqc show better results than hsqc alone.",10.1002/mrc.5212,2021-03-18,,"['stefan kuhn', 'eda tumer', 'simon colreavy-donnelly', 'ricardo moreira borges']"
2103.12450,are neural language models good plagiarists? a benchmark for neural   paraphrase detection,cs.cl cs.ai cs.dl,"the rise of language models such as bert allows for high-quality text paraphrasing. this is a problem to academic integrity, as it is difficult to differentiate between original and machine-generated content. we propose a benchmark consisting of paraphrased articles using recent language models relying on the transformer architecture. our contribution fosters future research of paraphrase detection systems as it offers a large collection of aligned original and paraphrased documents, a study regarding its structure, classification experiments with state-of-the-art systems, and we make our findings publicly available.",,2021-03-23,2021-11-15,"['jan philip wahle', 'terry ruas', 'norman meuschke', 'bela gipp']"
2103.12719,characterizing and improving the robustness of self-supervised learning   through background augmentations,cs.cv cs.ai,"recent progress in self-supervised learning has demonstrated promising results in multiple visual tasks. an important ingredient in high-performing self-supervised methods is the use of data augmentation by training models to place different augmented views of the same image nearby in embedding space. however, commonly used augmentation pipelines treat images holistically, ignoring the semantic relevance of parts of an image-e.g. a subject vs. a background-which can lead to the learning of spurious correlations. our work addresses this problem by investigating a class of simple, yet highly effective ""background augmentations"", which encourage models to focus on semantically-relevant content by discouraging them from focusing on image backgrounds. through a systematic investigation, we show that background augmentations lead to substantial improvements in performance across a spectrum of state-of-the-art self-supervised methods (moco-v2, byol, swav) on a variety of tasks, e.g. $\sim$+1-2% gains on imagenet, enabling performance on par with the supervised baseline. further, we find the improvement in limited-labels settings is even larger (up to 4.2%). background augmentations also improve robustness to a number of distribution shifts, including natural adversarial examples, imagenet-9, adversarial attacks, imagenet-renditions. we also make progress in completely unsupervised saliency detection, in the process of generating saliency masks used for background augmentations.",,2021-03-23,2021-11-12,"['chaitanya k. ryali', 'david j. schwab', 'ari s. morcos']"
2103.13268,address behaviour vulnerabilities in the next generation of autonomous   robots,cs.ro cs.ai,"robots applications in our daily life increase at an unprecedented pace. as robots will soon operate ""out in the wild"", we must identify the safety and security vulnerabilities they will face. robotics researchers and manufacturers focus their attention on new, cheaper, and more reliable applications. still, they often disregard the operability in adversarial environments where a trusted or untrusted user can jeopardize or even alter the robot's task.   in this paper, we identify a new paradigm of security threats in the next generation of robots. these threats fall beyond the known hardware or network-based ones, and we must find new solutions to address them. these new threats include malicious use of the robot's privileged access, tampering with the robot sensors system, and tricking the robot's deliberation into harmful behaviors. we provide a taxonomy of attacks that exploit these vulnerabilities with realistic examples, and we outline effective countermeasures to prevent better, detect, and mitigate them.",,2021-03-24,2021-11-17,['michele colledanchise']
2103.14749,pervasive label errors in test sets destabilize machine learning   benchmarks,stat.ml cs.ai cs.lg,"we identify label errors in the test sets of 10 of the most commonly-used computer vision, natural language, and audio datasets, and subsequently study the potential for these label errors to affect benchmark results. errors in test sets are numerous and widespread: we estimate an average of at least 3.3% errors across the 10 datasets, where for example label errors comprise at least 6% of the imagenet validation set. putative label errors are identified using confident learning algorithms and then human-validated via crowdsourcing (51% of the algorithmically-flagged candidates are indeed erroneously labeled, on average across the datasets). traditionally, machine learning practitioners choose which model to deploy based on test accuracy - our findings advise caution here, proposing that judging models over correctly labeled test sets may be more useful, especially for noisy real-world datasets. surprisingly, we find that lower capacity models may be practically more useful than higher capacity models in real-world datasets with high proportions of erroneously labeled data. for example, on imagenet with corrected labels: resnet-18 outperforms resnet-50 if the prevalence of originally mislabeled test examples increases by just 6%. on cifar-10 with corrected labels: vgg-11 outperforms vgg-19 if the prevalence of originally mislabeled test examples increases by just 5%. test set errors across the 10 datasets can be viewed at https://labelerrors.com and all label errors can be reproduced by https://github.com/cleanlab/label-errors.",,2021-03-26,2021-11-07,"['curtis g. northcutt', 'anish athalye', 'jonas mueller']"
2103.14953,oled: one-class learned encoder-decoder network with adversarial context   masking for novelty detection,cs.cv cs.ai,"novelty detection is the task of recognizing samples that do not belong to the distribution of the target class. during training, the novelty class is absent, preventing the use of traditional classification approaches. deep autoencoders have been widely used as a base of many unsupervised novelty detection methods. in particular, context autoencoders have been successful in the novelty detection task because of the more effective representations they learn by reconstructing original images from randomly masked images. however, a significant drawback of context autoencoders is that random masking fails to consistently cover important structures of the input image, leading to suboptimal representations - especially for the novelty detection task. in this paper, to optimize input masking, we have designed a framework consisting of two competing networks, a mask module and a reconstructor. the mask module is a convolutional autoencoder that learns to generate optimal masks that cover the most important parts of images. alternatively, the reconstructor is a convolutional encoder-decoder that aims to reconstruct unperturbed images from masked images. the networks are trained in an adversarial manner in which the mask module generates masks that are applied to images given to the reconstructor. in this way, the mask module seeks to maximize the reconstruction error that the reconstructor is minimizing. when applied to novelty detection, the proposed approach learns semantically richer representations compared to context autoencoders and enhances novelty detection at test time through more optimal masking. novelty detection experiments on the mnist and cifar-10 image datasets demonstrate the proposed approach's superiority over cutting-edge methods. in a further experiment on the ucsd video dataset for novelty detection, the proposed approach achieves state-of-the-art results.",,2021-03-27,2021-11-09,"['john taylor jewell', 'vahid reza khazaie', 'yalda mohsenzadeh']"
2103.15798,rethinking neural operations for diverse tasks,cs.lg cs.ai cs.cv cs.na math.na stat.ml,"an important goal of automl is to automate-away the design of neural networks on new tasks in under-explored domains. motivated by this goal, we study the problem of enabling users to discover the right neural operations given data from their specific domain. we introduce a search space of operations called xd-operations that mimic the inductive bias of standard multi-channel convolutions while being much more expressive: we prove that it includes many named operations across multiple application areas. starting with any standard backbone such as resnet, we show how to transform it into a search space over xd-operations and how to traverse the space using a simple weight-sharing scheme. on a diverse set of tasks -- solving pdes, distance prediction for protein folding, and music modeling -- our approach consistently yields models with lower error than baseline networks and often even lower error than expert-designed domain-specific approaches.",,2021-03-29,2021-11-04,"['nicholas roberts', 'mikhail khodak', 'tri dao', 'liam li', 'christopher ré', 'ameet talwalkar']"
2103.16329,e-graphsage: a graph neural network based intrusion detection system for   iot,cs.ni cs.ai cs.cr cs.lg,"this paper presents a new network intrusion detection system (nids) based on graph neural networks (gnns). gnns are a relatively new sub-field of deep neural networks, which can leverage the inherent structure of graph-based data. training and evaluation data for nidss are typically represented as flow records, which can naturally be represented in a graph format. this establishes the potential and motivation for exploring gnns for network intrusion detection, which is the focus of this paper. current studies on machine learning-based nidss only consider the network flows independently rather than taking their interconnected patterns into consideration. this is the key limitation in the detection of sophisticated iot network attacks such as ddos and distributed port scan attacks launched by iot devices. in this paper, we propose \mbox{e-graphsage}, a gnn approach that overcomes this limitation and allows capturing both the edge features of a graph as well as the topological information for network anomaly detection in iot networks. to the best of our knowledge, our approach is the first successful, practical, and extensively evaluated approach of applying graph neural networks on the problem of network intrusion detection for iot using flow-based data. our extensive experimental evaluation on four recent nids benchmark datasets shows that our approach outperforms the state-of-the-art in terms of key classification metrics, which demonstrates the potential of gnns in network intrusion detection, and provides motivation for further research.",,2021-03-30,2021-11-01,"['wai weng lo', 'siamak layeghy', 'mohanad sarhan', 'marcus gallagher', 'marius portmann']"
2104.00835,cursed yet satisfied agents,cs.gt cs.ai econ.th,"in real life auctions, a widely observed phenomenon is the winner's curse -- the winner's high bid implies that the winner often over-estimates the value of the good for sale, resulting in an incurred negative utility. the seminal work of eyster and rabin [econometrica'05] introduced a behavioral model aimed to explain this observed anomaly. we term agents who display this bias ""cursed agents"". we adopt their model in the interdependent value setting, and aim to devise mechanisms that prevent the cursed agents from obtaining negative utility. we design mechanisms that are cursed ex-post ic, that is, incentivize agents to bid their true signal even though they are cursed, while ensuring that the outcome is individually rational -- the price the agents pay is no more than the agents' true value.   since the agents might over-estimate the good's value, such mechanisms might require the seller to make positive transfers to the agents to prevent agents from over-paying. for revenue maximization, we give the optimal deterministic and anonymous mechanism. for welfare maximization, we require ex-post budget balance (epbb), as positive transfers might lead to negative revenue. we propose a masking operation that takes any deterministic mechanism, and imposes that the seller would not make positive transfers, enforcing epbb. we show that in typical settings, epbb implies that the mechanism cannot make any positive transfers, implying that applying the masking operation on the fully efficient mechanism results in a socially optimal epbb mechanism. this further implies that if the valuation function is the maximum of agents' signals, the optimal epbb mechanism obtains zero welfare. in contrast, we show that for sum-concave valuations, which include weighted-sum valuations and l_p-norms, the welfare optimal epbb mechanism obtains half of the optimal welfare as the number of agents grows large.",,2021-04-01,2021-11-16,"['yiling chen', 'alon eden', 'juntao wang']"
2104.01328,uncertainty for identifying open-set errors in visual object detection,cs.cv cs.ai cs.lg cs.ro,"deployed into an open world, object detectors are prone to open-set errors, false positive detections of object classes not present in the training dataset. we propose gmm-det, a real-time method for extracting epistemic uncertainty from object detectors to identify and reject open-set errors. gmm-det trains the detector to produce a structured logit space that is modelled with class-specific gaussian mixture models. at test time, open-set errors are identified by their low log-probability under all gaussian mixture models. we test two common detector architectures, faster r-cnn and retinanet, across three varied datasets spanning robotics and computer vision. our results show that gmm-det consistently outperforms existing uncertainty techniques for identifying and rejecting open-set detections, especially at the low-error-rate operating point required for safety-critical applications. gmm-det maintains object detection performance, and introduces only minimal computational overhead. we also introduce a methodology for converting existing object detection datasets into specific open-set datasets to evaluate open-set performance in object detection.",10.1109/lra.2021.3123374,2021-04-03,2021-11-11,"['dimity miller', 'niko sünderhauf', 'michael milford', 'feras dayoub']"
2104.02821,towards measuring fairness in ai: the casual conversations dataset,cs.cv cs.ai cs.lg,"this paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age, genders, apparent skin tones and ambient lighting conditions. our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. the videos were recorded in multiple u.s. states with a diverse set of adults in various age, gender and apparent skin tone groups. a key feature is that each subject agreed to participate for their likenesses to be used. additionally, our age and gender annotations are provided by the subjects themselves. a group of trained annotators labeled the subjects' apparent skin tone using the fitzpatrick skin type scale. moreover, annotations for videos recorded in low ambient lighting are also provided. as an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the deepfake detection challenge (dfdc). experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones and thus may not generalize to all people. in addition, we also evaluate the state-of-the-art apparent age and gender classification methods. our experiments provides a thorough analysis on these models in terms of fair treatment of people from various backgrounds.",,2021-04-06,2021-11-03,"['caner hazirbas', 'joanna bitton', 'brian dolhansky', 'jacqueline pan', 'albert gordo', 'cristian canton ferrer']"
2104.03488,deep features for training support vector machine,cs.cv cs.ai,"features play a crucial role in computer vision. initially designed to detect salient elements by means of handcrafted algorithms, features are now often learned by different layers in convolutional neural networks (cnns). this paper develops a generic computer vision system based on features extracted from trained cnns. multiple learned features are combined into a single structure to work on different image classification tasks. the proposed system was experimentally derived by testing several approaches for extracting features from the inner layers of cnns and using them as inputs to svms that are then combined by sum rule. dimensionality reduction techniques are used to reduce the high dimensionality of inner layers. the resulting vision system is shown to significantly boost the performance of standard cnns across a large and diverse collection of image data sets. an ensemble of different topologies using the same approach obtains state-of-the-art results on a virus data set.",10.3390/jimaging6120143,2021-04-07,2021-06-28,"['loris nanni', 'stefano ghidoni', 'sheryl brahnam']"
2104.04654,regression networks for calculating englacial layer thickness,cs.ai eess.iv,"ice thickness estimation is an important aspect of ice sheet studies. in this work, we use convolutional neural networks with multiple output nodes to regress and learn the thickness of internal ice layers in snow radar images collected in northwest greenland. we experiment with some state-of-the-art networks and find that with the residual connections of resnet50, we could achieve a mean absolute error of 1.251 pixels over the test set. such regression-based networks can further be improved by embedding domain knowledge and radar information in the neural network in order to reduce the requirement of manual annotations.",10.1109/igarss47720.2021.9553596,2021-04-09,2021-06-11,"['debvrat varshney', 'maryam rahnemoonfar', 'masoud yari', 'john paden']"
2104.04696,mptp: motion-planning-aware task planning for navigation in belief space,cs.ro cs.ai,"we present an integrated task-motion planning (tmp) framework for navigation in large-scale environments. of late, tmp for manipulation has attracted significant interest resulting in a proliferation of different approaches. in contrast, tmp for navigation has received considerably less attention. autonomous robots operating in real-world complex scenarios require planning in the discrete (task) space and the continuous (motion) space. in knowledge-intensive domains, on the one hand, a robot has to reason at the highest-level, for example, the objects to procure, the regions to navigate to in order to acquire them; on the other hand, the feasibility of the respective navigation tasks have to be checked at the execution level. this presents a need for motion-planning-aware task planners. in this paper, we discuss a probabilistically complete approach that leverages this task-motion interaction for navigating in large knowledge-intensive domains, returning a plan that is optimal at the task-level. the framework is intended for motion planning under motion and sensing uncertainty, which is formally known as belief space planning. the underlying methodology is validated in simulation, in an office environment and its scalability is tested in the larger willow garage world. a reasonable comparison with a work that is closest to our approach is also provided. we also demonstrate the adaptability of our approach by considering a building floor navigation domain. finally, we also discuss the limitations of our approach and put forward suggestions for improvements and future work.",10.1016/j.robot.2021.103786,2021-04-10,,"['antony thomas', 'fulvio mastrogiovanni', 'marco baglietto']"
2104.05154,machine learning approach to uncovering residential energy consumption   patterns based on socioeconomic and smart meter data,cs.lg cs.ai cs.na math.na,"the smart meter data analysis contributes to better planning and operations for the power system. this study aims to identify the drivers of residential energy consumption patterns from the socioeconomic perspective based on the consumption and demographic data using machine learning. we model consumption patterns by representative loads and reveal the relationship between load patterns and socioeconomic characteristics. specifically, we analyze the real-world smart meter data and extract load patterns by clustering in a robust way. we further identify the influencing socioeconomic attributes on load patterns to improve our method's interpretability. the relationship between consumers' load patterns and selected socioeconomic features is characterized via machine learning models. the findings are as follows. (1) twelve load clusters, consisting of six for weekdays and six for weekends, exhibit a diverse pattern of lifestyle and a difference between weekdays and weekends. (2) among various socioeconomic features, age and education level are suggested to influence the load patterns. (3) our proposed analytical model using feature selection and machine learning is proved to be more effective than xgboost and conventional neural network model in mapping the relationship between load patterns and socioeconomic features.",,2021-04-11,2021-10-31,"['wenjun tang', 'hao wang', 'xian-long lee', 'hong-tzer yang']"
2104.05859,rapid exploration for open-world navigation with latent goal models,cs.ro cs.ai cs.lg,"we describe a robotic learning system for autonomous exploration and navigation in diverse, open-world environments. at the core of our method is a learned latent variable model of distances and actions, along with a non-parametric topological memory of images. we use an information bottleneck to regularize the learned policy, giving us (i) a compact visual representation of goals, (ii) improved generalization capabilities, and (iii) a mechanism for sampling feasible goals for exploration. trained on a large offline dataset of prior experience, the model acquires a representation of visual goals that is robust to task-irrelevant distractors. we demonstrate our method on a mobile ground robot in open-world exploration scenarios. given an image of a goal that is up to 80 meters away, our method leverages its representation to explore and discover the goal in under 20 minutes, even amidst previously-unseen obstacles and weather conditions. please check out the project website for videos of our experiments and information about the real-world dataset used at https://sites.google.com/view/recon-robot.",,2021-04-12,2021-10-29,"['dhruv shah', 'benjamin eysenbach', 'nicholas rhinehart', 'sergey levine']"
2104.06890,an introduction of mini-alphastar,cs.ai,"starcraft ii (sc2) is a real-time strategy game in which players produce and control multiple units to fight against opponent's units. due to its difficulties, such as huge state space, various action space, a long time horizon, and imperfect information, sc2 has been a research hotspot in reinforcement learning. recently, an agent called alphastar (as) has been proposed, which shows good performance, obtaining a high win rate of 99.8% against human players. we implemented a mini-scaled version of it called mini-alphastar (mas) based on as's paper and pseudocode. the difference between as and mas is that we substituted the hyper-parameters of as with smaller ones for mini-scale training. codes of mas are all open-sourced (https://github.com/liuruoze/mini-alphastar) for future research.",,2021-04-14,2021-11-17,"['ruo-ze liu', 'wenhai wang', 'yanjie shen', 'zhiqi li', 'yang yu', 'tong lu']"
2104.07149,on the robustness of intent classification and slot labeling in   goal-oriented dialog systems to real-world noise,cs.cl cs.ai,"intent classification (ic) and slot labeling (sl) models, which form the basis of dialogue systems, often encounter noisy data in real-word environments. in this work, we investigate how robust ic/sl models are to noisy data. we collect and publicly release a test-suite for seven common noise types found in production human-to-bot conversations (abbreviations, casing, misspellings, morphological variants, paraphrases, punctuation and synonyms). on this test-suite, we show that common noise types substantially degrade the ic accuracy and sl f1 performance of state-of-the-art bert-based ic/sl models. by leveraging cross-noise robustness transfer -- training on one noise type to improve robustness on another noise type -- we design aggregate data-augmentation approaches that increase the model performance across all seven noise types by +10.8% for ic accuracy and +15 points for sl f1 on average. to the best of our knowledge, this is the first work to present a single ic/sl model that is robust to a wide range of noise phenomena.",,2021-04-14,2021-11-01,"['sailik sengupta', 'jason krone', 'saab mansour']"
2104.07365,d-cliques: compensating for data heterogeneity with topology in   decentralized federated learning,cs.lg cs.ai cs.dc,"the convergence speed of machine learning models trained with federated learning is significantly affected by heterogeneous data partitions, even more so in a fully decentralized setting without a central server. in this paper, we show that the impact of label distribution skew, an important type of data heterogeneity, can be significantly reduced by carefully designing the underlying communication topology. we present d-cliques, a novel topology that reduces gradient bias by grouping nodes in sparsely interconnected cliques such that the label distribution in a clique is representative of the global label distribution. we also show how to adapt the updates of decentralized sgd to obtain unbiased gradients and implement an effective momentum with d-cliques. our extensive empirical evaluation on mnist and cifar10 demonstrates that our approach provides similar convergence speed as a fully-connected topology, which provides the best convergence in a data heterogeneous setting, with a significant reduction in the number of edges and messages. in a 1000-node topology, d-cliques require 98% less edges and 96% less total messages, with further possible gains using a small-world topology across cliques.",,2021-04-15,2021-11-04,"['aurélien bellet', 'anne-marie kermarrec', 'erick lavoie']"
2104.08368,motion prediction performance analysis for autonomous driving systems   and the effects of tracking noise,cs.cv cs.ai,"autonomous driving consists of a multitude of interacting modules, where each module must contend with errors from the others. typically, the motion prediction module depends upon a robust tracking system to capture each agent's past movement. in this work, we systematically explore the importance of the tracking module for the motion prediction task and ultimately conclude that the overall motion prediction performance is highly sensitive to the tracking module's imperfections. we explicitly compare models that use tracking information to models that do not across multiple scenarios and conditions. we find that the tracking information plays an essential role and improves motion prediction performance in noise-free conditions. however, in the presence of tracking noise, it can potentially affect the overall performance if not studied thoroughly. we thus argue practitioners should be mindful of noise when developing and testing motion/tracking modules, or that they should consider tracking free alternatives.",,2021-04-16,2021-11-12,"['ameni trabelsi', 'ross j. beveridge', 'nathaniel blanchard']"
2104.08620,decrypting cryptic crosswords: semantically complex wordplay puzzles as   a target for nlp,cs.cl cs.ai,"cryptic crosswords, the dominant crossword variety in the uk, are a promising target for advancing nlp systems that seek to process semantically complex, highly compositional language. cryptic clues read like fluent natural language but are adversarially composed of two parts: a definition and a wordplay cipher requiring character-level manipulations. expert humans use creative intelligence to solve cryptics, flexibly combining linguistic, world, and domain knowledge. in this paper, we make two main contributions. first, we present a dataset of cryptic clues as a challenging new benchmark for nlp systems that seek to process compositional language in more creative, human-like ways. after showing that three non-neural approaches and t5, a state-of-the-art neural language model, do not achieve good performance, we make our second main contribution: a novel curriculum approach, in which the model is first fine-tuned on related tasks such as unscrambling words.we also introduce a challenging data split, examine the meta-linguistic capabilities of subword-tokenized models, and investigate model systematicity by perturbing the wordplay part of clues, showing that t5 exhibits behavior partially consistent with human solving strategies. although our curricular approach considerably improves on the t5 baseline, our best-performing model still fails to generalize to the extent that humans can. thus, cryptic crosswords remain an unsolved challenge for nlp systems and a potential source of future innovation.",,2021-04-17,2021-11-05,"['joshua rozner', 'christopher potts', 'kyle mahowald']"
2104.08736,stochastic optimization of areas underprecision-recall curves with   provable convergence,cs.lg cs.ai cs.cv math.oc,"areas under roc (auroc) and precision-recall curves (auprc) are common metrics for evaluating classification performance for imbalanced problems. compared with auroc, auprc is a more appropriate metric for highly imbalanced datasets. while stochastic optimization of auroc has been studied extensively, principled stochastic optimization of auprc has been rarely explored. in this work, we propose a principled technical method to optimize auprc for deep learning. our approach is based on maximizing the averaged precision (ap), which is an unbiased point estimator of auprc. we cast the objective into a sum of {\it dependent compositional functions} with inner functions dependent on random variables of the outer level. we propose efficient adaptive and non-adaptive stochastic algorithms named soap with {\it provable convergence guarantee under mild conditions} by leveraging recent advances in stochastic compositional optimization. extensive experimental results on image and graph datasets demonstrate that our proposed method outperforms prior methods on imbalanced problems in terms of auprc. to the best of our knowledge, our work represents the first attempt to optimize auprc with provable convergence. the soap has been implemented in the libauc library at~\url{https://libauc.org/}.",,2021-04-18,2021-11-10,"['qi qi', 'youzhi luo', 'zhao xu', 'shuiwang ji', 'tianbao yang']"
2104.08762,case-based reasoning for natural language queries over knowledge bases,cs.cl cs.ai cs.lg,"it is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions -- a paradigm known as case-based reasoning (cbr). we propose a neuro-symbolic cbr approach (cbr-kbqa) for question answering over large knowledge bases. cbr-kbqa consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. on several kbqa datasets that contain complex questions, cbr-kbqa achieves competitive performance. for example, on the complexwebquestions dataset, cbr-kbqa outperforms the current state of the art by 11\% on accuracy. furthermore, we show that cbr-kbqa is capable of using new cases \emph{without} any further training: by incorporating a few human-labeled examples in the case memory, cbr-kbqa is able to successfully generate logical forms containing unseen kb entities as well as relations.",,2021-04-18,2021-11-07,"['rajarshi das', 'manzil zaheer', 'dung thai', 'ameya godbole', 'ethan perez', 'jay-yoon lee', 'lizhen tan', 'lazaros polymenakos', 'andrew mccallum']"
2104.08826,gpt3mix: leveraging large-scale language models for text augmentation,cs.cl cs.ai,"large-scale language models such as gpt-3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. this paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples. we also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. we perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. ablation studies and a qualitative analysis provide more insights into our approach.",,2021-04-18,2021-11-18,"['kang min yoo', 'dongju park', 'jaewook kang', 'sang-woo lee', 'woomyeong park']"
2104.08955,many-speakers single channel speech separation with optimal permutation   training,cs.sd cs.ai cs.lg eess.as,"single channel speech separation has experienced great progress in the last few years. however, training neural speech separation for a large number of speakers (e.g., more than 10 speakers) is out of reach for the current methods, which rely on the permutation invariant loss (pit). in this work, we present a permutation invariant training that employs the hungarian algorithm in order to train with an $o(c^3)$ time complexity, where $c$ is the number of speakers, in comparison to $o(c!)$ of pit based methods. furthermore, we present a modified architecture that can handle the increased number of speakers. our approach separates up to $20$ speakers and improves the previous results for large $c$ by a wide margin.",,2021-04-18,2021-11-07,"['shaked dovrat', 'eliya nachmani', 'lior wolf']"
2104.10036,vt-adl: a vision transformer network for image anomaly detection and   localization,cs.cv cs.ai cs.lg,"we present a transformer-based image anomaly detection and localization network. our proposed model is a combination of a reconstruction-based approach and patch embedding. the use of transformer networks helps to preserve the spatial information of the embedded patches, which are later processed by a gaussian mixture density network to localize the anomalous areas. in addition, we also publish btad, a real-world industrial anomaly dataset. our results are compared with other state-of-the-art algorithms using publicly available datasets like mnist and mvtec.",10.1109/isie45552.2021.9576231,2021-04-20,,"['pankaj mishra', 'riccardo verk', 'daniele fornasier', 'claudio piciarelli', 'gian luca foresti']"
2104.10777,viking: variational bayesian variance tracking,cs.lg cs.ai,"we consider the problem of time series forecasting in an adaptive setting. we focus on the inference of state-space models under unknown and potentially time-varying noise variances. we introduce an augmented model in which the variances are represented as auxiliary gaussian latent variables in a tracking mode. as variances are nonnegative, a transformation is chosen and applied to these latent variables. the inference relies on the online variational bayesian methodology, which consists in minimizing a kullback-leibler divergence at each time step. we observe that the minimum of the kullback-leibler divergence is an extension of the kalman filter taking into account the variance uncertainty. we design a novel algorithm, named viking, using these optimal recursive updates. for auxiliary latent variables, we use second-order bounds whose optimum admit closed-form solutions. experiments on synthetic data show that viking behaves well and is robust to misspecification.",,2021-04-16,2021-11-09,"['joseph de vilmarest', 'olivier wintenberger']"
2104.11510,time series forecasting via learning convolutionally low-rank models,cs.lg cs.ai,"recently, liu and zhang studied the rather challenging problem of time series forecasting from the perspective of compressed sensing. they proposed a no-learning method, named convolution nuclear norm minimization (cnnm), and proved that cnnm can exactly recover the future part of a series from its observed part, provided that the series is convolutionally low-rank. while impressive, the convolutional low-rankness condition may not be satisfied whenever the series is far from being seasonal, and is in fact brittle to the presence of trends and dynamics. this paper tries to approach the issues by integrating a learnable, orthonormal transformation into cnnm, with the purpose for converting the series of involute structures into regular signals of convolutionally low-rank. we prove that the resultant model, termed learning-based cnnm (lbcnnm), strictly succeeds in identifying the future part of a series, as long as the transform of the series is convolutionally low-rank. to learn proper transformations that may meet the required success conditions, we devise an interpretable method based on principal component pursuit (pcp). equipped with this learning method and some elaborate data argumentation skills, lbcnnm not only can handle well the major components of time series (including trends, seasonality and dynamics), but also can make use of the forecasts provided by some other forecasting methods; this means lbcnnm can be used as a general tool for model combination. extensive experiments on 100,452 real-world time series from time series data library (tsdl) and m4 competition (m4) demonstrate the superior performance of lbcnnm.",,2021-04-23,2021-11-08,['guangcan liu']
2104.11559,optimizing small berts trained for german ner,cs.cl cs.ai,"currently, the most widespread neural network architecture for training language models is the so called bert which led to improvements in various natural language processing (nlp) tasks. in general, the larger the number of parameters in a bert model, the better the results obtained in these nlp tasks. unfortunately, the memory consumption and the training duration drastically increases with the size of these models. in this article, we investigate various training techniques of smaller bert models: we combine different methods from other bert variants like albert, roberta, and relative positional encoding. in addition, we propose two new fine-tuning modifications leading to better performance: class-start-end tagging and a modified form of linear chain conditional random fields. furthermore, we introduce whole-word attention which reduces berts memory usage and leads to a small increase in performance compared to classical multi-head-attention. we evaluate these techniques on five public german named entity recognition (ner) tasks of which two are introduced by this article.",10.3390/info12110443,2021-04-23,2021-11-01,"['jochen zöllner', 'konrad sperfeld', 'christoph wick', 'roger labahn']"
2104.12643,exploring bayesian deep learning for urgent instructor intervention need   in mooc forums,cs.cl cs.ai,"massive open online courses (moocs) have become a popular choice for e-learning thanks to their great flexibility. however, due to large numbers of learners and their diverse backgrounds, it is taxing to offer real-time support. learners may post their feelings of confusion and struggle in the respective mooc forums, but with the large volume of posts and high workloads for mooc instructors, it is unlikely that the instructors can identify all learners requiring intervention. this problem has been studied as a natural language processing (nlp) problem recently, and is known to be challenging, due to the imbalance of the data and the complex nature of the task. in this paper, we explore for the first time bayesian deep learning on learner-based text posts with two methods: monte carlo dropout and variational inference, as a new solution to assessing the need of instructor interventions for a learner's post. we compare models based on our proposed methods with probabilistic modelling to its baseline non-bayesian models under similar circumstances, for different cases of applying prediction. the results suggest that bayesian deep learning offers a critical uncertainty measure that is not supplied by traditional neural networks. this adds more explainability, trust and robustness to ai, which is crucial in education-based applications. additionally, it can achieve similar or better performance compared to non-probabilistic neural networks, as well as grant lower variance.",10.1007/978-3-030-80421-3_10,2021-04-26,2021-11-15,"['jialin yu', 'laila alrajhi', 'anoushka harit', 'zhongtian sun', 'alexandra i. cristea', 'lei shi']"
2104.14744,human strategic decision making in parametrized games,cs.gt cs.ai cs.lg econ.th,"many real-world games contain parameters which can affect payoffs, action spaces, and information states. for fixed values of the parameters, the game can be solved using standard algorithms. however, in many settings agents must act without knowing the values of the parameters that will be encountered in advance. often the decisions must be made by a human under time and resource constraints, and it is unrealistic to assume that a human can solve the game in real time. we present a new framework that enables human decision makers to make fast decisions without the aid of real-time solvers. we demonstrate applicability to a variety of situations including settings with multiple players and imperfect information.",,2021-04-29,2021-11-07,['sam ganzfried']
2104.14762,gm-mlic: graph matching based multi-label image classification,cs.cv cs.ai,"multi-label image classification (mlic) aims to predict a set of labels that present in an image. the key to deal with such problem is to mine the associations between image contents and labels, and further obtain the correct assignments between images and their labels. in this paper, we treat each image as a bag of instances, and reformulate the task of mlic as an instance-label matching selection problem. to model such problem, we propose a novel deep learning framework named graph matching based multi-label image classification (gm-mlic), where graph matching (gm) scheme is introduced owing to its excellent capability of excavating the instance and label relationship. specifically, we first construct an instance spatial graph and a label semantic graph respectively, and then incorporate them into a constructed assignment graph by connecting each instance to all labels. subsequently, the graph network block is adopted to aggregate and update all nodes and edges state on the assignment graph to form structured representations for each instance and label. our network finally derives a prediction score for each instance-label correspondence and optimizes such correspondence with a weighted cross-entropy loss. extensive experiments conducted on various image datasets demonstrate the superiority of our proposed method.",10.24963/ijcai.2021/163,2021-04-30,2021-05-07,"['yanan wu', 'he liu', 'songhe feng', 'yi jin', 'gengyu lyu', 'zizhang wu']"
2105.00336,comprehensive review on twin support vector machines,cs.lg cs.ai,"twin support vector machine (twsvm) and twin support vector regression (tsvr) are newly emerging efficient machine learning techniques which offer promising solutions for classification and regression challenges respectively. twsvm is based upon the idea to identify two nonparallel hyperplanes which classify the data points to their respective classes. it requires to solve two small sized quadratic programming problems (qpps) in lieu of solving single large size qpp in support vector machine (svm) while tsvr is formulated on the lines of twsvm and requires to solve two svm kind problems. although there has been good research progress on these techniques; there is limited literature on the comparison of different variants of tsvr. thus, this review presents a rigorous analysis of recent research in twsvm and tsvr simultaneously mentioning their limitations and advantages. to begin with we first introduce the basic theory of support vector machine, twsvm and then focus on the various improvements and applications of twsvm, and then we introduce tsvr and its various enhancements. finally, we suggest future research and development prospects.",,2021-05-01,2021-11-06,"['m. tanveer', 't. rajani', 'r. rastogi', 'y. h. shao', 'm. a. ganaie']"
2105.02814,end-to-end deep meta modelling to calibrate and optimize energy   consumption and comfort,eess.sp cs.ai,"in this paper, we propose a new end-to-end methodology to optimize the energy performance as well as comfort and air quality in large buildings without any renovation work. we introduce a metamodel based on recurrent neural networks and trained to predict the behavior of a general class of buildings using a database sampled from a simulation program. this metamodel is then deployed in different frameworks and its parameters are calibrated using the specific data of two real buildings. parameters are estimated by comparing the predictions of the metamodel with real data obtained from sensors using the cma-es algorithm, a derivative free optimization procedure. then, energy consumptions are optimized while maintaining a target thermal comfort and air quality, using the nsga-ii multi-objective optimization procedure. the numerical experiments illustrate how this metamodel ensures a significant gain in energy efficiency, up to almost 10%, while being computationally much more appealing than numerical models and flexible enough to be adapted to several types of buildings.",,2021-02-01,2021-11-05,"['max cohen', 'sylvain le corff', 'maurice charbit', 'marius preda', 'gilles nozière']"
2105.03061,deep reinforcement learning-designed radiofrequency waveform in mri,eess.iv cs.ai cs.lg eess.sp,"carefully engineered radiofrequency (rf) pulses play a key role in a number of systems such as mobile phone, radar, and magnetic resonance imaging. the design of an rf waveform, however, is often posed as an inverse problem with no general solution. as a result, various design methods each with a specific purpose have been developed based on the intuition of human experts. in this work, we propose an artificial intelligence (ai)-powered rf pulse design framework, deeprf, which utilizes the self-learning characteristics of deep reinforcement learning to generate a novel rf pulse. the effectiveness of deeprf is demonstrated using four types of rf pulses that are commonly used. the deeprf-designed pulses successfully satisfy the design criteria while reporting reduced energy. analyses demonstrate the pulses utilize new mechanisms of magnetization manipulation, suggesting the potentials of deeprf in discovering unseen design dimensions beyond human intuition. this work may lay the foundation for an emerging field of ai-driven rf waveform design.",10.1038/s42256-021-00411-1,2021-05-07,2021-11-18,"['dongmyung shin', 'younghoon kim', 'chungseok oh', 'hongjun an', 'juhyung park', 'jiye kim', 'jongho lee']"
2105.03641,diversifying neural text generation with part-of-speech guided softmax   and sampling,cs.cl cs.ai,"neural text generation models are likely to suffer from the low-diversity problem. various decoding strategies and training-based methods have been proposed to promote diversity only by exploiting contextual features, but rarely do they consider incorporating syntactic structure clues. in this work, we propose using linguistic annotation, i.e., part-of-speech (pos), to guide the text generation. in detail, we introduce pos guided softmax to explicitly model two posterior probabilities: (i) next-pos, and (ii) next-token from the vocabulary of the target pos. a pos guided sampling strategy is further proposed to address the low-diversity problem by enriching the diversity of pos. extensive experiments and human evaluations demonstrate that, compared with existing state-of-the-art methods, our pos guided softmax and sampling (posg) can generate more diverse text while maintaining comparable quality.",,2021-05-08,2021-11-16,"['zhixian yang', 'pengxuan xu', 'xiaojun wan']"
2105.03962,stochastic multi-armed bandits with control variates,cs.lg cs.ai stat.ml,"this paper studies a new variant of the stochastic multi-armed bandits problem where auxiliary information about the arm rewards is available in the form of control variates. in many applications like queuing and wireless networks, the arm rewards are functions of some exogenous variables. the mean values of these variables are known a priori from historical data and can be used as control variates. leveraging the theory of control variates, we obtain mean estimates with smaller variance and tighter confidence bounds. we develop an improved upper confidence bound based algorithm named ucb-cv and characterize the regret bounds in terms of the correlation between rewards and control variates when they follow a multivariate normal distribution. we also extend ucb-cv to other distributions using resampling methods like jackknifing and splitting. experiments on synthetic problem instances validate performance guarantees of the proposed algorithms.",,2021-05-09,2021-11-09,"['arun verma', 'manjesh k. hanawal']"
2105.04554,local approximate gaussian process regression for data-driven   constitutive laws: development and comparison with neural networks,cs.ce cs.ai stat.ml,"hierarchical computational methods for multiscale mechanics such as the fe$^2$ and fe-fft methods are generally accompanied by high computational costs. data-driven approaches are able to speed the process up significantly by enabling to incorporate the effective micromechanical response in macroscale simulations without the need of performing additional computations at each gauss point explicitly. traditionally artificial neural networks (anns) have been the surrogate modeling technique of choice in the solid mechanics community. however they suffer from severe drawbacks due to their parametric nature and suboptimal training and inference properties for the investigated datasets in a three dimensional setting. these problems can be avoided using local approximate gaussian process regression (lagpr). this method can allow the prediction of stress outputs at particular strain space locations by training local regression models based on gaussian processes, using only a subset of the data for each local model, offering better and more reliable accuracy than anns. a modified newton-raphson approach is proposed to accommodate for the local nature of the lagpr approximation when solving the global structural problem in a fe setting. hence, the presented work offers a complete and general framework enabling multiscale calculations combining a data-driven constitutive prediction using lagpr, and macroscopic calculations using an fe scheme that we test for finite-strain three-dimensional hyperelastic problems.",10.1016/j.cma.2021.114217,2021-05-07,,"['jan niklas fuhg', 'michele marino', 'nikolaos bouklas']"
2105.04848,forecast analysis of the covid-19 incidence in lebanon: prediction of   future epidemiological trends to plan more effective control programs,cs.ai cs.cy,"ever since the covid-19 pandemic started, all the governments have been trying to limit its effects on their citizens and countries. this pandemic was harsh on different levels for almost all populations worldwide and this is what drove researchers and scientists to get involved and work on several kinds of simulations to get a better insight into this virus and be able to stop it the earliest possible. in this study, we simulate the spread of covid-19 in lebanon using an agent-based model where people are modeled as agents that have specific characteristics and behaviors determined from statistical distributions using monte carlo algorithm. these agents can go into the world, interact with each other, and thus, infect each other. this is how the virus spreads. during the simulation, we can introduce different non-pharmaceutical interventions - or more commonly npis - that aim to limit the spread of the virus (wearing a mask, closing locations, etc). our simulator was first validated on concepts (e.g. flattening the curve and second wave scenario), and then it was applied on the case of lebanon. we studied the effect of opening schools and universities on the pandemic situation in the country since the lebanese ministry of education is planning to do so progressively, starting from 21 april 2021. based on the results we obtained, we conclude that it would be better to delay the school openings while the vaccination campaign is still slow in the country.",10.1109/icabme53305.2021.9604861,2021-05-11,2021-06-22,"['salah el falou', 'fouad trad']"
2105.05873,out of the box: embodied navigation in the real world,cs.cv cs.ai cs.ro,"the research field of embodied ai has witnessed substantial progress in visual navigation and exploration thanks to powerful simulating platforms and the availability of 3d data of indoor and photorealistic environments. these two factors have opened the doors to a new generation of intelligent agents capable of achieving nearly perfect pointgoal navigation. however, such architectures are commonly trained with millions, if not billions, of frames and tested in simulation. together with great enthusiasm, these results yield a question: how many researchers will effectively benefit from these advances? in this work, we detail how to transfer the knowledge acquired in simulation into the real world. to that end, we describe the architectural discrepancies that damage the sim2real adaptation ability of models trained on the habitat simulator and propose a novel solution tailored towards the deployment in real-world scenarios. we then deploy our models on a locobot, a low-cost robot equipped with a single intel realsense camera. different from previous work, our testing scene is unavailable to the agent in simulation. the environment is also inaccessible to the agent beforehand, so it cannot count on scene-specific semantic priors. in this way, we reproduce a setting in which a research group (potentially from other fields) needs to employ the agent visual navigation capabilities as-a-service. our experiments indicate that it is possible to achieve satisfying results when deploying the obtained model in the real world. our code and models are available at https://github.com/aimagelab/loconav.",10.1007/978-3-030-89128-2_5,2021-05-12,,"['roberto bigazzi', 'federico landi', 'marcella cornia', 'silvia cascianelli', 'lorenzo baraldi', 'rita cucchiara']"
2105.06677,xai handbook: towards a unified framework for explainable ai,cs.ai cs.cv cs.hc cs.lg,"the field of explainable ai (xai) has quickly become a thriving and prolific community. however, a silent, recurrent and acknowledged issue in this area is the lack of consensus regarding its terminology. in particular, each new contribution seems to rely on its own (and often intuitive) version of terms like ""explanation"" and ""interpretation"". such disarray encumbers the consolidation of advances in the field towards the fulfillment of scientific and regulatory demands e.g., when comparing methods or establishing their compliance with respect to biases and fairness constraints. we propose a theoretical framework that not only provides concrete definitions for these terms, but it also outlines all steps necessary to produce explanations and interpretations. the framework also allows for existing contributions to be re-contextualized such that their scope can be measured, thus making them comparable to other methods. we show that this framework is compliant with desiderata on explanations, on interpretability and on evaluation metrics. we present a use-case showing how the framework can be used to compare lime, shap and mdnet, establishing their advantages and shortcomings. finally, we discuss relevant trends in xai as well as recommendations for future work, all from the standpoint of our framework.",,2021-05-14,,"['sebastian palacio', 'adriano lucieri', 'mohsin munir', 'jörn hees', 'sheraz ahmed', 'andreas dengel']"
2105.06742,cybersecurity anomaly detection in adversarial environments,cs.cr cs.ai stat.ml,"the proliferation of interconnected battlefield information-sharing devices, known as the internet of battlefield things (iobt), introduced several security challenges. inherent to the iobt operating environment is the practice of adversarial machine learning, which attempts to circumvent machine learning models. this work examines the feasibility of cost-effective unsupervised learning and graph-based methods for anomaly detection in the network intrusion detection system setting, and also leverages an ensemble approach to supervised learning of the anomaly detection problem. we incorporate a realistic adversarial training mechanism when training supervised models to enable strong classification performance in adversarial environments. the results indicate that the unsupervised and graph-based methods were outperformed in detecting anomalies (malicious activity) by the supervised stacking ensemble method with two levels. this model consists of three different classifiers in the first level, followed by either a naive bayes or decision tree classifier for the second level. the model maintains an f1-score above 0.97 for malicious samples across all tested level two classifiers. notably, naive bayes is the fastest level two classifier averaging 1.12 seconds while decision tree maintains the highest auc score of 0.98.",,2021-05-14,2021-11-02,"['david a. bierbrauer', 'alexander chang', 'will kritzer', 'nathaniel d. bastian']"
2105.07253,regret minimization experience replay in off-policy reinforcement   learning,cs.lg cs.ai,"in reinforcement learning, experience replay stores past samples for further reuse. prioritized sampling is a promising technique to better utilize these samples. previous criteria of prioritization include td error, recentness and corrective feedback, which are mostly heuristically designed. in this work, we start from the regret minimization objective, and obtain an optimal prioritization strategy for bellman update that can directly maximize the return of the policy. the theory suggests that data with higher hindsight td error, better on-policiness and more accurate q value should be assigned with higher weights during sampling. thus most previous criteria only consider this strategy partially. we not only provide theoretical justifications for previous criteria, but also propose two new methods to compute the prioritization weight, namely remern and remert. remern learns an error network, while remert exploits the temporal ordering of states. both methods outperform previous prioritized sampling algorithms in challenging rl benchmarks, including mujoco, atari and meta-world.",,2021-05-15,2021-11-09,"['xu-hui liu', 'zhenghai xue', 'jing-cheng pang', 'shengyi jiang', 'feng xu', 'yang yu']"
2105.07540,deep learning for detecting pulmonary tuberculosis via chest   radiography: an international study across 10 countries,eess.iv cs.ai cs.cv,"tuberculosis (tb) is a top-10 cause of death worldwide. though the who recommends chest radiographs (cxrs) for tb screening, the limited availability of cxr interpretation is a barrier. we trained a deep learning system (dls) to detect active pulmonary tb using cxrs from 9 countries across africa, asia, and europe, and utilized large-scale cxr pretraining, attention pooling, and noisy student semi-supervised learning. evaluation was on (1) a combined test set spanning china, india, us, and zambia, and (2) an independent mining population in south africa. given who targets of 90% sensitivity and 70% specificity, the dls's operating point was prespecified to favor sensitivity over specificity. on the combined test set, the dls's roc curve was above all 9 india-based radiologists, with an auc of 0.90 (95%ci 0.87-0.92). the dls's sensitivity (88%) was higher than the india-based radiologists (75% mean sensitivity), p<0.001 for superiority; and its specificity (79%) was non-inferior to the radiologists (84% mean specificity), p=0.004. similar trends were observed within hiv positive and sputum smear positive sub-groups, and in the south africa test set. we found that 5 us-based radiologists (where tb isn't endemic) were more sensitive and less specific than the india-based radiologists (where tb is endemic). the dls also remained non-inferior to the us-based radiologists. in simulations, using the dls as a prioritization tool for confirmatory testing reduced the cost per positive case detected by 40-80% compared to using confirmatory testing alone. to conclude, our dls generalized to 5 countries, and merits prospective evaluation to assist cost-effective screening efforts in radiologist-limited settings. operating point flexibility may permit customization of the dls to account for site-specific factors such as tb prevalence, demographics, clinical resources, and customary practice patterns.",,2021-05-16,2021-10-29,"['sahar kazemzadeh', 'jin yu', 'shahar jamshy', 'rory pilgrim', 'zaid nabulsi', 'christina chen', 'neeral beladia', 'charles lau', 'scott mayer mckinney', 'thad hughes', 'atilla kiraly', 'sreenivasa raju kalidindi', 'monde muyoyeta', 'jameson malemela', 'ting shih', 'greg s. corrado', 'lily peng', 'katherine chou', 'po-hsuan cameron chen', 'yun liu', 'krish eswaran', 'daniel tse', 'shravya shetty', 'shruthi prabhakara']"
2105.07831,how to explain neural networks: an approximation perspective,cs.lg cs.ai,"the lack of interpretability has hindered the large-scale adoption of ai technologies. however, the fundamental idea of interpretability, as well as how to put it into practice, remains unclear. we provide notions of interpretability based on approximation theory in this study. we first implement this approximation interpretation on a specific model (fully connected neural network) and then propose to use mlp as a universal interpreter to explain arbitrary black-box models. extensive experiments demonstrate the effectiveness of our approach.",,2021-05-17,2021-11-17,"['hangcheng dong', 'bingguo liu', 'fengdong chen', 'dong ye', 'guodong liu']"
2105.08847,"beyond ""fairness:"" structural (in)justice lenses on ai for education",cs.cy cs.ai cs.hc,"educational technologies, and the systems of schooling in which they are deployed, enact particular ideologies about what is important to know and how learners should learn. as artificial intelligence technologies -- in education and beyond -- may contribute to inequitable outcomes for marginalized communities, various approaches have been developed to evaluate and mitigate the harmful impacts of ai. however, we argue in this paper that the dominant paradigm of evaluating fairness on the basis of performance disparities in ai models is inadequate for confronting the systemic inequities that educational ai systems (re)produce. we draw on a lens of structural injustice informed by critical theory and black feminist scholarship to critically interrogate several widely-studied and widely-adopted categories of educational ai and explore how they are bound up in and reproduce historical legacies of structural injustice and inequity, regardless of the parity of their models' performance. we close with alternative visions for a more equitable future for educational ai.",,2021-05-18,2021-11-01,"['michael madaio', 'su lin blodgett', 'elijah mayfield', 'ezekiel dixon-román']"
2105.08923,reinforcement learning assisted oxygen therapy for covid-19 patients   under intensive care,cs.lg cs.ai,"patients with severe coronavirus disease 19 (covid-19) typically require supplemental oxygen as an essential treatment. we developed a machine learning algorithm, based on a deep reinforcement learning (rl), for continuous management of oxygen flow rate for critical ill patients under intensive care, which can identify the optimal personalized oxygen flow rate with strong potentials to reduce mortality rate relative to the current clinical practice. basically, we modeled the oxygen flow trajectory of covid-19 patients and their health outcomes as a markov decision process. based on individual patient characteristics and health status, a reinforcement learning based oxygen control policy is learned and real-time recommends the oxygen flow rate to reduce the mortality rate. we assessed the performance of proposed methods through cross validation by using a retrospective cohort of 1,372 critically ill patients with covid-19 from new york university langone health ambulatory care with electronic health records from april 2020 to january 2021. the mean mortality rate under the rl algorithm is lower than standard of care by 2.57% (95% ci: 2.08- 3.06) reduction (p<0.001) from 7.94% under the standard of care to 5.37 % under our algorithm and the averaged recommended oxygen flow rate is 1.28 l/min (95% ci: 1.14-1.42) lower than the rate actually delivered to patients. thus, the rl algorithm could potentially lead to better intensive care treatment that can reduce mortality rate, while saving the oxygen scarce resources. it can reduce the oxygen shortage issue and improve public health during the covid-19 pandemic.",,2021-05-19,2021-11-06,"['hua zheng', 'jiahao zhu', 'wei xie', 'judy zhong']"
2105.09829,personalized counterfactual fairness in recommendation,cs.ir cs.ai cs.lg,"recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. therefore, it is crucial to address the potential unfairness problems in recommendations. just like users have personalized preferences on items, users' demands for fairness are also personalized in many scenarios. therefore, it is important to provide personalized fair recommendations for users to satisfy their personalized fairness demands. besides, previous works on fair recommendation mainly focus on association-based fairness. however, it is important to advance from associative fairness notions to causal fairness notions for assessing fairness more properly in recommender systems. based on the above considerations, this paper focuses on achieving personalized counterfactual fairness for users in recommender systems. to this end, we introduce a framework for achieving counterfactually fair recommendations through adversary learning by generating feature-independent user embeddings for recommendation. the framework allows recommender systems to achieve personalized fairness for users while also covering non-personalized situations. experiments on two real-world datasets with shallow and deep recommendation algorithms show that our method can generate fairer recommendations for users with a desirable recommendation performance.",10.1145/3404835.3462966,2021-05-20,2021-11-04,"['yunqi li', 'hanxiong chen', 'shuyuan xu', 'yingqiang ge', 'yongfeng zhang']"
2105.11367,fedscale: benchmarking model and system performance of federated   learning at scale,cs.lg cs.ai cs.dc cs.pf,"we present fedscale, a diverse set of challenging and realistic benchmark datasets to facilitate scalable, comprehensive, and reproducible federated learning (fl) research. fedscale datasets are large-scale, encompassing a diverse range of important fl tasks, such as image classification, object detection, word prediction, and speech recognition. for each dataset, we provide a unified evaluation protocol using realistic data splits and evaluation metrics. to meet the pressing need for reproducing realistic fl at scale, we have also built an efficient evaluation platform to simplify and standardize the process of fl experimental setup and model evaluation. our evaluation platform provides flexible apis to implement new fl algorithms and includes new execution backends with minimal developer efforts. finally, we perform in-depth benchmark experiments on these datasets. our experiments suggest fruitful opportunities in heterogeneity-aware co-optimizations of the system and statistical efficiency under realistic fl characteristics. fedscale is open-source with permissive licenses and actively maintained, and we welcome feedback and contributions from the community.",,2021-05-24,2021-11-02,"['fan lai', 'yinwei dai', 'xiangfeng zhu', 'harsha v. madhyastha', 'mosharaf chowdhury']"
2105.11686,towards understanding the condensation of neural networks at initial   training,cs.lg cs.ai,"implicit regularization is important for understanding the learning of neural networks (nns). empirical works show that input weights of hidden neurons (the input weight of a hidden neuron consists of the weight from its input layer to the hidden neuron and its bias term) condense on isolated orientations with a small initialization. the condensation dynamics implies that the training implicitly regularizes a nn towards one with much smaller effective size. in this work, we utilize multilayer networks to show that the maximal number of condensed orientations in the initial training stage is twice the multiplicity of the activation function, where ""multiplicity"" is multiple roots of activation function at origin. our theoretical analysis confirms experiments for two cases, one is for the activation function of multiplicity one with arbitrary dimension input, which contains many common activation functions, and the other is for the layer with one-dimensional input and arbitrary multiplicity. this work makes a step towards understanding how small initialization implicitly leads nns to condensation at initial training stage, which lays a foundation for the future study of the nonlinear dynamics of nns and its implicit regularization effect at a later stage of training.",,2021-05-25,2021-11-17,"['zhi-qin john xu', 'hanxu zhou', 'tao luo', 'yaoyu zhang']"
2105.12564,predicting invasive ductal carcinoma using a reinforcement sample   learning strategy using deep learning,cs.cv cs.ai cs.lg eess.iv,"invasive ductal carcinoma is a prevalent, potentially deadly disease associated with a high rate of morbidity and mortality. its malignancy is the second leading cause of death from cancer in women. the mammogram is an extremely useful resource for mass detection and invasive ductal carcinoma diagnosis. we are proposing a method for invasive ductal carcinoma that will use convolutional neural networks (cnn) on mammograms to assist radiologists in diagnosing the disease. due to the varying image clarity and structure of certain mammograms, it is difficult to observe major cancer characteristics such as microcalcification and mass, and it is often difficult to interpret and diagnose these attributes. the aim of this study is to establish a novel method for fully automated feature extraction and classification in invasive ductal carcinoma computer-aided diagnosis (cad) systems. this article presents a tumor classification algorithm that makes novel use of convolutional neural networks on breast mammogram images to increase feature extraction and training speed. the algorithm makes two contributions.",,2021-05-26,2021-11-07,['rushabh patel']
2105.12960,hybrid encoding for generating large scale game level patterns with   local variations,cs.ne cs.ai,"generative adversarial networks (gans) are a powerful indirect genotype-to-phenotype mapping for evolutionary search. much previous work applying gans to level generation focuses on fixed-size segments combined into a whole level, but individual segments may not fit together cohesively. in contrast, segments in human designed levels are often repeated, directly or with variation, and organized into patterns (the symmetric eagle in level 1 of the legend of zelda, or repeated pipe motifs in super mario bros). such patterns can be produced with compositional pattern producing networks (cppns). cppns define latent vector gan inputs as a function of geometry, organizing segments output by a gan into complete levels. however, collections of latent vectors can also be evolved directly, producing more chaotic levels. we propose a hybrid approach that evolves cppns first, but allows latent vectors to evolve later, combining the benefits of both approaches. these approaches are evaluated in super mario bros. and the legend of zelda. we previously demonstrated via divergent search (map-elites) that cppns better cover the space of possible levels than directly evolved levels. here, we show that the hybrid approach (1) covers areas that neither of the other methods can, and (2) achieves comparable or superior qd scores.",,2021-05-27,2021-11-12,"['jacob schrum', 'benjamin capps', 'kirby steckel', 'vanessa volz', 'sebastian risi']"
2105.13283,deep ensembles from a bayesian perspective,cs.lg cs.ai stat.ml,"deep ensembles can be considered as the current state-of-the-art for uncertainty quantification in deep learning. while the approach was originally proposed as a non-bayesian technique, arguments supporting its bayesian footing have been put forward as well. we show that deep ensembles can be viewed as an approximate bayesian method by specifying the corresponding assumptions. our findings lead to an improved approximation which results in an enlarged epistemic part of the uncertainty. numerical examples suggest that the improved approximation can lead to more reliable uncertainties. analytical derivations ensure easy calculation of results.",,2021-05-27,2021-11-18,"['lara hoffmann', 'clemens elster']"
2105.14399,enhanced isotropy maximization loss: seamless and high-performance   out-of-distribution detection simply replacing the softmax loss,cs.lg cs.ai cs.cv cs.ne,"current out-of-distribution detection approaches usually present special requirements (e.g., collecting outlier data and hyperparameter validation) and produce side effects (e.g., classification accuracy drop and slow/inefficient inferences). recently, entropic out-of-distribution detection has been proposed as a seamless approach (i.e., a solution that avoids all previously mentioned drawbacks). the entropic out-of-distribution detection solution uses the isomax loss for training and the entropic score for out-of-distribution detection. the isomax loss works as a drop-in replacement of the softmax loss (i.e., the combination of the output linear layer, the softmax activation, and the cross-entropy loss) because swapping the softmax loss with the isomax loss requires no changes in the model's architecture or training procedures/hyperparameters. in this paper, we perform what we call an isometrization of the distances used in the isomax loss. additionally, we propose replacing the entropic score with the minimum distance score. experiments showed that these modifications significantly increase out-of-distribution detection performance while keeping the solution seamless. besides being competitive with or outperforming all major current approaches, the proposed solution avoids all their current limitations in addition to being much easier to use because only a simple loss replacement for training the neural network is required. the code to replace the softmax loss with the isomax+ loss and reproduce the results is available at https://github.com/dlmacedo/entropic-out-of-distribution-detection.",,2021-05-29,2021-11-16,"['david macêdo', 'teresa ludermir']"
2105.14426,icdar 2021 competition on scientific table image recognition to latex,cs.ir cs.ai cs.cv,"tables present important information concisely in many scientific documents. visual features like mathematical symbols, equations, and spanning cells make structure and content extraction from tables embedded in research documents difficult. this paper discusses the dataset, tasks, participants' methods, and results of the icdar 2021 competition on scientific table image recognition to latex. specifically, the task of the competition is to convert a tabular image to its corresponding latex source code. we proposed two subtasks. in subtask 1, we ask the participants to reconstruct the latex structure code from an image. in subtask 2, we ask the participants to reconstruct the latex content code from an image. this report describes the datasets and ground truth specification, details the performance evaluation metrics used, presents the final results, and summarizes the participating methods. submission by team vcgroup got the highest exact match accuracy score of 74% for subtask 1 and 55% for subtask 2, beating previous baselines by 5% and 12%, respectively. although improvements can still be made to the recognition capabilities of models, this competition contributes to the development of fully automated table recognition systems by challenging practitioners to solve problems under specific constraints and sharing their approaches; the platform will remain available for post-challenge submissions at https://competitions.codalab.org/competitions/26979 .",,2021-05-30,2021-11-11,"['pratik kayal', 'mrinal anand', 'harsh desai', 'mayank singh']"
2105.14713,1xn pattern for pruning convolutional neural networks,cs.cv cs.ai,"though network pruning receives popularity in reducing the complexity of convolutional neural networks (cnns), it remains an open issue to concurrently maintain model accuracy as well as achieve significant speedups on general cpus. in this paper, we propose a novel 1xn pruning pattern to break this limitation. in particular, consecutive n output kernels with the same input channel index are grouped into one block, which serves as a basic pruning granularity of our pruning pattern. our 1xn pattern prunes these blocks considered unimportant. we also provide a workflow of filter rearrangement that first rearranges the weight matrix in the output channel dimension to derive more influential blocks for accuracy improvements and then applies similar rearrangement to the next-layer weights in the input channel dimension to ensure correct convolutional operations. moreover, the output computation after our 1xn pruning can be realized via a parallelized block-wise vectorized operation, leading to significant speedups on general cpus. the efficacy of our pruning pattern is proved with experiments on ilsvrc-2012. for example, given the pruning rate of 50% and n=4, our pattern obtains about 3.0% improvements over filter pruning in the top-1 accuracy of mobilenet-v2. meanwhile, it obtains 56.04ms inference savings on cortex-a7 cpu over weight pruning. our project is made available at https://github.com/lmbxmu/1xn.",,2021-05-31,2021-11-17,"['mingbao lin', 'yuxin zhang', 'yuchao li', 'bohong chen', 'fei chao', 'mengdi wang', 'shen li', 'yonghong tian', 'rongrong ji']"
2106.00009,deep-learning discovers macroscopic governing equations for viscous   gravity currents from microscopic simulation data,physics.comp-ph cs.ai cs.lg physics.data-an,"although deep-learning has been successfully applied in a variety of science and engineering problems owing to its strong high-dimensional nonlinear mapping capability, it is of limited use in scientific knowledge discovery. in this work, we propose a deep-learning based framework to discover the macroscopic governing equation of viscous gravity current based on high-resolution microscopic simulation data without the need for prior knowledge of underlying terms. for two typical scenarios with different viscosity ratios, the deep-learning based equations exactly capture the same dominated terms as the theoretically derived equations for describing long-term asymptotic behaviors, which validates the proposed framework. unknown macroscopic equations are then obtained for describing short-term behaviors, and additional deep-learned compensation terms are eventually discovered. comparison of posterior tests shows that the deep-learning based pdes actually perform better than the theoretically derived pdes in predicting evolving viscous gravity currents for both long-term and short-term regimes. moreover, the proposed framework is proven to be very robust against non-biased data noise for training, which is up to 20%. consequently, the presented deep-learning framework shows considerable potential for discovering unrevealed intrinsic laws in scientific semantic space from raw experimental or simulation results in data space.",,2021-05-30,2021-11-18,"['junsheng zeng', 'hao xu', 'yuntian chen', 'dongxiao zhang']"
2106.00421,openbox: a generalized black-box optimization service,cs.lg cs.ai,"black-box optimization (bbo) has a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. however, it remains a challenge for users to apply bbo methods to their problems at hand with existing software packages, in terms of applicability, performance, and efficiency. in this paper, we build openbox, an open-source and general-purpose bbo service with improved usability. the modular design behind openbox also facilitates flexible abstraction and optimization of basic bbo components that are common in other existing systems. openbox is distributed, fault-tolerant, and scalable. to improve efficiency, openbox further utilizes ""algorithm agnostic"" parallelization and transfer learning. our experimental results demonstrate the effectiveness and efficiency of openbox compared to existing systems.",10.1145/3447548.3467061,2021-06-01,2021-11-04,"['yang li', 'yu shen', 'wentao zhang', 'yuanwei chen', 'huaijun jiang', 'mingchao liu', 'jiawei jiang', 'jinyang gao', 'wentao wu', 'zhi yang', 'ce zhang', 'bin cui']"
2106.00545,counterfactual invariance to spurious correlations: why and how to pass   stress tests,cs.lg cs.ai stat.ml,"informally, a 'spurious correlation' is the dependence of a model on some aspect of the input data that an analyst thinks shouldn't matter. in machine learning, these have a know-it-when-you-see-it character; e.g., changing the gender of a sentence's subject changes a sentiment predictor's output. to check for spurious correlations, we can 'stress test' models by perturbing irrelevant parts of input data and seeing if model predictions change. in this paper, we study stress testing using the tools of causal inference. we introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input shouldn't change model predictions. we connect counterfactual invariance to out-of-domain model performance, and provide practical schemes for learning (approximately) counterfactual invariant predictors (without access to counterfactual examples). it turns out that both the means and implications of counterfactual invariance depend fundamentally on the true underlying causal structure of the data -- in particular, whether the label causes the features or the features cause the label. distinct causal structures require distinct regularization schemes to induce counterfactual invariance. similarly, counterfactual invariance implies different domain shift guarantees depending on the underlying causal structure. this theory is supported by empirical results on text classification.",,2021-05-31,2021-11-02,"['victor veitch', ""alexander d'amour"", 'steve yadlowsky', 'jacob eisenstein']"
2106.01596,semantic-aware contrastive learning for multi-object medical image   segmentation,cs.cv cs.ai cs.lg,"medical image segmentation, or computing voxelwise semantic masks, is a fundamental yet challenging task to compute a voxel-level semantic mask. to increase the ability of encoder-decoder neural networks to perform this task across large clinical cohorts, contrastive learning provides an opportunity to stabilize model initialization and enhance encoders without labels. however, multiple target objects (with different semantic meanings) may exist in a single image, which poses a problem for adapting traditional contrastive learning methods from prevalent 'image-level classification' to 'pixel-level segmentation'. in this paper, we propose a simple semantic-aware contrastive learning approach leveraging attention masks to advance multi-object semantic segmentation. briefly, we embed different semantic objects to different clusters rather than the traditional image-level embeddings. we evaluate our proposed method on a multi-organ medical image segmentation task with both in-house data and miccai challenge 2015 btcv datasets. compared with current state-of-the-art training strategies, our proposed pipeline yields a substantial improvement of 5.53% and 6.09% on dice score for both medical image segmentation cohorts respectively (p-value<0.01). the performance of the proposed method is further assessed on natural images via the pascal voc 2012 dataset, and achieves a substantial improvement of 2.75% on miou (p-value<0.01).",,2021-06-03,2021-11-08,"['ho hin lee', 'yucheng tang', 'qi yang', 'xin yu', 'shunxing bao', 'leon y. cai', 'lucas w. remedios', 'bennett a. landman', 'yuankai huo']"
2106.01834,continual learning in deep networks: an analysis of the last layer,cs.lg cs.ai,"we study how different output layers in a deep neural network learn and forget in continual learning settings. the following three factors can affect catastrophic forgetting in the output layer: (1) weights modifications, (2) interference, and (3) projection drift. in this paper, our goal is to provide more insights into how changing the output layers may address (1) and (2). some potential solutions to those issues are proposed and evaluated here in several continual learning scenarios. we show that the best-performing type of the output layer depends on the data distribution drifts and/or the amount of data available. in particular, in some cases where a standard linear layer would fail, it turns out that changing parameterization is sufficient in order to achieve a significantly better performance, whithout introducing a continual-learning algorithm and instead using the standard sgd to train a model. our analysis and results shed light on the dynamics of the output layer in continual learning scenarios, and suggest a way of selecting the best type of output layer for a given scenario.",,2021-06-03,2021-11-18,"['timothée lesort', 'thomas george', 'irina rish']"
2106.01883,learning high-precision bounding box for rotated object detection via   kullback-leibler divergence,cs.cv cs.ai cs.lg,"existing rotated object detectors are mostly inherited from the horizontal detection paradigm, as the latter has evolved into a well-developed area. however, these detectors are difficult to perform prominently in high-precision detection due to the limitation of current regression loss design, especially for objects with large aspect ratios. taking the perspective that horizontal detection is a special case for rotated object detection, in this paper, we are motivated to change the design of rotation regression loss from induction paradigm to deduction methodology, in terms of the relation between rotation and horizontal detection. we show that one essential challenge is how to modulate the coupled parameters in the rotation regression loss, as such the estimated parameters can influence to each other during the dynamic joint optimization, in an adaptive and synergetic way. specifically, we first convert the rotated bounding box into a 2-d gaussian distribution, and then calculate the kullback-leibler divergence (kld) between the gaussian distributions as the regression loss. by analyzing the gradient of each parameter, we show that kld (and its derivatives) can dynamically adjust the parameter gradients according to the characteristics of the object. it will adjust the importance (gradient weight) of the angle parameter according to the aspect ratio. this mechanism can be vital for high-precision detection as a slight angle error would cause a serious accuracy drop for large aspect ratios objects. more importantly, we have proved that kld is scale invariant. we further show that the kld loss can be degenerated into the popular $l_{n}$-norm loss for horizontal detection. experimental results on seven datasets using different detectors show its consistent superiority, and codes are available at https://github.com/yangxue0827/rotationdetection.",,2021-06-03,2021-11-16,"['xue yang', 'xiaojiang yang', 'jirui yang', 'qi ming', 'wentao wang', 'qi tian', 'junchi yan']"
2106.02039,offline reinforcement learning as one big sequence modeling problem,cs.lg cs.ai,"reinforcement learning (rl) is typically concerned with estimating stationary policies or single-step models, leveraging the markov property to factorize problems in time. however, we can also view rl as a generic sequence modeling problem, with the goal being to produce a sequence of actions that leads to a sequence of high rewards. viewed in this way, it is tempting to consider whether high-capacity sequence prediction models that work well in other domains, such as natural-language processing, can also provide effective solutions to the rl problem. to this end, we explore how rl can be tackled with the tools of sequence modeling, using a transformer architecture to model distributions over trajectories and repurposing beam search as a planning algorithm. framing rl as sequence modeling problem simplifies a range of design decisions, allowing us to dispense with many of the components common in offline rl algorithms. we demonstrate the flexibility of this approach across long-horizon dynamics prediction, imitation learning, goal-conditioned rl, and offline rl. further, we show that this approach can be combined with existing model-free algorithms to yield a state-of-the-art planner in sparse-reward, long-horizon tasks.",,2021-06-03,2021-11-18,"['michael janner', 'qiyang li', 'sergey levine']"
2106.02067,learning to draw: emergent communication through sketching,cs.cv cs.ai cs.lg cs.ma,"evidence that visual communication preceded written language and provided a basis for it goes back to prehistory, in forms such as cave and rock paintings depicting traces of our distant ancestors. emergent communication research has sought to explore how agents can learn to communicate in order to collaboratively solve tasks. existing research has focused on language, with a learned communication channel transmitting sequences of discrete tokens between the agents. in this work, we explore a visual communication channel between agents that are allowed to draw with simple strokes. our agents are parameterised by deep neural networks, and the drawing procedure is differentiable, allowing for end-to-end training. in the framework of a referential communication game, we demonstrate that agents can not only successfully learn to communicate by drawing, but with appropriate inductive biases, can do so in a fashion that humans can interpret. we hope to encourage future research to consider visual communication as a more flexible and directly interpretable alternative of training collaborative agents.",,2021-06-03,2021-11-09,"['daniela mihai', 'jonathon hare']"
2106.02097,a consciousness-inspired planning agent for model-based reinforcement   learning,cs.ai cs.lg,"we present an end-to-end, model-based deep reinforcement learning agent which dynamically attends to relevant parts of its state during planning. the agent uses a bottleneck mechanism over a set-based representation to force the number of entities to which the agent attends at each planning step to be small. in experiments, we investigate the bottleneck mechanism with several sets of customized environments featuring different challenges. we consistently observe that the design allows the planning agents to generalize their learned task-solving abilities in compatible unseen environments by attending to the relevant objects, leading to better out-of-distribution generalization performance.",,2021-06-03,2021-11-04,"['mingde zhao', 'zhen liu', 'sitao luan', 'shuyuan zhang', 'doina precup', 'yoshua bengio']"
2106.02745,neural auto-curricula,cs.ai cs.ma,"when solving two-player zero-sum games, multi-agent reinforcement learning (marl) algorithms often create populations of agents where, at each iteration, a new agent is discovered as the best response to a mixture over the opponent population. within such a process, the update rules of ""who to compete with"" (i.e., the opponent mixture) and ""how to beat them"" (i.e., finding best responses) are underpinned by manually developed game theoretical principles such as fictitious play and double oracle. in this paper, we introduce a novel framework -- neural auto-curricula (nac) -- that leverages meta-gradient descent to automate the discovery of the learning update rule without explicit human design. specifically, we parameterise the opponent selection module by neural networks and the best-response module by optimisation subroutines, and update their parameters solely via interaction with the game engine, where both players aim to minimise their exploitability. surprisingly, even without human design, the discovered marl algorithms achieve competitive or even better performance with the state-of-the-art population-based game solvers (e.g., psro) on games of skill, differentiable lotto, non-transitive mixture games, iterated matching pennies, and kuhn poker. additionally, we show that nac is able to generalise from small games to large games, for example training on kuhn poker and outperforming psro on leduc poker. our work inspires a promising future direction to discover general marl algorithms solely from data.",,2021-06-04,2021-11-01,"['xidong feng', 'oliver slumbers', 'ziyu wan', 'bo liu', 'stephen mcaleer', 'ying wen', 'jun wang', 'yaodong yang']"
2106.02795,learnable fourier features for multi-dimensional spatial positional   encoding,cs.lg cs.ai cs.cv,"attentional mechanisms are order-invariant. positional encoding is a crucial component to allow attention-based deep model architectures such as transformer to address sequences or images where the position of information matters. in this paper, we propose a novel positional encoding method based on learnable fourier features. instead of hard-coding each position as a token or a vector, we represent each position, which can be multi-dimensional, as a trainable encoding based on learnable fourier feature mapping, modulated with a multi-layer perceptron. the representation is particularly advantageous for a spatial multi-dimensional position, e.g., pixel positions on an image, where $l_2$ distances or more complex positional relationships need to be captured. our experiments based on several public benchmark tasks show that our learnable fourier feature representation for multi-dimensional positional encoding outperforms existing methods by both improving the accuracy and allowing faster convergence.",,2021-06-05,2021-11-08,"['yang li', 'si si', 'gang li', 'cho-jui hsieh', 'samy bengio']"
2106.03442,average-reward reinforcement learning with trust region methods,cs.lg cs.ai,"most of reinforcement learning algorithms optimize the discounted criterion which is beneficial to accelerate the convergence and reduce the variance of estimates. although the discounted criterion is appropriate for certain tasks such as financial related problems, many engineering problems treat future rewards equally and prefer a long-run average criterion. in this paper, we study the reinforcement learning problem with the long-run average criterion. firstly, we develop a unified trust region theory with discounted and average criteria and derive a novel performance bound within the trust region with the perturbation analysis (pa) theory. secondly, we propose a practical algorithm named average policy optimization (apo), which improves the value estimation with a novel technique named average value constraint. finally, experiments are conducted in the continuous control environment mujoco. in most tasks, apo performs better than the discounted ppo, which demonstrates the effectiveness of our approach. our work provides a unified framework of the trust region approach including both the discounted and average criteria, which may complement the framework of reinforcement learning beyond the discounted objectives.",,2021-06-07,2021-10-31,"['xiaoteng ma', 'xiaohang tang', 'li xia', 'jun yang', 'qianchuan zhao']"
2106.03632,quantifying and improving transferability in domain generalization,cs.lg cs.ai stat.ml,"out-of-distribution generalization is one of the key challenges when transferring a model from the lab to the real world. existing efforts mostly focus on building invariant features among source and target domains. based on invariant features, a high-performing classifier on source domains could hopefully behave equally well on a target domain. in other words, the invariant features are \emph{transferable}. however, in practice, there are no perfectly transferable features, and some algorithms seem to learn ""more transferable"" features than others. how can we understand and quantify such \emph{transferability}? in this paper, we formally define transferability that one can quantify and compute in domain generalization. we point out the difference and connection with common discrepancy measures between domains, such as total variation and wasserstein distance. we then prove that our transferability can be estimated with enough samples and give a new upper bound for the target error based on our transferability. empirically, we evaluate the transferability of the feature embeddings learned by existing algorithms for domain generalization. surprisingly, we find that many algorithms are not quite learning transferable features, although few could still survive. in light of this, we propose a new algorithm for learning transferable features and test it over various benchmark datasets, including rotatedmnist, pacs, office-home and wilds-fmow. experimental results show that the proposed algorithm achieves consistent improvement over many state-of-the-art algorithms, corroborating our theoretical findings.",,2021-06-07,2021-11-01,"['guojun zhang', 'han zhao', 'yaoliang yu', 'pascal poupart']"
2106.03904,when in doubt: neural non-parametric uncertainty quantification for   epidemic forecasting,cs.lg cs.ai,"accurate and trustworthy epidemic forecasting is an important problem that has impact on public health planning and disease mitigation. most existing epidemic forecasting models disregard uncertainty quantification, resulting in mis-calibrated predictions. recent works in deep neural models for uncertainty-aware time-series forecasting also have several limitations; e.g. it is difficult to specify meaningful priors in bayesian nns, while methods like deep ensembling are computationally expensive in practice. in this paper, we fill this important gap. we model the forecasting task as a probabilistic generative process and propose a functional neural process model called epifnp, which directly models the probability density of the forecast value. epifnp leverages a dynamic stochastic correlation graph to model the correlations between sequences in a non-parametric way, and designs different stochastic latent variables to capture functional uncertainty from different perspectives. our extensive experiments in a real-time flu forecasting setting show that epifnp significantly outperforms previous state-of-the-art models in both accuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in calibration. additionally, due to properties of its generative process,epifnp learns the relations between the current season and similar patterns of historical seasons,enabling interpretable forecasts. beyond epidemic forecasting, the epifnp can be of independent interest for advancing principled uncertainty quantification in deep sequential models for predictive analytics",,2021-06-07,2021-11-15,"['harshavardhan kamarthi', 'lingkai kong', 'alexander rodríguez', 'chao zhang', 'b. aditya prakash']"
2106.04169,on improving adversarial transferability of vision transformers,cs.cv cs.ai cs.lg,"vision transformers (vits) process input images as sequences of patches via self-attention; a radically different architecture than convolutional neural networks (cnns). this makes it interesting to study the adversarial feature space of vit models and their transferability. in particular, we observe that adversarial patterns found via conventional adversarial attacks show very low black-box transferability even for large vit models. however, we show that this phenomenon is only due to the sub-optimal attack procedures that do not leverage the true representation potential of vits. a deep vit is composed of multiple blocks, with a consistent architecture comprising of self-attention and feed-forward layers, where each block is capable of independently producing a class token. formulating an attack using only the last class token (conventional approach) does not directly leverage the discriminative information stored in the earlier tokens, leading to poor adversarial transferability of vits. using the compositional nature of vit models, we enhance the transferability of existing attacks by introducing two novel strategies specific to the architecture of vit models. (i) self-ensemble: we propose a method to find multiple discriminative pathways by dissecting a single vit model into an ensemble of networks. this allows explicitly utilizing class-specific information at each vit block. (ii) token refinement: we then propose to refine the tokens to further enhance the discriminative capacity at each block of vit. our token refinement systematically combines the class tokens with structural information preserved within the patch tokens. an adversarial attack, when applied to such refined tokens within the ensemble of classifiers found in a single vision transformer, has significantly higher transferability.",,2021-06-08,2021-11-01,"['muzammal naseer', 'kanchana ranasinghe', 'salman khan', 'fahad shahbaz khan', 'fatih porikli']"
2106.04480,there is no turning back: a self-supervised approach for   reversibility-aware reinforcement learning,cs.lg cs.ai,"we propose to learn to distinguish reversible from irreversible actions for better informed decision-making in reinforcement learning (rl). from theoretical considerations, we show that approximate reversibility can be learned through a simple surrogate task: ranking randomly sampled trajectory events in chronological order. intuitively, pairs of events that are always observed in the same order are likely to be separated by an irreversible sequence of actions. conveniently, learning the temporal order of events can be done in a fully self-supervised way, which we use to estimate the reversibility of actions from experience, without any priors. we propose two different strategies that incorporate reversibility in rl agents, one strategy for exploration (rae) and one strategy for control (rac). we demonstrate the potential of reversibility-aware agents in several environments, including the challenging sokoban game. in synthetic tasks, we show that we can learn control policies that never fail and reduce to zero the side-effects of interactions, even without access to the reward function.",,2021-06-08,2021-10-29,"['nathan grinsztajn', 'johan ferret', 'olivier pietquin', 'philippe preux', 'matthieu geist']"
2106.04502,"federated hyperparameter tuning: challenges, baselines, and connections   to weight-sharing",cs.lg cs.ai cs.dc stat.ml,"tuning hyperparameters is a crucial but arduous part of the machine learning pipeline. hyperparameter optimization is even more challenging in federated learning, where models are learned over a distributed network of heterogeneous devices; here, the need to keep data on device and perform local training makes it difficult to efficiently train and evaluate configurations. in this work, we investigate the problem of federated hyperparameter tuning. we first identify key challenges and show how standard approaches may be adapted to form baselines for the federated setting. then, by making a novel connection to the neural architecture search technique of weight-sharing, we introduce a new method, fedex, to accelerate federated hyperparameter tuning that is applicable to widely-used federated optimization methods such as fedavg and recent variants. theoretically, we show that a fedex variant correctly tunes the on-device learning rate in the setting of online convex optimization across devices. empirically, we show that fedex can outperform natural baselines for federated hyperparameter tuning by several percentage points on the shakespeare, femnist, and cifar-10 benchmarks, obtaining higher accuracy using the same training budget.",,2021-06-08,2021-11-04,"['mikhail khodak', 'renbo tu', 'tian li', 'liam li', 'maria-florina balcan', 'virginia smith', 'ameet talwalkar']"
2106.04537,can you learn an algorithm? generalizing from easy to hard problems with   recurrent networks,cs.lg cs.ai,"deep neural networks are powerful machines for visual pattern recognition, but reasoning tasks that are easy for humans may still be difficult for neural models. humans possess the ability to extrapolate reasoning strategies learned on simple problems to solve harder examples, often by thinking for longer. for example, a person who has learned to solve small mazes can easily extend the very same search techniques to solve much larger mazes by spending more time. in computers, this behavior is often achieved through the use of algorithms, which scale to arbitrarily hard problem instances at the cost of more computation. in contrast, the sequential computing budget of feed-forward neural networks is limited by their depth, and networks trained on simple problems have no way of extending their reasoning to accommodate harder problems. in this work, we show that recurrent networks trained to solve simple problems with few recurrent steps can indeed solve much more complex problems simply by performing additional recurrences during inference. we demonstrate this algorithmic behavior of recurrent networks on prefix sum computation, mazes, and chess. in all three domains, networks trained on simple problem instances are able to extend their reasoning abilities at test time simply by ""thinking for longer.""",,2021-06-08,2021-11-02,"['avi schwarzschild', 'eitan borgnia', 'arjun gupta', 'furong huang', 'uzi vishkin', 'micah goldblum', 'tom goldstein']"
2106.04619,self-supervised learning with data augmentations provably isolates   content from style,stat.ml cs.ai cs.cv cs.lg,"self-supervised representation learning has shown remarkable success in a number of domains. a common practice is to perform data augmentation via hand-crafted transformations intended to leave the semantics of the data invariant. we seek to understand the empirical success of this approach from a theoretical perspective. we formulate the augmentation process as a latent variable model by postulating a partition of the latent representation into a content component, which is assumed invariant to augmentation, and a style component, which is allowed to change. unlike prior work on disentanglement and independent component analysis, we allow for both nontrivial statistical and causal dependencies in the latent space. we study the identifiability of the latent representation based on pairs of views of the observations and prove sufficient conditions that allow us to identify the invariant content partition up to an invertible mapping in both generative and discriminative settings. we find numerical simulations with dependent latent variables are consistent with our theory. lastly, we introduce causal3dident, a dataset of high-dimensional, visually complex images with rich causal dependencies, which we use to study the effect of data augmentations performed in practice.",,2021-06-08,2021-10-29,"['julius von kügelgen', 'yash sharma', 'luigi gresele', 'wieland brendel', 'bernhard schölkopf', 'michel besserve', 'francesco locatello']"
2106.04627,densely connected normalizing flows,cs.lg cs.ai cs.cv,"normalizing flows are bijective mappings between inputs and latent representations with a fully factorized distribution. they are very attractive due to exact likelihood valuation and efficient sampling. however, their effective capacity is often insufficient since the bijectivity constraint limits the model width. we address this issue by incrementally padding intermediate representations with noise. we precondition the noise in accordance with previous invertible units, which we describe as cross-unit coupling. our invertible glow-like modules increase the model expressivity by fusing a densely connected block with nystrom self-attention. we refer to our architecture as denseflow since both cross-unit and intra-module couplings rely on dense connectivity. experiments show significant improvements due to the proposed contributions and reveal state-of-the-art density estimation under moderate computing budgets.",,2021-06-08,2021-11-02,"['matej grcić', 'ivan grubišić', 'siniša šegvić']"
2106.04696,curriculum design for teaching via demonstrations: theory and   applications,cs.lg cs.ai,"we consider the problem of teaching via demonstrations in sequential decision-making settings. in particular, we study how to design a personalized curriculum over demonstrations to speed up the learner's convergence. we provide a unified curriculum strategy for two popular learner models: maximum causal entropy inverse reinforcement learning (maxent-irl) and cross-entropy behavioral cloning (crossent-bc). our unified strategy induces a ranking over demonstrations based on a notion of difficulty scores computed w.r.t. the teacher's optimal policy and the learner's current policy. compared to the state of the art, our strategy doesn't require access to the learner's internal dynamics and still enjoys similar convergence guarantees under mild technical conditions. furthermore, we adapt our curriculum strategy to the setting where no teacher agent is present using task-specific difficulty scores. experiments on a synthetic car driving environment and navigation-based environments demonstrate the effectiveness of our curriculum strategy.",,2021-06-08,2021-11-08,"['gaurav yengera', 'rati devidze', 'parameswaran kamalaruban', 'adish singla']"
2106.04715,measurable monte carlo search error bounds,cs.ai cs.na math.na,"monte carlo planners can often return sub-optimal actions, even if they are guaranteed to converge in the limit of infinite samples. known asymptotic regret bounds do not provide any way to measure confidence of a recommended action at the conclusion of search. in this work, we prove bounds on the sub-optimality of monte carlo estimates for non-stationary bandits and markov decision processes. these bounds can be directly computed at the conclusion of the search and do not require knowledge of the true action-value. the presented bound holds for general monte carlo solvers meeting mild convergence conditions. we empirically test the tightness of the bounds through experiments on a multi-armed bandit and a discrete markov decision process for both a simple solver and monte carlo tree search.",,2021-06-08,2021-11-02,"['john mern', 'mykel j. kochenderfer']"
2106.05386,artificial intelligence in drug discovery: applications and techniques,cs.lg cs.ai,"artificial intelligence (ai) has been transforming the practice of drug discovery in the past decade. various ai techniques have been used in a wide range of applications, such as virtual screening and drug design. in this survey, we first give an overview on drug discovery and discuss related applications, which can be reduced to two major tasks, i.e., molecular property prediction and molecule generation. we then discuss common data resources, molecule representations and benchmark platforms. furthermore, to summarize the progress of ai in drug discovery, we present the relevant ai techniques including model architectures and learning paradigms in the papers surveyed. we expect that this survey will serve as a guide for researchers who are interested in working at the interface of artificial intelligence and drug discovery. we also provide a github repository (https://github.com/dengjianyuan/survey_ai_drug_discovery) with the collection of papers and codes, if applicable, as a learning resource, which is regularly updated.",,2021-06-09,2021-11-02,"['jianyuan deng', 'zhibo yang', 'iwao ojima', 'dimitris samaras', 'fusheng wang']"
2106.05784,programming puzzles,cs.lg cs.ai cs.cl cs.pl cs.se,"we introduce a new type of programming challenge called programming puzzles, as an objective and comprehensive evaluation of program synthesis, and release an open-source dataset of python programming puzzles (p3). each puzzle is defined by a short python program $f$, and the goal is to find an input which makes $f$ return true. the puzzles are objective in that each one is specified entirely by the source code of its verifier $f$, so evaluating $f$ is all that is needed to test a candidate solution. they do not require an answer key or input/output examples, nor do they depend on natural language understanding. the dataset is comprehensive in that it spans problems of a range of difficulties and domains, ranging from trivial string manipulation problems, to classic programming puzzles (e.g., tower of hanoi), to interview/competitive-programming problems (e.g., dynamic programming), to longstanding open problems in algorithms and mathematics (e.g., factoring). we develop baseline enumerative program synthesis, gpt-3 and codex solvers that are capable of solving puzzles -- even without access to any reference solutions -- by learning from their own past solutions. codex performs best, solving up to 18% of 397 test problems with a single try and 80% of the problems with 1,000 tries per problem. in a small user study, we find a positive correlation between puzzle-solving performance and coding experience, and between the puzzle difficulty for humans and ai solvers. therefore, further improvements on p3 could have a significant impact on many program synthesis areas.",,2021-06-10,2021-11-06,"['tal schuster', 'ashwin kalyan', 'oleksandr polozov', 'adam tauman kalai']"
2106.05819,adversarial graph augmentation to improve graph contrastive learning,cs.lg cs.ai,"self-supervised learning of graph neural networks (gnn) is in great need because of the widespread label scarcity issue in real-world graph/network data. graph contrastive learning (gcl), by training gnns to maximize the correspondence between the representations of the same graph in its different augmented forms, may yield robust and transferable gnns even without using labels. however, gnns trained by traditional gcl often risk capturing redundant graph features and thus may be brittle and provide sub-par performance in downstream tasks. here, we propose a novel principle, termed adversarial-gcl (ad-gcl), which enables gnns to avoid capturing redundant information during the training by optimizing adversarial graph augmentation strategies used in gcl. we pair ad-gcl with theoretical explanations and design a practical instantiation based on trainable edge-dropping graph augmentation. we experimentally validate ad-gcl by comparing with the state-of-the-art gcl methods and achieve performance gains of up-to $14\%$ in unsupervised, $6\%$ in transfer, and $3\%$ in semi-supervised learning settings overall with 18 different benchmark datasets for the tasks of molecule property regression and classification, and social network classification.",,2021-06-10,2021-11-02,"['susheel suresh', 'pan li', 'cong hao', 'jennifer neville']"
2106.06926,bellman-consistent pessimism for offline reinforcement learning,cs.lg cs.ai stat.ml,"the use of pessimism, when reasoning about datasets lacking exhaustive exploration has recently gained prominence in offline reinforcement learning. despite the robustness it adds to the algorithm, overly pessimistic reasoning can be equally damaging in precluding the discovery of good policies, which is an issue for the popular bonus-based pessimism. in this paper, we introduce the notion of bellman-consistent pessimism for general function approximation: instead of calculating a point-wise lower bound for the value function, we implement pessimism at the initial state over the set of functions consistent with the bellman equations. our theoretical guarantees only require bellman closedness as standard in the exploratory setting, in which case bonus-based pessimism fails to provide guarantees. even in the special case of linear function approximation where stronger expressivity assumptions hold, our result improves upon a recent bonus-based approach by $\mathcal{o}(d)$ in its sample complexity when the action space is finite. remarkably, our algorithms automatically adapt to the best bias-variance tradeoff in the hindsight, whereas most prior approaches require tuning extra hyperparameters a priori.",,2021-06-13,2021-11-04,"['tengyang xie', 'ching-an cheng', 'nan jiang', 'paul mineiro', 'alekh agarwal']"
2106.07464,meta-interpretive learning as metarule specialisation,cs.lg cs.ai cs.lo,"in meta-interpretive learning (mil) the metarules, second-order datalog clauses acting as inductive bias, are manually defined by the user. in this work we show that second-order metarules for mil can be learned by mil. we define a generality ordering of metarules by $\theta$-subsumption and show that user-defined \emph{sort metarules} are derivable by specialisation of the most-general \emph{matrix metarules} in a language class; and that these matrix metarules are in turn derivable by specialisation of third-order \emph{punch metarules} with variables quantified over the set of atoms and for which only an upper bound on their number of literals need be user-defined. we show that the cardinality of a metarule language is polynomial in the number of literals in punch metarules. we re-frame mil as metarule specialisation by resolution. we modify the mil metarule specialisation operator to return new metarules rather than first-order clauses and prove the correctness of the new operator. we implement the new operator as toil, a sub-system of the mil system louise. our experiments show that as user-defined sort metarules are progressively replaced by sort metarules learned by toil, louise's predictive accuracy is maintained at the cost of a small increase in training times. we conclude that automatically derived metarules can replace user-defined metarules.",,2021-06-09,2021-11-03,"['stassa patsantzis', 'stephen h. muggleton']"
2106.07754,counterfactual explanations as interventions in latent space,cs.ai cs.cy cs.lg stat.ml,"explainable artificial intelligence (xai) is a set of techniques that allows the understanding of both technical and non-technical aspects of artificial intelligence (ai) systems. xai is crucial to help satisfying the increasingly important demand of \emph{trustworthy} artificial intelligence, characterized by fundamental characteristics such as respect of human autonomy, prevention of harm, transparency, accountability, etc. within xai techniques, counterfactual explanations aim to provide to end users a set of features (and their corresponding values) that need to be changed in order to achieve a desired outcome. current approaches rarely take into account the feasibility of actions needed to achieve the proposed explanations, and in particular they fall short of considering the causal impact of such actions. in this paper, we present counterfactual explanations as interventions in latent space (ceils), a methodology to generate counterfactual explanations capturing by design the underlying causal relations from the data, and at the same time to provide feasible recommendations to reach the proposed profile. moreover, our methodology has the advantage that it can be set on top of existing counterfactuals generator algorithms, thus minimising the complexity of imposing additional causal constrains. we demonstrate the effectiveness of our approach with a set of different experiments using synthetic and real datasets (including a proprietary dataset of the financial domain).",,2021-06-14,2021-11-08,"['riccardo crupi', 'alessandro castelnovo', 'daniele regoli', 'beatriz san miguel gonzalez']"
2106.07932,medical code prediction from discharge summary: document to sequence   bert using sequence attention,cs.ai,"clinical notes are unstructured text generated by clinicians during patient encounters. clinical notes are usually accompanied by a set of metadata codes from the international classification of diseases(icd). icd code is an important code used in various operations, including insurance, reimbursement, medical diagnosis, etc. therefore, it is important to classify icd codes quickly and accurately. however, annotating these codes is costly and time-consuming. so we propose a model based on bidirectional encoder representations from transformers (bert) using the sequence attention method for automatic icd code assignment. we evaluate our approach on the medical information mart for intensive care iii (mimic-iii) benchmark dataset. our model achieved performance of macro-averaged f1: 0.62898 and micro-averaged f1: 0.68555 and is performing better than a performance of the state-of-the-art model using the mimic-iii dataset. the contribution of this study proposes a method of using bert that can be applied to documents and a sequence attention method that can capture important sequence in-formation appearing in documents.",,2021-06-15,2021-11-10,"['tak-sung heo', 'yongmin yoo', 'yeongjoon park', 'byeong-cheol jo', 'kyungsun kim']"
2106.08796,tactile sim-to-real policy transfer via real-to-sim image translation,cs.ro cs.ai,"simulation has recently become key for deep reinforcement learning to safely and efficiently acquire general and complex control policies from visual and proprioceptive inputs. tactile information is not usually considered despite its direct relation to environment interaction. in this work, we present a suite of simulated environments tailored towards tactile robotics and reinforcement learning. a simple and fast method of simulating optical tactile sensors is provided, where high-resolution contact geometry is represented as depth images. proximal policy optimisation (ppo) is used to learn successful policies across all considered tasks. a data-driven approach enables translation of the current state of a real tactile sensor to corresponding simulated depth images. this policy is implemented within a real-time control loop on a physical robot to demonstrate zero-shot sim-to-real policy transfer on several physically-interactive tasks requiring a sense of touch.",,2021-06-16,2021-10-31,"['alex church', 'john lloyd', 'raia hadsell', 'nathan f. lepora']"
2106.09019,amortized synthesis of constrained configurations using a differentiable   surrogate,cs.lg cs.ai cs.ro,"in design, fabrication, and control problems, we are often faced with the task of synthesis, in which we must generate an object or configuration that satisfies a set of constraints while maximizing one or more objective functions. the synthesis problem is typically characterized by a physical process in which many different realizations may achieve the goal. this many-to-one map presents challenges to the supervised learning of feed-forward synthesis, as the set of viable designs may have a complex structure. in addition, the non-differentiable nature of many physical simulations prevents efficient direct optimization. we address both of these problems with a two-stage neural network architecture that we may consider to be an autoencoder. we first learn the decoder: a differentiable surrogate that approximates the many-to-one physical realization process. we then learn the encoder, which maps from goal to design, while using the fixed decoder to evaluate the quality of the realization. we evaluate the approach on two case studies: extruder path planning in additive manufacturing and constrained soft robot inverse kinematics. we compare our approach to direct optimization of the design using the learned surrogate, and to supervised learning of the synthesis problem. we find that our approach produces higher quality solutions than supervised learning, while being competitive in quality with direct optimization, at a greatly reduced computational cost.",,2021-06-16,2021-11-05,"['xingyuan sun', 'tianju xue', 'szymon rusinkiewicz', 'ryan p. adams']"
2106.09146,contrastive reinforcement learning of symbolic reasoning domains,cs.ai cs.lg,"abstract symbolic reasoning, as required in domains such as mathematics and logic, is a key component of human intelligence. solvers for these domains have important applications, especially to computer-assisted education. but learning to solve symbolic problems is challenging for machine learning algorithms. existing models either learn from human solutions or use hand-engineered features, making them expensive to apply in new domains. in this paper, we instead consider symbolic domains as simple environments where states and actions are given as unstructured text, and binary rewards indicate whether a problem is solved. this flexible setup makes it easy to specify new domains, but search and planning become challenging. we introduce four environments inspired by the mathematics common core curriculum, and observe that existing reinforcement learning baselines perform poorly. we then present a novel learning algorithm, contrastive policy learning (conpole) that explicitly optimizes the infonce loss, which lower bounds the mutual information between the current state and next states that continue on a path to the solution. conpole successfully solves all four domains. moreover, problem representations learned by conpole enable accurate prediction of the categories of problems in a real mathematics curriculum. our results suggest new directions for reinforcement learning in symbolic domains, as well as applications to mathematics education.",,2021-06-16,2021-11-08,"['gabriel poesia', 'wenxin dong', 'noah goodman']"
2106.09847,"disinformation, stochastic harm, and costly effort: a principal-agent   analysis of regulating social media platforms",cs.gt cs.ai econ.th,"the spread of disinformation on social media platforms is harmful to society. this harm may manifest as a gradual degradation of public discourse; but it can also take the form of sudden dramatic events such as the recent insurrection on capitol hill. the platforms themselves are in the best position to prevent the spread of disinformation, as they have the best access to relevant data and the expertise to use it. however, mitigating disinformation is costly, not only for implementing detection algorithms or employing manual effort, but also because limiting such highly viral content impacts user engagement and thus potential advertising revenue. since the costs of harmful content are borne by other entities, the platform will therefore have no incentive to exercise the socially-optimal level of effort. this problem is similar to that of environmental regulation, in which the costs of adverse events are not directly borne by a firm, the mitigation effort of a firm is not observable, and the causal link between a harmful consequence and a specific failure is difficult to prove. for environmental regulation, one solution is to perform costly monitoring to ensure that the firm takes adequate precautions according to a specified rule. however, a fixed rule for classifying disinformation becomes less effective over time, as bad actors can learn to sequentially and strategically bypass it. encoding our domain as a markov decision process, we demonstrate that no penalty based on a static rule, no matter how large, can incentivize adequate effort. penalties based on an adaptive rule can incentivize optimal effort, but counterintuitively, only if the regulator sufficiently overreacts to harmful events by requiring a greater-than-optimal level of effort. we prescribe the design of mechanisms that elicit platforms' costs of precautionary effort relating to the control of disinformation.",,2021-06-17,2021-11-12,"['shehroze khan', 'james r. wright']"
2106.10994,bernnet: learning arbitrary graph spectral filters via bernstein   approximation,cs.lg cs.ai,"many representative graph neural networks, e.g., gpr-gnn and chebnet, approximate graph convolutions with graph spectral filters. however, existing work either applies predefined filter weights or learns them without necessary constraints, which may lead to oversimplified or ill-posed filters. to overcome these issues, we propose bernnet, a novel graph neural network with theoretical support that provides a simple but effective scheme for designing and learning arbitrary graph spectral filters. in particular, for any filter over the normalized laplacian spectrum of a graph, our bernnet estimates it by an order-$k$ bernstein polynomial approximation and designs its spectral property by setting the coefficients of the bernstein basis. moreover, we can learn the coefficients (and the corresponding filter weights) based on observed graphs and their associated signals and thus achieve the bernnet specialized for the data. our experiments demonstrate that bernnet can learn arbitrary spectral filters, including complicated band-rejection and comb filters, and it achieves superior performance in real-world graph modeling tasks. code is available at https://github.com/ivam-he/bernnet.",,2021-06-21,2021-11-07,"['mingguo he', 'zhewei wei', 'zengfeng huang', 'hongteng xu']"
2106.11853,credal self-supervised learning,stat.ml cs.ai cs.lg,"self-training is an effective approach to semi-supervised learning. the key idea is to let the learner itself iteratively generate ""pseudo-supervision"" for unlabeled instances based on its current hypothesis. in combination with consistency regularization, pseudo-labeling has shown promising performance in various domains, for example in computer vision. to account for the hypothetical nature of the pseudo-labels, these are commonly provided in the form of probability distributions. still, one may argue that even a probability distribution represents an excessive level of informedness, as it suggests that the learner precisely knows the ground-truth conditional probabilities. in our approach, we therefore allow the learner to label instances in the form of credal sets, that is, sets of (candidate) probability distributions. thanks to this increased expressiveness, the learner is able to represent uncertainty and a lack of knowledge in a more flexible and more faithful manner. to learn from weakly labeled data of that kind, we leverage methods that have recently been proposed in the realm of so-called superset learning. in an exhaustive empirical evaluation, we compare our methodology to state-of-the-art self-supervision approaches, showing competitive to superior performance especially in low-label scenarios incorporating a high degree of uncertainty.",,2021-06-22,2021-11-04,"['julian lienen', 'eyke hüllermeier']"
2106.12169,apnn-tc: accelerating arbitrary precision neural networks on ampere gpu   tensor cores,cs.dc cs.ai cs.ar cs.cv,"over the years, accelerating neural networks with quantization has been widely studied. unfortunately, prior efforts with diverse precisions (e.g., 1-bit weights and 2-bit activations) are usually restricted by limited precision support on gpus (e.g., int1 and int4). to break such restrictions, we introduce the first arbitrary precision neural network framework (apnn-tc) to fully exploit quantization benefits on ampere gpu tensor cores. specifically, apnn-tc first incorporates a novel emulation algorithm to support arbitrary short bit-width computation with int1 compute primitives and xor/and boolean operations. second, apnn-tc integrates arbitrary precision layer designs to efficiently map our emulation algorithm to tensor cores with novel batching strategies and specialized memory organization. third, apnn-tc embodies a novel arbitrary precision nn design to minimize memory access across layers and further improve performance. extensive evaluations show that apnn-tc can achieve significant speedup over cutlass kernels and various nn models, such as resnet and vgg.",,2021-06-23,2021-11-16,"['boyuan feng', 'yuke wang', 'tong geng', 'ang li', 'yufei ding']"
2106.12242,a unified approach to fair online learning via blackwell approachability,cs.lg cs.ai cs.cy stat.ml,"we provide a setting and a general approach to fair online learning with stochastic sensitive and non-sensitive contexts. the setting is a repeated game between the player and nature, where at each stage both pick actions based on the contexts. inspired by the notion of unawareness, we assume that the player can only access the non-sensitive context before making a decision, while we discuss both cases of nature accessing the sensitive contexts and nature unaware of the sensitive contexts. adapting blackwell's approachability theory to handle the case of an unknown contexts' distribution, we provide a general necessary and sufficient condition for learning objectives to be compatible with some fairness constraints. this condition is instantiated on (group-wise) no-regret and (group-wise) calibration objectives, and on demographic parity as an additional constraint. when the objective is not compatible with the constraint, the provided framework permits to characterise the optimal trade-off between the two.",,2021-06-23,2021-11-07,"['evgenii chzhen', 'christophe giraud', 'gilles stoltz']"
2106.12447,how well do feature visualizations support causal understanding of cnn   activations?,cs.cv cs.ai cs.hc cs.lg,"a precise understanding of why units in an artificial network respond to certain stimuli would constitute a big step towards explainable artificial intelligence. one widely used approach towards this goal is to visualize unit responses via activation maximization. these synthetic feature visualizations are purported to provide humans with precise information about the image features that cause a unit to be activated - an advantage over other alternatives like strongly activating natural dataset samples. if humans indeed gain causal insight from visualizations, this should enable them to predict the effect of an intervention, such as how occluding a certain patch of the image (say, a dog's head) changes a unit's activation. here, we test this hypothesis by asking humans to decide which of two square occlusions causes a larger change to a unit's activation. both a large-scale crowdsourced experiment and measurements with experts show that on average the extremely activating feature visualizations by olah et al. (2017) indeed help humans on this task ($68 \pm 4$% accuracy; baseline performance without any visualizations is $60 \pm 3$%). however, they do not provide any substantial advantage over other visualizations (such as e.g. dataset samples), which yield similar performance ($66\pm3$% to $67 \pm3$% accuracy). taken together, we propose an objective psychophysical task to quantify the benefit of unit-level interpretability methods for humans, and find no evidence that a widely-used feature visualization method provides humans with better ""causal understanding"" of unit activations than simple alternative visualizations.",,2021-06-23,2021-11-12,"['roland s. zimmermann', 'judy borowski', 'robert geirhos', 'matthias bethge', 'thomas s. a. wallis', 'wieland brendel']"
2106.12543,synthetic benchmarks for scientific research in explainable machine   learning,cs.lg cs.ai stat.ml,"as machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. this has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as lime and shap. despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on real-world datasets. in this work, we address this issue by releasing xai-bench: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate ground-truth shapley values and other metrics. the synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. we demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. the versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. our code is available at https://github.com/abacusai/xai-bench.",,2021-06-23,2021-11-04,"['yang liu', 'sujay khandagale', 'colin white', 'willie neiswanger']"
2106.12831,extraction of common conceptual components from multiple ontologies,cs.ai,"understanding large ontologies is still an issue, and has an impact on many ontology engineering tasks. we describe a novel method for identifying and extracting conceptual components from domain ontologies, which are used to understand and compare them. the method is applied to two corpora of ontologies in the cultural heritage and conference domain, respectively. the results, which show good quality, are evaluated by manual inspection and by correlation with datasets and tool performance from the ontology alignment evaluation initiative.",,2021-06-24,2021-11-04,"['luigi asprino', 'valentina anita carriero', 'valentina presutti']"
2106.12894,inflow: robust outlier detection utilizing normalizing flows,cs.lg cs.ai cs.cr,"normalizing flows are prominent deep generative models that provide tractable probability distributions and efficient density estimation. however, they are well known to fail while detecting out-of-distribution (ood) inputs as they directly encode the local features of the input representations in their latent space. in this paper, we solve this overconfidence issue of normalizing flows by demonstrating that flows, if extended by an attention mechanism, can reliably detect outliers including adversarial attacks. our approach does not require outlier data for training and we showcase the efficiency of our method for ood detection by reporting state-of-the-art performance in diverse experimental settings. code available at https://github.com/computationalradiationphysics/inflow .",,2021-06-10,2021-11-16,"['nishant kumar', 'pia hanfeld', 'michael hecht', 'michael bussmann', 'stefan gumhold', 'nico hoffmann']"
2106.13008,autoformer: decomposition transformers with auto-correlation for   long-term series forecasting,cs.lg cs.ai,"extending the forecasting time is a critical demand for real applications, such as extreme weather early warning and long-term energy consumption planning. this paper studies the long-term forecasting problem of time series. prior transformer-based models adopt various self-attention mechanisms to discover the long-range dependencies. however, intricate temporal patterns of the long-term future prohibit the model from finding reliable dependencies. also, transformers have to adopt the sparse versions of point-wise self-attentions for long series efficiency, resulting in the information utilization bottleneck. going beyond transformers, we design autoformer as a novel decomposition architecture with an auto-correlation mechanism. we break with the pre-processing convention of series decomposition and renovate it as a basic inner block of deep models. this design empowers autoformer with progressive decomposition capacities for complex time series. further, inspired by the stochastic process theory, we design the auto-correlation mechanism based on the series periodicity, which conducts the dependencies discovery and representation aggregation at the sub-series level. auto-correlation outperforms self-attention in both efficiency and accuracy. in long-term forecasting, autoformer yields state-of-the-art accuracy, with a 38% relative improvement on six benchmarks, covering five practical applications: energy, traffic, economics, weather and disease. code is available at this repository: \url{https://github.com/thuml/autoformer}.",,2021-06-24,2021-11-02,"['haixu wu', 'jiehui xu', 'jianmin wang', 'mingsheng long']"
2106.13280,hierarchically integrated models: learning to navigate from   heterogeneous robots,cs.ro cs.ai cs.lg,"deep reinforcement learning algorithms require large and diverse datasets in order to learn successful policies for perception-based mobile navigation. however, gathering such datasets with a single robot can be prohibitively expensive. collecting data with multiple different robotic platforms with possibly different dynamics is a more scalable approach to large-scale data collection. but how can deep reinforcement learning algorithms leverage such heterogeneous datasets? in this work, we propose a deep reinforcement learning algorithm with hierarchically integrated models (hint). at training time, hint learns separate perception and dynamics models, and at test time, hint integrates the two models in a hierarchical manner and plans actions with the integrated model. this method of planning with hierarchically integrated models allows the algorithm to train on datasets gathered by a variety of different platforms, while respecting the physical capabilities of the deployment robot at test time. our mobile navigation experiments show that hint outperforms conventional hierarchical policies and single-source approaches.",,2021-06-24,2021-11-04,"['katie kang', 'gregory kahn', 'sergey levine']"
2106.13423,federated graph classification over non-iid graphs,cs.lg cs.ai cs.dc stat.ml,"federated learning has emerged as an important paradigm for training machine learning models in different domains. for graph-level tasks such as graph classification, graphs can also be regarded as a special type of data samples, which can be collected and stored in separate local systems. similar to other domains, multiple local systems, each holding a small set of graphs, may benefit from collaboratively training a powerful graph mining model, such as the popular graph neural networks (gnns). to provide more motivation towards such endeavors, we analyze real-world graphs from different domains to confirm that they indeed share certain graph properties that are statistically significant compared with random graphs. however, we also find that different sets of graphs, even from the same domain or same dataset, are non-iid regarding both graph structures and node features. to handle this, we propose a graph clustered federated learning (gcfl) framework that dynamically finds clusters of local systems based on the gradients of gnns, and theoretically justify that such clusters can reduce the structure and feature heterogeneity among graphs owned by the local systems. moreover, we observe the gradients of gnns to be rather fluctuating in gcfl which impedes high-quality clustering, and design a gradient sequence-based clustering mechanism based on dynamic time warping (gcfl+). extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed frameworks.",,2021-06-25,2021-11-07,"['han xie', 'jing ma', 'li xiong', 'carl yang']"
2106.14483,cheating detection pipeline for online interviews and exams,cs.cv cs.ai cs.hc cs.lg cs.mm,"remote examination and job interviews have gained popularity and become indispensable because of both pandemics and the advantage of remote working circumstances. most companies and academic institutions utilize these systems for their recruitment processes and also for online exams. however, one of the critical problems of the remote examination systems is conducting the exams in a reliable environment. in this work, we present a cheating analysis pipeline for online interviews and exams. the system only requires a video of the candidate, which is recorded during the exam. then cheating detection pipeline is employed to detect another person, electronic device usage, and candidate absence status. the pipeline consists of face detection, face recognition, object detection, and face tracking algorithms. to evaluate the performance of the pipeline we collected a private video dataset. the video dataset includes both cheating activities and clean videos. ultimately, our pipeline presents an efficient and fast guideline to detect and analyze cheating activities in an online interview and exam video.",,2021-06-28,2021-11-14,"['azmi can özgen', 'mahiye uluyağmur öztürk', 'umut bayraktar']"
2106.14855,k-net: towards unified image segmentation,cs.cv cs.ai,"semantic, instance, and panoptic segmentations have been addressed using different and specialized frameworks despite their underlying connections. this paper presents a unified, simple, and effective framework for these essentially similar tasks. the framework, named k-net, segments both instances and semantic categories consistently by a group of learnable kernels, where each kernel is responsible for generating a mask for either a potential instance or a stuff class. to remedy the difficulties of distinguishing various instances, we propose a kernel update strategy that enables each kernel dynamic and conditional on its meaningful group in the input image. k-net can be trained in an end-to-end manner with bipartite matching, and its training and inference are naturally nms-free and box-free. without bells and whistles, k-net surpasses all previous published state-of-the-art single-model results of panoptic segmentation on ms coco test-dev split and semantic segmentation on ade20k val split with 55.2% pq and 54.3% miou, respectively. its instance segmentation performance is also on par with cascade mask r-cnn on ms coco with 60%-90% faster inference speeds. code and models will be released at https://github.com/zwwwayne/k-net/.",,2021-06-28,2021-11-01,"['wenwei zhang', 'jiangmiao pang', 'kai chen', 'chen change loy']"
2106.15011,are conditional gans explicitly conditional?,cs.cv cs.ai,"this paper proposes two important contributions for conditional generative adversarial networks (cgans) to improve the wide variety of applications that exploit this architecture. the first main contribution is an analysis of cgans to show that they are not explicitly conditional. in particular, it will be shown that the discriminator and subsequently the cgan does not automatically learn the conditionality between inputs. the second contribution is a new method, called a contrario cgan, that explicitly models conditionality for both parts of the adversarial architecture via a novel a contrario loss that involves training the discriminator to learn unconditional (adverse) examples. this leads to a novel type of data augmentation approach for gans (a contrario learning) which allows to restrict the search space of the generator to conditional outputs using adverse examples. extensive experimentation is carried out to evaluate the conditionality of the discriminator by proposing a probability distribution analysis. comparisons with the cgan architecture for different applications show significant improvements in performance on well known datasets including, semantic image synthesis, image segmentation, monocular depth prediction and ""single label""-to-image using different metrics including fr\'echet inception distance (fid), mean intersection over union (miou), root mean square error log (rmse log) and number of statistically-different bins (ndb).",,2021-06-28,2021-11-04,"['houssem-eddine boulahbal', 'adrian voicila', 'andrew comport']"
2106.15047,benchmarking knowledge-driven zero-shot learning,cs.ai,"external knowledge (a.k.a. side information) plays a critical role in zero-shot learning (zsl) which aims to predict with unseen classes that have never appeared in training data. several kinds of external knowledge, such as text and attribute, have been widely investigated, but they alone are limited with incomplete semantics. some very recent studies thus propose to use knowledge graph (kg) due to its high expressivity and compatibility for representing kinds of knowledge. however, the zsl community is still in short of standard benchmarks for studying and comparing different external knowledge settings and different kg-based zsl methods. in this paper, we proposed six resources covering three tasks, i.e., zero-shot image classification (zs-imgc), zero-shot relation extraction (zs-re), and zero-shot kg completion (zs-kgc). each resource has a normal zsl benchmark and a kg containing semantics ranging from text to attribute, from relational knowledge to logical expressions. we have clearly presented these resources including their construction, statistics, data formats and usage cases w.r.t. different zsl methods. more importantly, we have conducted a comprehensive benchmarking study, with two general and state-of-the-art methods, two setting-specific methods and one interpretable method. we discussed and compared different zsl paradigms w.r.t. different external knowledge settings, and found that our resources have great potential for developing more advanced zsl methods and more solutions for applying kgs for augmenting machine learning. all the resources are available at https://github.com/china-uk-zsl/resources_for_kzsl.",,2021-06-28,2021-11-11,"['yuxia geng', 'jiaoyan chen', 'xiang zhuang', 'zhuo chen', 'jeff z. pan', 'juan li', 'zonggang yuan', 'huajun chen']"
2106.15324,effective evaluation of deep active learning on image classification   tasks,cs.cv cs.ai cs.lg,"with the goal of making deep learning more label-efficient, a growing number of papers have been studying active learning (al) for deep models. however, there are a number of issues in the prevalent experimental settings, mainly stemming from a lack of unified implementation and benchmarking. issues in the current literature include sometimes contradictory observations on the performance of different al algorithms, unintended exclusion of important generalization approaches such as data augmentation and sgd for optimization, a lack of study of evaluation facets like the labeling efficiency of al, and little or no clarity on the scenarios in which al outperforms random sampling (rs). in this work, we present a unified re-implementation of state-of-the-art al algorithms in the context of image classification via our new open-source al toolkit distil, and we carefully study these issues as facets of effective evaluation. on the positive side, we show that al techniques are $2\times$ to $4\times$ more label-efficient compared to rs with the use of data augmentation. surprisingly, when data augmentation is included, there is no longer a consistent gain in using badge, a state-of-the-art approach, over simple uncertainty sampling. we then do a careful analysis of how existing approaches perform with varying amounts of redundancy and number of examples per class. finally, we provide several insights for al practitioners to consider in future work, such as the effect of the al batch size, the effect of initialization, the importance of retraining the model at every round, and other insights.",,2021-06-16,2021-11-02,"['nathan beck', 'durga sivasubramanian', 'apurva dani', 'ganesh ramakrishnan', 'rishabh iyer']"
2106.15962,on the generative utility of cyclic conditionals,cs.lg cs.ai stat.ml,"we study whether and how can we model a joint distribution $p(x,z)$ using two conditional models $p(x|z)$ and $q(z|x)$ that form a cycle. this is motivated by the observation that deep generative models, in addition to a likelihood model $p(x|z)$, often also use an inference model $q(z|x)$ for extracting representation, but they rely on a usually uninformative prior distribution $p(z)$ to define a joint distribution, which may render problems like posterior collapse and manifold mismatch. to explore the possibility to model a joint distribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and determinacy, corresponding to the existence and uniqueness of a joint distribution whose conditional distributions coincide with them. we develop a general theory for operable equivalence criteria for compatibility, and sufficient conditions for determinacy. based on the theory, we propose a novel generative modeling framework cygen that only uses the two cyclic conditional models. we develop methods to achieve compatibility and determinacy, and to use the conditional models to fit and generate data. with the prior constraint removed, cygen better fits data and captures more representative features, supported by both synthetic and real-world experiments.",,2021-06-30,2021-11-06,"['chang liu', 'haoyue tang', 'tao qin', 'jintao wang', 'tie-yan liu']"
2107.00048,uncertainty-aware learning for improvements in image quality of the   canada-france-hawaii telescope,astro-ph.im cs.ai,"we leverage state-of-the-art machine learning methods and a decade's worth of archival data from cfht to predict observatory image quality (iq) from environmental conditions and observatory operating parameters. specifically, we develop accurate and interpretable models of the complex dependence between data features and observed iq for cfht's wide-field camera, megacam. our contributions are several-fold. first, we collect, collate and reprocess several disparate data sets gathered by cfht scientists. second, we predict probability distribution functions (pdfs) of iq and achieve a mean absolute error of $\sim0.07''$ for the predicted medians. third, we explore the data-driven actuation of the 12 dome ""vents"" installed in 2013-14 to accelerate the flushing of hot air from the dome. we leverage epistemic and aleatoric uncertainties in conjunction with probabilistic generative modeling to identify candidate vent adjustments that are in-distribution (id); for the optimal configuration for each id sample, we predict the reduction in required observing time to achieve a fixed snr. on average, the reduction is $\sim12\%$. finally, we rank input features by their shapley values to identify the most predictive variables for each observation. our long-term goal is to construct reliable and real-time models that can forecast optimal observatory operating parameters to optimize iq. we can then feed such forecasts into scheduling protocols and predictive maintenance routines. we anticipate that such approaches will become standard in automating observatory operations and maintenance by the time cfht's successor, the maunakea spectroscopic explorer, is installed in the next decade.",,2021-06-30,2021-11-15,"['sankalp gilda', 'stark c. draper', 'sebastien fabbro', 'william mahoney', 'simon prunet', 'kanoa withington', 'matthew wilson', 'yuan-sen ting', 'andrew sheinis']"
2107.00156,a study of the quality of wikidata,cs.ai,"wikidata has been increasingly adopted by many communities for a wide variety of applications, which demand high-quality knowledge to deliver successful results. in this paper, we develop a framework to detect and analyze low-quality statements in wikidata by shedding light on the current practices exercised by the community. we explore three indicators of data quality in wikidata, based on: 1) community consensus on the currently recorded knowledge, assuming that statements that have been removed and not added back are implicitly agreed to be of low quality; 2) statements that have been deprecated; and 3) constraint violations in the data. we combine these indicators to detect low-quality statements, revealing challenges with duplicate entities, missing triples, violated type rules, and taxonomic distinctions. our findings complement ongoing efforts by the wikidata community to improve data quality, aiming to make it easier for users and editors to find and correct mistakes.",,2021-06-30,2021-11-17,"['kartik shenoy', 'filip ilievski', 'daniel garijo', 'daniel schwabe', 'pedro szekely']"
2107.00488,differentiable particle filters through conditional normalizing flow,cs.ai cs.lg,"differentiable particle filters provide a flexible mechanism to adaptively train dynamic and measurement models by learning from observed data. however, most existing differentiable particle filters are within the bootstrap particle filtering framework and fail to incorporate the information from latest observations to construct better proposals. in this paper, we utilize conditional normalizing flows to construct proposal distributions for differentiable particle filters, enriching the distribution families that the proposal distributions can represent. in addition, normalizing flows are incorporated in the construction of the dynamic model, resulting in a more expressive dynamic model. we demonstrate the performance of the proposed conditional normalizing flow-based differentiable particle filters in a visual tracking task.",,2021-07-01,2021-11-10,"['xiongjie chen', 'hao wen', 'yunpeng li']"
2107.02233,end-to-end weak supervision,cs.lg cs.ai stat.ml,"aggregating multiple sources of weak supervision (ws) can ease the data-labeling bottleneck prevalent in many machine learning applications, by replacing the tedious manual collection of ground truth labels. current state of the art approaches that do not use any labeled training data, however, require two separate modeling steps: learning a probabilistic latent variable model based on the ws sources -- making assumptions that rarely hold in practice -- followed by downstream model training. importantly, the first step of modeling does not consider the performance of the downstream model. to address these caveats we propose an end-to-end approach for directly learning the downstream model by maximizing its agreement with probabilistic labels generated by reparameterizing previous probabilistic posteriors with a neural network. our results show improved performance over prior work in terms of end model performance on downstream test sets, as well as in terms of improved robustness to dependencies among weak supervision sources.",,2021-07-05,2021-10-30,"['salva rühling cachay', 'benedikt boecking', 'artur dubrawski']"
2107.02524,depth-aware multi-grid deep homography estimation with contextual   correlation,cs.cv cs.ai,"homography estimation is an important task in computer vision applications, such as image stitching, video stabilization, and camera calibration. traditional homography estimation methods heavily depend on the quantity and distribution of feature correspondences, leading to poor robustness in low-texture scenes. the learning solutions, on the contrary, try to learn robust deep features but demonstrate unsatisfying performance in the scenes with low overlap rates. in this paper, we address these two problems simultaneously by designing a contextual correlation layer (ccl). the ccl can efficiently capture the long-range correlation within feature maps and can be flexibly used in a learning framework. in addition, considering that a single homography can not represent the complex spatial transformation in depth-varying images with parallax, we propose to predict multi-grid homography from global to local. moreover, we equip our network with a depth perception capability, by introducing a novel depth-aware shape-preserved loss. extensive experiments demonstrate the superiority of our method over state-of-the-art solutions in the synthetic benchmark dataset and real-world dataset. the codes and models will be available at https://github.com/nie-lang/multi-grid-deep-homography.",10.1109/tcsvt.2021.3125736,2021-07-06,2021-11-03,"['lang nie', 'chunyu lin', 'kang liao', 'shuaicheng liu', 'yao zhao']"
2107.02661,does dataset complexity matters for model explainers?,cs.lg cs.ai,"strategies based on explainable artificial intelligence - xai have emerged in computing to promote a better understanding of predictions made by black box models. most xai measures used today explain these types of models, generating attribute rankings aimed at explaining the model, that is, the analysis of attribute importance of model. there is no consensus on which xai measure generates an overall explainability rank. for this reason, several proposals for tools have emerged (ciu, dalex, eli5, lofo, shap and skater). an experimental benchmark of explainable ai techniques capable of producing global explainability ranks based on tabular data related to different problems and ensemble models are presented herein. seeking to answer questions such as ""are the explanations generated by the different measures the same, similar or different?"" and ""how does data complexity play along model explainability?"" the results from the construction of 82 computational models and 592 ranks shed some light on the other side of the problem of explainability: dataset complexity!",,2021-07-06,2021-11-17,"['josé ribeiro', 'raíssa silva', 'lucas cardoso', 'ronnie alves']"
2107.02748,majority-3sat (and related problems) in polynomial time,cs.cc cs.ai cs.ds,"majority-sat is the problem of determining whether an input $n$-variable formula in conjunctive normal form (cnf) has at least $2^{n-1}$ satisfying assignments. majority-sat and related problems have been studied extensively in various ai communities interested in the complexity of probabilistic planning and inference. although majority-sat has been known to be pp-complete for over 40 years, the complexity of a natural variant has remained open: majority-$k$sat, where the input cnf formula is restricted to have clause width at most $k$.   we prove that for every $k$, majority-$k$sat is in p. in fact, for any positive integer $k$ and rational $\rho \in (0,1)$ with bounded denominator, we give an algorithm that can determine whether a given $k$-cnf has at least $\rho \cdot 2^n$ satisfying assignments, in deterministic linear time (whereas the previous best-known algorithm ran in exponential time). our algorithms have interesting positive implications for counting complexity and the complexity of inference, significantly reducing the known complexities of related problems such as e-maj-$k$sat and maj-maj-$k$sat. at the heart of our approach is an efficient method for solving threshold counting problems by extracting sunflowers found in the corresponding set system of a $k$-cnf.   we also show that the tractability of majority-$k$sat is somewhat fragile. for the closely related gtmajority-sat problem (where we ask whether a given formula has greater than $2^{n-1}$ satisfying assignments) which is known to be pp-complete, we show that gtmajority-$k$sat is in p for $k\le 3$, but becomes np-complete for $k\geq 4$. these results are counterintuitive, because the ``natural'' classifications of these problems would have been pp-completeness, and because there is a stark difference in the complexity of gtmajority-$k$sat and majority-$k$sat for all $k\ge 4$.",,2021-07-06,2021-11-15,"['shyan akmal', 'ryan williams']"
2107.04457,aligning an optical interferometer with beam divergence control and   continuous action space,cs.ro cs.ai cs.lg physics.optics,"reinforcement learning is finding its way to real-world problem application, transferring from simulated environments to physical setups. in this work, we implement vision-based alignment of an optical mach-zehnder interferometer with a confocal telescope in one arm, which controls the diameter and divergence of the corresponding beam. we use a continuous action space; exponential scaling enables us to handle actions within a range of over two orders of magnitude. our agent trains only in a simulated environment with domain randomizations. in an experimental evaluation, the agent significantly outperforms an existing solution and a human expert.",,2021-07-09,2021-11-16,"['stepan makarenko', 'dmitry sorokin', 'alexander ulanov', 'a. i. lvovsky']"
2107.04827,identifying layers susceptible to adversarial attacks,cs.lg cs.ai cs.cv,"in this paper, we investigate the use of pretraining with adversarial networks, with the objective of discovering the relationship between network depth and robustness. for this purpose, we selectively retrain different portions of vgg and resnet architectures on cifar-10, imagenette, and imagenet using non-adversarial and adversarial data. experimental results show that susceptibility to adversarial samples is associated with low-level feature extraction layers. therefore, retraining of high-level layers is insufficient for achieving robustness. furthermore, adversarial attacks yield outputs from early layers that differ statistically from features for non-adversarial samples and do not permit consistent classification by subsequent layers. this supports common hypotheses regarding the association of robustness with the feature extractor, insufficiency of deeper layers in providing robustness, and large differences in adversarial and non-adversarial feature vectors.",,2021-07-10,2021-10-28,"['shoaib ahmed siddiqui', 'thomas breuel']"
2107.06071,aistrom -- a roadmap for developing a successful ai strategy,cs.ai,"a total of 34% of ai research and development projects fails or are abandoned, according to a recent survey by rackspace technology of 1,870 companies. we propose a new strategic framework, aistrom, that empowers managers to create a successful ai strategy based on a thorough literature review. this provides a unique and integrated approach that guides managers and lead developers through the various challenges in the implementation process. in the aistrom framework, we start by identifying the top n potential projects (typically 3-5). for each of those, seven areas of focus are thoroughly analysed. these areas include creating a data strategy that takes into account unique cross-departmental machine learning data requirements, security, and legal requirements. aistrom then guides managers to think about how to put together an interdisciplinary artificial intelligence (ai) implementation team given the scarcity of ai talent. once an ai team strategy has been established, it needs to be positioned within the organization, either cross-departmental or as a separate division. other considerations include ai as a service (aiaas), or outsourcing development. looking at new technologies, we have to consider challenges such as bias, legality of black-box-models, and keeping humans in the loop. next, like any project, we need value-based key performance indicators (kpis) to track and validate the progress. depending on the company's risk-strategy, a swot analysis (strengths, weaknesses, opportunities, and threats) can help further classify the shortlisted projects. finally, we should make sure that our strategy includes continuous education of employees to enable a culture of adoption. this unique and comprehensive framework offers a valuable, literature supported, tool for managers and lead developers.",10.1109/access.2021.3127548,2021-06-25,2021-11-15,['dorien herremans']
2107.06675,"m5 competition uncertainty: overdispersion, distributional forecasting,   gamlss and beyond",stat.ml cs.ai cs.lg stat.ap stat.me,"the m5 competition uncertainty track aims for probabilistic forecasting of sales of thousands of walmart retail goods. we show that the m5 competition data faces strong overdispersion and sporadic demand, especially zero demand. we discuss resulting modeling issues concerning adequate probabilistic forecasting of such count data processes. unfortunately, the majority of popular prediction methods used in the m5 competition (e.g. lightgbm and xgboost gbms) fails to address the data characteristics due to the considered objective functions. the distributional forecasting provides a suitable modeling approach for to the overcome those problems. the gamlss framework allows flexible probabilistic forecasting using low dimensional distributions. we illustrate, how the gamlss approach can be applied for the m5 competition data by modeling the location and scale parameter of various distributions, e.g. the negative binomial distribution. finally, we discuss software packages for distributional modeling and their drawback, like the r package gamlss with its package extensions, and (deep) distributional forecasting libraries such as tensorflow probability.",10.1016/j.ijforecast.2021.09.008,2021-07-14,2021-11-10,['florian ziel']
2107.06870,reinforced hybrid genetic algorithm for the traveling salesman problem,cs.ne cs.ai,"we propose a novel method called the reinforced hybrid genetic algorithm (rhga) for solving the famous np-hard traveling salesman problem (tsp). specifically, we combine a reinforcement learning technique with the well-known edge assembly crossover genetic algorithm (eax-ga) and the lin-kernighan-helsgaun (lkh) local search heuristic. with the help of the proposed hybrid mechanism, the genetic evolution of eax-ga and the local search of lkh can boost each other's performance. and the reinforcement learning technique based on q-learning further promotes the hybrid genetic algorithm. experimental results on 138 well-known and widely used tsp benchmarks with the number of cities ranging from 1,000 to 85,900 demonstrate the excellent performance of rhga, that outperforms eax-ga and lkh significantly.",,2021-07-09,2021-11-06,"['jiongzhi zheng', 'jialun zhong', 'menglei chen', 'kun he']"
2107.07502,multibench: multiscale benchmarks for multimodal representation learning,cs.lg cs.ai cs.cl cs.cv cs.mm,"learning multimodal representations involves integrating information from multiple heterogeneous sources of data. it is a challenging yet crucial area with numerous real-world applications in multimedia, affective computing, robotics, finance, human-computer interaction, and healthcare. unfortunately, multimodal research has seen limited resources to study (1) generalization across domains and modalities, (2) complexity during training and inference, and (3) robustness to noisy and missing modalities. in order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release multibench, a systematic and unified large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. multibench provides an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. to enable holistic evaluation, multibench offers a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. multibench introduces impactful challenges for future research, including scalability to large-scale multimodal datasets and robustness to realistic imperfections. to accompany this benchmark, we also provide a standardized implementation of 20 core approaches in multimodal learning. simply applying methods proposed in different research areas can improve the state-of-the-art performance on 9/15 datasets. therefore, multibench presents a milestone in unifying disjoint efforts in multimodal research and paves the way towards a better understanding of the capabilities and limitations of multimodal models, all the while ensuring ease of use, accessibility, and reproducibility. multibench, our standardized code, and leaderboards are publicly available, will be regularly updated, and welcomes inputs from the community.",,2021-07-15,2021-11-10,"['paul pu liang', 'yiwei lyu', 'xiang fan', 'zetian wu', 'yun cheng', 'jason wu', 'leslie chen', 'peter wu', 'michelle a. lee', 'yuke zhu', 'ruslan salakhutdinov', 'louis-philippe morency']"
2107.08353,top-label calibration and multiclass-to-binary reductions,cs.lg cs.ai stat.me stat.ml,"we investigate the relationship between commonly considered notions of multiclass calibration and the calibration algorithms used to achieve these notions, leading to two broad contributions. first, we propose a new and arguably natural notion of top-label calibration, which requires the reported probability of the most likely label to be calibrated. along the way, we highlight certain philosophical issues with the closely related and popular notion of confidence calibration. second, we outline general 'wrapper' multiclass-to-binary (m2b) algorithms that can be used to achieve confidence, top-label, and class-wise calibration, using underlying binary calibration routines. our wrappers can also be generalized to other notions of calibration, if required for certain practical applications. we instantiate these wrappers with the binary histogram binning (hb) algorithm, and show that the overall procedure has distribution-free calibration guarantees. in an empirical evaluation, we find that with the right m2b wrapper, hb performs significantly better than other calibration approaches. code for this work has been made publicly available at https://github.com/aigen/df-posthoc-calibration.",,2021-07-17,2021-10-29,"['chirag gupta', 'aaditya k. ramdas']"
2107.08558,a topological perspective on causal inference,cs.ai cs.lg stat.me,"this paper presents a topological learning-theoretic perspective on causal inference by introducing a series of topologies defined on general spaces of structural causal models (scms). as an illustration of the framework we prove a topological causal hierarchy theorem, showing that substantive assumption-free causal inference is possible only in a meager set of scms. thanks to a known correspondence between open sets in the weak topology and statistically verifiable hypotheses, our results show that inductive assumptions sufficient to license valid causal inferences are statistically unverifiable in principle. similar to no-free-lunch theorems for statistical inference, the present results clarify the inevitability of substantial assumptions for causal inference. an additional benefit of our topological approach is that it easily accommodates scms with infinitely many variables. we finally suggest that the framework may be helpful for the positive project of exploring and assessing alternative causal-inductive assumptions.",,2021-07-18,2021-11-05,"['duligur ibeling', 'thomas icard']"
2107.09996,marsexplorer: exploration of unknown terrains via deep reinforcement   learning and procedurally generated environments,cs.ro cs.ai cs.lg,"this paper is an initial endeavor to bridge the gap between powerful deep reinforcement learning methodologies and the problem of exploration/coverage of unknown terrains. within this scope, marsexplorer, an openai-gym compatible environment tailored to exploration/coverage of unknown areas, is presented. marsexplorer translates the original robotics problem into a reinforcement learning setup that various off-the-shelf algorithms can tackle. any learned policy can be straightforwardly applied to a robotic platform without an elaborate simulation model of the robot's dynamics to apply a different learning/adaptation phase. one of its core features is the controllable multi-dimensional procedural generation of terrains, which is the key for producing policies with strong generalization capabilities. four different state-of-the-art rl algorithms (a3c, ppo, rainbow, and sac) are trained on the marsexplorer environment, and a proper evaluation of their results compared to the average human-level performance is reported. in the follow-up experimental analysis, the effect of the multi-dimensional difficulty setting on the learning capabilities of the best-performing algorithm (ppo) is analyzed. a milestone result is the generation of an exploration policy that follows the hilbert curve without providing this information to the environment or rewarding directly or indirectly hilbert-curve-like trajectories. the experimental analysis is concluded by evaluating ppo learned policy algorithm side-by-side with frontier-based exploration strategies. a study on the performance curves revealed that ppo-based policy was capable of performing adaptive-to-the-unknown-terrain sweeping without leaving expensive-to-revisit areas uncovered, underlying the capability of rl-based methodologies to tackle exploration tasks efficiently. the source code can be found at: https://github.com/dimikout3/marsexplorer.",,2021-07-21,2021-11-06,"['dimitrios i. koutras', 'athanasios ch. kapoutsis', 'angelos a. amanatiadis', 'elias b. kosmatopoulos']"
2107.10332,machine learning characterization of cancer patients-derived   extracellular vesicles using vibrational spectroscopies,q-bio.ot cs.ai cs.lg physics.bio-ph,"the early detection of cancer is a challenging problem in medicine. the blood sera of cancer patients are enriched with heterogeneous secretory lipid bound extracellular vesicles (evs), which present a complex repertoire of information and biomarkers, representing their cell of origin, that are being currently studied in the field of liquid biopsy and cancer screening. vibrational spectroscopies provide non-invasive approaches for the assessment of structural and biophysical properties in complex biological samples. in this pilot study, multiple raman spectroscopy measurements were performed on the evs extracted from the blood sera of 9 patients consisting of four different cancer subtypes (colorectal cancer, hepatocellular carcinoma, breast cancer and pancreatic cancer) and five healthy patients (controls). ftir (fourier transform infrared) spectroscopy measurements were performed as a complementary approach to raman analysis, on two of the four cancer subtypes.   the adaboost random forest classifier, decision trees, and support vector machines (svm) distinguished the baseline corrected raman spectra of cancer evs from those of healthy controls (18 spectra) with a classification accuracy of above 90 percent when reduced to a spectral frequency range of 1800 to 1940 inverse cm and subjected to a 50:50 training: testing split. ftir classification accuracy on 14 spectra showed an 80 percent classification accuracy. our findings demonstrate that basic machine learning algorithms are powerful applied intelligence tools to distinguish the complex vibrational spectra of cancer patient evs from those of healthy patients. these experimental methods hold promise as valid and efficient liquid biopsy for artificial intelligence-assisted early cancer screening.",,2021-07-21,2021-11-17,"['abicumaran uthamacumaran', 'samir elouatik', 'mohamed abdouh', 'michael berteau-rainville', 'zu-hua gao', 'goffredo arena']"
2107.10624,lana: latency aware network acceleration,cs.cv cs.ai cs.lg,"we introduce latency-aware network acceleration (lana) - an approach that builds on neural architecture search techniques and teacher-student distillation to accelerate neural networks. lana consists of two phases: in the first phase, it trains many alternative operations for every layer of the teacher network using layer-wise feature map distillation. in the second phase, it solves the combinatorial selection of efficient operations using a novel constrained integer linear optimization (ilp) approach. ilp brings unique properties as it (i) performs nas within a few seconds to minutes, (ii) easily satisfies budget constraints, (iii) works on the layer-granularity, (iv) supports a huge search space $o(10^{100})$, surpassing prior search approaches in efficacy and efficiency. in extensive experiments, we show that lana yields efficient and accurate models constrained by a target latency budget, while being significantly faster than other techniques. we analyze three popular network architectures: efficientnetv1, efficientnetv2 and resnest, and achieve accuracy improvement for all models (up to $3.0\%$) when compressing larger models to the latency level of smaller models. lana achieves significant speed-ups (up to $5\times$) with minor to no accuracy drop on gpu and cpu. the code will be shared soon.",,2021-07-12,2021-11-18,"['pavlo molchanov', 'jimmy hall', 'hongxu yin', 'jan kautz', 'nicolo fusi', 'arash vahdat']"
2107.12064,how knowledge graph and attention help? a quantitative analysis into   bag-level relation extraction,cs.cl cs.ai,"knowledge graph (kg) and attention mechanism have been demonstrated effective in introducing and selecting useful information for weakly supervised methods. however, only qualitative analysis and ablation study are provided as evidence. in this paper, we contribute a dataset and propose a paradigm to quantitatively evaluate the effect of attention and kg on bag-level relation extraction (re). we find that (1) higher attention accuracy may lead to worse performance as it may harm the model's ability to extract entity mention features; (2) the performance of attention is largely influenced by various noise distribution patterns, which is closely related to real-world datasets; (3) kg-enhanced attention indeed improves re performance, while not through enhanced attention but by incorporating entity prior; and (4) attention mechanism may exacerbate the issue of insufficient training data. based on these findings, we show that a straightforward variant of re model can achieve significant improvements (6% auc on average) on two real-world datasets as compared with three state-of-the-art baselines. our codes and datasets are available at https://github.com/zig-kwin-hu/how-kg-att-help.",10.18653/v1/2021.acl-long.359,2021-07-26,,"['zikun hu', 'yixin cao', 'lifu huang', 'tat-seng chua']"
2107.12375,geometric deep learning on molecular representations,physics.chem-ph cs.ai cs.lg q-bio.bm,"geometric deep learning (gdl), which is based on neural network architectures that incorporate and process symmetry information, has emerged as a recent paradigm in artificial intelligence. gdl bears particular promise in molecular modeling applications, in which various molecular representations with different symmetry properties and levels of abstraction exist. this review provides a structured and harmonized overview of molecular gdl, highlighting its applications in drug discovery, chemical synthesis prediction, and quantum chemistry. emphasis is placed on the relevance of the learned molecular features and their complementarity to well-established molecular descriptors. this review provides an overview of current challenges and opportunities, and presents a forecast of the future of gdl for molecular sciences.",,2021-07-26,2021-11-05,"['kenneth atz', 'francesca grisoni', 'gisbert schneider']"
2107.12977,the social dilemma in artificial intelligence development and why we   have to solve it,cs.ai cs.cy cs.lg,"while the demand for ethical artificial intelligence (ai) systems increases, the number of unethical uses of ai accelerates, even though there is no shortage of ethical guidelines. we argue that a possible underlying cause for this is that ai developers face a social dilemma in ai development ethics, preventing the widespread adaptation of ethical best practices. we define the social dilemma for ai development and describe why the current crisis in ai development ethics cannot be solved without relieving ai developers of their social dilemma. we argue that ai development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.",,2021-07-27,2021-11-17,"['inga strümke', 'marija slavkovik', 'vince i. madai']"
2107.13355,a computer vision-based approach for driver distraction recognition   using deep learning and genetic algorithm based ensemble,cs.cv cs.ai,"as the proportion of road accidents increases each year, driver distraction continues to be an important risk component in road traffic injuries and deaths. the distractions caused by the increasing use of mobile phones and other wireless devices pose a potential risk to road safety. our current study aims to aid the already existing techniques in driver posture recognition by improving the performance in the driver distraction classification problem. we present an approach using a genetic algorithm-based ensemble of six independent deep neural architectures, namely, alexnet, vgg-16, efficientnet b0, vanilla cnn, modified densenet, and inceptionv3 + bilstm. we test it on two comprehensive datasets, the auc distracted driver dataset, on which our technique achieves an accuracy of 96.37%, surpassing the previously obtained 95.98%, and on the state farm driver distraction dataset, on which we attain an accuracy of 99.75%. the 6-model ensemble gave an inference time of 0.024 seconds as measured on our machine with ubuntu 20.04(64-bit) and gpu as geforce gtx 1080.",10.1007/978-3-030-87897-9_5,2021-07-28,,"['ashlesha kumar', 'kuldip singh sangwan', 'n/a dhiraj']"
2107.13625,adaptation and generalization for unknown sensitive factors of   variations,cs.lg cs.ai cs.cv cs.cy,"assured ai in unrestricted settings is a critical problem. our framework addresses ai assurance challenges lying at the intersection of domain adaptation, fairness, and counterfactuals analysis, operating via the discovery and intervention on factors of variations in data (e.g. weather or illumination conditions) that significantly affect the robustness of ai models. robustness is understood here as insensitivity of the model performance to variations in sensitive factors. sensitive factors are traditionally set in a supervised setting, whereby factors are known a-priori (e.g. for fairness this could be factors like sex or race). in contrast, our motivation is real-life scenarios where less, or nothing, is actually known a-priori about certain factors that cause models to fail. this leads us to consider various settings (unsupervised, domain generalization, semi-supervised) that correspond to different degrees of incomplete knowledge about those factors. therefore, our two step approach works by a) discovering sensitive factors that cause ai systems to fail in a unsupervised fashion, and then b) intervening models to lessen these factor's influence. our method considers 3 interventions consisting of augmentation, coherence, and adversarial interventions (acai). we demonstrate the ability for interventions on discovered/source factors to generalize to target/real factors. we also demonstrate how adaptation to real factors of variations can be performed in the semi-supervised case where some target factor labels are known, via automated intervention selection. experiments show that our approach improves on baseline models, with regard to achieving optimal utility vs. sensitivity/robustness tradeoffs.",,2021-07-28,2021-11-17,"['william paul', 'philippe burlina']"
2107.14077,a fair and ethical healthcare artificial intelligence system for   monitoring driver behavior and preventing road accidents,cs.cy cs.ai cs.hc cs.lg,"this paper presents a new approach to prevent transportation accidents and monitor driver's behavior using a healthcare ai system that incorporates fairness and ethics. dangerous medical cases and unusual behavior of the driver are detected. fairness algorithm is approached in order to improve decision-making and address ethical issues such as privacy issues, and to consider challenges that appear in the wild within ai in healthcare and driving. a healthcare professional will be alerted about any unusual activity, and the driver's location when necessary, is provided in order to enable the healthcare professional to immediately help to the unstable driver. therefore, using the healthcare ai system allows for accidents to be predicted and thus prevented and lives may be saved based on the built-in ai system inside the vehicle which interacts with the er system.",10.1007/978-3-030-89880-9_33,2021-06-16,2021-11-07,"['soraia oueida', 'soaad hossain', 'yehia kotb', 'syed ishtiaque ahmed']"
2107.14483,maniskill: generalizable manipulation skill benchmark with large-scale   demonstrations,cs.lg cs.ai cs.cv cs.ro,"object manipulation from 3d visual inputs poses many challenges on building generalizable perception and policy models. however, 3d assets in existing benchmarks mostly lack the diversity of 3d shapes that align with real-world intra-class complexity in topology and geometry. here we propose sapien manipulation skill benchmark (maniskill) to benchmark manipulation skills over diverse objects in a full-physics simulator. 3d assets in maniskill include large intra-class topological and geometric variations. tasks are carefully chosen to cover distinct types of manipulation challenges. latest progress in 3d vision also makes us believe that we should customize the benchmark so that the challenge is inviting to researchers working on 3d deep learning. to this end, we simulate a moving panoramic camera that returns ego-centric point clouds or rgb-d images. in addition, we would like maniskill to serve a broad set of researchers interested in manipulation research. besides supporting the learning of policies from interactions, we also support learning-from-demonstrations (lfd) methods, by providing a large number of high-quality demonstrations (~36,000 successful trajectories, ~1.5m point cloud/rgb-d frames in total). we provide baselines using 3d deep learning and lfd algorithms. all code of our benchmark (simulator, environment, sdk, and baselines) is open-sourced, and a challenge facing interdisciplinary researchers will be held based on the benchmark.",,2021-07-30,2021-11-04,"['tongzhou mu', 'zhan ling', 'fanbo xiang', 'derek yang', 'xuanlin li', 'stone tao', 'zhiao huang', 'zhiwei jia', 'hao su']"
2108.00238,unlimited neighborhood interaction for heterogeneous trajectory   prediction,cs.ai cs.cv,"understanding complex social interactions among agents is a key challenge for trajectory prediction. most existing methods consider the interactions between pairwise traffic agents or in a local area, while the nature of interactions is unlimited, involving an uncertain number of agents and non-local areas simultaneously. besides, they treat heterogeneous traffic agents the same, namely those among agents of different categories, while neglecting people's diverse reaction patterns toward traffic agents in ifferent categories. to address these problems, we propose a simple yet effective unlimited neighborhood interaction network (unin), which predicts trajectories of heterogeneous agents in multiple categories. specifically, the proposed unlimited neighborhood interaction module generates the fused-features of all agents involved in an interaction simultaneously, which is adaptive to any number of agents and any range of interaction area. meanwhile, a hierarchical graph attention module is proposed to obtain category-to-category interaction and agent-to-agent interaction. finally, parameters of a gaussian mixture model are estimated for generating the future trajectories. extensive experimental results on benchmark datasets demonstrate a significant performance improvement of our method over the state-of-the-art methods.",,2021-07-31,2021-11-02,"['fang zheng', 'le wang', 'sanping zhou', 'wei tang', 'zhenxing niu', 'nanning zheng', 'gang hua']"
2108.01034,an efficient image-to-image translation hourglass-based architecture for   object pushing policy learning,cs.ro cs.ai cs.lg,"humans effortlessly solve pushing tasks in everyday life but unlocking these capabilities remains a challenge in robotics because physics models of these tasks are often inaccurate or unattainable. state-of-the-art data-driven approaches learn to compensate for these inaccuracies or replace the approximated physics models altogether. nevertheless, approaches like deep q-networks (dqns) suffer from local optima in large state-action spaces. furthermore, they rely on well-chosen deep learning architectures and learning paradigms. in this paper, we propose to frame the learning of pushing policies (where to push and how) by dqns as an image-to-image translation problem and exploit an hourglass-based architecture. we present an architecture combining a predictor of which pushes lead to changes in the environment with a state-action value predictor dedicated to the pushing task. moreover, we investigate positional information encoding to learn position-dependent policy behaviors. we demonstrate in simulation experiments with a ur5 robot arm that our overall architecture helps the dqn learn faster and achieve higher performance in a pushing task involving objects with unknown dynamics.",,2021-08-02,2021-11-16,"['marco ewerton', 'angel martínez-gonzález', 'jean-marc odobez']"
2108.01455,febr: expert-based recommendation framework for beneficial and   personalized content,cs.ir cs.ai cs.lg,"so far, most research on recommender systems focused on maintaining long-term user engagement and satisfaction, by promoting relevant and personalized content. however, it is still very challenging to evaluate the quality and the reliability of this content. in this paper, we propose febr (expert-based recommendation framework), an apprenticeship learning framework to assess the quality of the recommended content on online platforms. the framework exploits the demonstrated trajectories of an expert (assumed to be reliable) in a recommendation evaluation environment, to recover an unknown utility function. this function is used to learn an optimal policy describing the expert's behavior, which is then used in the framework to provide high-quality and personalized recommendations. we evaluate the performance of our solution through a user interest simulation environment (using recsim). we simulate interactions under the aforementioned expert policy for videos recommendation, and compare its efficiency with standard recommendation methods. the results show that our approach provides a significant gain in terms of content quality, evaluated by experts and watched by users, while maintaining almost the same watch time as the baseline approaches.",,2021-07-17,2021-11-03,"['mohamed lechiakh', 'alexandre maurer']"
2108.01899,generic neural architecture search via regression,cs.lg cs.ai cs.cv cs.ne,"most existing neural architecture search (nas) algorithms are dedicated to and evaluated by the downstream tasks, e.g., image classification in computer vision. however, extensive experiments have shown that, prominent neural architectures, such as resnet in computer vision and lstm in natural language processing, are generally good at extracting patterns from the input data and perform well on different downstream tasks. in this paper, we attempt to answer two fundamental questions related to nas. (1) is it necessary to use the performance of specific downstream tasks to evaluate and search for good neural architectures? (2) can we perform nas effectively and efficiently while being agnostic to the downstream tasks? to answer these questions, we propose a novel and generic nas framework, termed generic nas (gennas). gennas does not use task-specific labels but instead adopts regression on a set of manually designed synthetic signal bases for architecture evaluation. such a self-supervised regression task can effectively evaluate the intrinsic power of an architecture to capture and transform the input signal patterns, and allow more sufficient usage of training samples. extensive experiments across 13 cnn search spaces and one nlp space demonstrate the remarkable efficiency of gennas using regression, in terms of both evaluating the neural architectures (quantified by the ranking correlation spearman's rho between the approximated performances and the downstream task performances) and the convergence speed for training (within a few seconds).",,2021-08-04,2021-11-17,"['yuhong li', 'cong hao', 'pan li', 'jinjun xiong', 'deming chen']"
2108.03272,igibson 2.0: object-centric simulation for robot learning of everyday   household tasks,cs.ro cs.ai cs.cv cs.lg,"recent research in embodied ai has been boosted by the use of simulation environments to develop and train robot learning approaches. however, the use of simulation has skewed the attention to tasks that only require what robotics simulators can simulate: motion and physical contact. we present igibson 2.0, an open-source simulation environment that supports the simulation of a more diverse set of household tasks through three key innovations. first, igibson 2.0 supports object states, including temperature, wetness level, cleanliness level, and toggled and sliced states, necessary to cover a wider range of tasks. second, igibson 2.0 implements a set of predicate logic functions that map the simulator states to logic states like cooked or soaked. additionally, given a logic state, igibson 2.0 can sample valid physical states that satisfy it. this functionality can generate potentially infinite instances of tasks with minimal effort from the users. the sampling mechanism allows our scenes to be more densely populated with small objects in semantically meaningful locations. third, igibson 2.0 includes a virtual reality (vr) interface to immerse humans in its scenes to collect demonstrations. as a result, we can collect demonstrations from humans on these new types of tasks, and use them for imitation learning. we evaluate the new capabilities of igibson 2.0 to enable robot learning of novel tasks, in the hope of demonstrating the potential of this new simulator to support new research in embodied ai. igibson 2.0 and its new dataset are publicly available at http://svl.stanford.edu/igibson/.",,2021-08-06,2021-11-03,"['chengshu li', 'fei xia', 'roberto martín-martín', 'michael lingelbach', 'sanjana srivastava', 'bokui shen', 'kent vainio', 'cem gokmen', 'gokul dharan', 'tanish jain', 'andrey kurenkov', 'c. karen liu', 'hyowon gweon', 'jiajun wu', 'li fei-fei', 'silvio savarese']"
2108.03900,multi-view trgru: transformer based spatiotemporal model for short-term   metro origin-destination matrix prediction,cs.ai,"accurate prediction of short-term od matrix (i.e. the distribution of passenger flows from various origins to destinations) is a crucial task in metro systems. it is highly challenging due to the constantly changing nature of many impacting factors and the real-time delayed data collection problem. recently, some deep learning-based models have been proposed for od matrix forecasting in ride-hailing and high way traffic scenarios. however, these models can not sufficiently capture the complex spatiotemporal correlation between stations in metro networks due to their different prior knowledge and contextual settings. in this paper we propose a hybrid framework multi-view trgru to address od metro matrix prediction. in particular, it uses three modules to model three flow change patterns: recent trend, daily trend, weekly trend. in each module, a multi-view representation based on embedding for each station is constructed and fed into a transformer based gated recurrent structure so as to capture the dynamic spatial dependency in od flows of different stations by a global self-attention mechanism. extensive experiments on three large-scale, real-world metro datasets demonstrate the superiority of our multi-view trgru over other competitors.",,2021-08-09,2021-11-12,"['jiexia ye', 'furong zheng', 'juanjuan zhao', 'kejiang ye', 'chengzhong xu']"
2108.03997,a new step for computing,cs.dc cs.ai,"the data center of tomorrow is a data center made up of heterogeneous systems, which will run heterogeneous workloads. the systems will be located as close as possible to the data. heterogeneous systems will be equipped with binary, biological inspired and quantum accelerators. these architectures will be the foundations to address challenges. like an orchestra conductor, the hybrid cloud will make it possible to set these systems to music thanks to a layer of security and intelligent automation.",,2021-07-22,2021-11-04,['xavier vasques']
2108.04927,"embodied bert: a transformer model for embodied, language-guided visual   task completion",cs.cv cs.ai cs.cl cs.lg,"language-guided robots performing home and office tasks must navigate in and interact with the world. grounding language instructions against visual observations and actions to take in an environment is an open challenge. we present embodied bert (embert), a transformer-based model which can attend to high-dimensional, multi-modal inputs across long temporal horizons for language-conditioned task completion. additionally, we bridge the gap between successful object-centric navigation models used for non-interactive agents and the language-guided visual task completion benchmark, alfred, by introducing object navigation targets for embert training. we achieve competitive performance on the alfred benchmark, and embert marks the first transformer-based model to successfully handle the long-horizon, dense, multi-modal histories of alfred, and the first alfred model to utilize object-centric navigation targets.",,2021-08-10,2021-11-04,"['alessandro suglia', 'qiaozi gao', 'jesse thomason', 'govind thattai', 'gaurav sukhatme']"
2108.05075,turning your strength against you: detecting and mitigating robust and   universal adversarial patch attacks,cs.cr cs.ai cs.lg,"adversarial patch attacks against image classification deep neural networks (dnns), which inject arbitrary distortions within a bounded region of an image, can generate adversarial perturbations that are robust (i.e., remain adversarial in physical world) and universal (i.e., remain adversarial on any input). such attacks can lead to severe consequences in real-world dnn-based systems.   this work proposes jujutsu, a technique to detect and mitigate robust and universal adversarial patch attacks. for detection, jujutsu exploits the attacks' universal property - jujutsu first locates the region of the potential adversarial patch, and then strategically transfers it to a dedicated region in a new image to determine whether it is truly malicious. for attack mitigation, jujutsu leverages the attacks' localized nature via image inpainting to synthesize the semantic contents in the pixels that are corrupted by the attacks, and reconstruct the ``clean'' image.   we evaluate jujutsu on four diverse datasets (imagenet, imagenette, celeba and place365), and show that jujutsu achieves superior performance and significantly outperforms existing techniques. we find that jujutsu can further defend against different variants of the basic attack, including 1) physical-world attack; 2) attacks that target diverse classes; 3) attacks that construct patches in different shapes and 4) adaptive attacks.",,2021-08-11,2021-11-16,"['zitao chen', 'pritam dash', 'karthik pattabiraman']"
2108.06912,blockchain-based trustworthy federated learning architecture,cs.lg cs.ai,"federated learning is an emerging privacy-preserving ai technique where clients (i.e., organisations or devices) train models locally and formulate a global model based on the local model updates without transferring local data externally. however, federated learning systems struggle to achieve trustworthiness and embody responsible ai principles. in particular, federated learning systems face accountability and fairness challenges due to multi-stakeholder involvement and heterogeneity in client data distribution. to enhance the accountability and fairness of federated learning systems, we present a blockchain-based trustworthy federated learning architecture. we first design a smart contract-based data-model provenance registry to enable accountability. additionally, we propose a weighted fair data sampler algorithm to enhance fairness in training data. we evaluate the proposed approach using a covid-19 x-ray detection use case. the evaluation results show that the approach is feasible to enable accountability and improve fairness. the proposed algorithm can achieve better performance than the default federated learning setting in terms of the model's generalisation and accuracy.",,2021-08-16,2021-10-28,"['sin kit lo', 'yue liu', 'qinghua lu', 'chen wang', 'xiwei xu', 'hye-young paik', 'liming zhu']"
2108.08052,moser flow: divergence-based generative modeling on manifolds,stat.ml cs.ai cs.lg,"we are interested in learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. current extensions of existing (euclidean) generative models are restricted to specific geometries and typically suffer from high computational costs. we introduce moser flow (mf), a new class of generative models within the family of continuous normalizing flows (cnf). mf also produces a cnf via a solution to the change-of-variable formula, however differently from other cnf methods, its model (learned) density is parameterized as the source (prior) density minus the divergence of a neural network (nn). the divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. therefore, unlike other cnfs, mf does not require invoking or backpropagating through an ode solver during training. furthermore, representing the model density explicitly as the divergence of a nn rather than as a solution of an ode facilitates learning high fidelity densities. theoretically, we prove that mf constitutes a universal density approximator under suitable assumptions. empirically, we demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity over existing cnfs on challenging synthetic geometries and real-world benchmarks from the earth and climate sciences.",,2021-08-18,2021-11-02,"['noam rozen', 'aditya grover', 'maximilian nickel', 'yaron lipman']"
2108.08339,real-time bangla license plate recognition system for low resource   video-based applications,cs.cv cs.ai,"automatic license plate recognition systems aim to provide a solution for detecting, localizing, and recognizing license plate characters from vehicles appearing in video frames. however, deploying such systems in the real world requires real-time performance in low-resource environments. in our paper, we propose a two-stage detection pipeline paired with vision api that provides real-time inference speed along with consistently accurate detection and recognition performance. we used a haar-cascade classifier as a filter on top of our backbone mobilenet ssdv2 detection model. this reduces inference time by only focusing on high confidence detections and using them for recognition. we also impose a temporal frame separation strategy to distinguish between multiple vehicle license plates in the same clip. furthermore, there are no publicly available bangla license plate datasets, for which we created an image dataset and a video dataset containing license plates in the wild. we trained our models on the image dataset and achieved an ap(0.5) score of 86% and tested our pipeline on the video dataset and observed reasonable detection and recognition performance (82.7% detection rate, and 60.8% ocr f1 score) with real-time processing speed (27.2 frames per second).",,2021-08-18,2021-11-14,"['alif ashrafee', 'akib mohammed khan', 'mohammad sabik irbaz', 'md abdullah al nasim']"
2108.09484,cushlepor: customising hlepor metric using optuna for higher agreement   with human judgments or pre-trained language model labse,cs.cl cs.ai cs.lg,"human evaluation has always been expensive while researchers struggle to trust the automatic metrics. to address this, we propose to customise traditional metrics by taking advantages of the pre-trained language models (plms) and the limited available human labelled scores. we first re-introduce the hlepor metric factors, followed by the python version we developed (ported) which achieved the automatic tuning of the weighting parameters in hlepor metric. then we present the customised hlepor (cushlepor) which uses optuna hyper-parameter optimisation framework to fine-tune hlepor weighting parameters towards better agreement to pre-trained language models (using labse) regarding the exact mt language pairs that cushlepor is deployed to. we also optimise cushlepor towards professional human evaluation data based on mqm and psqm framework on english-german and chinese-english language pairs. the experimental investigations show cushlepor boosts hlepor performances towards better agreements to plms like labse with much lower cost, and better agreements to human evaluations including mqm and psqm scores, and yields much better performances than bleu (data available at \url{https://github.com/poethan/cushlepor}). official results show that our submissions win three language pairs including \textbf{english-german} and \textbf{chinese-english} on \textit{news} domain via cushlepor(lm) and \textbf{english-russian} on \textit{ted} domain via hlepor.",,2021-08-21,2021-11-15,"['lifeng han', 'irina sorokina', 'gleb erofeev', 'serge gladkoff']"
2108.10152,emotion recognition from multiple modalities: fundamentals and   methodologies,eess.sp cs.ai cs.lg cs.mm,"humans are emotional creatures. multiple modalities are often involved when we express emotions, whether we do so explicitly (e.g., facial expression, speech) or implicitly (e.g., text, image). enabling machines to have emotional intelligence, i.e., recognizing, interpreting, processing, and simulating emotions, is becoming increasingly important. in this tutorial, we discuss several key aspects of multi-modal emotion recognition (mer). we begin with a brief introduction on widely used emotion representation models and affective modalities. we then summarize existing emotion annotation strategies and corresponding computational tasks, followed by the description of main challenges in mer. furthermore, we present some representative approaches on representation learning of each affective modality, feature fusion of different affective modalities, classifier optimization for mer, and domain adaptation for mer. finally, we outline several real-world applications and discuss some future directions.",10.1109/msp.2021.3106895,2021-08-18,,"['sicheng zhao', 'guoli jia', 'jufeng yang', 'guiguang ding', 'kurt keutzer']"
2108.10226,ecg-based heart arrhythmia diagnosis through attentional convolutional   neural networks,eess.sp cs.ai cs.lg,"electrocardiography (ecg) signal is a highly applied measurement for individual heart condition, and much effort have been endeavored towards automatic heart arrhythmia diagnosis based on machine learning. however, traditional machine learning models require large investment of time and effort for raw data preprocessing and feature extraction, as well as challenged by poor classification performance. here, we propose a novel deep learning model, named attention-based convolutional neural networks (abcnn) that taking advantage of cnn and multi-head attention, to directly work on the raw ecg signals and automatically extract the informative dependencies for accurate arrhythmia detection. to evaluate the proposed approach, we conduct extensive experiments over a benchmark ecg dataset. our main task is to find the arrhythmia from normal heartbeats and, at the meantime, accurately recognize the heart diseases from five arrhythmia types. we also provide convergence analysis of abcnn and intuitively show the meaningfulness of extracted representation through visualization. the experimental results show that the proposed abcnn outperforms the widely used baselines, which puts one step closer to intelligent heart disease diagnosis system.",,2021-08-18,2021-10-28,"['ziyu liu', 'xiang zhang']"
2108.10511,cmml: contextual modulation meta learning for cold-start recommendation,cs.ir cs.ai,"practical recommender systems experience a cold-start problem when observed user-item interactions in the history are insufficient. meta learning, especially gradient based one, can be adopted to tackle this problem by learning initial parameters of the model and thus allowing fast adaptation to a specific task from limited data examples. though with significant performance improvement, it commonly suffers from two critical issues: the non-compatibility with mainstream industrial deployment and the heavy computational burdens, both due to the inner-loop gradient operation. these two issues make them hard to be applied in practical recommender systems. to enjoy the benefits of meta learning framework and mitigate these problems, we propose a recommendation framework called contextual modulation meta learning (cmml). cmml is composed of fully feed-forward operations so it is computationally efficient and completely compatible with the mainstream industrial deployment. cmml consists of three components, including a context encoder that can generate context embedding to represent a specific task, a hybrid context generator that aggregates specific user-item features with task-level context, and a contextual modulation network, which can modulate the recommendation model to adapt effectively. we validate our approach on both scenario-specific and user-specific cold-start setting on various real-world datasets, showing cmml can achieve comparable or even better performance with gradient based methods yet with much higher computational efficiency and better interpretability.",,2021-08-23,2021-10-28,"['xidong feng', 'chen chen', 'dong li', 'mengchen zhao', 'jianye hao', 'jun wang']"
2108.10851,autoencoder-based semantic novelty detection: towards dependable   ai-based systems,cs.ai cs.se,"many autonomous systems, such as driverless taxis, perform safety critical functions. autonomous systems employ artificial intelligence (ai) techniques, specifically for the environment perception. engineers cannot completely test or formally verify ai-based autonomous systems. the accuracy of ai-based systems depends on the quality of training data. thus, novelty detection - identifying data that differ in some respect from the data used for training - becomes a safety measure for system development and operation. in this paper, we propose a new architecture for autoencoder-based semantic novelty detection with two innovations: architectural guidelines for a semantic autoencoder topology and a semantic error calculation as novelty criteria. we demonstrate that such a semantic novelty detection outperforms autoencoder-based novelty detection approaches known from literature by minimizing false negatives.",10.3390/app11219881,2021-08-24,2021-08-25,"['andreas rausch', 'azarmidokht motamedi sedeh', 'meng zhang']"
2108.11172,superpixel-guided discriminative low-rank representation of   hyperspectral images for classification,cs.cv cs.ai,"in this paper, we propose a novel classification scheme for the remotely sensed hyperspectral image (hsi), namely sp-dlrr, by comprehensively exploring its unique characteristics, including the local spatial information and low-rankness. sp-dlrr is mainly composed of two modules, i.e., the classification-guided superpixel segmentation and the discriminative low-rank representation, which are iteratively conducted. specifically, by utilizing the local spatial information and incorporating the predictions from a typical classifier, the first module segments pixels of an input hsi (or its restoration generated by the second module) into superpixels. according to the resulting superpixels, the pixels of the input hsi are then grouped into clusters and fed into our novel discriminative low-rank representation model with an effective numerical solution. such a model is capable of increasing the intra-class similarity by suppressing the spectral variations locally while promoting the inter-class discriminability globally, leading to a restored hsi with more discriminative pixels. experimental results on three benchmark datasets demonstrate the significant superiority of sp-dlrr over state-of-the-art methods, especially for the case with an extremely limited number of training pixels.",10.1109/tip.2021.3120675,2021-08-25,2021-10-25,"['shujun yang', 'junhui hou', 'yuheng jia', 'shaohui mei', 'qian du']"
2108.11791,multiple sclerosis lesions identification/segmentation in magnetic   resonance imaging using ensemble cnn and uncertainty classification,eess.iv cs.ai cs.cv,"to date, several automated strategies for identification/segmentation of multiple sclerosis (ms) lesions with the use of magnetic resonance imaging (mri) have been presented but they are either outperformed by human experts or perform differently from them. this is mainly due to the ambiguity originated by mri instabilities, peculiar variability of ms and unspecific nature of mri with respect to ms. physicians partially manage the uncertainty generated by ambiguity relying on their personal radiological/clinical/anatomical background and experience. we present an automated framework based on three pivotal concepts to better emulate human reasoning: 1. the modelling of uncertainty; 2. the proposal of two, separately trained, cnn, one optimized with respect to lesions themselves and the other to the environment surrounding lesions, respectively repeated for axial, coronal and sagittal directions; 3. the definition of an ensemble classifier to merge the information collected by all cnn. the proposed framework is trained, validated and tested on the 2016 msseg benchmark public data set from a single imaging modality, the fluid-attenuated inversion recovery (flair). the comparison, made with the consensus (the ground-truth) between 7 human raters and with each of the 7 human raters, proves that there is no significant difference between the automated and the human raters. the results of our framework concerning the uncertainty are also reported, even if a comparison with the raters is impossible because they don't recognize this class.",,2021-08-26,2021-10-29,"['giuseppe placidi', 'luigi cinque', 'filippo mignosi', 'matteo polsinelli']"
2108.11838,geometry based machining feature retrieval with inductive transfer   learning,cs.cv cs.ai,"manufacturing industries have widely adopted the reuse of machine parts as a method to reduce costs and as a sustainable manufacturing practice. identification of reusable features from the design of the parts and finding their similar features from the database is an important part of this process. in this project, with the help of fully convolutional geometric features, we are able to extract and learn the high level semantic features from cad models with inductive transfer learning. the extracted features are then compared with that of other cad models from the database using frobenius norm and identical features are retrieved. later we passed the extracted features to a deep convolutional neural network with a spatial pyramid pooling layer and the performance of the feature retrieval increased significantly. it was evident from the results that the model could effectively capture the geometrical elements from machining features.",,2021-08-26,2021-11-15,"['n s kamal', 'barathi ganesh hb', 'sajith variyar vv', 'sowmya v', 'soman kp']"
2108.12056,continual learning under domain transfer with sparse synaptic bursting,cs.lg cs.ai cs.cv,"existing machines are functionally specific tools that were made for easy prediction and control. tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. but first they must be capable of learning, and retaining, new information without repeated exposure to it. past efforts to engineer such systems have sought to build or regulate artificial neural networks using task-specific modules with constrained circumstances of application. this has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. in this paper, we introduce a system that can learn sequentially over previously unseen datasets (imagenet, cifar-100) with little forgetting over time. this is accomplished by regulating the activity of weights in a convolutional neural network on the basis of inputs using top-down modulation generated by a second feed-forward neural network. we find that our method learns continually under domain transfer with sparse bursts of activity in weights that are recycled across tasks, rather than by maintaining task-specific modules. sparse synaptic bursting is found to balance enhanced and diminished activity in a way that facilitates adaptation to new inputs without corrupting previously acquired functions. this behavior emerges during a prior meta-learning phase in which regulated synapses are selectively disinhibited, or grown, from an initial state of uniform suppression.",,2021-08-26,2021-11-16,"['shawn l. beaulieu', 'jeff clune', 'nick cheney']"
2108.13024,a temporal knowledge graph completion method based on balanced timestamp   distribution,cs.ai,"completion through the embedding representation of the knowledge graph (kge) has been a research hotspot in recent years. realistic knowledge graphs are mostly related to time, while most of the existing kge algorithms ignore the time information. a few existing methods directly or indirectly encode the time information, ignoring the balance of timestamp distribution, which greatly limits the performance of temporal knowledge graph completion (kgc). in this paper, a temporal kgc method is proposed based on the direct encoding time information framework, and a given time slice is treated as the finest granularity for balanced timestamp distribution. a large number of experiments on temporal knowledge graph datasets extracted from the real world demonstrate the effectiveness of our method.",,2021-08-30,2021-11-06,"['kangzheng liu', 'yuhong zhang']"
2108.13637,"when are deep networks really better than decision forests at small   sample sizes, and how?",cs.lg cs.ai q-bio.nc stat.ml,"deep networks and decision forests (such as random forests and gradient boosted trees) are the leading machine learning methods for structured and tabular data, respectively. many papers have empirically compared large numbers of classifiers on one or two different domains (e.g., on 100 different tabular data settings). however, a careful conceptual and empirical comparison of these two strategies using the most contemporary best practices has yet to be performed. conceptually, we illustrate that both can be profitably viewed as ""partition and vote"" schemes. specifically, the representation space that they both learn is a partitioning of feature space into a union of convex polytopes. for inference, each decides on the basis of votes from the activated nodes. this formulation allows for a unified basic understanding of the relationship between these methods. empirically, we compare these two strategies on hundreds of tabular data settings, as well as several vision and auditory settings. our focus is on datasets with at most 10,000 samples, which represent a large fraction of scientific and biomedical datasets. in general, we found forests to excel at tabular and structured data (vision and audition) with small sample sizes, whereas deep nets performed better on structured data with larger sample sizes. this suggests that further gains in both scenarios may be realized via further combining aspects of forests and networks. we will continue revising this technical report in the coming months with updated results.",,2021-08-31,2021-11-02,"['haoyin xu', 'kaleab a. kinfu', 'will levine', 'sambit panda', 'jayanta dey', 'michael ainsworth', 'yu-chung peng', 'madi kusmanov', 'florian engert', 'christopher m. white', 'joshua t. vogelstein', 'carey e. priebe']"
2108.13643,learning to synthesize programs as interpretable and generalizable   policies,cs.lg cs.ai cs.pl,"recently, deep reinforcement learning (drl) methods have achieved impressive performance on tasks in a variety of domains. however, neural network policies produced with drl methods are not human-interpretable and often have difficulty generalizing to novel scenarios. to address these issues, prior works explore learning programmatic policies that are more interpretable and structured for generalization. yet, these works either employ limited policy representations (e.g. decision trees, state machines, or predefined program templates) or require stronger supervision (e.g. input/output state pairs or expert demonstrations). we present a framework that instead learns to synthesize a program, which details the procedure to solve a task in a flexible and expressive manner, solely from reward signals. to alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task. experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms drl and program synthesis baselines while producing interpretable and more generalizable policies. we also justify the necessity of the proposed two-stage learning scheme as well as analyze various methods for learning the program embedding.",,2021-08-31,2021-11-02,"['dweep trivedi', 'jesse zhang', 'shao-hua sun', 'joseph j. lim']"
2108.13744,the horn non-clausal class and its polynomiality,cs.ai,"the expressiveness of propositional non-clausal (nc) formulas is exponentially richer than that of clausal formulas. yet, clausal efficiency outperforms non-clausal one. indeed, a major weakness of the latter is that, while horn clausal formulas, along with horn algorithms, are crucial for the high efficiency of clausal reasoning, no horn-like formulas in non-clausal form had been proposed. to overcome such weakness, we define the hybrid class $\mathbb{h_{nc}}$ of horn non-clausal (horn-nc) formulas, by adequately lifting the horn pattern to nc form, and argue that $\mathbb{h_{nc}}$, along with future horn-nc algorithms, shall increase non-clausal efficiency just as the horn class has increased clausal efficiency. secondly, we: (i) give the compact, inductive definition of $\mathbb{h_{nc}}$; (ii) prove that syntactically $\mathbb{h_{nc}}$ subsumes the horn class but semantically both classes are equivalent, and (iii) characterize the non-clausal formulas belonging to $\mathbb{h_{nc}}$. thirdly, we define the non-clausal unit-resolution calculus, $ur_{nc}$, and prove that it checks the satisfiability of $\mathbb{h_{nc}}$ in polynomial time. this fact, to our knowledge, makes $\mathbb{h_{nc}}$ the first characterized polynomial class in nc reasoning. finally, we prove that $\mathbb{h_{nc}}$ is linearly recognizable, and also that it is both strictly succincter and exponentially richer than the horn class. we discuss that in nc automated reasoning, e.g. satisfiability solving, theorem proving, logic programming, etc., can directly benefit from $\mathbb{h_{nc}}$ and $ur_{nc}$ and that, as a by-product of its proved properties, $\mathbb{h_{nc}}$ arises as a new alternative to analyze horn functions and implication systems.",,2021-08-31,2021-11-17,['gonzalo e. imaz']
2109.00031,deep dna storage: scalable and robust dna storage via coding theory and   deep learning,cs.it cs.ai math.it,"the concept of dna storage was first suggested in 1959 by richard feynman who shared his vision regarding nanotechnology in the talk ""there is plenty of room at the bottom"". later, towards the end of the 20-th century, the interest in storage solutions based on dna molecules was increased as a result of the human genome project which in turn led to a significant progress in sequencing and assembly methods. dna storage enjoys major advantages over the well-established magnetic and optical storage solutions. as opposed to magnetic solutions, dna storage does not require electrical supply to maintain data integrity and is superior to other storage solutions in both density and durability. given the trends in cost decreases of dna synthesis and sequencing, it is now acknowledged that within the next 10-15 years dna storage may become a highly competitive archiving technology and probably later the main such technology. with that said, the current implementations of dna based storage systems are very limited and are not fully optimized to address the unique pattern of errors which characterize the synthesis and sequencing processes. in this work, we propose a robust, efficient and scalable solution to implement dna-based storage systems. our method deploys deep neural networks (dnn) which reconstruct a sequence of letters based on imperfect cluster of copies generated by the synthesis and sequencing processes. a tailor-made error-correcting code (ecc) is utilized to combat patterns of errors which occur during this process. since our reconstruction method is adapted to imperfect clusters, our method overcomes the time bottleneck of the noisy dna copies clustering process by allowing the use of a rapid and scalable pseudo-clustering instead. our architecture combines between convolutions and transformers blocks and is trained using synthetic data modelled after real data statistics.",,2021-08-31,2021-11-05,"['daniella bar-lev', 'itai orr', 'omer sabary', 'tuvi etzion', 'eitan yaakobi']"
2109.00460,from movement kinematics to object properties: online recognition of   human carefulness,cs.ro cs.ai,"when manipulating objects, humans finely adapt their motions to the characteristics of what they are handling. thus, an attentive observer can foresee hidden properties of the manipulated object, such as its weight, temperature, and even whether it requires special care in manipulation. this study is a step towards endowing a humanoid robot with this last capability. specifically, we study how a robot can infer online, from vision alone, whether or not the human partner is careful when moving an object. we demonstrated that a humanoid robot could perform this inference with high accuracy (up to 81.3%) even with a low-resolution camera. only for short movements without obstacles, carefulness recognition was insufficient. the prompt recognition of movement carefulness from observing the partner's action will allow robots to adapt their actions on the object to show the same degree of care as their human partners.",10.1007/978-3-030-90525-5_6,2021-09-01,,"['linda lastrico', 'alessandro carfì', 'francesco rea', 'alessandra sciutti', 'fulvio mastrogiovanni']"
2109.01050,characterizing possible failure modes in physics-informed neural   networks,cs.lg cs.ai cs.na math.na physics.comp-ph,"recent work in scientific machine learning has developed so-called physics-informed neural network (pinn) models. the typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. we demonstrate that, while existing pinn methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. in particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. we provide evidence that the soft regularization in pinns, which involves pde-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. importantly, we show that these possible failure modes are not due to the lack of expressivity in the nn architecture, but that the pinn's setup makes the loss landscape very hard to optimize. we then describe two promising solutions to address these failure modes. the first approach is to use curriculum regularization, where the pinn's loss term starts from a simple pde regularization, and becomes progressively more complex as the nn gets trained. the second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular pinn training.",,2021-09-02,2021-11-11,"['aditi s. krishnapriyan', 'amir gholami', 'shandian zhe', 'robert m. kirby', 'michael w. mahoney']"
2109.01115,learning language-conditioned robot behavior from offline data and   crowd-sourced annotation,cs.ro cs.ai cs.lg,"we study the problem of learning a range of vision-based manipulation tasks from a large offline dataset of robot interaction. in order to accomplish this, humans need easy and effective ways of specifying tasks to the robot. goal images are one popular form of task specification, as they are already grounded in the robot's observation space. however, goal images also have a number of drawbacks: they are inconvenient for humans to provide, they can over-specify the desired behavior leading to a sparse reward signal, or under-specify task information in the case of non-goal reaching tasks. natural language provides a convenient and flexible alternative for task specification, but comes with the challenge of grounding language in the robot's observation space. to scalably learn this grounding we propose to leverage offline robot datasets (including highly sub-optimal, autonomously collected data) with crowd-sourced natural language labels. with this data, we learn a simple classifier which predicts if a change in state completes a language instruction. this provides a language-conditioned reward function that can then be used for offline multi-task rl. in our experiments, we find that on language-conditioned manipulation tasks our approach outperforms both goal-image specifications and language conditioned imitation techniques by more than 25%, and is able to perform visuomotor tasks from natural language, such as ""open the right drawer"" and ""move the stapler"", on a franka emika panda robot.",,2021-09-02,2021-10-31,"['suraj nair', 'eric mitchell', 'kevin chen', 'brian ichter', 'silvio savarese', 'chelsea finn']"
2109.01575,continuous-time behavior trees as discontinuous dynamical systems,eess.sy cs.ai cs.ro cs.sy,"behavior trees represent a hierarchical and modular way of combining several low-level control policies into a high-level task-switching policy. hybrid dynamical systems can also be seen in terms of task switching between different policies, and therefore several comparisons between behavior trees and hybrid dynamical systems have been made, but only informally, and only in discrete time. a formal continuous-time formulation of behavior trees has been lacking. additionally, convergence analyses of specific classes of behavior tree designs have been made, but not for general designs.   in this letter, we provide the first continuous-time formulation of behavior trees, show that they can be seen as discontinuous dynamical systems (a subclass of hybrid dynamical systems), which enables the application of existence and uniqueness results to behavior trees, and finally, provide sufficient conditions under which such systems will converge to a desired region of the state space for general designs. with these results, a large body of results on continuous-time dynamical systems can be brought to use when designing behavior tree controllers.",,2021-09-03,2021-11-10,"['christopher iliffe sprague', 'petter ögren']"
2109.01879,moving object detection for event-based vision using k-means clustering,cs.cv cs.ai eess.iv,"moving object detection is important in computer vision. event-based cameras are bio-inspired cameras that work by mimicking the working of the human eye. these cameras have multiple advantages over conventional frame-based cameras, like reduced latency, hdr, reduced motion blur during high motion, low power consumption, etc. in spite of these advantages, event-based cameras are noise-sensitive and have low resolution. moreover, the task of moving object detection in these cameras is difficult, as event-based sensors lack useful visual features like texture and color. in this paper, we investigate the application of the k-means clustering technique in detecting moving objects in event-based data.",,2021-09-04,2021-11-08,"['anindya mondal', 'mayukhmali das']"
2109.02165,fbdnn: filter banks and deep neural networks for portable and fast   brain-computer interfaces,eess.sp cs.ai cs.lg,"objective: to propose novel ssvep classification methodologies using deep neural networks (dnns) and improve performances in single-channel and user-independent brain-computer interfaces (bcis) with small data lengths. approach: we propose the utilization of filter banks (creating sub-band components of the eeg signal) in conjunction with dnns. in this context, we created three different models: a recurrent neural network (fbrnn) analyzing the time domain, a 2d convolutional neural network (fbcnn-2d) processing complex spectrum features and a 3d convolutional neural network (fbcnn-3d) analyzing complex spectrograms, which we introduce in this study as possible input for ssvep classification. we trained our neural networks with an open dataset and conceived them so as not to require calibration from the final user: therefore, the test subject data was separated from training and validation. results: the dnns with the filter banks surpassed the accuracy of similar networks without this preprocessing step by considerable margins (up to 4.6%), and they outperformed common ssvep classification methods (svm and fbcca) by even higher margins (up to 7.1%). out of the three dnns using filter banks, the best results were obtained by the fbrnn, followed by the fbcnn-3d, and finally by the fbcnn-2d. conclusion and significance: filter banks allow different types of deep neural networks to more efficiently analyze the harmonic components of ssvep. complex spectrograms carry more information than complex spectrum features and magnitude spectrum, allowing the fbcnn-3d to surpass the other cnns. the mean test accuracy (87.3%) and f1-score (0.877) obtained in the challenging classification problem indicates a strong potential for the construction of portable, economical, fast and low-latency bcis.",,2021-09-05,2021-11-05,"['pedro r. a. s. bassi', 'romis attux']"
2109.02173,multi-agent variational occlusion inference using people as sensors,cs.ro cs.ai cs.cv cs.lg cs.ma,"autonomous vehicles must reason about spatial occlusions in urban environments to ensure safety without being overly cautious. prior work explored occlusion inference from observed social behaviors of road agents, hence treating people as sensors. inferring occupancy from agent behaviors is an inherently multimodal problem; a driver may behave similarly for different occupancy patterns ahead of them (e.g., a driver may move at constant speed in traffic or on an open road). past work, however, does not account for this multimodality, thus neglecting to model this source of aleatoric uncertainty in the relationship between driver behaviors and their environment. we propose an occlusion inference method that characterizes observed behaviors of human agents as sensor measurements, and fuses them with those from a standard sensor suite. to capture the aleatoric uncertainty, we train a conditional variational autoencoder with a discrete latent space to learn a multimodal mapping from observed driver trajectories to an occupancy grid representation of the view ahead of the driver. our method handles multi-agent scenarios, combining measurements from multiple observed drivers using evidential theory to solve the sensor fusion problem. our approach is validated on a real-world dataset, outperforming baselines and demonstrating real-time capable performance. our code is available at https://github.com/sisl/multiagentvariationalocclusioninference .",,2021-09-05,2021-11-10,"['masha itkina', 'ye-ji mun', 'katherine driggs-campbell', 'mykel j. kochenderfer']"
2109.03150,recommendation fairness: from static to dynamic,cs.ir cs.ai cs.lg,"driven by the need to capture users' evolving interests and optimize their long-term experiences, more and more recommender systems have started to model recommendation as a markov decision process and employ reinforcement learning to address the problem. shouldn't research on the fairness of recommender systems follow the same trend from static evaluation and one-shot intervention to dynamic monitoring and non-stop control? in this paper, we portray the recent developments in recommender systems first and then discuss how fairness could be baked into the reinforcement learning techniques for recommendation. moreover, we argue that in order to make further progress in recommendation fairness, we may want to consider multi-agent (game-theoretic) optimization, multi-objective (pareto) optimization, and simulation-based optimization, in the general framework of stochastic games.",,2021-09-05,2021-11-01,"['dell zhang', 'jun wang']"
2109.03806,exploration of quantum neural architecture by mixing quantum neuron   designs,quant-ph cs.ai,"with the constant increase of the number of quantum bits (qubits) in the actual quantum computers, implementing and accelerating the prevalent deep learning on quantum computers are becoming possible. along with this trend, there emerge quantum neural architectures based on different designs of quantum neurons. a fundamental question in quantum deep learning arises: what is the best quantum neural architecture? inspired by the design of neural architectures for classical computing which typically employs multiple types of neurons, this paper makes the very first attempt to mix quantum neuron designs to build quantum neural architectures. we observe that the existing quantum neuron designs may be quite different but complementary, such as neurons from variational quantum circuits (vqc) and quantumflow. more specifically, vqc can apply real-valued weights but suffer from being extended to multiple layers, while quantumflow can build a multi-layer network efficiently, but is limited to use binary weights. to take their respective advantages, we propose to mix them together and figure out a way to connect them seamlessly without additional costly measurement. we further investigate the design principles to mix quantum neurons, which can provide guidance for quantum neural architecture exploration in the future. experimental results demonstrate that the identified quantum neural architectures with mixed quantum neurons can achieve 90.62% of accuracy on the mnist dataset, compared with 52.77% and 69.92% on the vqc and quantumflow, respectively.",,2021-09-08,2021-11-06,"['zhepeng wang', 'zhiding liang', 'shanglin zhou', 'caiwen ding', 'yiyu shi', 'weiwen jiang']"
2109.04024,on the approximation of cooperative heterogeneous multi-agent   reinforcement learning (marl) using mean field control (mfc),cs.lg cs.ai cs.gt cs.ma,"mean field control (mfc) is an effective way to mitigate the curse of dimensionality of cooperative multi-agent reinforcement learning (marl) problems. this work considers a collection of $n_{\mathrm{pop}}$ heterogeneous agents that can be segregated into $k$ classes such that the $k$-th class contains $n_k$ homogeneous agents. we aim to prove approximation guarantees of the marl problem for this heterogeneous system by its corresponding mfc problem. we consider three scenarios where the reward and transition dynamics of all agents are respectively taken to be functions of $(1)$ joint state and action distributions across all classes, $(2)$ individual distributions of each class, and $(3)$ marginal distributions of the entire population. we show that, in these cases, the $k$-class marl problem can be approximated by mfc with errors given as $e_1=\mathcal{o}(\frac{\sqrt{|\mathcal{x}|}+\sqrt{|\mathcal{u}|}}{n_{\mathrm{pop}}}\sum_{k}\sqrt{n_k})$, $e_2=\mathcal{o}(\left[\sqrt{|\mathcal{x}|}+\sqrt{|\mathcal{u}|}\right]\sum_{k}\frac{1}{\sqrt{n_k}})$ and $e_3=\mathcal{o}\left(\left[\sqrt{|\mathcal{x}|}+\sqrt{|\mathcal{u}|}\right]\left[\frac{a}{n_{\mathrm{pop}}}\sum_{k\in[k]}\sqrt{n_k}+\frac{b}{\sqrt{n_{\mathrm{pop}}}}\right]\right)$, respectively, where $a, b$ are some constants and $|\mathcal{x}|,|\mathcal{u}|$ are the sizes of state and action spaces of each agent. finally, we design a natural policy gradient (npg) based algorithm that, in the three cases stated above, can converge to an optimal marl policy within $\mathcal{o}(e_j)$ error with a sample complexity of $\mathcal{o}(e_j^{-3})$, $j\in\{1,2,3\}$, respectively.",,2021-09-08,2021-11-14,"['washim uddin mondal', 'mridul agarwal', 'vaneet aggarwal', 'satish v. ukkusuri']"
2109.04344,evilmodel 2.0: bringing neural network models into malware attacks,cs.cr cs.ai,"in recent years, neural network has shown its strong power in various fields, and it also brings increasing security threats. the stegomalware based on neural network model is a representative one. previous research preliminary proves the feasibility of launching malicious attacks by triggering malware embedded in the neural network model. however, the existing works have not shown that this emerging threat is practical in real-world attacks because of the low malware embedding rate, the high model performance degradation and the extra efforts. therefore, we predict an improved stegomalware called evilmodel. we embed binary formed malware into neural network model as its parameters on the basis of analyzing the structure of the neural network model, and propose three new malware embedding technologies, namely msb reservation, fast substitution and half substitution. by marrying 19 malware samples and 10 popular neural network models, we build 550 malware-embedded models, and analyze these models' performance on imagenet dataset. the experimental results show that the half substitution almost performs perfectly, with a malware embedding rate of 48.52% and no model performance degradation or extra effort. considering a series of factors, we propose a quantitative algorithm to evaluate the different embedding methods. the evaluation result indicates that evilmodel is much superior to the classic stegonet. additionally, we conduct a case study to trigger evilmodel in a real-world scenario. to understand the proposed malware embedding technology deeply, we also investigate the impact of neural network structures, layer and parameter size on malware embedding capacity and embedded model accuracy. we also give some possible countermeasures to defend evilmodel. we hope this work can provide a comprehensive understanding of such a novel ai-powered threat, and recommend to defense it in advance.",,2021-09-09,2021-11-13,"['zhi wang', 'chaoge liu', 'xiang cui', 'jie yin', 'xutong wang']"
2109.04683,pip: physical interaction prediction via mental simulation with span   selection,cs.cv cs.ai,"accurate prediction of physical interaction outcomes is a crucial component of human intelligence and is important for safe and efficient deployments of robots in the real world. while there are existing vision-based intuitive physics models that learn to predict physical interaction outcomes, they mostly focus on generating short sequences of future frames based on physical properties (e.g. mass, friction and velocity) extracted from visual inputs or a latent space. however, there is a lack of intuitive physics models that are tested on long physical interaction sequences with multiple interactions among different objects. we hypothesize that selective temporal attention during approximate mental simulations helps humans in physical interaction outcome prediction. with these motivations, we propose a novel scheme: physical interaction prediction via mental simulation with span selection (pip). it utilizes a deep generative model to model approximate mental simulations by generating future frames of physical interactions before employing selective temporal attention in the form of span selection for predicting physical interaction outcomes. to evaluate our model, we further propose the large-scale space+ dataset of synthetic videos with long sequences of three prime physical interactions in a 3d environment. our experiments show that pip outperforms human, baseline, and related intuitive physics models that utilize mental simulation. furthermore, pip's span selection module effectively identifies the frames indicating key physical interactions among objects, allowing for added interpretability.",,2021-09-10,2021-11-14,"['jiafei duan', 'samson yu', 'soujanya poria', 'bihan wen', 'cheston tan']"
2109.05486,a socially aware reinforcement learning agent for the single track road   problem,cs.ai cs.gt cs.hc cs.ro,"we present the single track road problem. in this problem two agents face each-other at opposite positions of a road that can only have one agent pass at a time. we focus on the scenario in which one agent is human, while the other is an autonomous agent. we run experiments with human subjects in a simple grid domain, which simulates the single track road problem. we show that when data is limited, building an accurate human model is very challenging, and that a reinforcement learning agent, which is based on this data, does not perform well in practice. however, we show that an agent that tries to maximize a linear combination of the human's utility and its own utility, achieves a high score, and significantly outperforms other baselines, including an agent that tries to maximize only its own utility.",,2021-09-12,2021-11-02,"['ido shapira', 'amos azaria']"
2109.05779,deep joint source-channel coding for multi-task network,cs.cv cs.ai,"multi-task learning (mtl) is an efficient way to improve the performance of related tasks by sharing knowledge. however, most existing mtl networks run on a single end and are not suitable for collaborative intelligence (ci) scenarios. in this work, we propose an mtl network with a deep joint source-channel coding (jscc) framework, which allows operating under ci scenarios. we first propose a feature fusion based mtl network (ffmnet) for joint object detection and semantic segmentation. compared with other mtl networks, ffmnet gets higher performance with fewer parameters. then ffmnet is split into two parts, which run on a mobile device and an edge server respectively. the feature generated by the mobile device is transmitted through the wireless channel to the edge server. to reduce the transmission overhead of the intermediate feature, a deep jscc network is designed. by combining two networks together, the whole model achieves 512x compression for the intermediate feature and a performance loss within 2% on both tasks. at last, by training with noise, the ffmnet with jscc is robust to various channel conditions and outperforms the separate source and channel coding scheme.",10.1109/lsp.2021.3113827,2021-09-13,2021-09-27,"['mengyang wang', 'zhicong zhang', 'jiahui li', 'mengyao ma', 'xiaopeng fan']"
2109.06515,netmarble ai center's wmt21 automatic post-editing shared task   submission,cs.cl cs.ai,"this paper describes netmarble's submission to wmt21 automatic post-editing (ape) shared task for the english-german language pair. first, we propose a curriculum training strategy in training stages. facebook fair's wmt19 news translation model was chosen to engage the large and powerful pre-trained neural networks. then, we post-train the translation model with different levels of data at each training stages. as the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually. we also show a way to utilize the additional data in large volume for ape tasks. for further improvement, we apply multi-task learning strategy with the dynamic weight average during the fine-tuning stage. to fine-tune the ape corpus with limited data, we add some related subtasks to learn a unified representation. finally, for better performance, we leverage external translations as augmented machine translation (mt) during the post-training and fine-tuning. as experimental results show, our ape system significantly improves the translations of provided mt results by -2.848 and +3.74 on the development dataset in terms of ter and bleu, respectively. it also demonstrates its effectiveness on the test dataset with higher quality than the development dataset.",,2021-09-14,2021-11-16,"['shinhyeok oh', 'sion jang', 'hu xu', 'shounan an', 'insoo oh']"
2109.07016,graph embedding via diffusion-wavelets-based node feature distribution   characterization,cs.lg cs.ai cs.si,"recent years have seen a rise in the development of representational learning methods for graph data. most of these methods, however, focus on node-level representation learning at various scales (e.g., microscopic, mesoscopic, and macroscopic node embedding). in comparison, methods for representation learning on whole graphs are currently relatively sparse. in this paper, we propose a novel unsupervised whole graph embedding method. our method uses spectral graph wavelets to capture topological similarities on each k-hop sub-graph between nodes and uses them to learn embeddings for the whole graph. we evaluate our method against 12 well-known baselines on 4 real-world datasets and show that our method achieves the best performance across all experiments, outperforming the current state-of-the-art by a considerable margin.",10.1145/3459637.3482115,2021-09-14,,"['lili wang', 'chenghan huang', 'weicheng ma', 'xinyuan cao', 'soroush vosoughi']"
2109.07023,embedding node structural role identity using stress majorization,cs.si cs.ai cs.lg,"nodes in networks may have one or more functions that determine their role in the system. as opposed to local proximity, which captures the local context of nodes, the role identity captures the functional ""role"" that nodes play in a network, such as being the center of a group, or the bridge between two groups. this means that nodes far apart in a network can have similar structural role identities. several recent works have explored methods for embedding the roles of nodes in networks. however, these methods all rely on either approximating or indirect modeling of structural equivalence. in this paper, we present a novel and flexible framework using stress majorization, to transform the high-dimensional role identities in networks directly (without approximation or indirect modeling) to a low-dimensional embedding space. our method is also flexible, in that it does not rely on specific structural similarity definitions. we evaluated our method on the tasks of node classification, clustering, and visualization, using three real-world and five synthetic networks. our experiments show that our framework achieves superior results than existing methods in learning node role representations.",10.1145/3459637.3482095,2021-09-14,,"['lili wang', 'chenghan huang', 'weicheng ma', 'ying lu', 'soroush vosoughi']"
2109.07103,automatic symmetry discovery with lie algebra convolutional network,cs.lg cs.ai math.gr,"existing equivariant neural networks require prior knowledge of the symmetry group and discretization for continuous groups. we propose to work with lie algebras (infinitesimal generators) instead of lie groups. our model, the lie algebra convolutional network (l-conv) can automatically discover symmetries and does not require discretization of the group. we show that l-conv can serve as a building block to construct any group equivariant feedforward architecture. both cnns and graph convolutional networks can be expressed as l-conv with appropriate groups. we discover direct connections between l-conv and physics: (1) group invariant loss generalizes field theory (2) euler-lagrange equation measures the robustness, and (3) equivariance leads to conservation laws and noether current.these connections open up new avenues for designing more general equivariant networks and applying them to important problems in physical sciences",,2021-09-15,2021-11-01,"['nima dehmamy', 'robin walters', 'yanchen liu', 'dashun wang', 'rose yu']"
2109.07843,label assignment distillation for object detection,cs.cv cs.ai,this article has been removed by arxiv administrators due to a claim of copyright infringement,,2021-09-16,2021-09-18,['hailun zhang']
2109.08006,deep algorithmic question answering: towards a compositionally hybrid ai   for algorithmic reasoning,cs.ai,"an important aspect of artificial intelligence (ai) is the ability to reason in a step-by-step ""algorithmic"" manner that can be inspected and verified for its correctness. this is especially important in the domain of question answering (qa). we argue that the challenge of algorithmic reasoning in qa can be effectively tackled with a ""systems"" approach to ai which features a hybrid use of symbolic and sub-symbolic methods including deep neural networks. additionally, we argue that while neural network models with end-to-end training pipelines perform well in narrow applications such as image classification and language modelling, they cannot, on their own, successfully perform algorithmic reasoning, especially if the task spans multiple domains. we discuss a few notable exceptions and point out how they are still limited when the qa problem is widened to include other intelligence-requiring tasks. however, deep learning, and machine learning in general, do play important roles as components in the reasoning process. we propose an approach to algorithm reasoning for qa, deep algorithmic question answering (daqa), based on three desirable properties: interpretability, generalizability, and robustness which such an ai system should possess, and conclude that they are best achieved with a combination of hybrid and compositional ai.",,2021-09-16,2021-11-05,['kwabena nuamah']
2109.08022,meta-path-based fake news detection leveraging multi-level social   context information,cs.si cs.ai cs.cy,"fake news, false or misleading information presented as news, has a significant impact on many aspects of society, such as in politics or healthcare domains. due to the deceiving nature of fake news, applying natural language processing (nlp) techniques to the news content alone is insufficient. the multi-level social context information (news publishers and engaged users in social media) and temporal information of user engagement are important information in fake news detection. the proper usage of this information, however, introduces three chronic difficulties: 1) multi-level social context information is hard to be used without information loss, 2) temporal information is hard to be used along with multi-level social context information, 3) news representation with multi-level social context and temporal information is hard to be learned in an end-to-end manner. to overcome all three difficulties, we propose a novel fake news detection framework, hetero-scan. we use meta-path to extract meaningful multi-level social context information without loss. meta-path, a composite relation connecting two node types, is proposed to capture the semantics in the heterogeneous graph. we then propose meta-path instance encoding and aggregation methods to capture the temporal information of user engagement and produce news representation end-to-end. according to our experiment, hetero-scan yields significant performance improvement over state-of-the-art fake news detection methods.",,2021-09-13,2021-11-16,"['jian cui', 'kwanwoo kim', 'seung ho na', 'seungwon shin']"
2109.08817,learning to regrasp by learning to place,cs.ro cs.ai cs.cv cs.lg,"in this paper, we explore whether a robot can learn to regrasp a diverse set of objects to achieve various desired grasp poses. regrasping is needed whenever a robot's current grasp pose fails to perform desired manipulation tasks. endowing robots with such an ability has applications in many domains such as manufacturing or domestic services. yet, it is a challenging task due to the large diversity of geometry in everyday objects and the high dimensionality of the state and action space. in this paper, we propose a system for robots to take partial point clouds of an object and the supporting environment as inputs and output a sequence of pick-and-place operations to transform an initial object grasp pose to the desired object grasp poses. the key technique includes a neural stable placement predictor and a regrasp graph-based solution through leveraging and changing the surrounding environment. we introduce a new and challenging synthetic dataset for learning and evaluating the proposed approach. we demonstrate the effectiveness of our proposed system with both simulator and real-world experiments. more videos and visualization examples are available on our project webpage.",,2021-09-17,2021-11-17,"['shuo cheng', 'kaichun mo', 'lin shao']"
2109.09113,hptq: hardware-friendly post training quantization,cs.cv cs.ai,"neural network quantization enables the deployment of models on edge devices. an essential requirement for their hardware efficiency is that the quantizers are hardware-friendly: uniform, symmetric, and with power-of-two thresholds. to the best of our knowledge, current post-training quantization methods do not support all of these constraints simultaneously. in this work, we introduce a hardware-friendly post training quantization (hptq) framework, which addresses this problem by synergistically combining several known quantization methods. we perform a large-scale study on four tasks: classification, object detection, semantic segmentation and pose estimation over a wide variety of network architectures. our extensive experiments show that competitive results can be obtained under hardware-friendly constraints.",,2021-09-19,2021-11-16,"['hai victor habi', 'reuven peretz', 'elad cohen', 'lior dikstein', 'oranit dror', 'idit diamant', 'roy h. jennings', 'arnon netzer']"
2109.09331,modular design patterns for hybrid actors,cs.ai cs.ma cs.se,"recently, a boxology (graphical language) with design patterns for hybrid ai was proposed, combining symbolic and sub-symbolic learning and reasoning. in this paper, we extend this boxology with actors and their interactions. the main contributions of this paper are: 1) an extension of the taxonomy to describe distributed hybrid ai systems with actors and interactions; and 2) showing examples using a few design patterns relevant in multi-agent systems and human-agent interaction.",,2021-09-20,2021-11-09,"['andré meyer-vitali', 'wico mulder', 'maaike h. t. de boer']"
2109.09390,socially supervised representation learning: the role of subjectivity in   learning efficient representations,cs.ai,"despite its rise as a prominent solution to the data inefficiency of today's machine learning models, self-supervised learning has yet to be studied from a purely multi-agent perspective. in this work, we propose that aligning internal subjective representations, which naturally arise in a multi-agent setup where agents receive partial observations of the same underlying environmental state, can lead to more data-efficient representations. we propose that multi-agent environments, where agents do not have access to the observations of others but can communicate within a limited range, guarantees a common context that can be leveraged in individual representation learning. the reason is that subjective observations necessarily refer to the same subset of the underlying environmental states and that communication about these states can freely offer a supervised signal. to highlight the importance of communication, we refer to our setting as \textit{socially supervised representation learning}. we present a minimal architecture comprised of a population of autoencoders, where we define loss functions, capturing different aspects of effective communication, and examine their effect on the learned representations. we show that our proposed architecture allows the emergence of aligned representations. the subjectivity introduced by presenting agents with distinct perspectives of the environment state contributes to learning abstract representations that outperform those learned by a single autoencoder and a population of autoencoders, presented with identical perspectives of the environment state. altogether, our results demonstrate how communication from subjective perspectives can lead to the acquisition of more abstract representations in multi-agent systems, opening promising perspectives for future research at the intersection of representation learning and emergent communication.",,2021-09-20,2021-11-02,"['julius taylor', 'eleni nisioti', 'clément moulin-frier']"
2109.10057,lotr: face landmark localization using localization transformer,cs.cv cs.ai cs.lg,"this paper presents a novel transformer-based facial landmark localization network named localization transformer (lotr). the proposed framework is a direct coordinate regression approach leveraging a transformer network to better utilize the spatial information in the feature map. an lotr model consists of three main modules: 1) a visual backbone that converts an input image into a feature map, 2) a transformer module that improves the feature representation from the visual backbone, and 3) a landmark prediction head that directly predicts the landmark coordinates from the transformer's representation. given cropped-and-aligned face images, the proposed lotr can be trained end-to-end without requiring any post-processing steps. this paper also introduces the smooth-wing loss function, which addresses the gradient discontinuity of the wing loss, leading to better convergence than standard loss functions such as l1, l2, and wing loss. experimental results on the jd landmark dataset provided by the first grand challenge of 106-point facial landmark localization indicate the superiority of lotr over the existing methods on the leaderboard and two recent heatmap-based approaches. on the wflw dataset, the proposed lotr framework demonstrates promising results compared with several state-of-the-art methods. additionally, we report the improvement in state-of-the-art face recognition performance when using our proposed lotrs for face alignment.",,2021-09-21,2021-11-05,"['ukrit watchareeruetai', 'benjaphan sommana', 'sanjana jain', 'pavit noinongyao', 'ankush ganguly', 'aubin samacoits', 'samuel w. f. earp', 'nakarin sritrakool']"
2109.10187,oriented object detection in aerial images based on area ratio of   parallelogram,cs.cv cs.ai,"oriented object detection is a challenging task in aerial images since the objects in aerial images are displayed in arbitrary directions and are frequently densely packed. the mainstream detectors describe rotating objects using a five-parament or eight-parament representations, which suffer from representation ambiguity for orientated object definition. in this paper, we propose a novel representation method based on area ratio of parallelogram, called arp. specifically, arp regresses the minimum bounding rectangle of the oriented object and three area ratios. three area ratios include the area ratio of a directed object to the smallest circumscribed rectangle and two parallelograms to the minimum circumscribed rectangle. it simplifies offset learning and eliminates the issue of angular periodicity or label point sequences for oriented objects. to further remedy the confusion issue of nearly horizontal objects, the area ratio between the object and its minimal circumscribed rectangle is employed to guide the selection of horizontal or oriented detection for each object. moreover, the rotated efficient intersection over union (r-eiou) loss with horizontal bounding box and three area ratios are designed to optimize the bounding box regression for rotating objects. experimental results on remote sensing datasets, including hrsc2016, dota, and ucas-aod, show that our method achieves superior detection performance than many state-of-the-art approaches.",,2021-09-21,2021-11-08,"['xinyi yu', 'mi lin', 'jiangping lu', 'linlin ou']"
2109.10231,salientrack: providing salient information for semi-automated   self-tracking feedback with model explanations,cs.hc cs.ai,"self-tracking can improve people's awareness of their unhealthy behaviors to provide insights towards behavior change. prior work has explored how self-trackers reflect on their logged data, but it remains unclear how much they learn from the tracking feedback, and which information is more useful. indeed, the feedback can still be overwhelming, and making it concise can improve learning by increasing focus and reducing interpretation burden. to streamline the feedback, we propose a self-tracking feedback saliency framework to define when to provide feedback, on which specific information, why those details, and how to present them (manual elicitation or automatic feedback). we collected survey and meal image data from a field study of mobile food tracking, and implemented salientrack, a machine learning model to predict when a user would learn from tracked events. using explainable ai (xai) techniques, salientrack identifies which features of the event are most salient, why they lead to positive learning outcomes, and prioritizes how to present the feedback based on attribution scores. we demonstrate use cases and conducted a formative study to show the usability and usefulness of salientrack. we discuss implications for learnability in self-tracking, and how adding model explainability expands opportunities for improving feedback experience.",,2021-09-21,2021-11-16,"['yunlong wang', 'jiaying liu', 'homin park', 'jordan schultz-mcardle', 'stephanie rosenthal', 'brian y. lim']"
2109.11541,csagn: conversational structure aware graph network for conversational   semantic role labeling,cs.cl cs.ai cs.lg,"conversational semantic role labeling (csrl) is believed to be a crucial step towards dialogue understanding. however, it remains a major challenge for existing csrl parser to handle conversational structural information. in this paper, we present a simple and effective architecture for csrl which aims to address this problem. our model is based on a conversational structure-aware graph network which explicitly encodes the speaker dependent information. we also propose a multi-task learning method to further improve the model. experimental results on benchmark datasets show that our model with our proposed training objectives significantly outperforms previous baselines.",,2021-09-23,2021-11-04,"['han wu', 'kun xu', 'linqi song']"
2109.11808,a dynamic programming algorithm for informative measurements and   near-optimal path-planning,cs.lg cs.ai cs.ro math.oc,"an informative measurement is the most efficient way to gain information about an unknown state. we give a first-principles derivation of a general-purpose dynamic programming algorithm that returns a sequence of informative measurements by sequentially maximizing the entropy of possible measurement outcomes. this algorithm can be used by an autonomous agent or robot to decide where best to measure next, planning a path corresponding to an optimal sequence of informative measurements. this algorithm is applicable to states and controls that are continuous or discrete, and agent dynamics that is either stochastic or deterministic; including markov decision processes. recent results from approximate dynamic programming and reinforcement learning, including on-line approximations such as rollout and monte carlo tree search, allow an agent or robot to solve the measurement task in real-time. the resulting near-optimal solutions include non-myopic paths and measurement sequences that can generally outperform, sometimes substantially, commonly-used greedy heuristics such as maximizing the entropy of each measurement outcome. this is demonstrated for a global search problem, where on-line planning with an extended local search is found to reduce the number of measurements in the search by half.",,2021-09-24,2021-11-02,"['peter n. loxley', 'ka wai cheung']"
2109.12075,towards a measure of general machine intelligence,cs.ai cs.lg,"to build general-purpose artificial intelligence systems that can deal with unknown variables across unknown domains, we need benchmarks that measure how well these systems perform on tasks they have never seen before. a prerequisite for this is a measure of a task's generalization difficulty, or how dissimilar it is from the system's prior knowledge and experience. if the skill of an intelligence system in a particular domain is defined as it's ability to consistently generate a set of instructions (or programs) to solve tasks in that domain, current benchmarks do not quantitatively measure the efficiency of acquiring new skills, making it possible to brute-force skill acquisition by training with unlimited amounts of data and compute power. with this in mind, we first propose a common language of instruction, a programming language that allows the expression of programs in the form of directed acyclic graphs across a wide variety of real-world domains and computing platforms. using programs generated in this language, we demonstrate a match-based method to both score performance and calculate the generalization difficulty of any given set of tasks. we use these to define a numeric benchmark called the generalization index, or the g-index, to measure and compare the skill-acquisition efficiency of any intelligence system on a set of real-world tasks. finally, we evaluate the suitability of some well-known models as general intelligence systems by calculating their g-index scores.",,2021-09-24,2021-11-14,"['gautham venkatasubramanian', 'sibesh kar', 'abhimanyu singh', 'shubham mishra', 'dushyant yadav', 'shreyansh chandak']"
2109.12445,algorithmic information design in multi-player games: possibility and   limits in singleton congestion,cs.gt cs.ai,"most algorithmic studies on multi-agent information design so far have focused on the restricted situation with no inter-agent externalities; a few exceptions investigated truly strategic games such as zero-sum games and second-price auctions but have all focused only on optimal public signaling. this paper initiates the algorithmic information design of both \emph{public} and \emph{private} signaling in a fundamental class of games with negative externalities, i.e., singleton congestion games, with wide application in today's digital economy, machine scheduling, routing, etc.   for both public and private signaling, we show that the optimal information design can be efficiently computed when the number of resources is a constant. to our knowledge, this is the first set of efficient \emph{exact} algorithms for information design in succinctly representable many-player games. our results hinge on novel techniques such as developing certain ``reduced forms'' to compactly characterize equilibria in public signaling or to represent players' marginal beliefs in private signaling. when there are many resources, we show computational intractability results. to overcome the issue of multiple equilibria, here we introduce a new notion of equilibrium-\emph{oblivious} hardness, which rules out any possibility of computing a good signaling scheme, irrespective of the equilibrium selection rule.",,2021-09-25,2021-11-06,"['chenghan zhou', 'thanh h. nguyen', 'haifeng xu']"
2109.12456,auditing ai models for verified deployment under semantic specifications,cs.lg cs.ai cs.cv,"auditing trained deep learning (dl) models prior to deployment is vital for preventing unintended consequences. one of the biggest challenges in auditing is the lack of human-interpretable specifications for the dl models that are directly useful to the auditor. we address this challenge through a sequence of semantically-aligned unit tests, where each unit test verifies whether a predefined specification (e.g., accuracy over 95%) is satisfied with respect to controlled and semantically aligned variations in the input space (e.g., in face recognition, the angle relative to the camera). we enable such unit tests through variations in a semantically-interpretable latent space of a generative model. further, we conduct certified training for the dl model through a shared latent space representation with the generative model. with evaluations on four different datasets, covering images of chest x-rays, human faces, imagenet classes, and towers, we show how auditai allows us to obtain controlled variations for certified training. thus, our framework, auditai, bridges the gap between semantically-aligned formal verification and scalability. a blog post accompanying the paper is at this link https://developer.nvidia.com/blog/nvidia-research-auditing-ai-models-for-verified-deployment-under-semantic-specifications",,2021-09-25,2021-11-01,"['homanga bharadhwaj', 'de-an huang', 'chaowei xiao', 'anima anandkumar', 'animesh garg']"
2109.12907,expressing high-level scientific claims with formal semantics,cs.dl cs.ai,"the use of semantic technologies is gaining significant traction in science communication with a wide array of applications in disciplines including the life sciences, computer science, and the social sciences. languages like rdf, owl, and other formalisms based on formal logic are applied to make scientific knowledge accessible not only to human readers but also to automated systems. these approaches have mostly focused on the structure of scientific publications themselves, on the used scientific methods and equipment, or on the structure of the used datasets. the core claims or hypotheses of scientific work have only been covered in a shallow manner, such as by linking mentioned entities to established identifiers. in this research, we therefore want to find out whether we can use existing semantic formalisms to fully express the content of high-level scientific claims using formal semantics in a systematic way. analyzing the main claims from a sample of scientific articles from all disciplines, we find that their semantics are more complex than what a straight-forward application of formalisms like rdf or owl account for, but we managed to elicit a clear semantic pattern which we call the 'super-pattern'. we show here how the instantiation of the five slots of this super-pattern leads to a strictly defined statement in higher-order logic. we successfully applied this super-pattern to an enlarged sample of scientific claims. we show that knowledge representation experts, when instructed to independently instantiate the super-pattern with given scientific claims, show a high degree of consistency and convergence given the complexity of the task and the subject. these results therefore open the door for expressing high-level scientific findings in a manner they can be automatically interpreted, which on the longer run can allow us to do automated consistency checking, and much more.",10.1145/3460210.3493561,2021-09-27,2021-10-29,"['cristina-iulia bucur', 'tobias kuhn', 'davide ceolin', 'jacco van ossenbruggen']"
2109.12912,a user-centred framework for explainable artificial intelligence in   human-robot interaction,cs.ai cs.hc cs.ro,"state of the art artificial intelligence (ai) techniques have reached an impressive complexity. consequently, researchers are discovering more and more methods to use them in real-world applications. however, the complexity of such systems requires the introduction of methods that make those transparent to the human user. the ai community is trying to overcome the problem by introducing the explainable ai (xai) field, which is tentative to make ai algorithms less opaque. however, in recent years, it became clearer that xai is much more than a computer science problem: since it is about communication, xai is also a human-agent interaction problem. moreover, ai came out of the laboratories to be used in real life. this implies the need for xai solutions tailored to non-expert users. hence, we propose a user-centred framework for xai that focuses on its social-interactive aspect taking inspiration from cognitive and social sciences' theories and findings. the framework aims to provide a structure for interactive xai solutions thought for non-expert users.",,2021-09-27,2021-11-05,"['marco matarese', 'francesco rea', 'alessandra sciutti']"
2109.13419,the role of lookahead and approximate policy evaluation in policy   iteration with linear value function approximation,cs.lg cs.ai cs.sy eess.sy,"when the sizes of the state and action spaces are large, solving mdps can be computationally prohibitive even if the probability transition matrix is known. so in practice, a number of techniques are used to approximately solve the dynamic programming problem, including lookahead, approximate policy evaluation using an m-step return, and function approximation. in a recent paper, (efroni et al. 2019) studied the impact of lookahead on the convergence rate of approximate dynamic programming. in this paper, we show that these convergence results change dramatically when function approximation is used in conjunction with lookout and approximate policy evaluation using an m-step return. specifically, we show that when linear function approximation is used to represent the value function, a certain minimum amount of lookahead and multi-step return is needed for the algorithm to even converge. and when this condition is met, we characterize the finite-time performance of policies obtained using such approximate policy iteration. our results are presented for two different procedures to compute the function approximation: linear least-squares regression and gradient descent.",,2021-09-27,2021-11-14,"['anna winnicki', 'joseph lubars', 'michael livesay', 'r. srikant']"
2109.13863,a first-occupancy representation for reinforcement learning,cs.lg cs.ai,"both animals and artificial agents benefit from state representations that support rapid transfer of learning across tasks and which enable them to efficiently traverse their environments to reach rewarding states. the successor representation (sr), which measures the expected cumulative, discounted state occupancy under a fixed policy, enables efficient transfer to different reward structures in an otherwise constant markovian environment and has been hypothesized to underlie aspects of biological behavior and neural activity. however, in the real world, rewards may move or only be available for consumption once, may shift location, or agents may simply aim to reach goal states as rapidly as possible without the constraint of artificially imposed task horizons. in such cases, the most behaviorally-relevant representation would carry information about when the agent was likely to first reach states of interest, rather than how often it should expect to visit them over a potentially infinite time span. to reflect such demands, we introduce the first-occupancy representation (fr), which measures the expected temporal discount to the first time a state is accessed. we demonstrate that the fr facilitates exploration, the selection of efficient paths to desired states, allows the agent, under certain conditions, to plan provably optimal trajectories defined by a sequence of subgoals, and induces similar behavior to animals avoiding threatening stimuli.",,2021-09-28,2021-11-06,"['ted moskovitz', 'spencer r. wilson', 'maneesh sahani']"
2109.13916,unsolved problems in ml safety,cs.lg cs.ai cs.cl cs.cv,"machine learning (ml) systems are rapidly increasing in size, are acquiring new capabilities, and are increasingly deployed in high-stakes settings. as with other powerful technologies, safety for ml should be a leading research priority. in response to emerging safety challenges in ml, such as those introduced by recent large-scale models, we provide a new roadmap for ml safety and refine the technical problems that the field needs to address. we present four problems ready for research, namely withstanding hazards (""robustness""), identifying hazards (""monitoring""), steering ml systems (""alignment""), and reducing hazards in deployment (""external safety""). throughout, we clarify each problem's motivation and provide concrete research directions.",,2021-09-28,2021-10-30,"['dan hendrycks', 'nicholas carlini', 'john schulman', 'jacob steinhardt']"
2109.14076,raft: a real-world few-shot text classification benchmark,cs.cl cs.ai cs.lg,"large pre-trained language models have shown promise for few-shot learning, completing text-based tasks given only a few task-specific examples. will models soon solve classification tasks that have so far been reserved for human research assistants? existing benchmarks are not designed to measure progress in applied settings, and so don't directly answer this question. the raft benchmark (real-world annotated few-shot tasks) focuses on naturally occurring tasks and uses an evaluation setup that mirrors deployment. baseline evaluations on raft reveal areas current techniques struggle with: reasoning over long texts and tasks with many classes. human baselines show that some classification tasks are difficult for non-expert humans, reflecting that real-world value sometimes depends on domain expertise. yet even non-expert human baseline f1 scores exceed gpt-3 by an average of 0.11. the raft datasets and leaderboard will track which model improvements translate into real-world benefits at https://raft.elicit.org .",,2021-09-28,2021-11-08,"['neel alex', 'eli lifland', 'lewis tunstall', 'abhishek thakur', 'pegah maham', 'c. jess riedel', 'emmie hine', 'carolyn ashurst', 'paul sedille', 'alexis carlier', 'michael noetel', 'andreas stuhlmüller']"
2109.14285,be confident! towards trustworthy graph neural networks via confidence   calibration,cs.lg cs.ai,"despite graph neural networks (gnns) have achieved remarkable accuracy, whether the results are trustworthy is still unexplored. previous studies suggest that many modern neural networks are over-confident on the predictions, however, surprisingly, we discover that gnns are primarily in the opposite direction, i.e., gnns are under-confident. therefore, the confidence calibration for gnns is highly desired. in this paper, we propose a novel trustworthy gnn model by designing a topology-aware post-hoc calibration function. specifically, we first verify that the confidence distribution in a graph has homophily property, and this finding inspires us to design a calibration gnn model (cagcn) to learn the calibration function. cagcn is able to obtain a unique transformation from logits of gnns to the calibrated confidence for each node, meanwhile, such transformation is able to preserve the order between classes, satisfying the accuracy-preserving property. moreover, we apply the calibration gnn to self-training framework, showing that more trustworthy pseudo labels can be obtained with the calibrated confidence and further improve the performance. extensive experiments demonstrate the effectiveness of our proposed model in terms of both calibration and accuracy.",,2021-09-29,2021-11-05,"['xiao wang', 'hongrui liu', 'chuan shi', 'cheng yang']"
2109.14746,improvising the learning of neural networks on hyperspherical manifold,cs.cv cs.ai,"the impact of convolution neural networks (cnns) in the supervised settings provided tremendous increment in performance. the representations learned from cnn's operated on hyperspherical manifold led to insightful outcomes in face recognition, face identification, and other supervised tasks. a broad range of activation functions were developed with hypersphere intuition which performs superior to softmax in euclidean space. the main motive of this research is to provide insights. first, the stereographic projection is implied to transform data from euclidean space ($\mathbb{r}^{n}$) to hyperspherical manifold ($\mathbb{s}^{n}$) to analyze the performance of angular margin losses. secondly, proving theoretically and practically that decision boundaries constructed on hypersphere using stereographic projection obliges the learning of neural networks. experiments have demonstrated that applying stereographic projection on existing state-of-the-art angular margin objective functions improved performance for standard image classification data sets (cifar-10,100). further, we ran our experiments on malaria-thin blood smear images, resulting in effective outcomes. the code is publicly available at:https://github.com/barulalithb/stereo-angular-margin.",,2021-09-29,2021-11-06,"['lalith bharadwaj baru', 'sai vardhan kanumolu', 'akshay patel shilhora', 'madhu g']"
2109.14979,moving object detection for event-based vision using graph spectral   clustering,cs.cv cs.ai eess.iv,"moving object detection has been a central topic of discussion in computer vision for its wide range of applications like in self-driving cars, video surveillance, security, and enforcement. neuromorphic vision sensors (nvs) are bio-inspired sensors that mimic the working of the human eye. unlike conventional frame-based cameras, these sensors capture a stream of asynchronous 'events' that pose multiple advantages over the former, like high dynamic range, low latency, low power consumption, and reduced motion blur. however, these advantages come at a high cost, as the event camera data typically contains more noise and has low resolution. moreover, as event-based cameras can only capture the relative changes in brightness of a scene, event data do not contain usual visual information (like texture and color) as available in video data from normal cameras. so, moving object detection in event-based cameras becomes an extremely challenging task. in this paper, we present an unsupervised graph spectral clustering technique for moving object detection in event-based data (gsceventmod). we additionally show how the optimum number of moving objects can be automatically determined. experimental comparisons on publicly available datasets show that the proposed gsceventmod algorithm outperforms a number of state-of-the-art techniques by a maximum margin of 30%.",,2021-09-30,2021-11-09,"['anindya mondal', 'shashant r', 'jhony h. giraldo', 'thierry bouwmans', 'ananda s. chowdhury']"
2110.00188,offline reinforcement learning with reverse model-based imagination,cs.lg cs.ai,"in offline reinforcement learning (offline rl), one of the main challenges is to deal with the distributional shift between the learning policy and the given dataset. to address this problem, recent offline rl methods attempt to introduce conservatism bias to encourage learning in high-confidence areas. model-free approaches directly encode such bias into policy or value function learning using conservative regularizations or special network structures, but their constrained policy search limits the generalization beyond the offline dataset. model-based approaches learn forward dynamics models with conservatism quantifications and then generate imaginary trajectories to extend the offline datasets. however, due to limited samples in offline datasets, conservatism quantifications often suffer from overgeneralization in out-of-support regions. the unreliable conservative measures will mislead forward model-based imaginations to undesired areas, leading to overaggressive behaviors. to encourage more conservatism, we propose a novel model-based offline rl framework, called reverse offline model-based imagination (romi). we learn a reverse dynamics model in conjunction with a novel reverse policy, which can generate rollouts leading to the target goal states within the offline dataset. these reverse imaginations provide informed data augmentation for model-free policy learning and enable conservative generalization beyond the offline dataset. romi can effectively combine with off-the-shelf model-free algorithms to enable model-based generalization with proper conservatism. empirical results show that our method can generate more conservative behaviors and achieve state-of-the-art performance on offline rl benchmark tasks.",,2021-09-30,2021-11-14,"['jianhao wang', 'wenzhe li', 'haozhe jiang', 'guangxiang zhu', 'siyuan li', 'chongjie zhang']"
2110.00438,guiding evolutionary strategies by differentiable robot simulators,cs.ro cs.ai cs.lg cs.ne cs.sy eess.sy,"in recent years, evolutionary strategies were actively explored in robotic tasks for policy search as they provide a simpler alternative to reinforcement learning algorithms. however, this class of algorithms is often claimed to be extremely sample-inefficient. on the other hand, there is a growing interest in differentiable robot simulators (drs) as they potentially can find successful policies with only a handful of trajectories. but the resulting gradient is not always useful for the first-order optimization. in this work, we demonstrate how drs gradient can be used in conjunction with evolutionary strategies. preliminary results suggest that this combination can reduce sample complexity of evolutionary strategies by 3x-5x times in both simulation and the real world.",,2021-10-01,2021-11-09,"['vladislav kurenkov', 'bulat maksudov']"
2110.00685,fast multi-resolution transformer fine-tuning for extreme multi-label   text classification,cs.lg cs.ai cs.ir stat.ml,"extreme multi-label text classification (xmc) seeks to find relevant labels from an extreme large label collection for a given text input. many real-world applications can be formulated as xmc problems, such as recommendation systems, document tagging and semantic search. recently, transformer based xmc methods, such as x-transformer and lightxml, have shown significant improvement over other xmc methods. despite leveraging pre-trained transformer models for text representation, the fine-tuning procedure of transformer models on large label space still has lengthy computational time even with powerful gpus. in this paper, we propose a novel recursive approach, xr-transformer to accelerate the procedure through recursively fine-tuning transformer models on a series of multi-resolution objectives related to the original xmc objective function. empirical results show that xr-transformer takes significantly less training time compared to other transformer-based xmc models while yielding better state-of-the-art results. in particular, on the public amazon-3m dataset with 3 million labels, xr-transformer is not only 20x faster than x-transformer but also improves the precision@1 from 51% to 54%.",,2021-10-01,2021-10-28,"['jiong zhang', 'wei-cheng chang', 'hsiang-fu yu', 'inderjit s. dhillon']"
2110.01052,learn then test: calibrating predictive algorithms to achieve risk   control,cs.lg cs.ai cs.cv stat.me stat.ml,"we introduce learn then test, a framework for calibrating machine learning models so that their predictions satisfy explicit, finite-sample statistical guarantees regardless of the underlying model and (unknown) data-generating distribution. the framework addresses, among other examples, false discovery rate control in multi-label classification, intersection-over-union control in instance segmentation, and the simultaneous control of the type-1 error of outlier detection and confidence set coverage in classification or regression. to accomplish this, we solve a key technical challenge: the control of arbitrary risks that are not necessarily monotonic. our main insight is to reframe the risk-control problem as multiple hypothesis testing, enabling techniques and mathematical arguments different from those in the previous literature. we use our framework to provide new calibration methods for several core machine learning tasks with detailed worked examples in computer vision.",,2021-10-03,2021-11-11,"['anastasios n. angelopoulos', 'stephen bates', 'emmanuel j. candès', 'michael i. jordan', 'lihua lei']"
2110.01445,robust and decomposable average precision for image retrieval,cs.lg cs.ai cs.cv cs.ne stat.ml,"in image retrieval, standard evaluation metrics rely on score ranking, e.g. average precision (ap). in this paper, we introduce a method for robust and decomposable average precision (roadmap) addressing two major challenges for end-to-end training of deep neural networks with ap: non-differentiability and non-decomposability. firstly, we propose a new differentiable approximation of the rank function, which provides an upper bound of the ap loss and ensures robust training. secondly, we design a simple yet effective loss function to reduce the decomposability gap between the ap in the whole training set and its averaged batch approximation, for which we provide theoretical guarantees. extensive experiments conducted on three image retrieval datasets show that roadmap outperforms several recent ap approximation methods and highlight the importance of our two contributions. finally, using roadmap for training deep models yields very good performances, outperforming state-of-the-art results on the three datasets.",,2021-10-01,2021-11-02,"['elias ramzi', 'nicolas thome', 'clément rambour', 'nicolas audebert', 'xavier bitot']"
2110.01777,metapix: domain transfer for semantic segmentation by meta pixel   weighting,cs.cv cs.ai,"training a deep neural model for semantic segmentation requires collecting a large amount of pixel-level labeled data. to alleviate the data scarcity problem presented in the real world, one could utilize synthetic data whose label is easy to obtain. previous work has shown that the performance of a semantic segmentation model can be improved by training jointly with real and synthetic examples with a proper weighting on the synthetic data. such weighting was learned by a heuristic to maximize the similarity between synthetic and real examples. in our work, we instead learn a pixel-level weighting of the synthetic data by meta-learning, i.e., the learning of weighting should only be minimizing the loss on the target task. we achieve this by gradient-on-gradient technique to propagate the target loss back into the parameters of the weighting model. the experiments show that our method with only one single meta module can outperform a complicated combination of an adversarial feature alignment, a reconstruction loss, plus a hierarchical heuristic weighting at pixel, region and image levels.",,2021-10-04,,"['yiren jian', 'chongyang gao']"
2110.01810,deep synoptic monte carlo planning in reconnaissance blind chess,cs.ai cs.lg,"this paper introduces deep synoptic monte carlo planning (dsmcp) for large imperfect information games. the algorithm constructs a belief state with an unweighted particle filter and plans via playouts that start at samples drawn from the belief state. the algorithm accounts for uncertainty by performing inference on ""synopses,"" a novel stochastic abstraction of information states. dsmcp is the basis of the program penumbra, which won the official 2020 reconnaissance blind chess competition versus 33 other programs. this paper also evaluates algorithm variants that incorporate caution, paranoia, and a novel bandit algorithm. furthermore, it audits the synopsis features used in penumbra with per-bit saliency statistics.",,2021-10-04,2021-11-01,['gregory clark']
2110.02376,foundations of symbolic languages for model interpretability,cs.ai cs.lo,"several queries and scores have recently been proposed to explain individual predictions over ml models. given the need for flexible, reliable, and easy-to-apply interpretability methods for ml models, we foresee the need for developing declarative languages to naturally specify different explainability queries. we do this in a principled way by rooting such a language in a logic, called foil, that allows for expressing many simple but important explainability queries, and might serve as a core for more expressive interpretability languages. we study the computational complexity of foil queries over two classes of ml models often deemed to be easily interpretable: decision trees and obdds. since the number of possible inputs for an ml model is exponential in its dimension, the tractability of the foil evaluation problem is delicate but can be achieved by either restricting the structure of the models or the fragment of foil being evaluated. we also present a prototype implementation of foil wrapped in a high-level declarative language and perform experiments showing that such a language can be used in practice.",,2021-10-05,2021-11-14,"['marcelo arenas', 'daniel baez', 'pablo barceló', 'jorge pérez', 'bernardo subercaseaux']"
2110.02403,tradeoffs in streaming binary classification under limited inspection   resources,cs.lg cs.ai,"institutions are increasingly relying on machine learning models to identify and alert on abnormal events, such as fraud, cyber attacks and system failures. these alerts often need to be manually investigated by specialists. given the operational cost of manual inspections, the suspicious events are selected by alerting systems with carefully designed thresholds. in this paper, we consider an imbalanced binary classification problem, where events arrive sequentially and only a limited number of suspicious events can be inspected. we model the event arrivals as a non-homogeneous poisson process, and compare various suspicious event selection methods including those based on static and adaptive thresholds. for each method, we analytically characterize the tradeoff between the minority-class detection rate and the inspection capacity as a function of the data class imbalance and the classifier confidence score densities. we implement the selection methods on a real public fraud detection dataset and compare the empirical results with analytical bounds. finally, we investigate how class imbalance and the choice of classifier impact the tradeoff.",,2021-10-05,2021-10-29,"['parisa hassanzadeh', 'danial dervovic', 'samuel assefa', 'prashant reddy', 'manuela veloso']"
2110.02739,a step towards efficient evaluation of complex perception tasks in   simulation,cs.lg cs.ai cs.cv cs.ro,"there has been increasing interest in characterising the error behaviour of systems which contain deep learning models before deploying them into any safety-critical scenario. however, characterising such behaviour usually requires large-scale testing of the model that can be extremely computationally expensive for complex real-world tasks. for example, tasks involving compute intensive object detectors as one of their components. in this work, we propose an approach that enables efficient large-scale testing using simplified low-fidelity simulators and without the computational cost of executing expensive deep learning models. our approach relies on designing an efficient surrogate model corresponding to the compute intensive components of the task under test. we demonstrate the efficacy of our methodology by evaluating the performance of an autonomous driving task in the carla simulator with reduced computational expense by training efficient surrogate models for pixor and centerpoint lidar detectors, whilst demonstrating that the accuracy of the simulation is maintained.",,2021-09-28,2021-11-04,"['jonathan sadeghi', 'blaine rogers', 'james gunn', 'thomas saunders', 'sina samangooei', 'puneet kumar dokania', 'john redford']"
2110.03395,slash: embracing probabilistic circuits into neural answer set   programming,cs.ai,"the goal of combining the robustness of neural networks and the expressivity of symbolic methods has rekindled the interest in neuro-symbolic ai. recent advancements in neuro-symbolic ai often consider specifically-tailored architectures consisting of disjoint neural and symbolic components, and thus do not exhibit desired gains that can be achieved by integrating them into a unifying framework. we introduce slash -- a novel deep probabilistic programming language (dppl). at its core, slash consists of neural-probabilistic predicates (npps) and logical programs which are united via answer set programming. the probability estimates resulting from npps act as the binding element between the logical program and raw input data, thereby allowing slash to answer task-dependent logical queries. this allows slash to elegantly integrate the symbolic and neural components in a unified framework. we evaluate slash on the benchmark data of mnist addition as well as novel tasks for dppls such as missing data prediction and set prediction with state-of-the-art performance, thereby showing the effectiveness and generality of our method.",,2021-10-07,2021-11-01,"['arseny skryagin', 'wolfgang stammer', 'daniel ochs', 'devendra singh dhami', 'kristian kersting']"
2110.03469,federated learning from small datasets,cs.lg cs.ai cs.dc,"federated learning allows multiple parties to collaboratively train a joint model without sharing local data. this enables applications of machine learning in settings of inherently distributed, undisclosable data such as in the medical domain. in practice, joint training is usually achieved by aggregating local models, for which local training objectives have to be in expectation similar to the joint (global) objective. often, however, local datasets are so small that local objectives differ greatly from the global objective, resulting in federated learning to fail. we propose a novel approach that intertwines model aggregations with permutations of local models. the permutations expose each local model to a daisy chain of local datasets resulting in more efficient training in data-sparse domains. this enables training on extremely small local datasets, such as patient data across hospitals, while retaining the training efficiency and privacy benefits of federated learning.",,2021-10-07,2021-11-02,"['michael kamp', 'jonas fischer', 'jilles vreeken']"
2110.03485,cartoon explanations of image classifiers,cs.ai cs.cv,"we present {cartoonx} (cartoon explanation), a novel model-agnostic explanation method tailored towards image classifiers and based on the rate-distortion explanation (rde) framework. natural images are roughly piece-wise smooth signals -- also called cartoon-like images -- and tend to be sparse in the wavelet domain. cartoonx is the first explanation method to exploit this by requiring its explanations to be sparse in the wavelet domain, thus extracting the {relevant piece-wise smooth} part of an image instead of relevant pixel-sparse regions. we demonstrate that cartoonx can reveal novel valuable explanatory information, particularly for misclassifications. moreover, we show that cartoonx achieves a lower distortion with fewer coefficients than other state-of-the-art methods.",,2021-10-07,2021-11-17,"['stefan kolek', 'duc anh nguyen', 'ron levie', 'joan bruna', 'gitta kutyniok']"
2110.03613,a data-centric approach for training deep neural networks with less data,cs.ai,"while the availability of large datasets is perceived to be a key requirement for training deep neural networks, it is possible to train such models with relatively little data. however, compensating for the absence of large datasets demands a series of actions to enhance the quality of the existing samples and to generate new ones. this paper summarizes our winning submission to the ""data-centric ai"" competition. we discuss some of the challenges that arise while training with a small dataset, offer a principled approach for systematic data quality enhancement, and propose a gan-based solution for synthesizing new data points. our evaluations indicate that the dataset generated by the proposed pipeline offers 5% accuracy improvement while being significantly smaller than the baseline.",,2021-10-07,2021-10-29,"['mohammad motamedi', 'nikolay sakharnykh', 'tim kaldewey']"
2110.04186,medical dead-ends and learning to identify high-risk states and   treatments,cs.lg cs.ai,"machine learning has successfully framed many sequential decision making problems as either supervised prediction, or optimal decision-making policy identification via reinforcement learning. in data-constrained offline settings, both approaches may fail as they assume fully optimal behavior or rely on exploring alternatives that may not exist. we introduce an inherently different approach that identifies possible ``dead-ends'' of a state space. we focus on the condition of patients in the intensive care unit, where a ``medical dead-end'' indicates that a patient will expire, regardless of all potential future treatment sequences. we postulate ``treatment security'' as avoiding treatments with probability proportional to their chance of leading to dead-ends, present a formal proof, and frame discovery as an rl problem. we then train three independent deep neural models for automated state construction, dead-end discovery and confirmation. our empirical results discover that dead-ends exist in real clinical data among septic patients, and further reveal gaps between secure treatments and those that were administered.",,2021-10-08,2021-11-05,"['mehdi fatemi', 'taylor w. killian', 'jayakumar subramanian', 'marzyeh ghassemi']"
2110.04652,representation learning for online and offline rl in low-rank mdps,cs.lg cs.ai stat.ml,"this work studies the question of representation learning in rl: how can we learn a compact low-dimensional representation such that on top of the representation we can perform rl procedures such as exploration and exploitation, in a sample efficient manner. we focus on the low-rank markov decision processes (mdps) where the transition dynamics correspond to a low-rank transition matrix. unlike prior works that assume the representation is known (e.g., linear mdps), here we need to learn the representation for the low-rank mdp. we study both the online rl and offline rl settings. for the online setting, operating with the same computational oracles used in flambe (agarwal et.al), the state-of-art algorithm for learning representations in low-rank mdps, we propose an algorithm rep-ucb upper confidence bound driven representation learning for rl), which significantly improves the sample complexity from $\widetilde{o}( a^9 d^7 / (\epsilon^{10} (1-\gamma)^{22}))$ for flambe to $\widetilde{o}( a^4 d^4 / (\epsilon^2 (1-\gamma)^{3}) )$ with $d$ being the rank of the transition matrix (or dimension of the ground truth representation), $a$ being the number of actions, and $\gamma$ being the discounted factor. notably, rep-ucb is simpler than flambe, as it directly balances the interplay between representation learning, exploration, and exploitation, while flambe is an explore-then-commit style approach and has to perform reward-free exploration step-by-step forward in time. for the offline rl setting, we develop an algorithm that leverages pessimism to learn under a partial coverage condition: our algorithm is able to compete against any policy as long as it is covered by the offline distribution.",,2021-10-09,2021-11-10,"['masatoshi uehara', 'xuezhou zhang', 'wen sun']"
2110.04719,"structure learning in polynomial time: greedy algorithms, bregman   information, and exponential families",cs.lg cs.ai stat.ml,"greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. in the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst-case exponential runtime. in practice, however, they are very efficient. we provide new insight into this phenomenon by studying a general greedy score-based algorithm for learning dags. unlike edge-greedy algorithms such as the popular ges and hill-climbing algorithms, our approach is vertex-greedy and requires at most a polynomial number of score evaluations. we then show how recent polynomial-time algorithms for learning dag models are a special case of this algorithm, thereby illustrating how these order-based algorithms can be rigourously interpreted as score-based algorithms. this observation suggests new score functions and optimality conditions based on the duality between bregman divergences and exponential families, which we explore in detail. explicit sample and computational complexity bounds are derived. finally, we provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings.",,2021-10-10,2021-10-28,"['goutham rajendran', 'bohdan kivva', 'ming gao', 'bryon aragam']"
2110.05231,multi-modal self-supervised pre-training for regulatory genome across   cell types,q-bio.gn cs.ai cs.lg,"in the genome biology research, regulatory genome modeling is an important topic for many regulatory downstream tasks, such as promoter classification, transaction factor binding sites prediction. the core problem is to model how regulatory elements interact with each other and its variability across different cell types. however, current deep learning methods often focus on modeling genome sequences of a fixed set of cell types and do not account for the interaction between multiple regulatory elements, making them only perform well on the cell types in the training set and lack the generalizability required in biological applications. in this work, we propose a simple yet effective approach for pre-training genome data in a multi-modal and self-supervised manner, which we call genebert. specifically, we simultaneously take the 1d sequence of genome data and a 2d matrix of (transcription factors x regions) as the input, where three pre-training tasks are proposed to improve the robustness and generalizability of our model. we pre-train our model on the atac-seq dataset with 17 million genome sequences. we evaluate our genebert on regulatory downstream tasks across different cell types, including promoter classification, transaction factor binding sites prediction, disease risk estimation, and splicing sites prediction. extensive experiments demonstrate the effectiveness of multi-modal and self-supervised pre-training for large-scale regulatory genomics data.",,2021-10-11,2021-11-03,"['shentong mo', 'xi fu', 'chenyang hong', 'yizhen chen', 'yuxuan zheng', 'xiangru tang', 'zhiqiang shen', 'eric p xing', 'yanyan lan']"
2110.05610,tsk fuzzy system towards few labeled incomplete multi-view data   classification,cs.lg cs.ai,"data collected by multiple methods or from multiple sources is called multi-view data. to make full use of the multi-view data, multi-view learning plays an increasingly important role. traditional multi-view learning methods rely on a large number of labeled and completed multi-view data. however, it is expensive and time-consuming to obtain a large number of labeled multi-view data in real-world applications. moreover, multi-view data is often incomplete because of data collection failures, self-deficiency, or other reasons. therefore, we may have to face the problem of fewer labeled and incomplete multi-view data in real application scenarios. in this paper, a transductive semi-supervised incomplete multi-view tsk fuzzy system modeling method (ssimv_tsk) is proposed to address these challenges. first, in order to alleviate the dependency on labeled data and keep the model interpretable, the proposed method integrates missing view imputation, pseudo label learning of unlabeled data, and fuzzy system modeling into a single process to yield a model with interpretable fuzzy rules. then, two new mechanisms, i.e. the bidirectional structural preservation of instance and label, as well as the adaptive multiple alignment collaborative learning, are proposed to improve the robustness of the model. the proposed method has the following distinctive characteristics: 1) it can deal with the incomplete and few labeled multi-view data simultaneously; 2) it integrates the missing view imputation and model learning as a single process, which is more efficient than the traditional two-step strategy; 3) attributed to the interpretable fuzzy inference rules, this method is more interpretable. experimental results on real datasets show that the proposed method significantly outperforms the state-of-the-art methods.",,2021-10-08,2021-11-15,"['wei zhang', 'zhaohong deng', 'qiongdan lou', 'te zhang', 'kup-sze choi', 'shitong wang']"
2110.05836,avoe: a synthetic 3d dataset on understanding violation of expectation   for artificial cognition,cs.cv cs.ai,"recent work in cognitive reasoning and computer vision has engendered an increasing popularity for the violation-of-expectation (voe) paradigm in synthetic datasets. inspired by work in infant psychology, researchers have started evaluating a model's ability to discriminate between expected and surprising scenes as a sign of its reasoning ability. existing voe-based 3d datasets in physical reasoning only provide vision data. however, current cognitive models of physical reasoning by psychologists reveal infants create high-level abstract representations of objects and interactions. capitalizing on this knowledge, we propose avoe: a synthetic 3d voe-based dataset that presents stimuli from multiple novel sub-categories for five event categories of physical reasoning. compared to existing work, avoe is armed with ground-truth labels of abstract features and rules augmented to vision data, paving the way for high-level symbolic predictions in physical reasoning tasks.",,2021-10-12,2021-11-16,"['arijit dasgupta', 'jiafei duan', 'marcelo h. ang', 'cheston tan']"
2110.06348,exact and bounded collision probability for motion planning under   gaussian uncertainty,cs.ro cs.ai,"computing collision-free trajectories is of prime importance for safe navigation. we present an approach for computing the collision probability under gaussian distributed motion and sensing uncertainty with the robot and static obstacle shapes approximated as ellipsoids. the collision condition is formulated as the distance between ellipsoids and unlike previous approaches we provide a method for computing the exact collision probability. furthermore, we provide a tight upper bound that can be computed much faster during online planning. comparison to other state-of-the-art methods is also provided. the proposed method is evaluated in simulation under varying configuration and number of obstacles.",10.1109/lra.2021.3121073,2021-10-12,,"['antony thomas', 'fulvio mastrogiovanni', 'marco baglietto']"
2110.06467,dual-branch attention-in-attention transformer for single-channel speech   enhancement,cs.sd cs.ai eess.as,"curriculum learning begins to thrive in the speech enhancement area, which decouples the original spectrum estimation task into multiple easier sub-tasks to achieve better performance. motivated by that, we propose a dual-branch attention-in-attention transformer dubbed db-aiat to handle both coarse- and fine-grained regions of the spectrum in parallel. from a complementary perspective, a magnitude masking branch is proposed to coarsely estimate the overall magnitude spectrum, and simultaneously a complex refining branch is elaborately designed to compensate for the missing spectral details and implicitly derive phase information. within each branch, we propose a novel attention-in-attention transformer-based module to replace the conventional rnns and temporal convolutional networks for temporal sequence modeling. specifically, the proposed attention-in-attention transformer consists of adaptive temporal-frequency attention transformer blocks and an adaptive hierarchical attention module, aiming to capture long-term temporal-frequency dependencies and further aggregate global hierarchical contextual information. experimental results on voice bank + demand demonstrate that db-aiat yields state-of-the-art performance (e.g., 3.31 pesq, 95.6% stoi and 10.79db ssnr) over previous advanced systems with a relatively small model size (2.81m).",,2021-10-12,2021-11-05,"['guochen yu', 'andong li', 'yutian wang', 'yinuo guo', 'hui wang', 'chengshi zheng']"
2110.06523,recommending pois for tourists by user behavior modeling and   pseudo-rating,cs.ir cs.ai cs.db,"poi recommendation is a key task in tourism information systems. however, in contrast to conventional point of interest (poi) recommender systems, the available data is extremely sparse; most tourist visit a few sightseeing spots once and most of these spots have no check-in data from new tourists. most conventional systems rank sightseeing spots based on their popularity, reputations, and category-based similarities with users' preferences. they do not clarify what users can experience in these spots, which makes it difficult to meet diverse tourism needs. to this end, in this work, we propose a mechanism to recommend pois to tourists. our mechanism include two components: one is a probabilistic model that reveals the user behaviors in tourism; the other is a pseudo rating mechanism to handle the cold-start issue in pois recommendations. we carried out extensive experiments with two datasets collected from flickr. the experimental results demonstrate that our methods are superior to the state-of-the-art methods in both the recommendation performances (precision, recall and f-measure) and fairness. the experimental results also validate the robustness of the proposed methods, i.e., our methods can handle well the issue of data sparsity.",,2021-10-13,2021-11-16,"['kun yi', 'ryu yamagishi', 'taishan li', 'zhengyang bai', 'qiang ma']"
2110.06829,towards a fully rl-based market simulator,cs.ma cs.ai cs.lg q-fin.tr,"we present a new financial framework where two families of rl-based agents representing the liquidity providers and liquidity takers learn simultaneously to satisfy their objective. thanks to a parametrized reward formulation and the use of deep rl, each group learns a shared policy able to generalize and interpolate over a wide range of behaviors. this is a step towards a fully rl-based market simulator replicating complex market conditions particularly suited to study the dynamics of the financial market under various scenarios.",10.1145/3490354.3494372,2021-10-13,2021-11-08,"['leo ardon', 'nelson vadori', 'thomas spooner', 'mengda xu', 'jared vann', 'sumitra ganesh']"
2110.06831,safe driving via expert guided policy optimization,cs.ai cs.ro,"when learning common skills like driving, beginners usually have domain experts standing by to ensure the safety of the learning process. we formulate such learning scheme under the expert-in-the-loop reinforcement learning where a guardian is introduced to safeguard the exploration of the learning agent. while allowing the sufficient exploration in the uncertain environment, the guardian intervenes under dangerous situations and demonstrates the correct actions to avoid potential accidents. thus erl enables both exploration and expert's partial demonstration as two training sources. following such a setting, we develop a novel expert guided policy optimization (egpo) method which integrates the guardian in the loop of reinforcement learning. the guardian is composed of an expert policy to generate demonstration and a switch function to decide when to intervene. particularly, a constrained optimization technique is used to tackle the trivial solution that the agent deliberately behaves dangerously to deceive the expert into taking over. offline rl technique is further used to learn from the partial demonstration generated by the expert. safe driving experiments show that our method achieves superior training and test-time safety, outperforms baselines with a substantial margin in sample efficiency, and preserves the generalizabiliy to unseen environments in test-time. demo video and source code are available at: https://decisionforce.github.io/egpo/",,2021-10-13,2021-10-30,"['zhenghao peng', 'quanyi li', 'chunxiao liu', 'bolei zhou']"
2110.06980,output space entropy search framework for multi-objective bayesian   optimization,cs.lg cs.ai stat.ml,"we consider the problem of black-box multi-objective optimization (moo) using expensive function evaluations (also referred to as experiments), where the goal is to approximate the true pareto set of solutions by minimizing the total resource cost of experiments. for example, in hardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive computational simulations. the key challenge is to select the sequence of experiments to uncover high-quality solutions using minimal resources. in this paper, we propose a general framework for solving moo problems based on the principle of output space entropy (ose) search: select the experiment that maximizes the information gained per unit resource cost about the true pareto front. we appropriately instantiate the principle of ose search to derive efficient algorithms for the following four moo problem settings: 1) the most basic em single-fidelity setting, where experiments are expensive and accurate; 2) handling em black-box constraints} which cannot be evaluated without performing experiments; 3) the discrete multi-fidelity setting, where experiments can vary in the amount of resources consumed and their evaluation accuracy; and 4) the em continuous-fidelity setting, where continuous function approximations result in a huge space of experiments. experiments on diverse synthetic and real-world benchmarks show that our ose search based algorithms improve over state-of-the-art methods in terms of both computational-efficiency and accuracy of moo solutions.",10.1613/jair.1.12966,2021-10-13,2021-11-03,"['syrine belakaria', 'aryan deshwal', 'janardhan rao doppa']"
2110.07554,looper: an end-to-end ml platform for product decisions,cs.lg cs.ai cs.se,"modern software systems and products increasingly rely on machine learning models to make data-driven decisions based on interactions with users and systems, e.g., compute infrastructure. for broader adoption, this practice must (i) accommodate software engineers without ml backgrounds, and (ii) provide mechanisms to optimize for product goals. in this work, we describe general principles and a specific end-to-end ml platform, looper, which offers easy-to-use apis for decision-making and feedback collection. looper supports the full end-to-end ml lifecycle from online data collection to model training, deployment, inference, and extends support to evaluation and tuning against product goals. we outline the platform architecture and overall impact of production deployment -- looper currently hosts 700 ml models and makes 6 million decisions per second. we also describe the learning curve and summarize experiences of platform adopters.",,2021-10-14,2021-11-17,"['igor l. markov', 'hanson wang', 'nitya kasturi', 'shaun singh', 'sze wai yuen', 'mia garrard', 'sarah tran', 'yin huang', 'zehui wang', 'igor glotov', 'tanvi gupta', 'boshuang huang', 'peng chen', 'xiaowen xie', 'michael belkin', 'sal uryasev', 'sam howie', 'eytan bakshy', 'norm zhou']"
2110.07722,the sigma-max system induced from randomness and fuzziness,cs.ai cs.lo math.pr,"this paper managed to induce probability theory (sigma system) and possibility theory (max system) respectively from randomness and fuzziness, through which the premature theory of possibility is expected to be well founded. such an objective is achieved by addressing three open key issues: a) the lack of clear mathematical definitions of randomness and fuzziness; b) the lack of intuitive mathematical definition of possibility; c) the lack of abstraction procedure of the axiomatic definitions of probability/possibility from their intuitive definitions. especially, the last issue involves the question why the key axiom of ""maxitivity"" is adopted for possibility measure. by taking advantage of properties of the well-defined randomness and fuzziness, we derived the important conclusion that ""max"" is the only but un-strict disjunctive operator that is applicable across the fuzzy event space, and is an exact operator for fuzzy feature extraction that assures the max inference is an exact mechanism. it is fair to claim that the long-standing problem of lack of consensus to the foundation of possibility theory is well resolved, which would facilitate wider adoption of possibility theory in practice and promote cross prosperity of the two uncertainty theories of probability and possibility.",,2021-10-12,,"['wei mei', 'ming li', 'yuanzeng cheng', 'limin liu']"
2110.07803,contraqa: question answering under contradicting contexts,cs.cl cs.ai,"with a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world question answering (qa) systems face the challenges of synthesizing and reasoning over contradicting information to derive correct answers. this urgency gives rise to the need to make qa systems robust to misinformation, a topic previously unexplored. we study the risk of misinformation to qa models by investigating the behavior of the qa model under contradicting contexts that are mixed with both real and fake information. we create the first large-scale dataset for this problem, namely contra-qa, which contains over 10k human-written and model-generated contradicting pairs of contexts. experiments show that qa models are vulnerable under contradicting contexts brought by misinformation. to defend against such a threat, we build a misinformation-aware qa system as a counter-measure that integrates question answering and misinformation detection in a joint fashion.",,2021-10-14,2021-11-04,"['liangming pan', 'wenhu chen', 'min-yen kan', 'william yang wang']"
2110.08003,a broad-persistent advising approach for deep interactive reinforcement   learning in robotic environments,cs.ro cs.ai,"deep reinforcement learning (deeprl) methods have been widely used in robotics to learn about the environment and acquire behaviors autonomously. deep interactive reinforcement learning (deepirl) includes interactive feedback from an external trainer or expert giving advice to help learners choosing actions to speed up the learning process. however, current research has been limited to interactions that offer actionable advice to only the current state of the agent. additionally, the information is discarded by the agent after a single use that causes a duplicate process at the same state for a revisit. in this paper, we present broad-persistent advising (bpa), a broad-persistent advising approach that retains and reuses the processed information. it not only helps trainers to give more general advice relevant to similar states instead of only the current state but also allows the agent to speed up the learning process. we test the proposed approach in two continuous robotic scenarios, namely, a cart pole balancing task and a simulated robot navigation task. the obtained results show that the performance of the agent using bpa improves while keeping the number of interactions required for the trainer in comparison to the deepirl approach.",,2021-10-15,2021-11-18,"['hung son nguyen', 'francisco cruz', 'richard dazeley']"
2110.08187,crop rotation modeling for deep learning-based parcel classification   from satellite time series,cs.cv cs.ai,"while annual crop rotations play a crucial role for agricultural optimization, they have been largely ignored for automated crop type mapping. in this paper, we take advantage of the increasing quantity of annotated satellite data to propose the first deep learning approach modeling simultaneously the inter- and intra-annual agricultural dynamics of parcel classification. along with simple training adjustments, our model provides an improvement of over 6.3 miou points over the current state-of-the-art of crop classification. furthermore, we release the first large-scale multi-year agricultural dataset with over 300,000 annotated parcels.",,2021-10-15,2021-11-16,"['félix quinton', 'loic landrieu']"
2110.08322,robustness of different loss functions and their impact on networks   learning capability,cs.lg cs.ai,"recent developments in ai have made it ubiquitous, every industry is trying to adopt some form of intelligent processing of their data. despite so many advances in the field, ais full capability is yet to be exploited by the industry. industries that involve some risk factors still remain cautious about the usage of ai due to the lack of trust in such autonomous systems. present-day ai might be very good in a lot of things but it is very bad in reasoning and this behavior of ai can lead to catastrophic results. autonomous cars crashing into a person or a drone getting stuck in a tree are a few examples where ai decisions lead to catastrophic results. to develop insight and generate an explanation about the learning capability of ai, we will try to analyze the working of loss functions. for our case, we will use two sets of loss functions, generalized loss functions like binary cross-entropy or bce and specialized loss functions like dice loss or focal loss. through a series of experiments, we will establish whether combining different loss functions is better than using a single loss function and if yes, then what is the reason behind it. in order to establish the difference between generalized loss and specialized losses, we will train several models using the above-mentioned losses and then compare their robustness on adversarial examples. in particular, we will look at how fast the accuracy of different models decreases when we change the pixels corresponding to the most salient gradients.",,2021-10-15,2021-11-09,['vishal rajput']
2110.08642,local advantage actor-critic for robust multi-agent deep reinforcement   learning,cs.lg cs.ai cs.ma,"policy gradient methods have become popular in multi-agent reinforcement learning, but they suffer from high variance due to the presence of environmental stochasticity and exploring agents (i.e., non-stationarity), which is potentially worsened by the difficulty in credit assignment. as a result, there is a need for a method that is not only capable of efficiently solving the above two problems but also robust enough to solve a variety of tasks. to this end, we propose a new multi-agent policy gradient method, called robust local advantage (rola) actor-critic. rola allows each agent to learn an individual action-value function as a local critic as well as ameliorating environment non-stationarity via a novel centralized training approach based on a centralized critic. by using this local critic, each agent calculates a baseline to reduce variance on its policy gradient estimation, which results in an expected advantage action-value over other agents' choices that implicitly improves credit assignment. we evaluate rola across diverse benchmarks and show its robustness and effectiveness over a number of state-of-the-art multi-agent policy gradient algorithms.",,2021-10-16,2021-11-01,"['yuchen xiao', 'xueguang lyu', 'christopher amato']"
2110.08944,developing a novel fair-loan-predictor through a multi-sensitive   debiasing pipeline: dualfair,cs.lg cs.ai cs.cy,"machine learning (ml) models are increasingly used for high-stake applications that can greatly impact people's lives. despite their use, these models have the potential to be biased towards certain social groups on the basis of race, gender, or ethnicity. many prior works have attempted to mitigate this ""model discrimination"" by updating the training data (pre-processing), altering the model learning process (in-processing), or manipulating model output (post-processing). however, these works have not yet been extended to the realm of multi-sensitive parameters and sensitive options (mspso), where sensitive parameters are attributes that can be discriminated against (e.g race) and sensitive options are options within sensitive parameters (e.g black or white), thus giving them limited real-world usability. prior work in fairness has also suffered from an accuracy-fairness tradeoff that prevents both the accuracy and fairness from being high. moreover, previous literature has failed to provide holistic fairness metrics that work with mspso. in this paper, we solve all three of these problems by (a) creating a novel bias mitigation technique called dualfair and (b) developing a new fairness metric (i.e. awi) that can handle mspso. lastly, we test our novel mitigation method using a comprehensive u.s mortgage lending dataset and show that our classifier, or fair loan predictor, obtains better fairness and accuracy metrics than current state-of-the-art models.",,2021-10-17,2021-11-14,"['jashandeep singh', 'arashdeep singh', 'ariba khan', 'amar gupta']"
2110.09456,normformer: improved transformer pretraining with extra normalization,cs.cl cs.ai,"during pretraining, the pre-layernorm transformer suffers from a gradient magnitude mismatch: gradients at early layers are much larger than at later layers. these issues can be alleviated by our proposed normformer architecture, which adds three normalization operations to each layer: a layer norm after self attention, head-wise scaling of self-attention outputs, and a layer norm after the first fully connected layer. the extra operations incur negligible compute cost (+0.4% parameter increase), but improve pretraining perplexity and downstream task performance for both causal and masked language models ranging from 125 million to 2.7 billion parameters. for example, adding normformer on top of our strongest 1.3b parameter baseline can reach equal perplexity 24% faster, or converge 0.27 perplexity better in the same compute budget. this model reaches gpt3-large (1.3b) zero shot performance 60% faster. for masked language modeling, normformer improves fine-tuned glue performance by 1.9% on average. code to train normformer models is available in fairseq https://github.com/pytorch/fairseq/tree/main/examples/normformer .",,2021-10-18,2021-11-01,"['sam shleifer', 'jason weston', 'myle ott']"
2110.10349,distributed reinforcement learning for privacy-preserving dynamic edge   caching,cs.lg cs.ai cs.cr cs.mm,"mobile edge computing (mec) is a prominent computing paradigm which expands the application fields of wireless communication. due to the limitation of the capacities of user equipments and mec servers, edge caching (ec) optimization is crucial to the effective utilization of the caching resources in mec-enabled wireless networks. however, the dynamics and complexities of content popularities over space and time as well as the privacy preservation of users pose significant challenges to ec optimization. in this paper, a privacy-preserving distributed deep deterministic policy gradient (p2d3pg) algorithm is proposed to maximize the cache hit rates of devices in the mec networks. specifically, we consider the fact that content popularities are dynamic, complicated and unobservable, and formulate the maximization of cache hit rates on devices as distributed problems under the constraints of privacy preservation. in particular, we convert the distributed optimizations into distributed model-free markov decision process problems and then introduce a privacy-preserving federated learning method for popularity prediction. subsequently, a p2d3pg algorithm is developed based on distributed reinforcement learning to solve the distributed problems. simulation results demonstrate the superiority of the proposed approach in improving ec hit rate over the baseline methods while preserving user privacy.",,2021-10-19,2021-11-01,"['shengheng liu', 'chong zheng', 'yongming huang', 'tony q. s. quek']"
2110.10572,estimation & recognition under perspective of random-fuzzy dual   interpretation of unknown quantity: with demonstration of imm filter,eess.sy cs.ai cs.sy eess.sp math.pr stat.ap,"this paper is to consider the problems of estimation and recognition from the perspective of sigma-max inference (probability-possibility inference), with a focus on discovering whether some of the unknown quantities involved could be more faithfully modeled as fuzzy uncertainty. two related key issues are addressed: 1) the random-fuzzy dual interpretation of unknown quantity being estimated; 2) the principle of selecting sigma-max operator for practical problems, such as estimation and recognition. our perspective, conceived from definitions of randomness and fuzziness, is that continuous unknown quantity involved in estimation with inaccurate prior should be more appropriately modeled as randomness and handled by sigma inference; whereas discrete unknown quantity involved in recognition with insufficient (and inaccurate) prior could be better modeled as fuzziness and handled by max inference. the philosophy was demonstrated by an updated version of the well-known interacting multiple model (imm) filter, for which the jump markovian system is reformulated as a hybrid uncertainty system, with continuous state evolution modeled as usual as model-conditioned stochastic system and discrete mode transitions modeled as fuzzy system by a possibility (instead of probability) transition matrix, and hypotheses mixing is conducted by using the operation of ""max"" instead of ""sigma"". for our example of maneuvering target tracking using simulated data from both a short-range fire control radar and a long-range surveillance radar, the updated imm filter shows significant improvement over the classic imm filter, due to its peculiarity of hard decision of system model and a faster response to the transition of discrete mode.",,2021-10-20,2021-11-01,"['wei mei', 'yunfeng xu', 'limin liu']"
2110.10632,more efficient exploration with symbolic priors on action sequence   equivalences,cs.lg cs.ai,"incorporating prior knowledge in reinforcement learning algorithms is mainly an open question. even when insights about the environment dynamics are available, reinforcement learning is traditionally used in a tabula rasa setting and must explore and learn everything from scratch. in this paper, we consider the problem of exploiting priors about action sequence equivalence: that is, when different sequences of actions produce the same effect. we propose a new local exploration strategy calibrated to minimize collisions and maximize new state visitations. we show that this strategy can be computed at little cost, by solving a convex optimization problem. by replacing the usual epsilon-greedy strategy in a dqn, we demonstrate its potential in several environments with various dynamic structures.",,2021-10-20,2021-11-07,"['toby johnstone', 'nathan grinsztajn', 'johan ferret', 'philippe preux']"
2110.10906,single-modal entropy based active learning for visual question answering,cs.cv cs.ai cs.cl cs.lg,"constructing a large-scale labeled dataset in the real world, especially for high-level tasks (eg, visual question answering), can be expensive and time-consuming. in addition, with the ever-growing amounts of data and architecture complexity, active learning has become an important aspect of computer vision research. in this work, we address active learning in the multi-modal setting of visual question answering (vqa). in light of the multi-modal inputs, image and question, we propose a novel method for effective sample acquisition through the use of ad hoc single-modal branches for each input to leverage its information. our mutual information based sample acquisition strategy single-modal entropic measure (smem) in addition to our self-distillation technique enables the sample acquisitor to exploit all present modalities and find the most informative samples. our novel idea is simple to implement, cost-efficient, and readily adaptable to other multi-modal tasks. we confirm our findings on various vqa datasets through state-of-the-art performance by comparing to existing active learning baselines.",,2021-10-21,2021-11-18,"['dong-jin kim', 'jae won cho', 'jinsoo choi', 'yunjae jung', 'in so kweon']"
2110.10953,"mos: a low latency and lightweight framework for face detection,   landmark localization, and head pose estimation",cs.cv cs.ai,"with the emergence of service robots and surveillance cameras, dynamic face recognition (dfr) in wild has received much attention in recent years. face detection and head pose estimation are two important steps for dfr. very often, the pose is estimated after the face detection. however, such sequential computations lead to higher latency. in this paper, we propose a low latency and lightweight network for simultaneous face detection, landmark localization and head pose estimation. inspired by the observation that it is more challenging to locate the facial landmarks for faces with large angles, a pose loss is proposed to constrain the learning. moreover, we also propose an uncertainty multi-task loss to learn the weights of individual tasks automatically. another challenge is that robots often use low computational units like arm based computing core and we often need to use lightweight networks instead of the heavy ones, which lead to performance drop especially for small and hard faces. in this paper, we propose online feedback sampling to augment the training samples across different scales, which increases the diversity of training data automatically. through validation in commonly used wider face, aflw and aflw2000 datasets, the results show that the proposed method achieves the state-of-the-art performance in low computational resources. the code and data will be available at https://github.com/lyp-deeplearning/mos-multi-task-face-detect.",,2021-10-21,2021-11-01,"['yepeng liu', 'zaiwang gu', 'shenghua gao', 'dong wang', 'yusheng zeng', 'jun cheng']"
2110.11482,aware adoption of artificial intelligence and big data: a value   framework for reusable knowledge,cs.ai,"artificial intelligence (ai) provides practical advantages in different applied domains. this is changing the way decision-makers reason about complex systems. indeed, broader visibility on greater information (re)sources, e.g. big data (bd), is now available to intelligent agents. on the other hand, such decisions are not always based on reusable, multi-purpose, and explainable knowledge. therefore, it is necessary to define new models to describe and manage this new (re)source of uncertainty.   this contribution aims to introduce a formal framework to deal with the notion of value in the ai-bd context, embracing both the multiplicity of value dimensions and the uncertainty in their visibility as the foundations for a dynamic, relational representation of value. the framework design is based on abstract and highly scalable definitions to represent value, even considering the interaction of different agents through comparison, combination, and update of states of knowledge. in such a model, both big data and different types of intelligence are considered as resources. the information extracted from data becomes a renewable resource if it can be transformed into knowledge, which is reusable beyond a specific scenario and, dynamically, over time.   the focus on reusable knowledge is exploited in the relation between human and artificial intelligences, which is characterised by a ""non-classical"" form of uncertainty related to data observability. finally, we identify applicative domains for future investigation, in order to address the impact of the dynamic behaviour of value dimensions on strategies and decision-making, enhancing the adaptability and, hence, the sustainability of ai-bd initiatives over time.",,2021-10-21,2021-11-11,"['mario angelelli', 'massimiliano gervasi']"
2110.11945,soft: softmax-free transformer with linear complexity,cs.cv cs.ai cs.lg,"vision transformers (vits) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. however, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. various attempts on approximating the self-attention computation with linear complexity have been made in natural language processing. however, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. we further identify that their limitations are rooted in keeping the softmax self-attention during approximations. specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. keeping this softmax operation challenges any subsequent linearization efforts. based on this insight, for the first time, a softmax-free transformer or soft is proposed. to remove softmax in self-attention, gaussian kernel function is used to replace the dot-product similarity without further normalization. this enables a full self-attention matrix to be approximated via a low-rank matrix decomposition. the robustness of the approximation is achieved by calculating its moore-penrose inverse using a newton-raphson method. extensive experiments on imagenet show that our soft significantly improves the computational efficiency of existing vit variants. crucially, with a linear complexity, much longer token sequences are permitted in soft, resulting in superior trade-off between accuracy and complexity.",,2021-10-22,2021-10-29,"['jiachen lu', 'jinghan yao', 'junge zhang', 'xiatian zhu', 'hang xu', 'weiguo gao', 'chunjing xu', 'tao xiang', 'li zhang']"
2110.12108,conformallayers: a non-linear sequential neural network with associative   layers,cs.lg cs.ai cs.cv,"convolutional neural networks (cnns) have been widely applied. but as the cnns grow, the number of arithmetic operations and memory footprint also increase. furthermore, typical non-linear activation functions do not allow associativity of the operations encoded by consecutive layers, preventing the simplification of intermediate steps by combining them. we present a new activation function that allows associativity between sequential layers of cnns. even though our activation function is non-linear, it can be represented by a sequence of linear operations in the conformal model for euclidean geometry. in this domain, operations like, but not limited to, convolution, average pooling, and dropout remain linear. we take advantage of associativity to combine all the ""conformal layers"" and make the cost of inference constant regardless of the depth of the network.",,2021-10-22,2021-11-09,"['eduardo vera sousa', 'leandro a. f. fernandes', 'cristina nader vasconcelos']"
2110.12541,partially intervenable causal models,stat.me cs.ai math.st stat.th,"graphical causal models led to the development of complete non-parametric identification theory in arbitrary structured systems, and general approaches to efficient inference. nevertheless, graphical approaches to causal inference have not been embraced by the statistics and public health communities. in those communities causal assumptions are instead expressed in terms of potential outcomes, or responses to hypothetical interventions. such interventions are generally conceptualized only on a limited set of variables, where the corresponding experiment could, in principle, be performed. by contrast, graphical approaches to causal inference generally assume interventions on all variables are well defined - an overly restrictive and unrealistic assumption that may have limited the adoption of these approaches in applied work in statistics and public health. in this paper, we build on a unification of graphical and potential outcomes approaches to causality exemplified by single world intervention graphs (swigs) to define graphical models with a restricted set of allowed interventions. we give a complete identification theory for such models, and develop a complete calculus of interventions based on a generalization of the do-calculus, and axioms that govern probabilistic operations on markov kernels. a corollary of our results is a complete identification theory for causal effects in another graphical framework with a restricted set of interventions, the decision theoretic graphical formulation of causality.",,2021-10-24,2021-10-30,"['amiremad ghassami', 'ilya shpitser']"
2110.12662,sampling-based robust control of autonomous systems with non-gaussian   noise,eess.sy cs.ai cs.ro cs.sy,"controllers for autonomous systems that operate in safety-critical settings must account for stochastic disturbances. such disturbances are often modelled as process noise, and common assumptions are that the underlying distributions are known and/or gaussian. in practice, however, these assumptions may be unrealistic and can lead to poor approximations of the true noise distribution. we present a novel planning method that does not rely on any explicit representation of the noise distributions. in particular, we address the problem of computing a controller that provides probabilistic guarantees on safely reaching a target. first, we abstract the continuous system into a discrete-state model that captures noise by probabilistic transitions between states. as a key contribution, we adapt tools from the scenario approach to compute probably approximately correct (pac) bounds on these transition probabilities, based on a finite number of samples of the noise. we capture these bounds in the transition probability intervals of a so-called interval markov decision process (imdp). this imdp is robust against uncertainty in the transition probabilities, and the tightness of the probability intervals can be controlled through the number of samples. we use state-of-the-art verification techniques to provide guarantees on the imdp, and compute a controller for which these guarantees carry over to the autonomous system. realistic benchmarks show the practical applicability of our method, even when the imdp has millions of states or transitions.",,2021-10-25,2021-11-13,"['thom s. badings', 'alessandro abate', 'nils jansen', 'david parker', 'hasan a. poonawala', 'marielle stoelinga']"
2110.13047,drug similarity and link prediction using graph embeddings on medical   knowledge graphs,cs.ir cs.ai,the paper utilizes the graph embeddings generated for entities of a large biomedical database to perform link prediction to capture various new relationships among different entities. a novel node similarity measure is proposed that utilizes the graph embeddings and link prediction scores to find similarity scores among various drugs which can be used by the medical experts to recommend alternative drugs to avoid side effects from original one. utilizing machine learning on knowledge graph for drug similarity and recommendation will be less costly and less time consuming with higher scalability as compared to traditional biomedical methods due to the dependency on costly medical equipment and experts of the latter ones.,,2021-10-22,2021-10-29,"['prakhar gurawa', 'matthias nickles']"
2110.13179,probabilistic hierarchical forecasting with deep poisson mixtures,cs.lg cs.ai,"hierarchical forecasting problems arise when time series compose a group structure that naturally defines aggregation and disaggregation coherence constraints for the predictions. in this work, we explore a new forecast representation, the poisson mixture mesh (pmm), that can produce probabilistic, coherent predictions; it is compatible with the neural forecasting innovations, and defines simple aggregation and disaggregation rules capable of accommodating hierarchical structures, unknown during its optimization. we performed an empirical evaluation to compare the pmm to other hierarchical forecasting methods on australian domestic tourism data, where we obtain a 20 percent relative improvement.",,2021-10-25,2021-10-29,"['kin g. olivares', 'nganba meetei', 'ruijun ma', 'rohan reddy', 'mengfei cao']"
2110.13188,multi-task meta-learning modification with stochastic approximation,cs.lg cs.ai cs.cv,"meta-learning methods aim to build learning algorithms capable of quickly adapting to new tasks in low-data regime. one of the main benchmarks of such an algorithms is a few-shot learning problem. in this paper we investigate the modification of standard meta-learning pipeline that takes a multi-task approach during training. the proposed method simultaneously utilizes information from several meta-training tasks in a common loss function. the impact of each of these tasks in the loss function is controlled by the corresponding weight. proper optimization of these weights can have a big influence on training of the entire model and might improve the quality on test time tasks. in this work we propose and investigate the use of methods from the family of simultaneous perturbation stochastic approximation (spsa) approaches for meta-train tasks weights optimization. we have also compared the proposed algorithms with gradient-based methods and found that stochastic approximation demonstrates the largest quality boost in test time. proposed multi-task modification can be applied to almost all methods that use meta-learning pipeline. in this paper we study applications of this modification on prototypical networks and model-agnostic meta-learning algorithms on cifar-fs, fc100, tieredimagenet and miniimagenet few-shot learning benchmarks. during these experiments, multi-task modification has demonstrated improvement over original methods. the proposed spsa-tracking algorithm shows the largest accuracy boost that is competitive against the state-of-the-art meta-learning methods. our code is available online.",,2021-10-25,2021-11-05,"['andrei boiarov', 'konstantin khabarlak', 'igor yastrebov']"
2110.13214,iconqa: a new benchmark for abstract diagram understanding and visual   language reasoning,cs.cv cs.ai cs.cl cs.lg,"current visual question answering (vqa) tasks mainly consider answering human-annotated questions for natural images. however, aside from natural images, abstract diagrams with semantic richness are still understudied in visual understanding and reasoning research. in this work, we introduce a new challenge of icon question answering (iconqa) with the goal of answering a question in an icon image context. we release iconqa, a large-scale dataset that consists of 107,439 questions and three sub-tasks: multi-image-choice, multi-text-choice, and filling-in-the-blank. the iconqa dataset is inspired by real-world diagram word problems that highlight the importance of abstract diagram understanding and comprehensive cognitive reasoning. thus, iconqa requires not only perception skills like object recognition and text understanding, but also diverse cognitive reasoning skills, such as geometric reasoning, commonsense reasoning, and arithmetic reasoning. to facilitate potential iconqa models to learn semantic representations for icon images, we further release an icon dataset icon645 which contains 645,687 colored icons on 377 classes. we conduct extensive user studies and blind experiments and reproduce a wide range of advanced vqa methods to benchmark the iconqa task. also, we develop a strong iconqa baseline patch-trm that applies a pyramid cross-modal transformer with input diagram embeddings pre-trained on the icon dataset. iconqa and icon645 are available at https://iconqa.github.io.",,2021-10-25,2021-11-06,"['pan lu', 'liang qiu', 'jiaqi chen', 'tony xia', 'yizhou zhao', 'wei zhang', 'zhou yu', 'xiaodan liang', 'song-chun zhu']"
2110.13621,model-based reinforcement learning for service mesh fault resiliency in   a web application-level,cs.dc cs.ai cs.lg cs.ni,"microservice-based architectures enable different aspects of web applications to be created and updated independently, even after deployment. associated technologies such as service mesh provide application-level fault resilience through attribute configurations that govern the behavior of request-response service -- and the interactions among them -- in the presence of failures. while this provides tremendous flexibility, the configured values of these attributes -- and the relationships among them -- can significantly affect the performance and fault resilience of the overall application. furthermore, it is impossible to determine the best and worst combinations of attribute values with respect to fault resiliency via testing, due to the complexities of the underlying distributed system and the many possible attribute value combinations. in this paper, we present a model-based reinforcement learning workflow towards service mesh fault resiliency. our approach enables the prediction of the most significant fault resilience behaviors at a web application-level, scratching from single service to aggregated multi-service management with efficient agent collaborations.",,2021-10-21,,"['fanfei meng', 'lalita jagadeesan', 'marina thottan']"
2110.13957,unbiased graph embedding with biased graph observations,cs.lg cs.ai,"graph embedding techniques have been increasingly employed in real-world machine learning tasks on graph-structured data, such as social recommendations and protein structure modeling. since the generation of a graph is inevitably affected by some sensitive node attributes (such as gender and age of users in a social network), the learned graph representations can inherit such sensitive information and introduce undesirable biases in downstream tasks. most existing works on debiasing graph representations add ad-hoc constraints on the learned embeddings to restrict their distributions, which however compromise the utility of resulting graph representations in downstream tasks.   in this paper, we propose a principled new way for obtaining unbiased representations by learning from an underlying bias-free graph that is not influenced by sensitive attributes. based on this new perspective, we propose two complementary methods for uncovering such an underlying graph with the goal of introducing minimum impact on the utility of learned representations in downstream tasks. both our theoretical justification and extensive experiment comparisons against state-of-the-art solutions demonstrate the effectiveness of our proposed methods.",,2021-10-26,2021-10-29,"['nan wang', 'lu lin', 'jundong li', 'hongning wang']"
2110.14000,towards hyperparameter-free policy selection for offline reinforcement   learning,cs.lg cs.ai stat.ml,"how to select between policies and value functions produced by different training algorithms in offline reinforcement learning (rl) -- which is crucial for hyperpa-rameter tuning -- is an important open question. existing approaches based on off-policy evaluation (ope) often require additional function approximation and hence hyperparameters, creating a chicken-and-egg situation. in this paper, we design hyperparameter-free algorithms for policy selection based on bvft [xj21], a recent theoretical advance in value-function selection, and demonstrate their effectiveness in discrete-action benchmarks such as atari. to address performance degradation due to poor critics in continuous-action domains, we further combine bvft with ope to get the best of both worlds, and obtain a hyperparameter-tuning method for q-function based ope with theoretical guarantees as a side product.",,2021-10-26,2021-11-02,"['siyuan zhang', 'nan jiang']"
2110.14270,counterfactual shapley additive explanations,cs.lg cs.ai,"feature attributions are a common paradigm for model explanations due to their simplicity in assigning a single numeric score for each input feature to a model. in the actionable recourse setting, wherein the goal of the explanations is to improve outcomes for model consumers, it is often unclear how feature attributions should be correctly used. with this work, we aim to strengthen and clarify the link between actionable recourse and feature attributions. concretely, we propose a variant of shap, coshap, that uses counterfactual generation techniques to produce a background dataset for use within the marginal (a.k.a. interventional) shapley value framework. we motivate the need within the actionable recourse setting for careful consideration of background datasets when using shapley values for feature attributions, alongside the requirement for monotonicity, with numerous synthetic examples. moreover, we demonstrate the efficacy of coshap by proposing and justifying a quantitative score for feature attributions, counterfactual-ability, showing that as measured by this metric, coshap is superior to existing methods when evaluated on public datasets using monotone tree ensembles.",,2021-10-27,2021-11-02,"['emanuele albini', 'jason long', 'danial dervovic', 'daniele magazzeni']"
2110.14432,iterative teaching by label synthesis,cs.lg cs.ai cs.cv,"in this paper, we consider the problem of iterative machine teaching, where a teacher provides examples sequentially based on the current iterative learner. in contrast to previous methods that have to scan over the entire pool and select teaching examples from it in each iteration, we propose a label synthesis teaching framework where the teacher randomly selects input teaching examples (e.g., images) and then synthesizes suitable outputs (e.g., labels) for them. we show that this framework can avoid costly example selection while still provably achieving exponential teachability. we propose multiple novel teaching algorithms in this framework. finally, we empirically demonstrate the value of our framework.",,2021-10-27,2021-11-09,"['weiyang liu', 'zhen liu', 'hanchen wang', 'liam paull', 'bernhard schölkopf', 'adrian weller']"
2110.14461,hand gesture detection in tests performed by older adults,cs.cv cs.ai,"our team are developing a new online test that analyses hand movement features associated with ageing that can be completed remotely from the research centre. to obtain hand movement features, participants will be asked to perform a variety of hand gestures using their own computer cameras. however, it is challenging to collect high quality hand movement video data, especially for older participants, many of whom have no it background. during the data collection process, one of the key steps is to detect whether the participants are following the test instructions correctly and also to detect similar gestures from different devices. furthermore, we need this process to be automated and accurate as we expect many thousands of participants to complete the test. we have implemented a hand gesture detector to detect the gestures in the hand movement tests and our detection map is 0.782 which is better than the state-of-the-art. in this research, we have processed 20,000 images collected from hand movement tests and labelled 6,450 images to detect different hand gestures in the hand movement tests. this paper has the following three contributions. firstly, we compared and analysed the performance of different network structures for hand gesture detection. secondly, we have made many attempts to improve the accuracy of the model and have succeeded in improving the classification accuracy for similar gestures by implementing attention layers. thirdly, we have created two datasets and included 20 percent of blurred images in the dataset to investigate how different network structures were impacted by noisy data, our experiments have also shown our network has better performance on the noisy dataset.",,2021-10-27,2021-10-28,"['guan huang', 'son n. tran', 'quan bai', 'jane alty']"
2110.14711,a survey of self-supervised and few-shot object detection,cs.cv cs.ai cs.lg,"labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. while few-shot object detection is about training a model on novel (unseen) object classes with little data, it still requires prior training on many labeled examples of base (seen) classes. on the other hand, self-supervised methods aim at learning representations from unlabeled data which transfer well to downstream tasks such as object detection. combining few-shot and self-supervised object detection is a promising research direction. in this survey, we review and characterize the most recent approaches on few-shot and self-supervised object detection. then, we give our main takeaways and discuss future research directions. project page at https://gabrielhuang.github.io/fsod-survey/",,2021-10-27,2021-11-08,"['gabriel huang', 'issam laradji', 'david vazquez', 'simon lacoste-julien', 'pau rodriguez']"
2110.14771,abides-gym: gym environments for multi-agent discrete event simulation   and application to financial markets,cs.ma cs.ai q-fin.tr,"model-free reinforcement learning (rl) requires the ability to sample trajectories by taking actions in the original problem environment or a simulated version of it. breakthroughs in the field of rl have been largely facilitated by the development of dedicated open source simulators with easy to use frameworks such as openai gym and its atari environments. in this paper we propose to use the openai gym framework on discrete event time based discrete event multi-agent simulation (demas). we introduce a general technique to wrap a demas simulator into the gym framework. we expose the technique in detail and implement it using the simulator abides as a base. we apply this work by specifically using the markets extension of abides, abides-markets, and develop two benchmark financial markets openai gym environments for training daily investor and execution agents. as a result, these two environments describe classic financial problems with a complex interactive market behavior response to the experimental agent's action.",10.1145/3490354.3494433,2021-10-27,,"['selim amrouni', 'aymeric moulin', 'jared vann', 'svitlana vyetrenko', 'tucker balch', 'manuela veloso']"
2110.14775,bi-gcn: boundary-aware input-dependent graph convolution network for   biomedical image segmentation,cs.cv cs.ai,"segmentation is an essential operation of image processing. the convolution operation suffers from a limited receptive field, while global modelling is fundamental to segmentation tasks. in this paper, we apply graph convolution into the segmentation task and propose an improved \textit{laplacian}. different from existing methods, our \textit{laplacian} is data-dependent, and we introduce two attention diagonal matrices to learn a better vertex relationship. in addition, it takes advantage of both region and boundary information when performing graph-based information propagation. specifically, we model and reason about the boundary-aware region-wise correlations of different classes through learning graph representations, which is capable of manipulating long range semantic reasoning across various regions with the spatial enhancement along the object's boundary. our model is well-suited to obtain global semantic region information while also accommodates local spatial boundary characteristics simultaneously. experiments on two types of challenging datasets demonstrate that our method outperforms the state-of-the-art approaches on the segmentation of polyps in colonoscopy images and of the optic disc and optic cup in colour fundus images.",,2021-10-27,2021-10-31,"['yanda meng', 'hongrun zhang', 'dongxu gao', 'yitian zhao', 'xiaoyun yang', 'xuesheng qian', 'xiaowei huang', 'yalin zheng']"
2110.14870,a scenario-based platform for testing autonomous vehicle behavior   prediction models in simulation,cs.ai,"behavior prediction remains one of the most challenging tasks in the autonomous vehicle (av) software stack. forecasting the future trajectories of nearby agents plays a critical role in ensuring road safety, as it equips avs with the necessary information to plan safe routes of travel. however, these prediction models are data-driven and trained on data collected in real life that may not represent the full range of scenarios an av can encounter. hence, it is important that these prediction models are extensively tested in various test scenarios involving interactive behaviors prior to deployment. to support this need, we present a simulation-based testing platform which supports (1) intuitive scenario modeling with a probabilistic programming language called scenic, (2) specifying a multi-objective evaluation metric with a partial priority ordering, (3) falsification of the provided metric, and (4) parallelization of simulations for scalable testing. as a part of the platform, we provide a library of 25 scenic programs that model challenging test scenarios involving interactive traffic participant behaviors. we demonstrate the effectiveness and the scalability of our platform by testing a trained behavior prediction model and searching for failure scenarios.",,2021-10-27,2021-11-13,"['francis indaheng', 'edward kim', 'kesav viswanadha', 'jay shenoy', 'jinkyu kim', 'daniel j. fremont', 'sanjit a. seshia']"
2110.14880,aeva: black-box backdoor detection using adversarial extreme value   analysis,cs.lg cs.ai,"deep neural networks (dnns) are proved to be vulnerable against backdoor attacks. a backdoor is often embedded in the target dnns through injecting a backdoor trigger into training examples, which can cause the target dnns misclassify an input attached with the backdoor trigger. existing backdoor detection methods often require the access to the original poisoned training data, the parameters of the target dnns, or the predictive confidence for each given input, which are impractical in many real-world applications, e.g., on-device deployed dnns. we address the black-box hard-label backdoor detection problem where the dnn is fully black-box and only its final output label is accessible. we approach this problem from the optimization perspective and show that the objective of backdoor detection is bounded by an adversarial objective. further theoretical and empirical studies reveal that this adversarial objective leads to a solution with highly skewed distribution; a singularity is often observed in the adversarial map of a backdoor-infected example, which we call the adversarial singularity phenomenon. based on this observation, we propose the adversarial extreme value analysis(aeva) to detect backdoors in black-box neural networks. aeva is based on an extreme value analysis of the adversarial map, computed from the monte-carlo gradient estimation. evidenced by extensive experiments across multiple popular tasks and backdoor attacks, our approach is shown effective in detecting backdoor attacks under the black-box hard-label scenarios.",,2021-10-28,2021-10-29,"['junfeng guo', 'ang li', 'cong liu']"
2110.14890,smore: knowledge graph completion and multi-hop reasoning in massive   knowledge graphs,cs.lg cs.ai cs.db cs.dc,"knowledge graphs (kgs) capture knowledge in the form of head--relation--tail triples and are a crucial component in many ai systems. there are two important reasoning tasks on kgs: (1) single-hop knowledge graph completion, which involves predicting individual links in the kg; and (2), multi-hop reasoning, where the goal is to predict which kg entities satisfy a given logical query. embedding-based methods solve both tasks by first computing an embedding for each entity and relation, then using them to form predictions. however, existing scalable kg embedding frameworks only support single-hop knowledge graph completion and cannot be applied to the more challenging multi-hop reasoning task. here we present scalable multi-hop reasoning (smore), the first general framework for both single-hop and multi-hop reasoning in kgs. using a single machine smore can perform multi-hop reasoning in freebase kg (86m entities, 338m edges), which is 1,500x larger than previously considered kgs. the key to smore's runtime performance is a novel bidirectional rejection sampling that achieves a square root reduction of the complexity of online training data generation. furthermore, smore exploits asynchronous scheduling, overlapping cpu-based data sampling, gpu-based embedding computation, and frequent cpu--gpu io. smore increases throughput (i.e., training speed) over prior multi-hop kg frameworks by 2.2x with minimal gpu memory requirements (2gb for training 400-dim embeddings on 86m-node freebase) and achieves near linear speed-up with the number of gpus. moreover, on the simpler single-hop knowledge graph completion task smore achieves comparable or even better runtime performance to state-of-the-art frameworks on both single gpu and multi-gpu settings.",,2021-10-28,2021-11-01,"['hongyu ren', 'hanjun dai', 'bo dai', 'xinyun chen', 'denny zhou', 'jure leskovec', 'dale schuurmans']"
2110.15032,oneflow: redesign the distributed deep learning framework from scratch,cs.dc cs.ai cs.lg,"deep learning frameworks such as tensorflow and pytorch provide a productive interface for expressing and training a deep neural network (dnn) model on a single device or using data parallelism. still, they may not be flexible or efficient enough in training emerging large models on distributed devices, which require more sophisticated parallelism beyond data parallelism. plugins or wrappers have been developed to strengthen these frameworks for model or pipeline parallelism, but they complicate the usage and implementation of distributed deep learning. aiming at a simple, neat redesign of distributed deep learning frameworks for various parallelism paradigms, we present oneflow, a novel distributed training framework based on an sbp (split, broadcast and partial-value) abstraction and the actor model. sbp enables much easier programming of data parallelism and model parallelism than existing frameworks, and the actor model provides a succinct runtime mechanism to manage the complex dependencies imposed by resource constraints, data movement and computation in distributed deep learning. we demonstrate the general applicability and efficiency of oneflow for training various large dnn models with case studies and extensive experiments. the results show that oneflow outperforms many well-known customized libraries built on top of the state-of-the-art frameworks. the code of oneflow is available at: https://github.com/oneflow-inc/oneflow.",,2021-10-28,2021-10-28,"['jinhui yuan', 'xinqi li', 'cheng cheng', 'juncheng liu', 'ran guo', 'shenghang cai', 'chi yao', 'fei yang', 'xiaodong yi', 'chuan wu', 'haoran zhang', 'jie zhao']"
2110.15089,d2rlir : an improved and diversified ranking function in interactive   recommendation systems based on deep reinforcement learning,cs.ir cs.ai,"recently, interactive recommendation systems based on reinforcement learning have been attended by researchers due to the consider recommendation procedure as a dynamic process and update the recommendation model based on immediate user feedback, which is neglected in traditional methods. the existing works have two significant drawbacks. firstly, inefficient ranking function to produce the top-n recommendation list. secondly, focusing on recommendation accuracy and inattention to other evaluation metrics such as diversity. this paper proposes a deep reinforcement learning based recommendation system by utilizing actor-critic architecture to model dynamic users' interaction with the recommender agent and maximize the expected long-term reward. furthermore, we propose utilizing spotify's annoy algorithm to find the most similar items to generated action by actor-network. after that, the total diversity effect ranking algorithm is used to generate the recommendations concerning relevancy and diversity. moreover, we apply positional encoding to compute representations of the user's interaction sequence without using sequence-aligned recurrent neural networks. extensive experiments on the movielens dataset demonstrate that our proposed model is able to generate a diverse while relevance recommendation list based on the user's preferences.",,2021-10-28,2021-10-28,"['vahid baghi', 'seyed mohammad seyed motehayeri', 'ali moeini', 'rooholah abedian']"
2110.15122,cafe: catastrophic data leakage in vertical federated learning,cs.lg cs.ai,"recent studies show that private training data can be leaked through the gradients sharing mechanism deployed in distributed machine learning systems, such as federated learning (fl). increasing batch size to complicate data recovery is often viewed as a promising defense strategy against data leakage. in this paper, we revisit this defense premise and propose an advanced data leakage attack with theoretical justification to efficiently recover batch data from the shared aggregated gradients. we name our proposed method as catastrophic data leakage in vertical federated learning (cafe). comparing to existing data leakage attacks, our extensive experimental results on vertical fl settings demonstrate the effectiveness of cafe to perform large-batch data leakage attack with improved data recovery quality. we also propose a practical countermeasure to mitigate cafe. our results suggest that private data participated in standard fl, especially the vertical case, have a high risk of being leaked from the training gradients. our analysis implies unprecedented and practical data leakage risks in those learning settings. the code of our work is available at https://github.com/derafael/cafe.",,2021-10-26,2021-11-02,"['xiao jin', 'pin-yu chen', 'chia-yi hsu', 'chia-mu yu', 'tianyi chen']"
2110.15192,rgp: neural network pruning through its regular graph structure,cs.lg cs.ai,"lightweight model design has become an important direction in the application of deep learning technology, pruning is an effective mean to achieve a large reduction in model parameters and flops. the existing neural network pruning methods mostly start from the importance of parameters, and design parameter evaluation metrics to perform parameter pruning iteratively. these methods are not studied from the perspective of model topology, may be effective but not efficient, and requires completely different pruning for different datasets. in this paper, we study the graph structure of the neural network, and propose regular graph based pruning (rgp) to perform a one-shot neural network pruning. we generate a regular graph, set the node degree value of the graph to meet the pruning ratio, and reduce the average shortest path length of the graph by swapping the edges to obtain the optimal edge distribution. finally, the obtained graph is mapped into a neural network structure to realize pruning. experiments show that the average shortest path length of the graph is negatively correlated with the classification accuracy of the corresponding neural network, and the proposed rgp shows a strong precision retention capability with extremely high parameter reduction (more than 90%) and flops reduction (more than 90%).",,2021-10-28,2021-11-18,"['zhuangzhi chen', 'jingyang xiang', 'yao lu', 'qi xuan', 'xiaoniu yang']"
2110.15344,learning to jump from pixels,cs.ro cs.ai,"today's robotic quadruped systems can robustly walk over a diverse range of rough but continuous terrains, where the terrain elevation varies gradually. locomotion on discontinuous terrains, such as those with gaps or obstacles, presents a complementary set of challenges. in discontinuous settings, it becomes necessary to plan ahead using visual inputs and to execute agile behaviors beyond robust walking, such as jumps. such dynamic motion results in significant motion of onboard sensors, which introduces a new set of challenges for real-time visual processing. the requirement for agility and terrain awareness in this setting reinforces the need for robust control. we present depth-based impulse control (dic), a method for synthesizing highly agile visually-guided locomotion behaviors. dic affords the flexibility of model-free learning but regularizes behavior through explicit model-based optimization of ground reaction forces. we evaluate the proposed method both in simulation and in the real world.",,2021-10-28,,"['gabriel b. margolis', 'tao chen', 'kartik paigwar', 'xiang fu', 'donghyun kim', 'sangbae kim', 'pulkit agrawal']"
2110.15385,data-driven residual generation for early fault detection with limited   data,eess.sy cs.ai cs.sy,"traditionally, fault detection and isolation community has used system dynamic equations to generate diagnosers and to analyze detectability and isolability of the dynamic systems. model-based fault detection and isolation methods use system model to generate a set of residuals as the bases for fault detection and isolation. however, in many complex systems it is not feasible to develop highly accurate models for the systems and to keep the models updated during the system lifetime. recently, data-driven solutions have received an immense attention in the industries systems for several practical reasons. first, these methods do not require the initial investment and expertise for developing accurate models. moreover, it is possible to automatically update and retrain the diagnosers as the system or the environment change over time. finally, unlike the model-based methods it is straight forward to combine time series measurements such as pressure and voltage with other sources of information such as system operating hours to achieve a higher accuracy. in this paper, we extend the traditional model-based fault detection and isolation concepts such as residuals, and detectable and isolable faults to the data-driven domain. we then propose an algorithm to automatically generate residuals from the normal operating data. we present the performance of our proposed approach through a comparative case study.",,2021-09-27,,"['hamed khorasgani', 'ahmed farahat', 'chetan gupta']"
2110.15387,anticipation-driven adaptive architecture for assisted living,cs.hc cs.ai,"anticipatory expression underlies human performance. medical conditions and, especially, aging result in diminished anticipatory action. in order to mitigate the loss, means for engaging still available resources (capabilities) can be provided. in particular, anticipation-driven adaptive environments could be beneficial in medical care, as well as in assisted living for those seeking such assistance. these adaptive environments are conceived to be individualized and individualizable, in order to stimulate independent action instead of creating dependencies.",,2021-10-15,,"['mihai nadin', 'asma naz']"
2110.15409,what makes us curious? analysis of a corpus of open-domain questions,cs.cl cs.ai cs.lg,"every day people ask short questions through smart devices or online forums to seek answers to all kinds of queries. with the increasing number of questions collected it becomes difficult to provide answers to each of them, which is one of the reasons behind the growing interest in automated question answering. some questions are similar to existing ones that have already been answered, while others could be answered by an external knowledge source such as wikipedia. an important question is what can be revealed by analysing a large set of questions. in 2017, ""we the curious"" science centre in bristol started a project to capture the curiosity of bristolians: the project collected more than 10,000 questions on various topics. as no rules were given during collection, the questions are truly open-domain, and ranged across a variety of topics. one important aim for the science centre was to understand what concerns its visitors had beyond science, particularly on societal and cultural issues. we addressed this question by developing an artificial intelligence tool that can be used to perform various processing tasks: detection of equivalence between questions; detection of topic and type; and answering of the question. as we focused on the creation of a ""generalist"" tool, we trained it with labelled data from different datasets. we called the resulting model qbert. this paper describes what information we extracted from the automated analysis of the wtc corpus of open-domain questions.",,2021-10-28,,"['zhaozhen xu', 'amelia howarth', 'nicole briggs', 'nello cristianini']"
2110.15415,on the use of csi for the generation of rf fingerprints and secret keys,cs.it cs.ai cs.cr math.it,"this paper presents a systematic approach to use channel state information for authentication and secret key distillation for physical layer security (pls). we use popular machine learning (ml) methods and signal processing-based approaches to disentangle the large scale fading and be used as a source of uniqueness, from the small scale fading, to be treated as a source of shared entropy secret key generation (skg). the ml-based approaches are completely unsupervised and hence avoid exhaustive measurement campaigns. we also propose using the hilbert schmidt independence criterion (hsic); our simulation results demonstrate that the extracted stochastic part of the channel state information (csi) vectors are statistically independent.",,2021-10-28,,"['muralikrishnan srinivasan', 'sotiris skaperas', 'arsenia chorti']"
2110.15431,universal decision models,cs.ai cs.lg,"humans are universal decision makers: we reason causally to understand the world; we act competitively to gain advantage in commerce, games, and war; and we are able to learn to make better decisions through trial and error. in this paper, we propose universal decision model (udm), a mathematical formalism based on category theory. decision objects in a udm correspond to instances of decision tasks, ranging from causal models and dynamical systems such as markov decision processes and predictive state representations, to network multiplayer games and witsenhausen's intrinsic models, which generalizes all these previous formalisms. a udm is a category of objects, which include decision objects, observation objects, and solution objects. bisimulation morphisms map between decision objects that capture structure-preserving abstractions. we formulate universal properties of udms, including information integration, decision solvability, and hierarchical abstraction. we describe universal functorial representations of udms, and propose an algorithm for computing the minimal object in a udm using algebraic topology. we sketch out an application of udms to causal inference in network economics, using a complex multiplayer producer-consumer two-sided marketplace.",,2021-10-28,,['sridhar mahadevan']
2110.15454,vigdet: knowledge informed neural temporal point process for   coordination detection on social media,cs.lg cs.ai cs.si,"recent years have witnessed an increasing use of coordinated accounts on social media, operated by misinformation campaigns to influence public opinion and manipulate social outcomes. consequently, there is an urgent need to develop an effective methodology for coordinated group detection to combat the misinformation on social media. however, existing works suffer from various drawbacks, such as, either limited performance due to extreme reliance on predefined signatures of coordination, or instead an inability to address the natural sparsity of account activities on social media with useful prior domain knowledge. therefore, in this paper, we propose a coordination detection framework incorporating neural temporal point process with prior knowledge such as temporal logic or pre-defined filtering functions. specifically, when modeling the observed data from social media with neural temporal point process, we jointly learn a gibbs-like distribution of group assignment based on how consistent an assignment is to (1) the account embedding space and (2) the prior knowledge. to address the challenge that the distribution is hard to be efficiently computed and sampled from, we design a theoretically guaranteed variational inference approach to learn a mean-field approximation for it. experimental results on a real-world dataset show the effectiveness of our proposed method compared to the sota model in both unsupervised and semi-supervised settings. we further apply our model on a covid-19 vaccine tweets dataset. the detection result suggests the presence of suspicious coordinated efforts on spreading misinformation about covid-19 vaccines.",,2021-10-28,,"['yizhou zhang', 'karishma sharma', 'yan liu']"
2110.15484,cycle-balanced representation learning for counterfactual inference,cs.lg cs.ai,"with the widespread accumulation of observational data, researchers obtain a new direction to learn counterfactual effects in many domains (e.g., health care and computational advertising) without randomized controlled trials(rcts). however, observational data suffer from inherent missing counterfactual outcomes, and distribution discrepancy between treatment and control groups due to behaviour preference. motivated by recent advances of representation learning in the field of domain adaptation, we propose a novel framework based on cycle-balanced representation learning for counterfactual inference (cbre), to solve above problems. specifically, we realize a robust balanced representation for different groups using adversarial training, and meanwhile construct an information loop, such that preserve original data properties cyclically, which reduces information loss when transforming data into latent representation space.experimental results on three real-world datasets demonstrate that cbre matches/outperforms the state-of-the-art methods, and it has a great potential to be applied to counterfactual inference.",,2021-10-28,,"['guanglin zhou', 'lina yao', 'xiwei xu', 'chen wang', 'liming zhu']"
2110.15489,galilai: out-of-task distribution detection using causal active   experimentation for safe transfer rl,cs.lg cs.ai,"out-of-distribution (ood) detection is a well-studied topic in supervised learning. extending the successes in supervised learning methods to the reinforcement learning (rl) setting, however, is difficult due to the data generating process - rl agents actively query their environment for data, and the data are a function of the policy followed by the agent. an agent could thus neglect a shift in the environment if its policy did not lead it to explore the aspect of the environment that shifted. therefore, to achieve safe and robust generalization in rl, there exists an unmet need for ood detection through active experimentation. here, we attempt to bridge this lacuna by first defining a causal framework for ood scenarios or environments encountered by rl agents in the wild. then, we propose a novel task: that of out-of-task distribution (ootd) detection. we introduce an rl agent that actively experiments in a test environment and subsequently concludes whether it is ootd or not. we name our method galilai, in honor of galileo galilei, as it discovers, among other causal processes, that gravitational acceleration is independent of the mass of a body. finally, we propose a simple probabilistic neural network baseline for comparison, which extends extant model-based rl. we find that galilai outperforms the baseline significantly. see visualizations of our method https://galil-ai.github.io/",,2021-10-28,,"['sumedh a sontakke', 'stephen iota', 'zizhao hu', 'arash mehrjou', 'laurent itti', 'bernhard schölkopf']"
2110.15525,pedenet: image anomaly localization via patch embedding and density   estimation,cs.cv cs.ai,"a neural network targeting at unsupervised image anomaly localization, called the pedenet, is proposed in this work. pedenet contains a patch embedding (pe) network, a density estimation (de) network, and an auxiliary network called the location prediction (lp) network. the pe network takes local image patches as input and performs dimension reduction to get low-dimensional patch embeddings via a deep encoder structure. being inspired by the gaussian mixture model (gmm), the de network takes those patch embeddings and then predicts the cluster membership of an embedded patch. the sum of membership probabilities is used as a loss term to guide the learning process. the lp network is a multi-layer perception (mlp), which takes embeddings from two neighboring patches as input and predicts their relative location. the performance of the proposed pedenet is evaluated extensively and benchmarked with that of state-of-the-art methods.",,2021-10-28,,"['kaitai zhang', 'bin wang', 'c. -c. jay kuo']"
2110.15527,pre-training co-evolutionary protein representation via a pairwise   masked language model,cs.cl cs.ai,"understanding protein sequences is vital and urgent for biology, healthcare, and medicine. labeling approaches are expensive yet time-consuming, while the amount of unlabeled data is increasing quite faster than that of the labeled data due to low-cost, high-throughput sequencing methods. in order to extract knowledge from these unlabeled data, representation learning is of significant value for protein-related tasks and has great potential for helping us learn more about protein functions and structures. the key problem in the protein sequence representation learning is to capture the co-evolutionary information reflected by the inter-residue co-variation in the sequences. instead of leveraging multiple sequence alignment as is usually done, we propose a novel method to capture this information directly by pre-training via a dedicated language model, i.e., pairwise masked language model (pmlm). in a conventional masked language model, the masked tokens are modeled by conditioning on the unmasked tokens only, but processed independently to each other. however, our proposed pmlm takes the dependency among masked tokens into consideration, i.e., the probability of a token pair is not equal to the product of the probability of the two tokens. by applying this model, the pre-trained encoder is able to generate a better representation for protein sequences. our result shows that the proposed method can effectively capture the inter-residue correlations and improves the performance of contact prediction by up to 9% compared to the mlm baseline under the same setting. the proposed model also significantly outperforms the msa baseline by more than 7% on the tape contact prediction benchmark when pre-trained on a subset of the sequence database which the msa is generated from, revealing the potential of the sequence pre-training method to surpass msa based methods in general.",,2021-10-29,,"['liang he', 'shizhuo zhang', 'lijun wu', 'huanhuan xia', 'fusong ju', 'he zhang', 'siyuan liu', 'yingce xia', 'jianwei zhu', 'pan deng', 'bin shao', 'tao qin', 'tie-yan liu']"
2110.15599,handshakes ai research at case 2021 task 1: exploring different   approaches for multilingual tasks,cs.cl cs.ai,"the aim of the case 2021 shared task 1 (h\""urriyeto\u{g}lu et al., 2021) was to detect and classify socio-political and crisis event information at document, sentence, cross-sentence, and token levels in a multilingual setting, with each of these subtasks being evaluated separately in each test language. our submission contained entries in all of the subtasks, and the scores obtained validated our research finding: that the multilingual aspect of the tasks should be embraced, so that modeling and training regimes use the multilingual nature of the tasks to their mutual benefit, rather than trying to tackle the different languages separately. our code is available at https://github.com/handshakesbydc/case2021/",,2021-10-29,,"['vivek kalyan', 'paul tan', 'shaun tan', 'martin andrews']"
2110.15622,path-enhanced multi-relational question answering with knowledge graph   embeddings,cs.cl cs.ai cs.lg,"the multi-relational knowledge base question answering (kbqa) system performs multi-hop reasoning over the knowledge graph (kg) to achieve the answer. recent approaches attempt to introduce the knowledge graph embedding (kge) technique to handle the kg incompleteness but only consider the triple facts and neglect the significant semantic correlation between paths and multi-relational questions. in this paper, we propose a path and knowledge embedding-enhanced multi-relational question answering model (pkeeqa), which leverages multi-hop paths between entities in the kg to evaluate the ambipolar correlation between a path embedding and a multi-relational question embedding via a customizable path representation mechanism, benefiting for achieving more accurate answers from the perspective of both the triple facts and the extra paths. experimental results illustrate that pkeeqa improves kbqa models' performance for multi-relational question answering with explainability to some extent derived from paths.",,2021-10-29,,"['guanglin niu', 'yang li', 'chengguang tang', 'zhongkai hu', 'shibin yang', 'peng li', 'chengyu wang', 'hao wang', 'jian sun']"
2110.15681,false positive detection and prediction quality estimation for lidar   point cloud segmentation,cs.cv cs.ai,"we present a novel post-processing tool for semantic segmentation of lidar point cloud data, called lidarmetaseg, which estimates the prediction quality segmentwise. for this purpose we compute dispersion measures based on network probability outputs as well as feature measures based on point cloud input features and aggregate them on segment level. these aggregated measures are used to train a meta classification model to predict whether a predicted segment is a false positive or not and a meta regression model to predict the segmentwise intersection over union. both models can then be applied to semantic segmentation inferences without knowing the ground truth. in our experiments we use different lidar segmentation models and datasets and analyze the power of our method. we show that our results outperform other standard approaches.",,2021-10-29,,"['pascal colling', 'matthias rottmann', 'lutz roese-koerner', 'hanno gottschalk']"
2110.15695,a protocol for emotions,cs.hc cs.ai cs.cy,"we tend to consider emotions a manifestation of our innermost nature of human beings. emotions characterize our lives in many ways and they chaperon every rational activity we carry out. despite their pervasiveness, there are still many things we ignore about emotions. among them, our understanding of how living beings transfer emotions is limited. in particular, there are highly sophisticated interactions between human beings that we would like to comprehend. for instance, think of a movie director who knows in advance the strong emotional impact that a certain scene will have on the spectators. although many artists rely on some emotional devices, their talent and vision are still the key factors.   in this work we analyze high-level protocols for transferring emotions between two intelligent agents. to the best of our knowledge, this is the first attempt to use communication protocols for modeling the exchange of human emotions. by means of a number of examples, we show that our protocols adequately model the engagement of the two parties. beyond the theoretical interest, our proposal can provide a stepping stone for several applications that we also discuss in this paper.",,2021-10-29,,['gabriele costa']
2110.15701,xi-learning: successor feature transfer learning for general reward   functions,cs.lg cs.ai,"transfer in reinforcement learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. successor features (sf) are a prominent transfer mechanism in domains where the reward function changes between tasks. they reevaluate the expected return of previously learned policies in a new target task and to transfer their knowledge. a limiting factor of the sf framework is its assumption that rewards linearly decompose into successor features and a reward weight vector. we propose a novel sf mechanism, $\xi$-learning, based on learning the cumulative discounted probability of successor features. crucially, $\xi$-learning allows to reevaluate the expected return of policies for general reward functions. we introduce two $\xi$-learning variations, prove its convergence, and provide a guarantee on its transfer performance. experimental evaluations based on $\xi$-learning with function approximation demonstrate the prominent advantage of $\xi$-learning over available mechanisms not only for general reward functions, but also in the case of linearly decomposable reward functions.",,2021-10-29,,"['chris reinke', 'xavier alameda-pineda']"
2110.15702,def-drel: systematic deployment of serverless functions in fog and cloud   environments using deep reinforcement learning,cs.dc cs.ai,"fog computing is introduced by shifting cloud resources towards the users' proximity to mitigate the limitations possessed by cloud computing. fog environment made its limited resource available to a large number of users to deploy their serverless applications, composed of several serverless functions. one of the primary intentions behind introducing the fog environment is to fulfil the demand of latency and location-sensitive serverless applications through its limited resources. the recent research mainly focuses on assigning maximum resources to such applications from the fog node and not taking full advantage of the cloud environment. this introduces a negative impact in providing the resources to a maximum number of connected users. to address this issue, in this paper, we investigated the optimum percentage of a user's request that should be fulfilled by fog and cloud. as a result, we proposed def-drel, a systematic deployment of serverless functions in fog and cloud environments using deep reinforcement learning, using several real-life parameters, such as distance and latency of the users from nearby fog node, user's priority, the priority of the serverless applications and their resource demand, etc. the performance of the def-drel algorithm is further compared with recent related algorithms. from the simulation and comparison results, its superiority over other algorithms and its applicability to the real-life scenario can be clearly observed.",,2021-10-29,2021-11-04,"['chinmaya kumar dehury', 'shivananda poojara', 'shridhar domanal', 'satish narayana srirama']"
2110.15706,integrating deep event-level and script-level information for script   event prediction,cs.cl cs.ai,"scripts are structured sequences of events together with the participants, which are extracted from the texts.script event prediction aims to predict the subsequent event given the historical events in the script. two kinds of information facilitate this task, namely, the event-level information and the script-level information. at the event level, existing studies view an event as a verb with its participants, while neglecting other useful properties, such as the state of the participants. at the script level, most existing studies only consider a single event sequence corresponding to one common protagonist. in this paper, we propose a transformer-based model, called mcpredictor, which integrates deep event-level and script-level information for script event prediction. at the event level, mcpredictor utilizes the rich information in the text to obtain more comprehensive event semantic representations. at the script-level, it considers multiple event sequences corresponding to different participants of the subsequent event. the experimental results on the widely-used new york times corpus demonstrate the effectiveness and superiority of the proposed model.",,2021-09-24,,"['long bai', 'saiping guan', 'jiafeng guo', 'zixuan li', 'xiaolong jin', 'xueqi cheng']"
2110.15718,deep convolutional forest: a dynamic deep ensemble approach for spam   detection in text,cs.cl cs.ai cs.lg,"the increase in people's use of mobile messaging services has led to the spread of social engineering attacks like phishing, considering that spam text is one of the main factors in the dissemination of phishing attacks to steal sensitive data such as credit cards and passwords. in addition, rumors and incorrect medical information regarding the covid-19 pandemic are widely shared on social media leading to people's fear and confusion. thus, filtering spam content is vital to reduce risks and threats. previous studies relied on machine learning and deep learning approaches for spam classification, but these approaches have two limitations. machine learning models require manual feature engineering, whereas deep neural networks require a high computational cost. this paper introduces a dynamic deep ensemble model for spam detection that adjusts its complexity and extracts features automatically. the proposed model utilizes convolutional and pooling layers for feature extraction along with base classifiers such as random forests and extremely randomized trees for classifying texts into spam or legitimate ones. moreover, the model employs ensemble learning procedures like boosting and bagging. as a result, the model achieved high precision, recall, f1-score and accuracy of 98.38%.",,2021-10-10,,"['mai a. shaaban', 'yasser f. hassan', 'shawkat k. guirguis']"
2110.15719,"generational frameshifts in technology: computer science and   neurosurgery, the vr use case",cs.hc cs.ai cs.cv cs.ne q-bio.ot,"we are at a unique moment in history where there is a confluence of technologies which will synergistically come together to transform the practice of neurosurgery. these technological transformations will be all-encompassing, including improved tools and methods for intraoperative performance of neurosurgery, scalable solutions for asynchronous neurosurgical training and simulation, as well as broad aggregation of operative data allowing fundamental changes in quality assessment, billing, outcome measures, and dissemination of surgical best practices. the ability to perform surgery more safely and more efficiently while capturing the operative details and parsing each component of the operation will open an entirely new epoch advancing our field and all surgical specialties. the digitization of all components within the operating room will allow us to leverage the various fields within computer and computational science to obtain new insights that will improve care and delivery of the highest quality neurosurgery regardless of location. the democratization of neurosurgery is at hand and will be driven by our development, extraction, and adoption of these tools of the modern world. virtual reality provides a good example of how consumer-facing technologies are finding a clear role in industry and medicine and serves as a notable example of the confluence of various computer science technologies creating a novel paradigm for scaling human ability and interactions. the authors describe the technology ecosystem that has come and highlight a myriad of computational and data sciences that will be necessary to enable the operating room of the near future.",,2021-10-08,2021-10-31,"['samuel r. browd', 'maya sharma', 'chetan sharma']"
2110.15720,weakly supervised concept map generation through task-guided graph   translation,cs.cl cs.ai,"recent years have witnessed the rapid development of concept map generation techniques due to their advantages in providing well-structured summarization of knowledge from free texts. traditional unsupervised methods do not generate task-oriented concept maps, whereas deep generative models require large amounts of training data. in this work, we present gt-d2g (graph translation based document-to-graph), an automatic concept map generation framework that leverages generalized nlp pipelines to derive semantic-rich initial graphs, and translates them into more concise structures under the weak supervision of document labels. the quality and interpretability of such concept maps are validated through human evaluation on three real-world corpora, and their utility in the downstream task is further demonstrated in the controlled experiments with scarce document labels.",,2021-10-08,2021-11-01,"['jiaying lu', 'xiangjue dong', 'carl yang']"
2110.15721,paperswithtopic: topic identification from paper title only,cs.cl cs.ai,"the deep learning field is growing rapidly as witnessed by the exponential growth of papers submitted to journals, conferences, and pre-print servers. to cope with the sheer number of papers, several text mining tools from natural language processing (nlp) have been proposed that enable researchers to keep track of recent findings. in this context, our paper makes two main contributions: first, we collected and annotated a dataset of papers paired by title and sub-field from the field of artificial intelligence (ai), and, second, we present results on how to predict a paper's ai sub-field from a given paper title only. importantly, for the latter, short-text classification task we compare several algorithms from conventional machine learning all the way up to recent, larger transformer architectures. finally, for the transformer models, we also present gradient-based, attention visualizations to further explain the model's classification process. all code can be found at \url{https://github.com/1pha/paperswithtopic}",,2021-10-09,,"['daehyun cho', 'christian wallraven']"
2110.15722,a novel sequence tagging framework for consumer event-cause extraction,cs.cl cs.ai,"consumer event-cause extraction, the task aimed at extracting the potential causes behind certain events in the text, has gained much attention in recent years due to its wide applications. the icdm 2020 conference sets up an evaluation competition that aims to extract events and the causes of the extracted events with a specified subject (a brand or product). in this task, we mainly focus on how to construct an end-to-end model, and extract multiple event types and event-causes simultaneously. to this end, we introduce a fresh perspective to revisit the relational event-cause extraction task and propose a novel sequence tagging framework, instead of extracting event types and events-causes separately. experiments show our framework outperforms baseline methods even when its encoder module uses an initialized pre-trained bert encoder, showing the power of the new tagging framework. in this competition, our team achieved 1st place in the first stage leaderboard, and 3rd place in the final stage leaderboard.",,2021-10-28,,"['congqing he', 'jie zhang', 'xiangyu zhu', 'huan liu', 'yukun huang']"
2110.15723,sp-gpt2: semantics improvement in vietnamese poetry generation,cs.cl cs.ai cs.lg,"automatic text generation has garnered growing attention in recent years as an essential step towards computer creativity. generative pretraining transformer 2 (gpt2) is one of the state of the art approaches that have excellent successes. in this paper, we took the first step to investigate the power of gpt2 in traditional vietnamese poetry generation. in the earlier time, our experiment with base gpt2 was quite good at generating the poem in the proper template. though it can learn the patterns, including rhyme and tone rules, from the training data, like almost all other text generation approaches, the poems generated still has a topic drift and semantic inconsistency. to improve the cohesion within the poems, we proposed a new model sp-gpt2 (semantic poem gpt2) which was built on the top gpt2 model and an additional loss to constrain context throughout the entire poem. for better evaluation, we examined the methods by both automatic quantitative evaluation and human evaluation. both automatic and human evaluation demonstrated that our approach can generate poems that have better cohesion without losing the quality due to additional loss. at the same time, we are the pioneers of this topic. we released the first computational scoring module for poems generated in the template containing the style rule dictionary. additionally, we are the first to publish a luc-bat dataset, including 87609 luc bat poems, which is equivalent to about 2.6 million sentences, combined with about 83579 poems in other styles was also published for further exploration. the code is available at https://github.com/fsoft-ailab/poem-generator",,2021-10-10,,"['tuan nguyen', 'hanh pham', 'truong bui', 'tan nguyen', 'duc luong', 'phong nguyen']"
2110.15725,batch-softmax contrastive loss for pairwise sentence scoring tasks,cs.cl cs.ai cs.ir cs.lg cs.ne,"the use of contrastive loss for representation learning has become prominent in computer vision, and it is now getting attention in natural language processing (nlp). here, we explore the idea of using a batch-softmax contrastive loss when fine-tuning large-scale pre-trained transformer models to learn better task-specific sentence embeddings for pairwise sentence scoring tasks. we introduce and study a number of variations in the calculation of the loss as well as in the overall training procedure; in particular, we find that data shuffling can be quite important. our experimental results show sizable improvements on a number of datasets and pairwise sentence scoring tasks including classification, ranking, and regression. finally, we offer detailed analysis and discussion, which should be useful for researchers aiming to explore the utility of contrastive loss in nlp.",,2021-10-10,,"['anton chernyavskiy', 'dmitry ilvovsky', 'pavel kalinin', 'preslav nakov']"
2110.15726,social media reveals urban-rural differences in stress across china,cs.cl cs.ai cs.cy cs.si,"modeling differential stress expressions in urban and rural regions in china can provide a better understanding of the effects of urbanization on psychological well-being in a country that has rapidly grown economically in the last two decades. this paper studies linguistic differences in the experiences and expressions of stress in urban-rural china from weibo posts from over 65,000 users across 329 counties using hierarchical mixed-effects models. we analyzed phrases, topical themes, and psycho-linguistic word choices in weibo posts mentioning stress to better understand appraisal differences surrounding psychological stress in urban and rural communities in china; we then compared them with large-scale polls from gallup. after controlling for socioeconomic and gender differences, we found that rural communities tend to express stress in emotional and personal themes such as relationships, health, and opportunity while users in urban areas express stress using relative, temporal, and external themes such as work, politics, and economics. these differences exist beyond controlling for gdp and urbanization, indicating a fundamentally different lifestyle between rural and urban residents in very specific environments, arguably having different sources of stress. we found corroborative trends in physical, financial, and social wellness with urbanization in gallup polls.",,2021-10-19,2021-11-03,"['jesse cui', 'tingdan zhang', 'kokil jaidka', 'dandan pang', 'garrick sherman', 'vinit jakhetiya', 'lyle ungar', 'sharath chandra guntuku']"
2110.15727,calling to cnn-lstm for rumor detection: a deep multi-channel model for   message veracity classification in microblogs,cs.cl cs.ai,"reputed by their low-cost, easy-access, real-time and valuable information, social media also wildly spread unverified or fake news. rumors can notably cause severe damage on individuals and the society. therefore, rumor detection on social media has recently attracted tremendous attention. most rumor detection approaches focus on rumor feature analysis and social features, i.e., metadata in social media. unfortunately, these features are data-specific and may not always be available, e.g., when the rumor has just popped up and not yet propagated. in contrast, post contents (including images or videos) play an important role and can indicate the diffusion purpose of a rumor. furthermore, rumor classification is also closely related to opinion mining and sentiment analysis. yet, to the best of our knowledge, exploiting images and sentiments is little investigated.considering the available multimodal features from microblogs, notably, we propose in this paper an end-to-end model called deepmonitor that is based on deep neural networks and allows quite accurate automated rumor verification, by utilizing all three characteristics: post textual and image contents, as well as sentiment. deepmonitor concatenates image features with the joint text and sentiment features to produce a reliable, fused classification. we conduct extensive experiments on two large-scale, real-world datasets. the results show that deepmonitor achieves a higher accuracy than state-of-the-art methods.",10.1007/978-3-030-86517-7_31,2021-10-11,,"['abderrazek azri', 'cécile favre', 'nouria harbi', 'jérôme darmont', 'camille noûs']"
2110.15728,deep learning for bias detection: from inception to deployment,cs.cl cs.ai cs.lg cs.ne cs.si,"to create a more inclusive workplace, enterprises are actively investing in identifying and eliminating unconscious bias (e.g., gender, race, age, disability, elitism and religion) across their various functions. we propose a deep learning model with a transfer learning based language model to learn from manually tagged documents for automatically identifying bias in enterprise content. we first pretrain a deep learning-based language-model using wikipedia, then fine tune the model with a large unlabelled data set related with various types of enterprise content. finally, a linear layer followed by softmax layer is added at the end of the language model and the model is trained on a labelled bias dataset consisting of enterprise content. the trained model is thoroughly evaluated on independent datasets to ensure a general application. we present the proposed method and its deployment detail in a real-world application.",,2021-10-12,,"['md abul bashar', 'richi nayak', 'anjor kothare', 'vishal sharma', 'kesavan kandadai']"
2110.15730,e-commerce dispute resolution prediction,cs.cl cs.ai,"e-commerce marketplaces support millions of daily transactions, and some disagreements between buyers and sellers are unavoidable. resolving disputes in an accurate, fast, and fair manner is of great importance for maintaining a trustworthy platform. simple cases can be automated, but intricate cases are not sufficiently addressed by hard-coded rules, and therefore most disputes are currently resolved by people. in this work we take a first step towards automatically assisting human agents in dispute resolution at scale. we construct a large dataset of disputes from the ebay online marketplace, and identify several interesting behavioral and linguistic patterns. we then train classifiers to predict dispute outcomes with high accuracy. we explore the model and the dataset, reporting interesting correlations, important features, and insights.",10.1145/3340531.3411906,2021-10-13,,"['david tsurel', 'michael doron', 'alexander nus', 'arnon dagan', 'ido guy', 'dafna shahaf']"
2110.15757,on structural parameterizations of the offensive alliance problem,cs.cc cs.ai cs.dm,"the offensive alliance problem has been studied extensively during the last twenty years. a set $s\subseteq v$ of vertices is an offensive alliance in an undirected graph $g=(v,e)$ if each $v\in n(s)$ has at least as many neighbours in $s$ as it has neighbours (including itself) not in $s$. we study the parameterized complexity of the offensive alliance problem, where the aim is to find a minimum size offensive alliance. our focus here lies on parameters that measure the structural properties of the input instance. we enhance our understanding of the problem from the viewpoint of parameterized complexity by showing that the problem is w[1]-hard parameterized by a wide range of fairly restrictive structural parameters such as the feedback vertex set number, treewidth, pathwidth, and treedepth of the input graph.",,2021-10-29,,"['ajinkya gaikwad', 'soumen maity']"
2110.15764,{\epsilon}-weakened robustness of deep neural networks,cs.lg cs.ai,"this paper introduces a notation of $\varepsilon$-weakened robustness for analyzing the reliability and stability of deep neural networks (dnns). unlike the conventional robustness, which focuses on the ""perfect"" safe region in the absence of adversarial examples, $\varepsilon$-weakened robustness focuses on the region where the proportion of adversarial examples is bounded by user-specified $\varepsilon$. smaller $\varepsilon$ means a smaller chance of failure. under such robustness definition, we can give conclusive results for the regions where conventional robustness ignores. we prove that the $\varepsilon$-weakened robustness decision problem is pp-complete and give a statistical decision algorithm with user-controllable error bound. furthermore, we derive an algorithm to find the maximum $\varepsilon$-weakened robustness radius. the time complexity of our algorithms is polynomial in the dimension and size of the network. so, they are scalable to large real-world networks. besides, we also show its potential application in analyzing quality issues.",,2021-10-29,,"['pei huang', 'yuting yang', 'minghao liu', 'fuqi jia', 'feifei ma', 'jian zhang']"
2110.15766,nxmtransformer: semi-structured sparsification for natural language   understanding via admm,cs.cl cs.ai,"natural language processing (nlp) has recently achieved success by using huge pre-trained transformer networks. however, these models often contain hundreds of millions or even billions of parameters, bringing challenges to online deployment due to latency constraints. recently, hardware manufacturers have introduced dedicated hardware for nxm sparsity to provide the flexibility of unstructured pruning with the runtime efficiency of structured approaches. nxm sparsity permits arbitrarily selecting m parameters to retain from a contiguous group of n in the dense representation. however, due to the extremely high complexity of pre-trained models, the standard sparse fine-tuning techniques often fail to generalize well on downstream tasks, which have limited data resources. to address such an issue in a principled manner, we introduce a new learning framework, called nxmtransformer, to induce nxm semi-structured sparsity on pretrained language models for natural language understanding to obtain better performance. in particular, we propose to formulate the nxm sparsity as a constrained optimization problem and use alternating direction method of multipliers (admm) to optimize the downstream tasks while taking the underlying hardware constraints into consideration. admm decomposes the nxm sparsification problem into two sub-problems that can be solved sequentially, generating sparsified transformer networks that achieve high accuracy while being able to effectively execute on newly released hardware. we apply our approach to a wide range of nlp tasks, and our proposed method is able to achieve 1.7 points higher accuracy in glue score than current practices. moreover, we perform detailed analysis on our approach and shed light on how admm affects fine-tuning accuracy for downstream tasks. finally, we illustrate how nxmtransformer achieves performance improvement with knowledge distillation.",,2021-10-28,,"['connor holmes', 'minjia zhang', 'yuxiong he', 'bo wu']"
2110.15781,two-sided fairness in rankings via lorenz dominance,cs.ir cs.ai cs.cy cs.lg,"we consider the problem of generating rankings that are fair towards both users and item producers in recommender systems. we address both usual recommendation (e.g., of music or movies) and reciprocal recommendation (e.g., dating). following concepts of distributive justice in welfare economics, our notion of fairness aims at increasing the utility of the worse-off individuals, which we formalize using the criterion of lorenz efficiency. it guarantees that rankings are pareto efficient, and that they maximally redistribute utility from better-off to worse-off, at a given level of overall utility. we propose to generate rankings by maximizing concave welfare functions, and develop an efficient inference procedure based on the frank-wolfe algorithm. we prove that unlike existing approaches based on fairness constraints, our approach always produces fair rankings. our experiments also show that it increases the utility of the worse-off at lower costs in terms of overall utility.",,2021-10-28,,"['virginie do', 'sam corbett-davies', 'jamal atif', 'nicolas usunier']"
2110.15788,towards intelligent load balancing in data centers,cs.dc cs.ai cs.ni,"network load balancers are important components in data centers to provide scalable services. workload distribution algorithms are based on heuristics, e.g., equal-cost multi-path (ecmp), weighted-cost multi-path (wcmp) or naive machine learning (ml) algorithms, e.g., ridge regression. advanced ml-based approaches help achieve performance gain in different networking and system problems. however, it is challenging to apply ml algorithms on networking problems in real-life systems. it requires domain knowledge to collect features from low-latency, high-throughput, and scalable networking systems, which are dynamic and heterogenous. this paper proposes aquarius to bridge the gap between ml and networking systems and demonstrates its usage in the context of network load balancers. this paper demonstrates its ability of conducting both offline data analysis and online model deployment in realistic systems. the results show that the ml model trained and deployed using aquarius improves load balancing performance yet they also reveals more challenges to be resolved to apply ml for networking systems.",,2021-10-27,,"['zhiyuan yao', 'yoann desmouceaux', 'mark townsley', 'thomas heide clausen']"
2110.15790,lstm-rpa: a simple but effective long sequence prediction algorithm for   music popularity prediction,cs.ir cs.ai cs.mm cs.sd cs.si eess.as,"the big data about music history contains information about time and users' behavior. researchers could predict the trend of popular songs accurately by analyzing this data. the traditional trend prediction models can better predict the short trend than the long trend. in this paper, we proposed the improved lstm rolling prediction algorithm (lstm-rpa), which combines lstm historical input with current prediction results as model input for next time prediction. meanwhile, this algorithm converts the long trend prediction task into multiple short trend prediction tasks. the evaluation results show that the lstm-rpa model increased f score by 13.03%, 16.74%, 11.91%, 18.52%, compared with lstm, bilstm, gru and rnn. and our method outperforms tradi-tional sequence models, which are arima and sma, by 10.67% and 3.43% improvement in f score.code: https://github.com/maliaosaide/lstm-rpa",,2021-10-27,,"['kun li', 'meng li', 'yanling li', 'min lin']"
2110.15794,clauserec: a clause recommendation framework for ai-aided contract   authoring,cs.cl cs.ai,"contracts are a common type of legal document that frequent in several day-to-day business workflows. however, there has been very limited nlp research in processing such documents, and even lesser in generating them. these contracts are made up of clauses, and the unique nature of these clauses calls for specific methods to understand and generate such documents. in this paper, we introduce the task of clause recommendation, asa first step to aid and accelerate the author-ing of contract documents. we propose a two-staged pipeline to first predict if a specific clause type is relevant to be added in a contract, and then recommend the top clauses for the given type based on the contract context. we pretrain bert on an existing library of clauses with two additional tasks and use it for our prediction and recommendation. we experiment with classification methods and similarity-based heuristics for clause relevance prediction, and generation-based methods for clause recommendation, and evaluate the results from various methods on several clause types. we provide analyses on the results, and further outline the advantages and limitations of the various methods for this line of research.",,2021-10-26,,"['vinay aggarwal', 'aparna garimella', 'balaji vasan srinivasan', 'anandhavelu n', 'rajiv jain']"
2110.15796,properties from mechanisms: an equivariance perspective on identifiable   representation learning,cs.lg cs.ai stat.ml,"a key goal of unsupervised representation learning is ""inverting"" a data generating process to recover its latent properties. existing work that provably achieves this goal relies on strong assumptions on relationships between the latent variables (e.g., independence conditional on auxiliary information). in this paper, we take a very different perspective on the problem and ask, ""can we instead identify latent properties by leveraging knowledge of the mechanisms that govern their evolution?"" we provide a complete characterization of the sources of non-identifiability as we vary knowledge about a set of possible mechanisms. in particular, we prove that if we know the exact mechanisms under which the latent properties evolve, then identification can be achieved up to any equivariances that are shared by the underlying mechanisms. we generalize this characterization to settings where we only know some hypothesis class over possible mechanisms, as well as settings where the mechanisms are stochastic. we demonstrate the power of this mechanism-based perspective by showing that we can leverage our results to generalize existing identifiable representation learning results. these results suggest that by exploiting inductive biases on mechanisms, it is possible to design a range of new identifiable representation learning approaches.",,2021-10-29,,"['kartik ahuja', 'jason hartford', 'yoshua bengio']"
2110.15797,discovering non-monotonic autoregressive orderings with variational   inference,cs.cl cs.ai cs.lg,"the predominant approach for language modeling is to process sequences from left to right, but this eliminates a source of information: the order by which the sequence was generated. one strategy to recover this information is to decode both the content and ordering of tokens. existing approaches supervise content and ordering by designing problem-specific loss functions and pre-training with an ordering pre-selected. other recent works use iterative search to discover problem-specific orderings for training, but suffer from high time complexity and cannot be efficiently parallelized. we address these limitations with an unsupervised parallelizable learner that discovers high-quality generation orders purely from training data -- no domain knowledge required. the learner contains an encoder network and decoder language model that perform variational inference with autoregressive orders (represented as permutation matrices) as latent variables. the corresponding elbo is not differentiable, so we develop a practical algorithm for end-to-end optimization using policy gradients. we implement the encoder as a transformer with non-causal attention that outputs permutations in one forward pass. permutations then serve as target generation orders for training an insertion-based transformer language model. empirical results in language modeling tasks demonstrate that our method is context-aware and discovers orderings that are competitive with or even better than fixed orders.",,2021-10-27,,"['xuanlin li', 'brandon trabucco', 'dong huk park', 'michael luo', 'sheng shen', 'trevor darrell', 'yang gao']"
2110.15799,guided policy search for parameterized skills using adverbs,cs.ai cs.cl cs.hc cs.ro,"we present a method for using adverb phrases to adjust skill parameters via learned adverb-skill groundings. these groundings allow an agent to use adverb feedback provided by a human to directly update a skill policy, in a manner similar to traditional local policy search methods. we show that our method can be used as a drop-in replacement for these policy search methods when dense reward from the environment is not available but human language feedback is. we demonstrate improved sample efficiency over modern policy search methods in two experiments.",,2021-10-23,,"['benjamin a. spiegel', 'george konidaris']"
2110.15801,application of the multi-label residual convolutional neural network   text classifier using content-based routing process,cs.cl cs.ai cs.lg,"in this article, we will present an nlp application in text classifying process using the content-based router. the ultimate goal throughout this article is to predict the event described by a legal ad from the plain text of the ad. this problem is purely a supervised problem that will involve the use of nlp techniques and conventional modeling methodologies through the use of the multi-label residual convolutional neural network for text classification. we will explain the approach put in place to solve the problem of classified ads, the difficulties encountered and the experimental results.",,2021-10-19,,"['tounsi achraf', 'elkefi safa']"
2110.15803,natural language processing for smart healthcare,cs.cl cs.ai,"smart healthcare has achieved significant progress in recent years. emerging artificial intelligence (ai) technologies enable various smart applications across various healthcare scenarios. as an essential technology powered by ai, natural language processing (nlp) plays a key role in smart healthcare due to its capability of analysing and understanding human language. in this work we review existing studies that concern nlp for smart healthcare from the perspectives of technique and application. we focus on feature extraction and modelling for various nlp tasks encountered in smart healthcare from a technical point of view. in the context of smart healthcare applications employing nlp techniques, the elaboration largely attends to representative smart healthcare scenarios, including clinical practice, hospital management, personal care, public health, and drug development. we further discuss the limitations of current works and identify the directions for future works.",,2021-10-18,,"['binggui zhou', 'guanghua yang', 'zheng shi', 'shaodan ma']"
2110.15828,resampling base distributions of normalizing flows,stat.ml cs.ai cs.lg,"normalizing flows are a popular class of models for approximating probability distributions. however, their invertible nature limits their ability to model target distributions with a complex topological structure, such as boltzmann distributions. several procedures have been proposed to solve this problem but many of them sacrifice invertibility and, thereby, tractability of the log-likelihood as well as other desirable properties. to address these limitations, we introduce a base distribution for normalizing flows based on learned rejection sampling, allowing the resulting normalizing flow to model complex topologies without giving up bijectivity. furthermore, we develop suitable learning algorithms using both maximizing the log-likelihood and the optimization of the reverse kullback-leibler divergence, and apply them to various sample problems, i.e.\ approximating 2d densities, density estimation of tabular data, image generation, and modeling boltzmann distributions. in these experiments our method is competitive with or outperforms the baselines.",,2021-10-29,,"['vincent stimper', 'bernhard schölkopf', 'josé miguel hernández-lobato']"
2110.15829,holistic deep learning,cs.lg cs.ai,"there is much interest in deep learning to solve challenges that arise in applying neural network models in real-world environments. in particular, three areas have received considerable attention: adversarial robustness, parameter sparsity, and output stability. despite numerous attempts on solving these problems independently, there is very little work addressing the challenges simultaneously. in this paper, we address this problem of constructing holistic deep learning models by proposing a novel formulation that solves these issues in combination. real-world experiments on both tabular and mnist dataset show that our formulation is able to simultaneously improve the accuracy, robustness, stability, and sparsity over traditional deep learning models among many others.",,2021-10-29,,"['dimitris bertsimas', 'léonard boussioux', 'kimberly villalobos carballo', 'michael lingzhi li', 'alex paskov', 'ivan paskov']"
2110.15866,towards comparative physical interpretation of spatial variability aware   neural networks: a summary of results,cs.lg cs.ai,"given spatial variability aware neural networks (svanns), the goal is to investigate mathematical (or computational) models for comparative physical interpretation towards their transparency (e.g., simulatibility, decomposability and algorithmic transparency). this problem is important due to important use-cases such as reusability, debugging, and explainability to a jury in a court of law. challenges include a large number of model parameters, vacuous bounds on generalization performance of neural networks, risk of overfitting, sensitivity to noise, etc., which all detract from the ability to interpret the models. related work on either model-specific or model-agnostic post-hoc interpretation is limited due to a lack of consideration of physical constraints (e.g., mass balance) and properties (e.g., second law of geography). this work investigates physical interpretation of svanns using novel comparative approaches based on geographically heterogeneous features. the proposed approach on feature-based physical interpretation is evaluated using a case-study on wetland mapping. the proposed physical interpretation improves the transparency of svann models and the analytical results highlight the trade-off between model transparency and model performance (e.g., f1-score). we also describe an interpretation based on geographically heterogeneous processes modeled as partial differential equations (pdes).",,2021-10-29,,"['jayant gupta', 'carl molnar', 'gaoxiang luo', 'joe knight', 'shashi shekhar']"
2110.15884,distributing deep learning hyperparameter tuning for 3d medical image   segmentation,cs.lg cs.ai cs.dc,"most research on novel techniques for 3d medical image segmentation (mis) is currently done using deep learning with gpu accelerators. the principal challenge of such technique is that a single input can easily cope computing resources, and require prohibitive amounts of time to be processed. distribution of deep learning and scalability over computing devices is an actual need for progressing on such research field. conventional distribution of neural networks consist in data parallelism, where data is scattered over resources (e.g., gpus) to parallelize the training of the model. however, experiment parallelism is also an option, where different training processes are parallelized across resources. while the first option is much more common on 3d image segmentation, the second provides a pipeline design with less dependence among parallelized processes, allowing overhead reduction and more potential scalability. in this work we present a design for distributed deep learning training pipelines, focusing on multi-node and multi-gpu environments, where the two different distribution approaches are deployed and benchmarked. we take as proof of concept the 3d u-net architecture, using the msd brain tumor segmentation dataset, a state-of-art problem in medical image segmentation with high computing and space requirements. using the bsc marenostrum supercomputer as benchmarking environment, we use tensorflow and ray as neural network training and experiment distribution platforms. we evaluate the experiment speed-up, showing the potential for scaling out on gpus and nodes. also comparing the different parallelism techniques, showing how experiment distribution leverages better such resources through scaling. finally, we provide the implementation of the design open to the community, and the non-trivial steps and methodology for adapting and deploying a mis case as the here presented.",,2021-10-29,,"['josep lluis berral', 'oriol aranda', 'juan luis dominguez', 'jordi torres']"
2110.15907,learning to be cautious,cs.ai cs.lg,"a key challenge in the field of reinforcement learning is to develop agents that behave cautiously in novel situations. it is generally impossible to anticipate all situations that an autonomous system may face or what behavior would best avoid bad outcomes. an agent that could learn to be cautious would overcome this challenge by discovering for itself when and how to behave cautiously. in contrast, current approaches typically embed task-specific safety information or explicit cautious behaviors into the system, which is error-prone and imposes extra burdens on practitioners. in this paper, we present both a sequence of tasks where cautious behavior becomes increasingly non-obvious, as well as an algorithm to demonstrate that it is possible for a system to \emph{learn} to be cautious. the essential features of our algorithm are that it characterizes reward function uncertainty without task-specific safety information and uses this uncertainty to construct a robust policy. specifically, we construct robust policies with a $k$-of-$n$ counterfactual regret minimization (cfr) subroutine given a learned reward function uncertainty represented by a neural network ensemble belief. these policies exhibit caution in each of our tasks without any task-specific safety tuning.",,2021-10-29,,"['montaser mohammedalamen', 'dustin morrill', 'alexander sieusahai', 'yash satsangi', 'michael bowling']"
2110.15914,improving the quality of generative models through smirnov   transformation,cs.lg cs.ai,"solving the convergence issues of generative adversarial networks (gans) is one of the most outstanding problems in generative models. in this work, we propose a novel activation function to be used as output of the generator agent. this activation function is based on the smirnov probabilistic transformation and it is specifically designed to improve the quality of the generated data. in sharp contrast with previous works, our activation function provides a more general approach that deals not only with the replication of categorical variables but with any type of data distribution (continuous or discrete). moreover, our activation function is derivable and therefore, it can be seamlessly integrated in the backpropagation computations during the gan training processes. to validate this approach, we evaluate our proposal against two different data sets: a) an artificially rendered data set containing a mixture of discrete and continuous variables, and b) a real data set of flow-based network traffic data containing both normal connections and cryptomining attacks. to evaluate the fidelity of the generated data, we analyze both their results in terms of quality measures of statistical nature and also regarding the use of these synthetic data to feed a nested machine learning-based classifier. the experimental results evince a clear outperformance of the gan network tuned with this new activation function with respect to both a na\""ive mean-based generator and a standard gan. the quality of the data is so high that the generated data can fully substitute real data for training the nested classifier without a fall in the obtained accuracy. this result encourages the use of gans to produce high-quality synthetic data that are applicable in scenarios in which data privacy must be guaranteed.",,2021-10-29,,"['ángel gonzález-prieto', 'alberto mozo', 'sandra gómez-canaval', 'edgar talavera']"
2110.15926,delayed propagation transformer: a universal computation engine towards   practical control in cyber-physical systems,cs.ai cs.sy eess.sy,"multi-agent control is a central theme in the cyber-physical systems (cps). however, current control methods either receive non-markovian states due to insufficient sensing and decentralized design, or suffer from poor convergence. this paper presents the delayed propagation transformer (dept), a new transformer-based model that specializes in the global modeling of cps while taking into account the immutable constraints from the physical world. dept induces a cone-shaped spatial-temporal attention prior, which injects the information propagation and aggregation principles and enables a global view. with physical constraint inductive bias baked into its design, our dept is ready to plug and play for a broad class of multi-agent systems. the experimental results on one of the most challenging cps -- network-scale traffic signal control system in the open world -- show that our model outperformed the state-of-the-art expert methods on synthetic and real-world datasets. our codes are released at: https://github.com/vita-group/dept.",,2021-10-29,,"['wenqing zheng', 'qiangqiang guo', 'hao yang', 'peihao wang', 'zhangyang wang']"
2110.15943,metaicl: learning to learn in context,cs.cl cs.ai,"we introduce metaicl (meta-training for in-context learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learn-ing on a large set of training tasks. this meta-training enables the model to more effectively learn a new task in context at test time, by simply conditioning on a few training examples with no parameter updates or task-specific templates. we experiment on a large, diverse collection of tasks consisting of 142 nlp datasets including classification, question answering, natural language inference, paraphrase detection and more, across seven different meta-training/target splits. metaicl outperforms a range of baselines including in-context learning without meta-training and multi-task learning followed by zero-shot transfer. we find that the gains are particularly significant for target tasks that have domain shifts from the meta-training tasks, and that using a diverse set of the meta-training tasks is key to improvements. we also show that metaicl approaches (and sometimes beats) the performance of models fully finetuned on the target task training data, and outperforms much bigger models with nearly 8x parameters.",,2021-10-29,,"['sewon min', 'mike lewis', 'luke zettlemoyer', 'hannaneh hajishirzi']"
2110.15949,sparsely changing latent states for prediction and planning in partially   observable domains,cs.lg cs.ai,"a common approach to prediction and planning in partially observable domains is to use recurrent neural networks (rnns), which ideally develop and maintain a latent memory about hidden, task-relevant factors. we hypothesize that many of these hidden factors in the physical world are constant over time, changing only sparsely. accordingly, we propose gated $l_0$ regularized dynamics (gatel0rd), a novel recurrent architecture that incorporates the inductive bias to maintain stable, sparsely changing latent states. the bias is implemented by means of a novel internal gating function and a penalty on the $l_0$ norm of latent state changes. we demonstrate that gatel0rd can compete with or outperform state-of-the-art rnns in a variety of partially observable prediction and control tasks. gatel0rd tends to encode the underlying generative factors of the environment, ignores spurious temporal dependencies, and generalizes better, improving sampling efficiency and prediction accuracy as well as behavior in model-based planning and reinforcement learning tasks. moreover, we show that the developing latent states can be easily interpreted, which is a step towards better explainability in rnns.",,2021-10-29,,"['christian gumbsch', 'martin v. butz', 'georg martius']"
2111.00003,a new algorithm based on extent bit-array for computing formal concepts,cs.ai cs.cr cs.ds,"the emergence of formal concept analysis (fca) as a data analysis technique has increased the need for developing algorithms which can compute formal concepts quickly. the current efficient algorithms for fca are variants of the close-by-one (cbo) algorithm, such as in-close2, in-close3 and in-close4, which are all based on horizontal storage of contexts. in this paper, based on algorithm in-close4, a new algorithm based on the vertical storage of contexts, called in-close5, is proposed, which can significantly reduce both the time complexity and space complexity of algorithm in-close4. technically, the new algorithm stores both context and extent of a concept as a vertical bit-array, while within in-close4 algorithm the context is stored only as a horizontal bit-array, which is very slow in finding the intersection of two extent sets. experimental results demonstrate that the proposed algorithm is much more effective than in-close4 algorithm, and it also has a broader scope of applicability in computing formal concept in which one can solve the problems that cannot be solved by the in-close4 algorithm.",,2021-10-28,,"['jianqin zhou', 'sichun yang', 'xifeng wang', 'wanquan liu']"
2111.00004,granule description based on compound concepts,cs.ai,"concise granule descriptions for describable granules and approaching description methods for indescribable granules are challenging and important issues in granular computing. the concept with only common attributes has been frequently studied. to investigate the granules with some special needs, we propose two new types of compound concepts in this paper: bipolar concept and common-and-necessary concept. based on the definitions of concept-forming operations, the logical formulas are derived for each of the following types of concepts: formal concept, three-way concept, object oriented concept, bipolar concept and common-and-necessary concept. furthermore, by utilizing the logical relationship among various concepts, we have derived concise and unified equivalent conditions for describable granules and approaching description methods for indescribable granules for all five kinds of concepts.",,2021-10-28,,"['jianqin zhou', 'sichun yang', 'xifeng wang', 'wanquan liu']"
2111.00005,concept and attribute reduction based on rectangle theory of formal   concept,cs.ai cs.cr,"based on rectangle theory of formal concept and set covering theory, the concept reduction preserving binary relations is investigated in this paper. it is known that there are three types of formal concepts: core concepts, relative necessary concepts and unnecessary concepts. first, we present the new judgment results for relative necessary concepts and unnecessary concepts. second, we derive the bounds for both the maximum number of relative necessary concepts and the maximum number of unnecessary concepts and it is a difficult problem as either in concept reduction preserving binary relations or attribute reduction of decision formal contexts, the computation of formal contexts from formal concepts is a challenging problem. third, based on rectangle theory of formal concept, a fast algorithm for reducing attributes while preserving the extensions for a set of formal concepts is proposed using the extension bit-array technique, which allows multiple context cells to be processed by a single 32-bit or 64-bit operator. technically, the new algorithm could store both formal context and extent of a concept as bit-arrays, and we can use bit-operations to process set operations ""or"" as well as ""and"". one more merit is that the new algorithm does not need to consider other concepts in the concept lattice, thus the algorithm is explicit to understand and fast. experiments demonstrate that the new algorithm is effective in the computation of attribute reductions.",,2021-10-28,,"['jianqin zhou', 'sichun yang', 'xifeng wang', 'wanquan liu']"
2111.00006,adaptive hierarchical similarity metric learning with noisy labels,cs.cv cs.ai cs.lg,"deep metric learning (dml) plays a critical role in various machine learning tasks. however, most existing deep metric learning methods with binary similarity are sensitive to noisy labels, which are widely present in real-world data. since these noisy labels often cause severe performance degradation, it is crucial to enhance the robustness and generalization ability of dml. in this paper, we propose an adaptive hierarchical similarity metric learning method. it considers two noise-insensitive information, \textit{i.e.}, class-wise divergence and sample-wise consistency. specifically, class-wise divergence can effectively excavate richer similarity information beyond binary in modeling by taking advantage of hyperbolic metric learning, while sample-wise consistency can further improve the generalization ability of the model using contrastive augmentation. more importantly, we design an adaptive strategy to integrate this information in a unified view. it is noteworthy that the new method can be extended to any pair-based metric loss. extensive experimental results on benchmark datasets demonstrate that our method achieves state-of-the-art performance compared with current deep metric learning approaches.",,2021-10-28,,"['jiexi yan', 'lei luo', 'cheng deng', 'heng huang']"
2111.00008,reinforced workload distribution fairness,cs.dc cs.ai cs.ni,"network load balancers are central components in data centers, that distributes workloads across multiple servers and thereby contribute to offering scalable services. however, when load balancers operate in dynamic environments with limited monitoring of application server loads, they rely on heuristic algorithms that require manual configurations for fairness and performance. to alleviate that, this paper proposes a distributed asynchronous reinforcement learning mechanism to-with no active load balancer state monitoring and limited network observations-improve the fairness of the workload distribution achieved by a load balancer. the performance of proposed mechanism is evaluated and compared with stateof-the-art load balancing algorithms in a simulator, under configurations with progressively increasing complexities. preliminary results show promise in rlbased load balancing algorithms, and identify additional challenges and future research directions, including reward function design and model scalability.",,2021-10-29,,"['zhiyuan yao', 'zihan ding', 'thomas heide clausen']"
2111.00035,"skyformer: remodel self-attention with gaussian kernel and nystr\""om   method",cs.lg cs.ai cs.cl stat.ml,"transformers are expensive to train due to the quadratic time and space complexity in the self-attention mechanism. on the other hand, although kernel machines suffer from the same computation bottleneck in pairwise dot products, several approximation schemes have been successfully incorporated to considerably reduce their computational cost without sacrificing too much accuracy. in this work, we leverage the computation methods for kernel machines to alleviate the high computational cost and introduce skyformer, which replaces the softmax structure with a gaussian kernel to stabilize the model training and adapts the nystr\""om method to a non-positive semidefinite matrix to accelerate the computation. we further conduct theoretical analysis by showing that the matrix approximation error of our proposed method is small in the spectral norm. experiments on long range arena benchmark show that the proposed method is sufficient in getting comparable or even better performance than the full self-attention while requiring fewer computation resources.",,2021-10-29,,"['yifan chen', 'qi zeng', 'heng ji', 'yun yang']"
2111.00052,diagnosing web data of icts to provide focused assistance in   agricultural adoptions,cs.cy cs.ai cs.si,"the past decade has witnessed a rapid increase in technology ownership across rural areas of india, signifying the potential for ict initiatives to empower rural households. in our work, we focus on the web infrastructure of one such ict - digital green that started in 2008. following a participatory approach for content production, digital green disseminates instructional agricultural videos to smallholder farmers via human mediators to improve the adoption of farming practices. their web-based data tracker, coco, captures data related to these processes, storing the attendance and adoption logs of over 2.3 million farmers across three continents and twelve countries. using this data, we model the components of the digital green ecosystem involving the past attendance-adoption behaviours of farmers, the content of the videos screened to them and their demographic features across five states in india. we use statistical tests to identify different factors which distinguish farmers with higher adoption rates to understand why they adopt more than others. our research finds that farmers with higher adoption rates adopt videos of shorter duration and belong to smaller villages. the co-attendance and co-adoption networks of farmers indicate that they greatly benefit from past adopters of a video from their village and group when it comes to adopting practices from the same video. following our analysis, we model the adoption of practices from a video as a prediction problem to identify and assist farmers who might face challenges in adoption in each of the five states. we experiment with different model architectures and achieve macro-f1 scores ranging from 79% to 89% using a random forest classifier. finally, we measure the importance of different features using shap values and provide implications for improving the adoption rates of nearly a million farmers across five states in india.",,2021-10-29,,"['ashwin singh', 'mallika subramanian', 'anmol agarwal', 'pratyush priyadarshi', 'shrey gupta', 'kiran garimella', 'sanjeev kumar', 'ritesh kumar', 'lokesh garg', 'erica arya', 'ponnurangam kumaraguru']"
2111.00053,symbolic regression via neural-guided genetic programming population   seeding,cs.ne cs.ai cs.lg,"symbolic regression is the process of identifying mathematical expressions that fit observed output from a black-box process. it is a discrete optimization problem generally believed to be np-hard. prior approaches to solving the problem include neural-guided search (e.g. using reinforcement learning) and genetic programming. in this work, we introduce a hybrid neural-guided/genetic programming approach to symbolic regression and other combinatorial optimization problems. we propose a neural-guided component used to seed the starting population of a random restart genetic programming component, gradually learning better starting populations. on a number of common benchmark tasks to recover underlying expressions from a dataset, our method recovers 65% more expressions than a recently published top-performing model using the same experimental setup. we demonstrate that running many genetic programming generations without interdependence on the neural-guided component performs better for symbolic regression than alternative formulations where the two are more strongly coupled. finally, we introduce a new set of 22 symbolic regression benchmark problems with increased difficulty over existing benchmarks. source code is provided at www.github.com/brendenpetersen/deep-symbolic-optimization.",,2021-10-29,2021-11-17,"['t. nathan mundhenk', 'mikel landajuela', 'ruben glatt', 'claudio p. santiago', 'daniel m. faissol', 'brenden k. petersen']"
2111.00071,"reskin: versatile, replaceable, lasting tactile skins",cs.ro cs.ai,"soft sensors have continued growing interest in robotics, due to their ability to enable both passive conformal contact from the material properties and active contact data from the sensor properties. however, the same properties of conformal contact result in faster deterioration of soft sensors and larger variations in their response characteristics over time and across samples, inhibiting their ability to be long-lasting and replaceable. reskin is a tactile soft sensor that leverages machine learning and magnetic sensing to offer a low-cost, diverse and compact solution for long-term use. magnetic sensing separates the electronic circuitry from the passive interface, making it easier to replace interfaces as they wear out while allowing for a wide variety of form factors. machine learning allows us to learn sensor response models that are robust to variations across fabrication and time, and our self-supervised learning algorithm enables finer performance enhancement with small, inexpensive data collection procedures. we believe that reskin opens the door to more versatile, scalable and inexpensive tactile sensation modules than existing alternatives.",,2021-10-29,,"['raunaq bhirangi', 'tess hellebrekers', 'carmel majidi', 'abhinav gupta']"
2111.00072,generalized proximal policy optimization with sample reuse,cs.lg cs.ai stat.ml,"in real-world decision making tasks, it is critical for data-driven reinforcement learning methods to be both stable and sample efficient. on-policy methods typically generate reliable policy improvement throughout training, while off-policy methods make more efficient use of data through sample reuse. in this work, we combine the theoretically supported stability benefits of on-policy algorithms with the sample efficiency of off-policy algorithms. we develop policy improvement guarantees that are suitable for the off-policy setting, and connect these bounds to the clipping mechanism used in proximal policy optimization. this motivates an off-policy version of the popular algorithm that we call generalized proximal policy optimization with sample reuse. we demonstrate both theoretically and empirically that our algorithm delivers improved performance by effectively balancing the competing goals of stability and sample efficiency.",,2021-10-29,,"['james queeney', 'ioannis ch. paschalidis', 'christos g. cassandras']"
2111.00077,deepdosenet: a deep learning model for 3d dose prediction in radiation   therapy,physics.med-ph cs.ai cs.cv cs.lg eess.iv,"the deepdosenet 3d dose prediction model based on resnet and dilated densenet is proposed. the 340 head-and-neck datasets from the 2020 aapm openkbp challenge were utilized, with 200 for training, 40 for validation, and 100 for testing. structures include 56gy, 63gy, 70gy ptvs, and brainstem, spinal cord, right parotid, left parotid, larynx, esophagus, and mandible oars. mean squared error (mse) loss, mean absolute error (mae) loss, and mae plus dose-volume histogram (dvh) based loss functions were investigated. each model's performance was compared using a 3d dose score, $\bar{s_{d}}$, (mean absolute difference between ground truth and predicted 3d dose distributions) and a dvh score, $\bar{s_{dvh}}$ (mean absolute difference between ground truth and predicted dose-volume metrics).furthermore, dvh metrics mean[gy] and d0.1cc [gy] for oars and d99%, d95%, d1% for ptvs were computed. deepdosenet with the mae plus dvh-based loss function had the best dose score performance of the openkbp entries. mae+dvh model had the lowest prediction error (p<0.0001, wilcoxon test) on validation and test datasets (validation: $\bar{s_{d}}$=2.3gy, $\bar{s_{dvh}}$=1.9gy; test: $\bar{s_{d}}$=2.0gy, $\bar{s_{dvh}}$=1.6gy) followed by the mae model (validation: $\bar{s_{d}}$=3.6gy, $\bar{s_{dvh}}$=2.4gy; test: $\bar{s_{d}}$=3.5gy, $\bar{s_{dvh}}$=2.3gy). the mse model had the highest prediction error (validation: $\bar{s_{d}}$=3.7gy, $\bar{s_{dvh}}$=3.2gy; test: $\bar{s_{d}}$=3.6gy, $\bar{s_{dvh}}$=3.0gy). no significant difference was found among models in terms of mean [gy], but the mae+dvh model significantly outperformed the mae and mse models in terms of d0.1cc[gy], particularly for mandible and parotids on both validation (p<0.01) and test (p<0.0001) datasets. mae+dvh outperformed (p<0.0001) in terms of d99%, d95%, d1% for targets. mae+dvh reduced $\bar{s_{d}}$ by ~60% and $\bar{s_{dvh}}$ by ~70%.",,2021-10-29,,"['mumtaz hussain soomro', 'victor gabriel leandro alves', 'hamidreza nourzadeh', 'jeffrey v. siebers']"
2111.00086,measuring a texts fairness dimensions using machine learning based on   social psychological factors,cs.ai cs.cl cs.cy,"fairness is a principal social value that can be observed in civilisations around the world. a manifestation of this is in social agreements, often described in texts, such as contracts. yet, despite the prevalence of such, a fairness metric for texts describing a social act remains wanting. to address this, we take a step back to consider the problem based on first principals. instead of using rules or templates, we utilise social psychology literature to determine the principal factors that humans use when making a fairness assessment. we then attempt to digitise these using word embeddings into a multi-dimensioned sentence level fairness perceptions vector to serve as an approximation for these fairness perceptions. the method leverages a pro-social bias within word embeddings, for which we obtain an f1= 81.0. a second approach, using pca and ml based on the said fairness approximation vector produces an f1 score of 86.2. we detail improvements that can be made in the methodology to incorporate the projection of sentence embedding on to a subspace representation of fairness.",,2021-10-29,2021-11-16,"['a. izzidien', 'j. watson', 'b. loe', 'p. romero', 's. fitz', 'd. stillwell']"
2111.00107,the golden rule as a heuristic to measure the fairness of texts using   machine learning,cs.cl cs.ai,"to treat others as one would wish to be treated is a common formulation of the golden rule (gr). yet, despite its prevalence as an axiom throughout history, no digitisation of the moral philosophy exists. in this paper we consider how to digitise it so that it may be used to measure sentences such as: the boy harmed the girl, and categorise them as fair or unfair. a review and reply to criticisms of the gr is made. we share the code for the digitisation of the gr, and test it with a list of sentences. implementing two approaches, one using the use, and a second using albert. we find f1 scores of 78.0, 85.0, respectively. a suggestion of how the technology may be implemented to avoid unfair biases in word embeddings is made - given that individuals would typically not wish to be on the receiving end of an unfair act, such as racism, irrespective of whether the corpus being used deems such discrimination as praiseworthy.",,2021-10-29,,"['a. izzidien', 'j. watson', 'b. loe', 'p. romero', 's. fitz', 'd. stillwell']"
2111.00110,fc2t2: the fast continuous convolutional taylor transform with   applications in vision and graphics,cs.lg cs.ai cs.cv,"series expansions have been a cornerstone of applied mathematics and engineering for centuries. in this paper, we revisit the taylor series expansion from a modern machine learning perspective. specifically, we introduce the fast continuous convolutional taylor transform (fc2t2), a variant of the fast multipole method (fmm), that allows for the efficient approximation of low dimensional convolutional operators in continuous space. we build upon the fmm which is an approximate algorithm that reduces the computational complexity of n-body problems from o(nm) to o(n+m) and finds application in e.g. particle simulations. as an intermediary step, the fmm produces a series expansion for every cell on a grid and we introduce algorithms that act directly upon this representation. these algorithms analytically but approximately compute the quantities required for the forward and backward pass of the backpropagation algorithm and can therefore be employed as (implicit) layers in neural networks. specifically, we introduce a root-implicit layer that outputs surface normals and object distances as well as an integral-implicit layer that outputs a rendering of a radiance field given a 3d pose. in the context of machine learning, $n$ and $m$ can be understood as the number of model parameters and model evaluations respectively which entails that, for applications that require repeated function evaluations which are prevalent in computer vision and graphics, unlike regular neural networks, the techniques introduce in this paper scale gracefully with parameters. for some applications, this results in a 200x reduction in flops compared to state-of-the-art approaches at a reasonable or non-existent loss in accuracy.",,2021-10-29,2021-11-10,"['henning lange', 'j. nathan kutz']"
2111.00116,visual explanations for convolutional neural networks via latent   traversal of generative adversarial networks,cs.cv cs.ai cs.lg eess.iv,"lack of explainability in artificial intelligence, specifically deep neural networks, remains a bottleneck for implementing models in practice. popular techniques such as gradient-weighted class activation mapping (grad-cam) provide a coarse map of salient features in an image, which rarely tells the whole story of what a convolutional neural network (cnn) learned. using covid-19 chest x-rays, we present a method for interpreting what a cnn has learned by utilizing generative adversarial networks (gans). our gan framework disentangles lung structure from covid-19 features. using this gan, we can visualize the transition of a pair of covid negative lungs in a chest radiograph to a covid positive pair by interpolating in the latent space of the gan, which provides fine-grained visualization of how the cnn responds to varying features within the lungs.",,2021-10-29,2021-11-01,"['amil dravid', 'aggelos k. katsaggelos']"
2111.00131,"three approaches to facilitate dnn generalization to objects in   out-of-distribution orientations and illuminations: late-stopping, tuning   batch normalization and invariance loss",cs.cv cs.ai cs.lg,"the training data distribution is often biased towards objects in certain orientations and illumination conditions. while humans have a remarkable capability of recognizing objects in out-of-distribution (ood) orientations and illuminations, deep neural networks (dnns) severely suffer in this case, even when large amounts of training examples are available. in this paper, we investigate three different approaches to improve dnns in recognizing objects in ood orientations and illuminations. namely, these are (i) training much longer after convergence of the in-distribution (ind) validation accuracy, i.e., late-stopping, (ii) tuning the momentum parameter of the batch normalization layers, and (iii) enforcing invariance of the neural activity in an intermediate layer to orientation and illumination conditions. each of these approaches substantially improves the dnn's ood accuracy (more than 20% in some cases). we report results in four datasets: two datasets are modified from the mnist and ilab datasets, and the other two are novel (one of 3d rendered cars and another of objects taken from various controlled orientations and illumination conditions). these datasets allow to study the effects of different amounts of bias and are challenging as dnns perform poorly in ood conditions. finally, we demonstrate that even though the three approaches focus on different aspects of dnns, they all tend to lead to the same underlying neural mechanism to enable ood accuracy gains -- individual neurons in the intermediate layers become more selective to a category and also invariant to ood orientations and illuminations.",,2021-10-29,,"['akira sakai', 'taro sunagawa', 'spandan madan', 'kanata suzuki', 'takashi katoh', 'hiromichi kobashi', 'hanspeter pfister', 'pawan sinha', 'xavier boix', 'tomotake sasaki']"
2111.00134,context meta-reinforcement learning via neuromodulation,cs.ne cs.ai cs.lg,"meta-reinforcement learning (meta-rl) algorithms enable agents to adapt quickly to tasks from few samples in dynamic environments. such a feat is achieved through dynamic representations in an agent's policy network (obtained via reasoning about task context, model parameter updates, or both). however, obtaining rich dynamic representations for fast adaptation beyond simple benchmark problems is challenging due to the burden placed on the policy network to accommodate different policies. this paper addresses the challenge by introducing neuromodulation as a modular component to augment a standard policy network that regulates neuronal activities in order to produce efficient dynamic representations for task adaptation. the proposed extension to the policy network is evaluated across multiple discrete and continuous control environments of increasing complexity. to prove the generality and benefits of the extension in meta-rl, the neuromodulated network was applied to two state-of-the-art meta-rl algorithms (cavia and pearl). the result demonstrates that meta-rl augmented with neuromodulation produces significantly better result and richer dynamic representations in comparison to the baselines.",,2021-10-29,,"['eseoghene ben-iwhiwhu', 'jeffery dick', 'nicholas a. ketz', 'praveen k. pilly', 'andrea soltoggio']"
2111.00149,temporal-spatial feature extraction based on convolutional neural   networks for travel time prediction,cs.lg cs.ai,"in recent years, some traffic information prediction methods have been proposed to provide the precise information of travel time, vehicle speed, and traffic flow for highways. however, big errors may be obtained by these methods for urban roads or the alternative roads of highways. therefore, this study proposes a travel time prediction method based on convolutional neural networks to extract important factors for the improvement of traffic information prediction. in practical experimental environments, the travel time records of no. 5 highway and the alternative roads of its were collected and used to evaluate the proposed method. the results showed that the mean absolute percentage error of the proposed method was about 5.69%. therefore, the proposed method based on deep learning techniques can improve the accuracy of travel time prediction.",,2021-10-29,,['chi-hua chen']
2111.00166,advanced algorithms of collision free navigation and flocking for   autonomous uavs,cs.ro cs.ai cs.sy eess.sy,"unmanned aerial vehicles (uavs) have become very popular for many military and civilian applications including in agriculture, construction, mining, environmental monitoring, etc. a desirable feature for uavs is the ability to navigate and perform tasks autonomously with least human interaction. this is a very challenging problem due to several factors such as the high complexity of uav applications, operation in harsh environments, limited payload and onboard computing power and highly nonlinear dynamics. the work presented in this report contributes towards the state-of-the-art in uav control for safe autonomous navigation and motion coordination of multi-uav systems. the first part of this report deals with single-uav systems. the complex problem of three-dimensional (3d) collision-free navigation in unknown/dynamic environments is addressed. to that end, advanced 3d reactive control strategies are developed adopting the sense-and-avoid paradigm to produce quick reactions around obstacles. a special case of navigation in 3d unknown confined environments (i.e. tunnel-like) is also addressed. general 3d kinematic models are considered in the design which makes these methods applicable to different uav types in addition to underwater vehicles. moreover, different implementation methods for these strategies with quadrotor-type uavs are also investigated considering uav dynamics in the control design. practical experiments and simulations were carried out to analyze the performance of the developed methods. the second part of this report addresses safe navigation for multi-uav systems. distributed motion coordination methods of multi-uav systems for flocking and 3d area coverage are developed. these methods offer good computational cost for large-scale systems. simulations were performed to verify the performance of these methods considering systems with different sizes.",,2021-10-29,,['taha elmokadem']
2111.00180,hierarchical heterogeneous graph representation learning for short text   classification,cs.cl cs.ai,"short text classification is a fundamental task in natural language processing. it is hard due to the lack of context information and labeled data in practice. in this paper, we propose a new method called shine, which is based on graph neural network (gnn), for short text classification. first, we model the short text dataset as a hierarchical heterogeneous graph consisting of word-level component graphs which introduce more semantic and syntactic information. then, we dynamically learn a short document graph that facilitates effective label propagation among similar short texts. thus, compared with existing gnn-based methods, shine can better exploit interactions between nodes of the same types and capture similarities between short texts. extensive experiments on various benchmark short text datasets show that shine consistently outperforms state-of-the-art methods, especially with fewer labels.",,2021-10-30,,"['yaqing wang', 'song wang', 'quanming yao', 'dejing dou']"
2111.00185,convergence and optimality of policy gradient methods in weakly smooth   settings,cs.lg cs.ai cs.sy eess.sy,"policy gradient methods have been frequently applied to problems in control and reinforcement learning with great success, yet existing convergence analysis still relies on non-intuitive, impractical and often opaque conditions. in particular, existing rates are achieved in limited settings, under strict smoothness and bounded conditions. in this work, we establish explicit convergence rates of policy gradient methods without relying on these conditions, instead extending the convergence regime to weakly smooth policy classes with $l_2$ integrable gradient. we provide intuitive examples to illustrate the insight behind these new conditions. we also characterize the sufficiency conditions for the ergodicity of near-linear mdps, which represent an important class of problems. notably, our analysis also shows that fast convergence rates are achievable for both the standard policy gradient and the natural policy gradient algorithms under these assumptions. lastly we provide conditions and analysis for optimality of the converged policies.",,2021-10-30,,"['matthew shunshi zhang', 'murat erdogdu', 'animesh garg']"
2111.00191,how should human translation coexist with nmt? efficient tool for   building high quality parallel corpus,cs.cl cs.ai,"this paper proposes a tool for efficiently constructing high-quality parallel corpora with minimizing human labor and making this tool publicly available. our proposed construction process is based on neural machine translation (nmt) to allow for it to not only coexist with human translation, but also improve its efficiency by combining data quality control with human translation in a data-centric approach.",,2021-10-30,,"['chanjun park', 'seolhwa lee', 'hyeonseok moon', 'sugyeong eo', 'jaehyung seo', 'heuiseok lim']"
2111.00200,autodrone: shortest optimized obstacle-free path planning for autonomous   drones,cs.ai cs.ro,"with technological advancement, drone has emerged as unmanned aerial vehicle that can be controlled by humans to fly or reach a destination. this may be autonomous as well, where the drone itself is intelligent enough to find a shortest obstacle-free path to reach the destination from a designated source. be it a planned smart city or even a wreckage site affected by natural calamity, we may imagine the buildings, any surface-erected structure or other blockage as obstacles for the drone to fly in a direct line-of-sight path. so, the whole bird's eye-view of the landscape can be transformed to a graph of grid-cells, where some are occupied to indicate the obstacles and some are free to indicate the free path. the autonomous drone (autodrone) will be able to find out the shortest hindrance-free path while travelling in two-dimensional space and move from one place to another. in this paper, we propose a method to find out an obstacle-free shortest path in the coordinate system guided by gps. this can be especially beneficial in rescue operations and fast delivery or pick-up in an energy-efficient way, where our algorithm will help in finding out the shortest path and angle along which it should fly. our work shows different scenarios to path-tracing, through the shortest feasible path computed by the autonomous drone.",,2021-10-30,,"['prithwish jana', 'debasish jana']"
2111.00201,a comparative review of recent few-shot object detection algorithms,cs.cv cs.ai,"few-shot object detection, learning to adapt to the novel classes with a few labeled data, is an imperative and long-lasting problem due to the inherent long-tail distribution of real-world data and the urgent demands to cut costs of data collection and annotation. recently, some studies have explored how to use implicit cues in extra datasets without target-domain supervision to help few-shot detectors refine robust task notions. this survey provides a comprehensive overview from current classic and latest achievements for few-shot object detection to future research expectations from manifold perspectives. in particular, we first propose a data-based taxonomy of the training data and the form of corresponding supervision which are accessed during the training stage. following this taxonomy, we present a significant review of the formal definition, main challenges, benchmark datasets, evaluation metrics, and learning strategies. in addition, we present a detailed investigation of how to interplay the object detection methods to develop this issue systematically. finally, we conclude with the current status of few-shot object detection, along with potential research directions for this field.",,2021-10-30,,"['leng jiaxu', 'chen taiyue', 'gao xinbo', 'yu yongtao', 'wang ye', 'gao feng', 'wang yue']"
2111.00206,one step at a time: pros and cons of multi-step meta-gradient   reinforcement learning,cs.lg cs.ai,"self-tuning algorithms that adapt the learning process online encourage more effective and robust learning. among all the methods available, meta-gradients have emerged as a promising approach. they leverage the differentiability of the learning rule with respect to some hyper-parameters to adapt them in an online fashion. although meta-gradients can be accumulated over multiple learning steps to avoid myopic updates, this is rarely used in practice. in this work, we demonstrate that whilst multi-step meta-gradients do provide a better learning signal in expectation, this comes at the cost of a significant increase in variance, hindering performance. in the light of this analysis, we introduce a novel method mixing multiple inner steps that enjoys a more accurate and robust meta-gradient signal, essentially trading off bias and variance in meta-gradient estimation. when applied to the snake game, the mixing meta-gradient algorithm can cut the variance by a factor of 3 while achieving similar or higher performance.",,2021-10-30,,"['clément bonnet', 'paul caron', 'thomas barrett', 'ian davies', 'alexandre laterre']"
2111.00210,mastering atari games with limited data,cs.lg cs.ai cs.cv cs.ro,"reinforcement learning has achieved great success in many applications. however, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. recently, there has been significant progress in sample efficient image-based rl algorithms; however, consistent human-level performance on the atari game benchmark remains an elusive goal. we propose a sample efficient model-based visual rl algorithm built on muzero, which we name efficientzero. our method achieves 190.4% mean human performance and 116.0% median performance on the atari 100k benchmark with only two hours of real-time game experience and outperforms the state sac in some tasks on the dmcontrol 100k benchmark. this is the first time an algorithm achieves super-human performance on atari games with such little data. efficientzero's performance is also close to dqn's performance at 200 million frames while we consume 500 times less data. efficientzero's low sample complexity and high performance can bring rl closer to real-world applicability. we implement our algorithm in an easy-to-understand manner and it is available at https://github.com/yewr/efficientzero. we hope it will accelerate the research of mcts-based rl algorithms in the wider community.",,2021-10-30,,"['weirui ye', 'shaohuai liu', 'thanard kurutach', 'pieter abbeel', 'yang gao']"
2111.00229,fuzzy conceptual graphs: a comparative discussion,cs.ai cs.it cs.lo math.it,"conceptual graphs (cg) are a graph-based knowledge representation and reasoning formalism; fuzzy conceptual graphs (fcg) constitute an extension that enriches their expressiveness, exploiting the fuzzy set theory so as to relax their constraints at various levels. this paper proposes a comparative study of existing approaches over their respective advantages and possible limitations. the discussion revolves around three axes: (a) critical view of each approach and comparison with previous propositions from the state of the art; (b) presentation of the many possible interpretations of each definition to illustrate its potential and its limits; (c) clarification of the part of cg impacted by the definition as well as the relaxed constraint.",,2021-10-26,,"['adam faci', 'marie-jeanne lesot', 'claire laudy']"
2111.00234,on joint learning for solving placement and routing in chip design,cs.lg cs.ai,"for its advantage in gpu acceleration and less dependency on human experts, machine learning has been an emerging tool for solving the placement and routing problems, as two critical steps in modern chip design flow. being still in its early stage, there are fundamental issues: scalability, reward design, and end-to-end learning paradigm etc. to achieve end-to-end placement learning, we first propose a joint learning method termed by deepplace for the placement of macros and standard cells, by the integration of reinforcement learning with a gradient based optimization scheme. to further bridge the placement with the subsequent routing task, we also develop a joint learning approach via reinforcement learning to fulfill both macro placement and routing, which is called deeppr. one key design in our (reinforcement) learning paradigm involves a multi-view embedding model to encode both global graph level and local node level information of the input macros. moreover, the random network distillation is devised to encourage exploration. experiments on public chip design benchmarks show that our method can effectively learn from experience and also provides intermediate placement for the post standard cell placement, within few hours for training.",,2021-10-30,,"['ruoyu cheng', 'junchi yan']"
2111.00278,a decentralized reinforcement learning framework for efficient passage   of emergency vehicles,cs.ai cs.sy eess.sy,"emergency vehicles (emvs) play a critical role in a city's response to time-critical events such as medical emergencies and fire outbreaks. the existing approaches to reduce emv travel time employ route optimization and traffic signal pre-emption without accounting for the coupling between route these two subproblems. as a result, the planned route often becomes suboptimal. in addition, these approaches also do not focus on minimizing disruption to the overall traffic flow. to address these issues, we introduce emvlight in this paper. this is a decentralized reinforcement learning (rl) framework for simultaneous dynamic routing and traffic signal control. emvlight extends dijkstra's algorithm to efficiently update the optimal route for an emv in real-time as it travels through the traffic network. consequently, the decentralized rl agents learn network-level cooperative traffic signal phase strategies that reduce emv travel time and the average travel time of non-emvs in the network. we have carried out comprehensive experiments with synthetic and real-world maps to demonstrate this benefit. our results show that emvlight outperforms benchmark transportation engineering techniques as well as existing rl-based traffic signal control methods.",,2021-10-30,2021-11-08,"['haoran su', 'yaofeng desmond zhong', 'biswadip dey', 'amit chakraborty']"
2111.00289,intrusion prevention through optimal stopping,cs.lg cs.ai cs.cr cs.ni,"we study automated intrusion prevention using reinforcement learning. following a novel approach, we formulate the problem of intrusion prevention as an (optimal) multiple stopping problem. this formulation gives us insight into the structure of optimal policies, which we show to have threshold properties. for most practical cases, it is not feasible to obtain an optimal defender policy using dynamic programming. we therefore develop a reinforcement learning approach to approximate an optimal policy. our method for learning and validating policies includes two systems: a simulation system where defender policies are incrementally learned and an emulation system where statistics are produced that drive simulation runs and where learned policies are evaluated. we show that our approach can produce effective defender policies for a practical it infrastructure of limited size. inspection of the learned policies confirms that they exhibit threshold properties.",,2021-10-30,,"['kim hammar', 'rolf stadler']"
2111.00293,long-range route-planning for autonomous vehicles in the polar oceans,cs.ro cs.ai,"there is an increasing demand for piloted autonomous underwater vehicles (auvs) to operate in polar ice conditions. at present, auvs are deployed from ships and directly human-piloted in these regions, entailing a high carbon cost and limiting the scope of operations. a key requirement for long-term autonomous missions is a long-range route planning capability that is aware of the changing ice conditions. in this paper we address the problem of automating long-range route-planning for auvs operating in the southern ocean. we present the route-planning method and results showing that efficient, ice-avoiding, long-distance traverses can be planned.",,2021-10-30,,"['maria fox', 'michael meredith', 'j. alexander brearley', 'dan jones', 'derek long']"
2111.00309,targetum: targeted high-utility itemset querying,cs.db cs.ai,"traditional high-utility itemset mining (huim) aims to determine all high-utility itemsets (huis) that satisfy the minimum utility threshold (\textit{minutil}) in transaction databases. however, in most applications, not all huis are interesting because only specific parts are required. thus, targeted mining based on user preferences is more important than traditional mining tasks. this paper is the first to propose a target-based huim problem and to provide a clear formulation of the targeted utility mining task in a quantitative transaction database. a tree-based algorithm known as target-based high-utility itemset querying using (targetum) is proposed. the algorithm uses a lexicographic querying tree and three effective pruning strategies to improve the mining efficiency. we implemented experimental validation on several real and synthetic databases, and the results demonstrate that the performance of \textbf{targetum} is satisfactory, complete, and correct. finally, owing to the lexicographic querying tree, the database no longer needs to be scanned repeatedly for multiple queries.",,2021-10-30,,"['jinbao miao', 'shicheng wan', 'wensheng gan', 'jiayi sun', 'jiahui chen']"
2111.00310,empbot: a t5-based empathetic chatbot focusing on sentiments,cs.cl cs.ai,"in this paper, we introduce empbot: an end-to-end empathetic chatbot. empathetic conversational agents should not only understand what is being discussed, but also acknowledge the implied feelings of the conversation partner and respond appropriately. to this end, we propose a method based on a transformer pretrained language model (t5). specifically, during finetuning we propose to use three objectives: response language modeling, sentiment understanding, and empathy forcing. the first objective is crucial for generating relevant and coherent responses, while the next ones are significant for acknowledging the sentimental state of the conversational partner and for favoring empathetic responses. we evaluate our model on the empatheticdialogues dataset using both automated metrics and human evaluation. the inclusion of the sentiment understanding and empathy forcing auxiliary losses favor empathetic responses, as human evaluation results indicate, comparing with the current state-of-the-art.",,2021-10-30,,"['emmanouil zaranis', 'georgios paraskevopoulos', 'athanasios katsamanis', 'alexandros potamianos']"
2111.00312,3dp3: 3d scene perception via probabilistic programming,cs.cv cs.ai,"we present 3dp3, a framework for inverse graphics that uses inference in a structured generative model of objects, scenes, and images. 3dp3 uses (i) voxel models to represent the 3d shape of objects, (ii) hierarchical scene graphs to decompose scenes into objects and the contacts between them, and (iii) depth image likelihoods based on real-time graphics. given an observed rgb-d image, 3dp3's inference algorithm infers the underlying latent 3d scene, including the object poses and a parsimonious joint parametrization of these poses, using fast bottom-up pose proposals, novel involutive mcmc updates of the scene graph structure, and, optionally, neural object detectors and pose estimators. we show that 3dp3 enables scene understanding that is aware of 3d shape, occlusion, and contact structure. our results demonstrate that 3dp3 is more accurate at 6dof object pose estimation from real images than deep learning baselines and shows better generalization to challenging scenes with novel viewpoints, contact, and partial observability.",,2021-10-30,,"['nishad gothoskar', 'marco cusumano-towner', 'ben zinberg', 'matin ghavamizadeh', 'falk pollok', 'austin garrett', 'joshua b. tenenbaum', 'dan gutfreund', 'vikash k. mansinghka']"
2111.00320,speaker conditioning of acoustic models using affine transformation for   multi-speaker speech recognition,eess.as cs.ai cs.lg cs.sd eess.sp,"this study addresses the problem of single-channel automatic speech recognition of a target speaker within an overlap speech scenario. in the proposed method, the hidden representations in the acoustic model are modulated by speaker auxiliary information to recognize only the desired speaker. affine transformation layers are inserted into the acoustic model network to integrate speaker information with the acoustic features. the speaker conditioning process allows the acoustic model to perform computation in the context of target-speaker auxiliary information. the proposed speaker conditioning method is a general approach and can be applied to any acoustic model architecture. here, we employ speaker conditioning on a resnet acoustic model. experiments on the wsj corpus show that the proposed speaker conditioning method is an effective solution to fuse speaker auxiliary information with acoustic features for multi-speaker speech recognition, achieving +9% and +20% relative wer reduction for clean and overlap speech scenarios, respectively, compared to the original resnet acoustic model baseline.",,2021-10-30,,"['midia yousefi', 'john h. l. hanse']"
2111.00341,causal discovery in linear structural causal models with deterministic   relations,cs.lg cs.ai cs.it math.it stat.ml,"linear structural causal models (scms) -- in which each observed variable is generated by a subset of the other observed variables as well as a subset of the exogenous sources -- are pervasive in causal inference and casual discovery. however, for the task of causal discovery, existing work almost exclusively focus on the submodel where each observed variable is associated with a distinct source with non-zero variance. this results in the restriction that no observed variable can deterministically depend on other observed variables or latent confounders. in this paper, we extend the results on structure learning by focusing on a subclass of linear scms which do not have this property, i.e., models in which observed variables can be causally affected by any subset of the sources, and are allowed to be a deterministic function of other observed variables or latent confounders. this allows for a more realistic modeling of influence or information propagation in systems. we focus on the task of causal discovery form observational data generated from a member of this subclass. we derive a set of necessary and sufficient conditions for unique identifiability of the causal structure. to the best of our knowledge, this is the first work that gives identifiability results for causal discovery under both latent confounding and deterministic relationships. further, we propose an algorithm for recovering the underlying causal structure when the aforementioned conditions are satisfied. we validate our theoretical results both on synthetic and real datasets.",,2021-10-30,,"['yuqin yang', 'mohamed nafea', 'amiremad ghassami', 'negar kiyavash']"
2111.00345,multi-agent advisor q-learning,cs.ai cs.ma,"in the last decade, there have been significant advances in multi-agent reinforcement learning (marl) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possible. however, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. an interesting question which arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. in this paper, we provide a principled framework for incorporating action recommendations from online sub-optimal advisors in multi-agent settings. we describe the problem of advising multiple intelligent reinforcement agents (admiral) in nonrestrictive general-sum stochastic game environments and present two novel q-learning based algorithms: admiral - decision making (admiral-dm) and admiral - advisor evaluation (admiral-ae), which allow us to improve learning by appropriately incorporating advice from an advisor (admiral-dm), and evaluate the effectiveness of an advisor (admiral-ae). we analyze the algorithms theoretically and provide fixed-point guarantees regarding their learning in general-sum stochastic games. furthermore, extensive experiments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.",,2021-10-25,2021-11-08,"['sriram ganapathi subramanian', 'matthew e. taylor', 'kate larson', 'mark crowley']"
2111.00358,a survey on the robustness of feature importance and counterfactual   explanations,cs.lg cs.ai,"there exist several methods that aim to address the crucial task of understanding the behaviour of ai/ml models. arguably, the most popular among them are local explanations that focus on investigating model behaviour for individual instances. several methods have been proposed for local analysis, but relatively lesser effort has gone into understanding if the explanations are robust and accurately reflect the behaviour of underlying models. in this work, we present a survey of the works that analysed the robustness of two classes of local explanations (feature importance and counterfactual explanations) that are popularly used in analysing ai/ml models in finance. the survey aims to unify existing definitions of robustness, introduces a taxonomy to classify different robustness approaches, and discusses some interesting results. finally, the survey introduces some pointers about extending current robustness analysis approaches so as to identify reliable explainability methods.",,2021-10-30,,"['saumitra mishra', 'sanghamitra dutta', 'jason long', 'daniele magazzeni']"
2111.00364,"sustainable ai: environmental implications, challenges and opportunities",cs.lg cs.ai cs.ar,"this paper explores the environmental impact of the super-linear growth trends for ai from a holistic perspective, spanning data, algorithms, and system hardware. we characterize the carbon footprint of ai computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. taking a step further, we capture the operational and manufacturing carbon footprint of ai computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of ai. based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of ai. we hope the key messages and insights presented in this paper can inspire the community to advance the field of ai in an environmentally-responsible manner.",,2021-10-30,,"['carole-jean wu', 'ramya raghavendra', 'udit gupta', 'bilge acun', 'newsha ardalani', 'kiwan maeng', 'gloria chang', 'fiona aga behram', 'james huang', 'charles bai', 'michael gschwind', 'anurag gupta', 'myle ott', 'anastasia melnikov', 'salvatore candido', 'david brooks', 'geeta chauhan', 'benjamin lee', 'hsien-hsin s. lee', 'bugra akyildiz', 'maximilian balandat', 'joe spisak', 'ravi jain', 'mike rabbat', 'kim hazelwood']"
2111.00375,conical classification for computationally efficient one-class topic   determination,cs.ai,"as the internet grows in size, so does the amount of text based information that exists. for many application spaces it is paramount to isolate and identify texts that relate to a particular topic. while one-class classification would be ideal for such analysis, there is a relative lack of research regarding efficient approaches with high predictive power. by noting that the range of documents we wish to identify can be represented as positive linear combinations of the vector space model representing our text, we propose conical classification, an approach that allows us to identify if a document is of a particular topic in a computationally efficient manner. we also propose normal exclusion, a modified version of bi-normal separation that makes it more suitable within the one-class classification context. we show in our analysis that our approach not only has higher predictive power on our datasets, but is also faster to compute.",,2021-10-30,,['sameer khanna']
2111.00395,a robust single-pixel particle image velocimetry based on fully   convolutional networks with cross-correlation embedded,physics.flu-dyn cs.ai cs.cv,"particle image velocimetry (piv) is essential in experimental fluid dynamics. in the current work, we propose a new velocity field estimation paradigm, which achieves a synergetic combination of the deep learning method and the traditional cross-correlation method. specifically, the deep learning method is used to optimize and correct a coarse velocity guess to achieve a super-resolution calculation. and the cross-correlation method provides the initial velocity field based on a coarse correlation with a large interrogation window. as a reference, the coarse velocity guess helps with improving the robustness of the proposed algorithm. this fully convolutional network with embedded cross-correlation is named as cc-fcn. cc-fcn has two types of input layers, one is for the particle images, and the other is for the initial velocity field calculated using cross-correlation with a coarse resolution. firstly, two pyramidal modules extract features of particle images and initial velocity field respectively. then the fusion module appropriately fuses these features. finally, cc-fcn achieves the super-resolution calculation through a series of deconvolution layers to obtain the single-pixel velocity field. as the supervised learning strategy is considered, synthetic data sets including ground-truth fluid motions are generated to train the network parameters. synthetic and real experimental piv data sets are used to test the trained neural network in terms of accuracy, precision, spatial resolution and robustness. the test results show that these attributes of cc-fcn are further improved compared with those of other tested piv algorithms. the proposed model could therefore provide competitive and robust estimations for piv experiments.",,2021-10-30,,"['qi gao', 'hongtao lin', 'han tu', 'haoran zhu', 'runjie wei', 'guoping zhang', 'xueming shao']"
2111.00398,a simple approach to image tilt correction with self-attention mobilenet   for smartphones,cs.cv cs.ai,"the main contributions of our work are two-fold. first, we present a self-attention mobilenet, called sa-mobilenet network that can model long-range dependencies between the image features instead of processing the local region as done by standard convolutional kernels. sa-mobilenet contains self-attention modules integrated with the inverted bottleneck blocks of the mobilenetv3 model which results in modeling of both channel-wise attention and spatial attention of the image features and at the same time introduce a novel self-attention architecture for low-resource devices. secondly, we propose a novel training pipeline for the task of image tilt detection. we treat this problem in a multi-label scenario where we predict multiple angles for a tilted input image in a narrow interval of range 1-2 degrees, depending on the dataset used. this process induces an implicit correlation between labels without any computational overhead of the second or higher-order methods in multi-label learning. with the combination of our novel approach and the architecture, we present state-of-the-art results on detecting the image tilt angle on mobile devices as compared to the mobilenetv3 model. finally, we establish that sa-mobilenet is more accurate than mobilenetv3 on sun397, nyu-v1, and ade20k datasets by 6.42%, 10.51%, and 9.09% points respectively, and faster by at least 4 milliseconds on snapdragon 750 octa-core.",,2021-10-30,,"['siddhant garg', 'debi prasanna mohanty', 'siva prasad thota', 'sukumar moharana']"
2111.00419,interpreting deep knowledge tracing model on ednet dataset,cs.ai,"with more deep learning techniques being introduced into the knowledge tracing domain, the interpretability issue of the knowledge tracing models has aroused researchers' attention. our previous study(lu et al. 2020) on building and interpreting the kt model mainly adopts the assistment dataset(feng, heffernan, and koedinger 2009),, whose size is relatively small. in this work, we perform the similar tasks but on a large and newly available dataset, called ednet(choi et al. 2020). the preliminary experiment results show the effectiveness of the interpreting techniques, while more questions and tasks are worthy to be further explored and accomplished.",,2021-10-31,,"['deliang wang', 'yu lu', 'qinggang meng', 'penghe chen']"
2111.00424,artificial association neural networks,cs.ai,"in the field of deep learning, various architectures have been developed. however, most studies are limited to specific tasks or datasets due to their fixed layer structure. this paper does not express the structure delivering information as a network model but as a data structure called an association tree(at). and we propose two artificial association networks(aans) designed to solve the problems of existing networks by analyzing the structure of human neural networks. defining the starting and ending points of the path in a single graph is difficult, and a tree cannot express the relationship among sibling nodes. on the contrary, an at can express leaf and root nodes as the starting and ending points of the path and the relationship among sibling nodes. instead of using fixed sequence layers, we create an at for each data and train aans according to the tree's structure. aans are data-driven learning in which the number of convolutions varies according to the depth of the tree. moreover, aans can simultaneously learn various types of datasets through the recursive learning. depth-first convolution (dfc) encodes the interaction result from leaf nodes to the root node in a bottom-up approach, and depth-first deconvolution (dfd) decodes the interaction result from the root node to the leaf nodes in a top-down approach. we conducted three experiments. the first experiment verified whether it could be processed by combining aans and feature extraction networks. in the second, we compared the performance of networks that separately learned image, sound, and tree, graph structure datasets with the performance simultaneously learned by connecting these networks. in the third, we verified whether the output of aans can embed all data in the at. as a result, aats learned without significant performance degradation.",,2021-10-31,2021-11-17,"['seokjun kim', 'jaeeun jang', 'hee-seok jung', 'hyeoncheol kim']"
2111.00490,dsc-iitism at fincausal 2021: combining pos tagging with attention-based   contextual representations for identifying causal relationships in financial   documents,cs.cl cs.ai,"causality detection draws plenty of attention in the field of natural language processing and linguistics research. it has essential applications in information retrieval, event prediction, question answering, financial analysis, and market research. in this study, we explore several methods to identify and extract cause-effect pairs in financial documents using transformers. for this purpose, we propose an approach that combines pos tagging with the bio scheme, which can be integrated with modern transformer models to address this challenge of identifying causality in a given text. our best methodology achieves an f1-score of 0.9551, and an exact match score of 0.8777 on the blind test in the fincausal-2021 shared task at the fincausal 2021 workshop.",,2021-10-31,,"['gunjan haldar', 'aman mittal', 'pradyumna gupta']"
2111.00506,pnpood : out-of-distribution detection for text classification via plug   andplay data augmentation,cs.ai,"while out-of-distribution (ood) detection has been well explored in computer vision, there have been relatively few prior attempts in ood detection for nlp classification. in this paper we argue that these prior attempts do not fully address the ood problem and may suffer from data leakage and poor calibration of the resulting models. we present pnpood, a data augmentation technique to perform ood detection via out-of-domain sample generation using the recently proposed plug and play language model (dathathri et al., 2020). our method generates high quality discriminative samples close to the class boundaries, resulting in accurate ood detection at test time. we demonstrate that our model outperforms prior models on ood sample detection, and exhibits lower calibration error on the 20 newsgroup text and stanford sentiment treebank dataset (lang, 1995; socheret al., 2013). we further highlight an important data leakage issue with datasets used in prior attempts at ood detection, and share results on a new dataset for ood detection that does not suffer from the same problem.",,2021-10-31,,"['mrinal rawat', 'ramya hebbalaguppe', 'lovekesh vig']"
2111.00528,calibrating the dice loss to handle neural network overconfidence for   biomedical image segmentation,eess.iv cs.ai cs.cv math.oc,"the dice similarity coefficient (dsc) is both a widely used metric and loss function for biomedical image segmentation due to its robustness to class imbalance. however, it is well known that the dsc loss is poorly calibrated, resulting in overconfident predictions that cannot be usefully interpreted in biomedical and clinical practice. performance is often the only metric used to evaluate segmentations produced by deep neural networks, and calibration is often neglected. however, calibration is important for translation into biomedical and clinical practice, providing crucial contextual information to model predictions for interpretation by scientists and clinicians. in this study, we identify poor calibration as an emerging challenge of deep learning based biomedical image segmentation. we provide a simple yet effective extension of the dsc loss, named the dsc++ loss, that selectively modulates the penalty associated with overconfident, incorrect predictions. as a standalone loss function, the dsc++ loss achieves significantly improved calibration over the conventional dsc loss across five well-validated open-source biomedical imaging datasets. similarly, we observe significantly improved when integrating the dsc++ loss into four dsc-based loss functions. finally, we use softmax thresholding to illustrate that well calibrated outputs enable tailoring of precision-recall bias, an important post-processing technique to adapt the model predictions to suit the biomedical or clinical task. the dsc++ loss overcomes the major limitation of the dsc, providing a suitable loss function for training deep learning segmentation models for use in biomedical and clinical practice.",,2021-10-31,,"['michael yeung', 'leonardo rundo', 'yang nan', 'evis sala', 'carola-bibiane schönlieb', 'guang yang']"
2111.00533,incorporating boundary uncertainty into loss functions for biomedical   image segmentation,eess.iv cs.ai cs.cv math.oc,"manual segmentation is used as the gold-standard for evaluating neural networks on automated image segmentation tasks. due to considerable heterogeneity in shapes, colours and textures, demarcating object boundaries is particularly difficult in biomedical images, resulting in significant inter and intra-rater variability. approaches, such as soft labelling and distance penalty term, apply a global transformation to the ground truth, redefining the loss function with respect to uncertainty. however, global operations are computationally expensive, and neither approach accurately reflects the uncertainty underlying manual annotation. in this paper, we propose the boundary uncertainty, which uses morphological operations to restrict soft labelling to object boundaries, providing an appropriate representation of uncertainty in ground truth labels, and may be adapted to enable robust model training where systematic manual segmentation errors are present. we incorporate boundary uncertainty with the dice loss, achieving consistently improved performance across three well-validated biomedical imaging datasets compared to soft labelling and distance-weighted penalty. boundary uncertainty not only more accurately reflects the segmentation process, but it is also efficient, robust to segmentation errors and exhibits better generalisation.",,2021-10-31,,"['michael yeung', 'guang yang', 'evis sala', 'carola-bibiane schönlieb', 'leonardo rundo']"
2111.00534,focal attention networks: optimising attention for biomedical image   segmentation,eess.iv cs.ai cs.cv math.oc,"in recent years, there has been increasing interest to incorporate attention into deep learning architectures for biomedical image segmentation. the modular design of attention mechanisms enables flexible integration into convolutional neural network architectures, such as the u-net. whether attention is appropriate to use, what type of attention to use, and where in the network to incorporate attention modules, are all important considerations that are currently overlooked. in this paper, we investigate the role of the focal parameter in modulating attention, revealing a link between attention in loss functions and networks. by incorporating a focal distance penalty term, we extend the unified focal loss framework to include boundary-based losses. furthermore, we develop a simple and interpretable, dataset and model-specific heuristic to integrate the focal parameter into the squeeze-and-excitation block and attention gate, achieving optimal performance with fewer number of attention modules on three well-validated biomedical imaging datasets, suggesting judicious use of attention modules results in better performance and efficiency.",,2021-10-31,,"['michael yeung', 'leonardo rundo', 'evis sala', 'carola-bibiane schönlieb', 'guang yang']"
2111.00539,cross-domain reasoning via template filling,cs.cl cs.ai,"in this paper, we explore the ability of sequence to sequence models to perform cross-domain reasoning. towards this, we present a prompt-template-filling approach to enable sequence to sequence models to perform cross-domain reasoning. we also present a case-study with commonsense and health and well-being domains, where we study how prompt-template-filling enables pretrained sequence to sequence models across domains. our experiments across several pretrained encoder-decoder models show that cross-domain reasoning is challenging for current models. we also show an in-depth error analysis and avenues for future research for reasoning across domains",,2021-10-31,,"['dheeraj rajagopal', 'vivek khetan', 'bogdan sacaleanu', 'anatole gershman', 'andrew fano', 'eduard hovy']"
2111.00552,fast global convergence of policy optimization for constrained mdps,cs.lg cs.ai math.oc,"we address the issue of safety in reinforcement learning. we pose the problem in a discounted infinite-horizon constrained markov decision process framework. existing results have shown that gradient-based methods are able to achieve an $\mathcal{o}(1/\sqrt{t})$ global convergence rate both for the optimality gap and the constraint violation. we exhibit a natural policy gradient-based algorithm that has a faster convergence rate $\mathcal{o}(\log(t)/t)$ for both the optimality gap and the constraint violation. when slater's condition is satisfied and known a priori, zero constraint violation can be further guaranteed for a sufficiently large $t$ while maintaining the same convergence rate.",,2021-10-31,,"['tao liu', 'ruida zhou', 'dileep kalathil', 'p. r. kumar', 'chao tian']"
2111.00570,an approach to inference-driven dialogue management within a social   chatbot,cs.cl cs.ai,"we present a chatbot implementing a novel dialogue management approach based on logical inference. instead of framing conversation a sequence of response generation tasks, we model conversation as a collaborative inference process in which speakers share information to synthesize new knowledge in real time. our chatbot pipeline accomplishes this modelling in three broad stages. the first stage translates user utterances into a symbolic predicate representation. the second stage then uses this structured representation in conjunction with a larger knowledge base to synthesize new predicates using efficient graph matching. in the third and final stage, our bot selects a small subset of predicates and translates them into an english response. this approach lends itself to understanding latent semantics of user inputs, flexible initiative taking, and responses that are novel and coherent with the dialogue context.",,2021-10-31,,"['sarah e. finch', 'james d. finch', 'daniil huryn', 'william hutsell', 'xiaoyuan huang', 'han he', 'jinho d. choi']"
2111.00572,what went wrong? explaining overall dialogue quality through   utterance-level impacts,cs.cl cs.ai,"improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings. this paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality. unlike prior work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting. experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable.",,2021-10-31,,"['james d. finch', 'sarah e. finch', 'jinho d. choi']"
2111.00585,jedai explains decision-making ai,cs.ai cs.ro,"this paper presents jedai, an ai system designed for outreach and educational efforts aimed at non-ai experts. jedai features a novel synthesis of research ideas from integrated task and motion planning and explainable ai. jedai helps users create high-level, intuitive plans while ensuring that they will be executable by the robot. it also provides users customized explanations about errors and helps improve their understanding of ai planning as well as the limits and capabilities of the underlying robot system.",,2021-10-31,,"['trevor angle', 'naman shah', 'pulkit verma', 'siddharth srivastava']"
2111.00592,unsupervised learning to subphenotype delirium patients from electronic   health records,cs.lg cs.ai,"delirium is a common acute onset brain dysfunction in the emergency setting and is associated with higher mortality. it is difficult to detect and monitor since its presentations and risk factors can be different depending on the underlying medical condition of patients. in our study, we aimed to identify subtypes within the delirium population and build subgroup-specific predictive models to detect delirium using medical information mart for intensive care iv (mimic-iv) data. we showed that clusters exist within the delirium population. differences in feature importance were also observed for subgroup-specific predictive models. our work could recalibrate existing delirium prediction models for each delirium subgroup and improve the precision of delirium detection and monitoring for icu or emergency department patients who had highly heterogeneous medical conditions.",,2021-10-31,,"['yiqing zhao', 'yuan luo']"
2111.00595,torchxrayvision: a library of chest x-ray datasets and models,eess.iv cs.ai cs.cv,"torchxrayvision is an open source software library for working with chest x-ray datasets and deep learning models. it provides a common interface and common pre-processing chain for a wide set of publicly available chest x-ray datasets. in addition, a number of classification and representation learning models with different architectures, trained on different data combinations, are available through the library to serve as baselines or feature extractors.",,2021-10-31,,"['joseph paul cohen', 'joseph d. viviano', 'paul bertin', 'paul morrison', 'parsa torabian', 'matteo guarrera', 'matthew p lungren', 'akshay chaudhari', 'rupert brooks', 'mohammad hashir', 'hadrien bertrand']"
2111.00604,graph embedding with hierarchical attentive membership,cs.ai cs.si,"the exploitation of graph structures is the key to effectively learning representations of nodes that preserve useful information in graphs. a remarkable property of graph is that a latent hierarchical grouping of nodes exists in a global perspective, where each node manifests its membership to a specific group based on the context composed by its neighboring nodes. most prior works ignore such latent groups and nodes' membership to different groups, not to mention the hierarchy, when modeling the neighborhood structure. thus, they fall short of delivering a comprehensive understanding of the nodes under different contexts in a graph. in this paper, we propose a novel hierarchical attentive membership model for graph embedding, where the latent memberships for each node are dynamically discovered based on its neighboring context. both group-level and individual-level attentions are performed when aggregating neighboring states to generate node embeddings. we introduce structural constraints to explicitly regularize the inferred memberships of each node, such that a well-defined hierarchical grouping structure is captured. the proposed model outperformed a set of state-of-the-art graph embedding solutions on node classification and link prediction tasks in a variety of graphs including citation networks and social networks. qualitative evaluations visualize the learned node embeddings along with the inferred memberships, which proved the concept of membership hierarchy and enables explainable embedding learning in graphs.",,2021-10-31,,"['lu lin', 'ethan blaser', 'hongning wang']"
2111.00611,r-bert-cnn: drug-target interactions extraction from biomedical   literature,cs.cl cs.ai cs.ir,"in this research, we present our work participation for the drugprot task of biocreative vii challenge. drug-target interactions (dtis) are critical for drug discovery and repurposing, which are often manually extracted from the experimental articles. there are >32m biomedical articles on pubmed and manually extracting dtis from such a huge knowledge base is challenging. to solve this issue, we provide a solution for track 1, which aims to extract 10 types of interactions between drug and protein entities. we applied an ensemble classifier model that combines biomed-roberta, a state of art language model, with convolutional neural networks (cnn) to extract these relations. despite the class imbalances in the biocreative vii drugprot test corpus, our model achieves a good performance compared to the average of other submissions in the challenge, with the micro f1 score of 55.67% (and 63% on biocreative vi chemprot test corpus). the results show the potential of deep learning in extracting various types of dtis.",,2021-10-31,,"['jehad aldahdooh', 'ziaurrehman tanoli', 'jing tang']"
2111.00621,clinical evidence engine: proof-of-concept for a   clinical-domain-agnostic decision support infrastructure,cs.ai cs.hc,"abstruse learning algorithms and complex datasets increasingly characterize modern clinical decision support systems (cdss). as a result, clinicians cannot easily or rapidly scrutinize the cdss recommendation when facing a difficult diagnosis or treatment decision in practice. over-trust or under-trust are frequent. prior research has explored supporting such assessments by explaining dst data inputs and algorithmic mechanisms. this paper explores a different approach: providing precisely relevant, scientific evidence from biomedical literature. we present a proof-of-concept system, clinical evidence engine, to demonstrate the technical and design feasibility of this approach across three domains (cardiovascular diseases, autism, cancer). leveraging clinical biobert, the system can effectively identify clinical trial reports based on lengthy clinical questions (e.g., ""risks of catheter infection among adult patients in intensive care unit who require arterial catheters, if treated with povidone iodine-alcohol""). this capability enables the system to identify clinical trials relevant to diagnostic/treatment hypotheses -- a clinician's or a cdss's. further, clinical evidence engine can identify key parts of a clinical trial abstract, including patient population (e.g., adult patients in intensive care unit who require arterial catheters), intervention (povidone iodine-alcohol), and outcome (risks of catheter infection). this capability opens up the possibility of enabling clinicians to 1) rapidly determine the match between a clinical trial and a clinical question, and 2) understand the result and contexts of the trial without extensive reading. we demonstrate this potential by illustrating two example use scenarios of the system. we discuss the idea of designing dst explanations not as specific to a dst or an algorithm, but as a domain-agnostic decision support infrastructure.",,2021-10-31,,"['bojian hou', 'hao zhang', 'gur ladizhinsky', 'gur ladizhinsky', 'stephen yang', 'volodymyr kuleshov', 'fei wang', 'qian yang']"
2111.00633,settling the horizon-dependence of sample complexity in reinforcement   learning,cs.lg cs.ai cs.ds math.oc stat.ml,"recently there is a surge of interest in understanding the horizon-dependence of the sample complexity in reinforcement learning (rl). notably, for an rl environment with horizon length $h$, previous work have shown that there is a probably approximately correct (pac) algorithm that learns an $o(1)$-optimal policy using $\mathrm{polylog}(h)$ episodes of environment interactions when the number of states and actions is fixed. it is yet unknown whether the $\mathrm{polylog}(h)$ dependence is necessary or not. in this work, we resolve this question by developing an algorithm that achieves the same pac guarantee while using only $o(1)$ episodes of environment interactions, completely settling the horizon-dependence of the sample complexity in rl. we achieve this bound by (i) establishing a connection between value functions in discounted and finite-horizon markov decision processes (mdps) and (ii) a novel perturbation analysis in mdps. we believe our new techniques are of independent interest and could be applied in related questions in rl.",,2021-10-31,,"['yuanzhi li', 'ruosong wang', 'lin f. yang']"
2111.00639,end-to-end learning of deep kernel acquisition functions for bayesian   optimization,stat.ml cs.ai cs.lg,"for bayesian optimization (bo) on high-dimensional data with complex structure, neural network-based kernels for gaussian processes (gps) have been used to learn flexible surrogate functions by the high representation power of deep learning. however, existing methods train neural networks by maximizing the marginal likelihood, which do not directly improve the bo performance. in this paper, we propose a meta-learning method for bo with neural network-based kernels that minimizes the expected gap between the true optimum value and the best value found by bo. we model a policy, which takes the current evaluated data points as input and outputs the next data point to be evaluated, by a neural network, where neural network-based kernels, gps, and mutual information-based acquisition functions are used as its layers. with our model, the neural network-based kernel is trained to be appropriate for the acquisition function by backpropagating the gap through the acquisition function and gp. our model is trained by a reinforcement learning framework from multiple tasks. since the neural network is shared across different tasks, we can gather knowledge on bo from multiple training tasks, and use the knowledge for unseen test tasks. in experiments using three text document datasets, we demonstrate that the proposed method achieves better bo performance than the existing methods.",,2021-10-31,,['tomoharu iwata']
2111.00655,collage: automated integration of deep learning backends,cs.lg cs.ai,"strong demands for efficient deployment of deep learning (dl) applications prompt the rapid development of a rich dl ecosystem. to keep up with its fast advancement, it is crucial for dl frameworks to efficiently integrate a variety of optimized libraries and runtimes as their backends and generate the fastest possible executable by using them properly. however, current dl frameworks require significant manual effort to integrate diverse backends and often fail to deliver high performance. in this paper, we propose collage, an automatic framework for integrating dl backends. collage provides a backend registration interface that allows users to precisely specify the capability of various backends. by leveraging the specifications of available backends, collage searches for an optimized backend placement for a given workload and execution environment. our evaluation shows that collage automatically integrates multiple backends together without manual intervention, and outperforms existing frameworks by 1.21x, 1.39x, 1.40x on two different nvidia gpus and an intel cpu respectively.",,2021-10-31,,"['byungsoo jeon', 'sunghyun park', 'peiyuan liao', 'sheng xu', 'tianqi chen', 'zhihao jia']"
2111.00658,rmna: a neighbor aggregation-based knowledge graph representation   learning model using rule mining,cs.lg cs.ai,"although the state-of-the-art traditional representation learning (trl) models show competitive performance on knowledge graph completion, there is no parameter sharing between the embeddings of entities, and the connections between entities are weak. therefore, neighbor aggregation-based representation learning (narl) models are proposed, which encode the information in the neighbors of an entity into its embeddings. however, existing narl models either only utilize one-hop neighbors, ignoring the information in multi-hop neighbors, or utilize multi-hop neighbors by hierarchical neighbor aggregation, destroying the completeness of multi-hop neighbors. in this paper, we propose a narl model named rmna, which obtains and filters horn rules through a rule mining algorithm, and uses selected horn rules to transform valuable multi-hop neighbors into one-hop neighbors, therefore, the information in valuable multi-hop neighbors can be completely utilized by aggregating these one-hop neighbors. in experiments, we compare rmna with the state-of-the-art trl models and narl models. the results show that rmna has a competitive performance.",,2021-10-31,2021-11-04,"['ling chen', 'jun cui', 'xing tang', 'chaodu song', 'yuntao qian', 'yansheng li', 'yongjun zhang']"
2111.00670,comparative explanations of recommendations,cs.ir cs.ai cs.cl,"as recommendation is essentially a comparative (or ranking) process, a good explanation should illustrate to users why an item is believed to be better than another, i.e., comparative explanations about the recommended items. ideally, after reading the explanations, a user should reach the same ranking of items as the system's. unfortunately, little research attention has yet been paid on such comparative explanations.   in this work, we develop an extract-and-refine architecture to explain the relative comparisons among a set of ranked items from a recommender system. for each recommended item, we first extract one sentence from its associated reviews that best suits the desired comparison against a set of reference items. then this extracted sentence is further articulated with respect to the target user through a generative model to better explain why the item is recommended. we design a new explanation quality metric based on bleu to guide the end-to-end training of the extraction and refinement components, which avoids generation of generic content. extensive offline evaluations on two large recommendation benchmark datasets and serious user studies against an array of state-of-the-art explainable recommendation algorithms demonstrate the necessity of comparative explanations and the effectiveness of our solution.",,2021-10-31,,"['aobo yang', 'nan wang', 'renqin cai', 'hongbo deng', 'hongning wang']"
2111.00684,graph structural attack by spectral distance,cs.lg cs.ai cs.cr cs.si,"graph convolutional networks (gcns) have fueled a surge of interest due to their superior performance on graph learning tasks, but are also shown vulnerability to adversarial attacks. in this paper, an effective graph structural attack is investigated to disrupt graph spectral filters in the fourier domain. we define the spectral distance based on the eigenvalues of graph laplacian to measure the disruption of spectral filters. we then generate edge perturbations by simultaneously maximizing a task-specific attack objective and the proposed spectral distance. the experiments demonstrate remarkable effectiveness of the proposed attack in the white-box setting at both training and test time. our qualitative analysis shows the connection between the attack behavior and the imposed changes on the spectral distribution, which provides empirical evidence that maximizing spectral distance is an effective manner to change the structural property of graphs in the spatial domain and perturb the frequency components in the fourier domain.",,2021-11-01,2021-11-03,"['lu lin', 'ethan blaser', 'hongning wang']"
2111.00705,communication-compressed adaptive gradient method for distributed   nonconvex optimization,cs.lg cs.ai cs.dc math.oc stat.ml,"due to the explosion in the size of the training datasets, distributed learning has received growing interest in recent years. one of the major bottlenecks is the large communication cost between the central server and the local workers. while error feedback compression has been proven to be successful in reducing communication costs with stochastic gradient descent (sgd), there are much fewer attempts in building communication-efficient adaptive gradient methods with provable guarantees, which are widely used in training large-scale machine learning models. in this paper, we propose a new communication-compressed amsgrad for distributed nonconvex optimization problem, which is provably efficient. our proposed distributed learning framework features an effective gradient compression strategy and a worker-side model update design. we prove that the proposed communication-efficient distributed adaptive gradient method converges to the first-order stationary point with the same iteration complexity as uncompressed vanilla amsgrad in the stochastic nonconvex optimization setting. experiments on various benchmarks back up our theory.",,2021-11-01,,"['yujia wang', 'lu lin', 'jinghui chen']"
2111.00722,edge-level explanations for graph neural networks by extending   explainability methods for convolutional neural networks,cs.lg cs.ai,"graph neural networks (gnns) are deep learning models that take graph data as inputs, and they are applied to various tasks such as traffic prediction and molecular property prediction. however, owing to the complexity of the gnns, it has been difficult to analyze which parts of inputs affect the gnn model's outputs. in this study, we extend explainability methods for convolutional neural networks (cnns), such as local interpretable model-agnostic explanations (lime), gradient-based saliency maps, and gradient-weighted class activation mapping (grad-cam) to gnns, and predict which edges in the input graphs are important for gnn decisions. the experimental results indicate that the lime-based approach is the most efficient explainability method for multiple tasks in the real-world situation, outperforming even the state-of-the-art method in gnn explainability.",,2021-11-01,,"['tetsu kasanishi', 'xueting wang', 'toshihiko yamasaki']"
2111.00724,adaptive multi-receptive field spatial-temporal graph convolutional   network for traffic forecasting,cs.lg cs.ai,"mobile network traffic forecasting is one of the key functions in daily network operation. a commercial mobile network is large, heterogeneous, complex and dynamic. these intrinsic features make mobile network traffic forecasting far from being solved even with recent advanced algorithms such as graph convolutional network-based prediction approaches and various attention mechanisms, which have been proved successful in vehicle traffic forecasting. in this paper, we cast the problem as a spatial-temporal sequence prediction task. we propose a novel deep learning network architecture, adaptive multi-receptive field spatial-temporal graph convolutional networks (amf-stgcn), to model the traffic dynamics of mobile base stations. amf-stgcn extends gcn by (1) jointly modeling the complex spatial-temporal dependencies in mobile networks, (2) applying attention mechanisms to capture various receptive fields of heterogeneous base stations, and (3) introducing an extra decoder based on a fully connected deep network to conquer the error propagation challenge with multi-step forecasting. experiments on four real-world datasets from two different domains consistently show amf-stgcn outperforms the state-of-the-art methods.",,2021-11-01,,"['xing wang', 'juan zhao', 'lin zhu', 'xu zhou', 'zhao li', 'junlan feng', 'chao deng', 'yong zhang']"
2111.00732,outlining and filling: hierarchical query graph generation for answering   complex questions over knowledge graph,cs.ai cs.cl,"query graph building aims to build correct executable sparql over the knowledge graph for answering natural language questions. although recent approaches perform well by nn-based query graph ranking, more complex questions bring three new challenges: complicated sparql syntax, huge search space for ranking, and noisy query graphs with local ambiguity. this paper handles these challenges. initially, we regard common complicated sparql syntax as the sub-graphs comprising of vertices and edges and propose a new unified query graph grammar to adapt them. subsequently, we propose a new two-stage approach to build query graphs. in the first stage, the top-$k$ related instances (entities, relations, etc.) are collected by simple strategies, as the candidate instances. in the second stage, a graph generation model performs hierarchical generation. it first outlines a graph structure whose vertices and edges are empty slots, and then fills the appropriate instances into the slots, thereby completing the query graph. our approach decomposes the unbearable search space of entire query graphs into affordable sub-spaces of operations, meanwhile, leverages the global structural information to eliminate local ambiguity. the experimental results demonstrate that our approach greatly improves state-of-the-art on the hardest kgqa benchmarks and has an excellent performance on complex questions.",,2021-11-01,,"['yongrui chen', 'huiying li', 'guilin qi', 'tianxing wu', 'tenggou wang']"
2111.00734,robust deep learning from crowds with belief propagation,cs.lg cs.ai stat.ml,"crowdsourcing systems enable us to collect noisy labels from crowd workers. a graphical model representing local dependencies between workers and tasks provides a principled way of reasoning over the true labels from the noisy answers. however, one needs a predictive model working on unseen data directly from crowdsourced datasets instead of the true labels in many cases. to infer true labels and learn a predictive model simultaneously, we propose a new data-generating process, where a neural network generates the true labels from task features. we devise an em framework alternating variational inference and deep learning to infer the true labels and to update the neural network, respectively. experimental results with synthetic and real datasets show a belief-propagation-based em algorithm is robust to i) corruption in task features, ii) multi-modal or mismatched worker prior, and iii) few spammers submitting noises to many tasks.",,2021-11-01,,"['hoyoung kim', 'seunghyuk cho', 'dongwoo kim', 'jungseul ok']"
2111.00739,urir: recommendation algorithm of user rnn encoder and item encoder   based on knowledge graph,cs.ir cs.ai,"due to a large amount of information, it is difficult for users to find what they are interested in among the many choices. in order to improve users' experience, recommendation systems have been widely used in music recommendations, movie recommendations, online shopping, and other scenarios. recently, knowledge graph (kg) has been proven to be an effective tool to improve the performance of recommendation systems. however, a huge challenge in applying knowledge graphs for recommendation is how to use knowledge graphs to obtain better user codes and item codes. in response to this problem, this research proposes a user recurrent neural network (rnn) encoder and item encoder recommendation algorithm based on knowledge graph (urir). this study encodes items by capturing high-level neighbor information to generate items' representation vectors and applies an rnn and items' representation vectors to encode users to generate users' representation vectors, and then perform inner product operation on users' representation vectors and items' representation vectors to get probabilities of users interaction with items. numerical experiments on three real-world datasets demonstrate that urir is superior performance to state-of-the-art algorithms in indicators such as auc, precision, recall, and mrr. this implies that urir can effectively use knowledge graph to obtain better user codes and item codes, thereby obtaining better recommendation results.",,2021-11-01,,"['na zhao', 'zhen long', 'zhi-dan zhao', 'jian wang']"
2111.00743,towards the generalization of contrastive self-supervised learning,cs.lg cs.ai cs.cv stat.ml,"recently, self-supervised learning has attracted great attention since it only requires unlabeled data for training. contrastive learning is a popular approach for self-supervised learning and empirically performs well in practice. however, the theoretical understanding of its generalization ability on downstream tasks is not well studied. to this end, we present a theoretical explanation of how contrastive self-supervised pre-trained models generalize to downstream tasks. concretely, we quantitatively show that the self-supervised model has generalization ability on downstream classification tasks if it embeds input data into a feature space with distinguishing centers of classes and closely clustered intra-class samples. with the above conclusion, we further explore simclr and barlow twins, which are two canonical contrastive self-supervised methods. we prove that the aforementioned feature space can be obtained via any of the methods, and thus explain their success on the generalization on downstream classification tasks. finally, various experiments are also conducted to verify our theoretical findings.",,2021-11-01,,"['weiran huang', 'mingyang yi', 'xuyang zhao']"
2111.00765,"validate on sim, detect on real -- model selection for domain   randomization",cs.ro cs.ai cs.lg,"a practical approach to learning robot skills, often termed sim2real, is to train control policies in simulation and then deploy them on a real robot. popular techniques to improve the sim2real transfer build on domain randomization (dr): training the policy on a diverse set of randomly generated domains with the hope of better generalization to the real world. due to the large number of hyper-parameters in both the policy learning and dr algorithms, one often ends up with a large number of trained models, where choosing the best model among them demands costly evaluation on the real robot. in this work we ask: can we rank the policies without running them in the real world? our main idea is that a predefined set of real world data can be used to evaluate all policies, using out-of-distribution detection (ood) techniques. in a sense, this approach can be seen as a ""unit test"" to evaluate policies before any real world execution. however, we find that by itself, the ood score can be inaccurate and very sensitive to the particular ood method. our main contribution is a simple-yet-effective policy score that combines ood with an evaluation in simulation. we show that our score - vsdr - can significantly improve the accuracy of policy ranking without requiring additional real world data. we evaluate the effectiveness of vsdr on sim2real transfer in a robotic grasping task with image inputs. we extensively evaluate different dr parameters and ood methods, and show that vsdr improves policy selection across the board. more importantly, our method achieves significantly better ranking, and uses significantly less data compared to baselines.",,2021-11-01,,"['gal leibovich', 'guy jacob', 'shadi endrawis', 'gal novik', 'aviv tamar']"
2111.00783,an ai-powered smart routing solution for payment systems,cs.ai,"in the current era of digitization, online payment systems are attracting considerable interest. improving the efficiency of a payment system is important since it has a substantial impact on revenues for businesses. a gateway is an integral component of a payment system through which every transaction is routed. in an online payment system, payment processors integrate with these gateways by means of various configurations such as pricing, methods, risk checks, etc. these configurations are called terminals. each gateway can have multiple terminals associated with it. routing a payment transaction through the best terminal is crucial to increase the probability of a payment transaction being successful. machine learning (ml) and artificial intelligence (ai) techniques can be used to accurately predict the best terminals based on their previous performance and various payment-related attributes. we have devised a pipeline consisting of static and dynamic modules. the static module does the initial filtering of the terminals using static rules and a logistic regression model that predicts gateway downtimes. subsequently, the dynamic module computes a lot of novel features based on success rate, payment attributes, time lag, etc. to model the terminal behaviour accurately. these features are updated using an adaptive time decay rate algorithm in real-time using a feedback loop and passed to a random forest classifier to predict the success probabilities for every terminal. this pipeline is currently in production at razorpay routing millions of transactions through it in real-time and has given a 4-6\% improvement in success rate across all payment methods (credit card, debit card, upi, net banking). this has made our payment system more resilient to performance drops, which has improved the user experience, instilled more trust in the merchants, and boosted the revenue of the business.",,2021-11-01,,"['ramya bygari', 'aayush gupta', 'shashwat raghuvanshi', 'aakanksha bapna', 'birendra sahu']"
2111.00787,knowledge-driven site selection via urban knowledge graph,cs.ai,"site selection determines optimal locations for new stores, which is of crucial importance to business success. especially, the wide application of artificial intelligence with multi-source urban data makes intelligent site selection promising. however, existing data-driven methods heavily rely on feature engineering, facing the issues of business generalization and complex relationship modeling. to get rid of the dilemma, in this work, we borrow ideas from knowledge graph (kg), and propose a knowledge-driven model for site selection, short for knowsite. specifically, motivated by distilled knowledge and rich semantics in kg, we firstly construct an urban kg (urbankg) with cities' key elements and semantic relationships captured. based on urbankg, we employ pre-training techniques for semantic representations, which are fed into an encoder-decoder structure for site decisions. with multi-relational message passing and relation path-based attention mechanism developed, knowsite successfully reveals the relationship between various businesses and site selection criteria. extensive experiments on two datasets demonstrate that knowsite outperforms representative baselines with both effectiveness and explainability achieved.",,2021-11-01,,"['yu liu', 'jingtao ding', 'yong li']"
2111.00801,livestock monitoring with transformer,cs.cv cs.ai,"tracking the behaviour of livestock enables early detection and thus prevention of contagious diseases in modern animal farms. apart from economic gains, this would reduce the amount of antibiotics used in livestock farming which otherwise enters the human diet exasperating the epidemic of antibiotic resistance - a leading cause of death. we could use standard video cameras, available in most modern farms, to monitor livestock. however, most computer vision algorithms perform poorly on this task, primarily because, (i) animals bred in farms look identical, lacking any obvious spatial signature, (ii) none of the existing trackers are robust for long duration, and (iii) real-world conditions such as changing illumination, frequent occlusion, varying camera angles, and sizes of the animals make it hard for models to generalize. given these challenges, we develop an end-to-end behaviour monitoring system for group-housed pigs to perform simultaneous instance level segmentation, tracking, action recognition and re-identification (star) tasks. we present starformer, the first end-to-end multiple-object livestock monitoring framework that learns instance-level embeddings for grouped pigs through the use of transformer architecture. for benchmarking, we present pigtrace, a carefully curated dataset comprising video sequences with instance level bounding box, segmentation, tracking and activity classification of pigs in real indoor farming environment. using simultaneous optimization on star tasks we show that starformer outperforms popular baseline models trained for individual tasks.",,2021-11-01,2021-11-02,"['bhavesh tangirala', 'ishan bhandari', 'daniel laszlo', 'deepak k. gupta', 'rajat m. thomas', 'devanshu arya']"
2111.00821,towards reformulating essence specifications for robustness,cs.ai cs.pl,"the essence language allows a user to specify a constraint problem at a level of abstraction above that at which constraint modelling decisions are made. essence specifications are refined into constraint models using the conjure automated modelling tool, which employs a suite of refinement rules. however, essence is a rich language in which there are many equivalent ways to specify a given problem. a user may therefore omit the use of domain attributes or abstract types, resulting in fewer refinement rules being applicable and therefore a reduced set of output models from which to select. this paper addresses the problem of recovering this information automatically to increase the robustness of the quality of the output constraint models in the face of variation in the input essence specification. we present reformulation rules that can change the type of a decision variable or add attributes that shrink its domain. we demonstrate the efficacy of this approach in terms of the quantity and quality of models conjure can produce from the transformed specification compared with the original.",,2021-11-01,,"['özgür akgün', 'alan m. frisch', 'ian p. gent', 'christopher jefferson', 'ian miguel', 'peter nightingale', 'andrás z. salamon']"
2111.00826,"teaching fairness, accountability, confidentiality, and transparency in   artificial intelligence through the lens of reproducibility",cs.ai,"in this work we explain the setup for a technical, graduate-level course on fairness, accountability, confidentiality and transparency in artificial intelligence (fact-ai) at the university of amsterdam, which teaches fact-ai concepts through the lens of reproducibility. the focal point of the course is a group project based on reproducing existing fact-ai algorithms from top ai conferences, and writing a report about their experiences. in the first iteration of the course, we created an open source repository with the code implementations from the group projects. in the second iteration, we encouraged students to submit their group projects to the machine learning reproducibility challenge, which resulted in 9 reports from our course being accepted to the challenge. we reflect on our experience teaching the course over two academic years, where one year coincided with a global pandemic, and propose guidelines for teaching fact-ai through reproducibility in graduate-level ai programs. we hope this can be a useful resource for instructors to set up similar courses at their universities in the future.",,2021-11-01,2021-11-09,"['ana lucic', 'maurits bleeker', 'sami jullien', 'samarth bhargav', 'maarten de rijke']"
2111.00830,deep learning transformer architecture for named entity recognition on   low resourced languages: state of the art results,cs.cl cs.ai,"this paper reports on the evaluation of deep learning (dl) transformer architecture models for named-entity recognition (ner) on ten low-resourced south african (sa) languages. in addition, these dl transformer models were compared to other neural network and machine learning (ml) ner models. the findings show that transformer models significantly improve performance when applying discrete fine-tuning parameters per language. furthermore, fine-tuned transformer models outperform other neural network and machine learning models with ner on the low-resourced sa languages. for example, the transformer models generated the highest f-scores for six of the ten sa languages, including the highest average f-score surpassing the conditional random fields ml model. additional research could evaluate the more recent transformer architecture models on other natural language processing tasks and applications, such as phrase chunking, machine translation, and part-of-speech tagging.",,2021-11-01,,['ridewaan hanslo']
2111.00837,simulating realistic mri variations to improve deep learning model and   visual explanations using gradcam,eess.iv cs.ai cs.cv,"in the medical field, landmark detection in mri plays an important role in reducing medical technician efforts in tasks like scan planning, image registration, etc. first, 88 landmarks spread across the brain anatomy in the three respective views -- sagittal, coronal, and axial are manually annotated, later guidelines from the expert clinical technicians are taken sub-anatomy-wise, for better localization of the existing landmarks, in order to identify and locate the important atlas landmarks even in oblique scans. to overcome limited data availability, we implement realistic data augmentation to generate synthetic 3d volumetric data. we use a modified highres3dnet model for solving brain mri volumetric landmark detection problem. in order to visually explain our trained model on unseen data, and discern a stronger model from a weaker model, we implement gradient-weighted class activation mapping (grad-cam) which produces a coarse localization map highlighting the regions the model is focusing. our experiments show that the proposed method shows favorable results, and the overall pipeline can be extended to a variable number of landmarks and other anatomies.",,2021-11-01,,"['muhammad ilyas patel', 'shrey singla', 'razeem ahmad ali mattathodi', 'sumit sharma', 'deepam gautam', 'srinivasa rao kundeti']"
2111.00841,"free probability, newton lilypads and jacobians of neural networks",stat.ml cs.ai cs.lg math.oc math.pr,"gradient descent during the learning process of a neural network can be subject to many instabilities. the spectral density of the jacobian is a key component for analyzing robustness. following the works of pennington et al., such jacobians are modeled using free multiplicative convolutions from free probability theory. we present a reliable and very fast method for computing the associated spectral densities. this method has a controlled and proven convergence.   our technique is based on an adaptative newton-raphson scheme, by finding and chaining basins of attraction: the newton algorithm finds contiguous lilypad-like basins and steps from one to the next, heading towards the objective.   we demonstrate the applicability of our method by using it to assess how the learning process is affected by network depth, layer widths and initialization choices: empirically, final test losses are very correlated to our free probability metrics.",,2021-11-01,,"['reda chhaibi', 'tariq daouda', 'ezechiel kahn']"
2111.00862,surreal decisions,cs.ai cs.lg econ.th,"although expected utility theory has proven a fruitful and elegant theory in the finite realm, attempts to generalize it to infinite values have resulted in many paradoxes. in this paper, we argue that the use of john conway's surreal numbers shall provide a firm mathematical foundation for transfinite decision theory. to that end, we prove a surreal representation theorem and show that our surreal decision theory respects dominance reasoning even in the case of infinite values. we then bring our theory to bear on one of the more venerable decision problems in the literature: pascal's wager. analyzing the wager showcases our theory's virtues and advantages. to that end, we analyze two objections against the wager: mixed strategies and many gods. after formulating the two objections in the framework of surreal utilities and probabilities, our theory correctly predicts that (1) the pure pascalian strategy beats all mixed strategies, and (2) what one should do in a pascalian decision problem depends on what one's credence function is like. our analysis therefore suggests that although pascal's wager is mathematically coherent, it does not deliver what it purports to, a rationally compelling argument that people should lead a religious life regardless of how confident they are in theism and its alternatives.",10.1111/phpr.12510,2021-10-23,,"['eddy keming chen', 'daniel rubio']"
2111.00867,interpretive blindness,cs.ai cs.cl,"we model here an epistemic bias we call \textit{interpretive blindness} (ib). ib is a special problem for learning from testimony, in which one acquires information only from text or conversation. we show that ib follows from a co-dependence between background beliefs and interpretation in a bayesian setting and the nature of contemporary testimony. we argue that a particular characteristic contemporary testimony, \textit{argumentative completeness}, can preclude learning in hierarchical bayesian settings, even in the presence of constraints that are designed to promote good epistemic practices.",,2021-10-19,,"['nicholas asher', 'julie hunter']"
2111.00869,detectornet: transformer-enhanced spatial temporal graph neural network   for traffic prediction,cs.cv cs.ai cs.lg,"detectors with high coverage have direct and far-reaching benefits for road users in route planning and avoiding traffic congestion, but utilizing these data presents unique challenges including: the dynamic temporal correlation, and the dynamic spatial correlation caused by changes in road conditions. although the existing work considers the significance of modeling with spatial-temporal correlation, what it has learned is still a static road network structure, which cannot reflect the dynamic changes of roads, and eventually loses much valuable potential information. to address these challenges, we propose detectornet enhanced by transformer. differs from previous studies, our model contains a multi-view temporal attention module and a dynamic attention module, which focus on the long-distance and short-distance temporal correlation, and dynamic spatial correlation by dynamically updating the learned knowledge respectively, so as to make accurate prediction. in addition, the experimental results on two public datasets and the comparison results of four ablation experiments proves that the performance of detectornet is better than the eleven advanced baselines.",10.1145/3474717.3483920,2021-10-18,,"['he li', 'shiyu zhang', 'xuejiao li', 'liangcai su', 'hongjie huang', 'duo jin', 'linghao chen', 'jianbing huang', 'jaesoo yoo']"
2111.00876,on the expressivity of markov reward,cs.lg cs.ai,"reward is the driving force for reinforcement-learning agents. this paper is dedicated to understanding the expressivity of reward as a way to capture tasks that we would want an agent to perform. we frame this study around three new abstract notions of ""task"" that might be desirable: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering over trajectories. our main results prove that while reward can express many of these tasks, there exist instances of each task type that no markov reward function can capture. we then provide a set of polynomial-time algorithms that construct a markov reward function that allows an agent to optimize tasks of each of these three types, and correctly determine when no such reward function exists. we conclude with an empirical study that corroborates and illustrates our theoretical findings.",,2021-11-01,,"['david abel', 'will dabney', 'anna harutyunyan', 'mark k. ho', 'michael l. littman', 'doina precup', 'satinder singh']"
2111.00886,intervention efficient algorithm for two-stage causal mdps,cs.lg cs.ai,"we study markov decision processes (mdp) wherein states correspond to causal graphs that stochastically generate rewards. in this setup, the learner's goal is to identify atomic interventions that lead to high rewards by intervening on variables at each state. generalizing the recent causal-bandit framework, the current work develops (simple) regret minimization guarantees for two-stage causal mdps, with parallel causal graph at each state. we propose an algorithm that achieves an instance dependent regret bound. a key feature of our algorithm is that it utilizes convex optimization to address the exploration problem. we identify classes of instances wherein our regret guarantee is essentially tight, and experimentally validate our theoretical results.",,2021-11-01,,"['rahul madhavan', 'aurghya maiti', 'gaurav sinha', 'siddharth barman']"
2111.00905,smart fashion: a review of ai applications in the fashion & apparel   industry,cs.cv cs.ai cs.lg,"the fashion industry is on the verge of an unprecedented change. the implementation of machine learning, computer vision, and artificial intelligence (ai) in fashion applications is opening lots of new opportunities for this industry. this paper provides a comprehensive survey on this matter, categorizing more than 580 related articles into 22 well-defined fashion-related tasks. such structured task-based multi-label classification of fashion research articles provides researchers with explicit research directions and facilitates their access to the related studies, improving the visibility of studies simultaneously. for each task, a time chart is provided to analyze the progress through the years. furthermore, we provide a list of 86 public fashion datasets accompanied by a list of suggested applications and additional information for each.",,2021-10-28,2021-11-02,"['seyed omid mohammadi', 'ahmad kalhor']"
2111.00918,combining expert knowledge and neural networks to model environmental   stresses in agriculture,cs.lg cs.ai cs.cy,"in this work we combine representation learning capabilities of neural network with agricultural knowledge from experts to model environmental heat and drought stresses. we first design deterministic expert models which serve as a benchmark and inform the design of flexible neural-network architectures. finally, a sensitivity analysis of the latter allows a clustering of hybrids into susceptible and resistant ones.",,2021-10-26,,"['kostadin cvejoski', 'jannis schuecker', 'anne-katrin mahlein', 'bogdan georgiev']"
2111.00941,turning traffic monitoring cameras into intelligent sensors for traffic   density estimation,cs.cv cs.ai,"accurate traffic state information plays a pivotal role in the intelligent transportation systems (its), and it is an essential input to various smart mobility applications such as signal coordination and traffic flow prediction. the current practice to obtain the traffic state information is through specialized sensors such as loop detectors and speed cameras. in most metropolitan areas, traffic monitoring cameras have been installed to monitor the traffic conditions on arterial roads and expressways, and the collected videos or images are mainly used for visual inspection by traffic engineers. unfortunately, the data collected from traffic monitoring cameras are affected by the 4l characteristics: low frame rate, low resolution, lack of annotated data, and located in complex road environments. therefore, despite the great potentials of the traffic monitoring cameras, the 4l characteristics hinder them from providing useful traffic state information (e.g., speed, flow, density). this paper focuses on the traffic density estimation problem as it is widely applicable to various traffic surveillance systems. to the best of our knowledge, there is a lack of the holistic framework for addressing the 4l characteristics and extracting the traffic density information from traffic monitoring camera data. in view of this, this paper proposes a framework for estimating traffic density using uncalibrated traffic monitoring cameras with 4l characteristics. the proposed framework consists of two major components: camera calibration and vehicle detection. the camera calibration method estimates the actual length between pixels in the images and videos, and the vehicle counts are extracted from the deep-learning-based vehicle detection method. combining the two components, high-granular traffic density can be estimated. to validate the proposed framework, two case studies were conducted in hong kong and sacramento. the results show that the mean absolute error (mae) in camera calibration is less than 0.2 meters out of 6 meters, and the accuracy of vehicle detection under various conditions is approximately 90%. overall, the mae for the estimated density is 9.04 veh/km/lane in hong kong and 1.30 veh/km/lane in sacramento. the research outcomes can be used to calibrate the speed-density fundamental diagrams, and the proposed framework can provide accurate and real-time traffic information without installing additional sensors.",,2021-10-29,,"['zijian hu', 'william h. k. lam', 's. c. wong', 'andy h. f. chow', 'wei ma']"
2111.00960,gtfs2vec -- learning gtfs embeddings for comparing public transport   offer in microregions,cs.lg cs.ai,"we selected 48 european cities and gathered their public transport timetables in the gtfs format. we utilized uber's h3 spatial index to divide each city into hexagonal micro-regions. based on the timetables data we created certain features describing the quantity and variety of public transport availability in each region. next, we trained an auto-associative deep neural network to embed each of the regions. having such prepared representations, we then used a hierarchical clustering approach to identify similar regions. to do so, we utilized an agglomerative clustering algorithm with a euclidean distance between regions and ward's method to minimize in-cluster variance. finally, we analyzed the obtained clusters at different levels to identify some number of clusters that qualitatively describe public transport availability. we showed that our typology matches the characteristics of analyzed cities and allows succesful searching for areas with similar public transport schedule characteristics.",10.1145/3486640.3491392,2021-11-01,2021-11-02,"['piotr gramacki', 'szymon woźniak', 'piotr szymański']"
2111.00962,refinegan: universally generating waveform better than ground truth with   highly accurate pitch and intensity responses,cs.sd cs.ai eess.as,"most gan(generative adversarial network)-based approaches towards high-fidelity waveform generation heavily rely on discriminators to improve their performance. however, the over-use of this gan method introduces much uncertainty into the generation process and often result in mismatches of pitch and intensity, which is fatal when it comes to sensitive using cases such as singing voice synthesis(svs). to address this problem, we propose refinegan, a high-fidelity neural vocoder with faster-than-real-time generation capability, and focused on the robustness, pitch and intensity accuracy, and full-band audio generation. we employed a pitch-guided refine architecture with a multi-scale spectrogram-based loss function to help stabilize the training process and maintain the robustness of the neural vocoder while using the gan-based training method. audio generated using this method shows a better performance in subjective tests when compared with the ground-truth audio. this result shows that the fidelity is even improved during the waveform reconstruction by eliminating defects produced by the speaker and the recording procedure. moreover, a further study shows that models trained on a specified type of data can perform on totally unseen language and unseen speaker identically well. generated sample pairs are provided on https://timedomain-tech.github.io/refinegan/.",,2021-11-01,2021-11-02,"['shengyuan xu', 'wenxiao zhao', 'jing guo']"
2111.00966,vpfnet: voxel-pixel fusion network for multi-class 3d object detection,cs.cv cs.ai cs.lg cs.ro,"many lidar-based methods for detecting large objects, single-class object detection, or under easy situations were claimed to perform quite well. however, their performances of detecting small objects or under hard situations did not surpass those of the fusion-based ones due to failure to leverage the image semantics. in order to elevate the detection performance in a complicated environment, this paper proposes a deep learning (dl)-embedded fusion-based multi-class 3d object detection network which admits both lidar and camera sensor data streams, named voxel-pixel fusion network (vpfnet). inside this network, a key novel component is called voxel-pixel fusion (vpf) layer, which takes advantage of the geometric relation of a voxel-pixel pair and fuses the voxel features and the pixel features with proper mechanisms. moreover, several parameters are particularly designed to guide and enhance the fusion effect after considering the characteristics of a voxel-pixel pair. finally, the proposed method is evaluated on the kitti benchmark for multi-class 3d object detection task under multilevel difficulty, and is shown to outperform all state-of-the-art methods in mean average precision (map). it is also noteworthy that our approach here ranks the first on the kitti leaderboard for the challenging pedestrian class.",,2021-11-01,,"['chia-hung wang', 'hsueh-wei chen', 'li-chen fu']"
2111.00969,generative occupancy fields for 3d surface-aware image synthesis,cs.cv cs.ai,"the advent of generative radiance fields has significantly promoted the development of 3d-aware image synthesis. the cumulative rendering process in radiance fields makes training these generative models much easier since gradients are distributed over the entire volume, but leads to diffused object surfaces. in the meantime, compared to radiance fields occupancy representations could inherently ensure deterministic surfaces. however, if we directly apply occupancy representations to generative models, during training they will only receive sparse gradients located on object surfaces and eventually suffer from the convergence problem. in this paper, we propose generative occupancy fields (gof), a novel model based on generative radiance fields that can learn compact object surfaces without impeding its training convergence. the key insight of gof is a dedicated transition from the cumulative rendering in radiance fields to rendering with only the surface points as the learned surface gets more and more accurate. in this way, gof combines the merits of two representations in a unified framework. in practice, the training-time transition of start from radiance fields and march to occupancy representations is achieved in gof by gradually shrinking the sampling region in its rendering process from the entire volume to a minimal neighboring region around the surface. through comprehensive experiments on multiple datasets, we demonstrate that gof can synthesize high-quality images with 3d consistency and simultaneously learn compact and smooth object surfaces. code, models, and demo videos are available at https://sheldontsui.github.io/projects/gof",,2021-11-01,,"['xudong xu', 'xingang pan', 'dahua lin', 'bo dai']"
2111.00970,hex2vec -- context-aware embedding h3 hexagons with openstreetmap tags,cs.lg cs.ai,"representation learning of spatial and geographic data is a rapidly developing field which allows for similarity detection between areas and high-quality inference using deep neural networks. past approaches however concentrated on embedding raster imagery (maps, street or satellite photos), mobility data or road networks. in this paper we propose the first approach to learning vector representations of openstreetmap regions with respect to urban functions and land-use in a micro-region grid. we identify a subset of osm tags related to major characteristics of land-use, building and urban region functions, types of water, green or other natural areas. through manual verification of tagging quality, we selected 36 cities were for training region representations. uber's h3 index was used to divide the cities into hexagons, and osm tags were aggregated for each hexagon. we propose the hex2vec method based on the skip-gram model with negative sampling. the resulting vector representations showcase semantic structures of the map characteristics, similar to ones found in vector-based language models. we also present insights from region similarity detection in six polish cities and propose a region typology obtained through agglomerative clustering.",10.1145/3486635.3491076,2021-11-01,,"['szymon woźniak', 'piotr szymański']"
2111.00977,fast convolution based on winograd minimum filtering: introduction and   development,cs.ai cs.ar,"convolutional neural network (cnn) has been widely used in various fields and played an important role. convolution operators are the fundamental component of convolutional neural networks, and it is also the most time-consuming part of network training and inference. in recent years, researchers have proposed several fast convolution algorithms including fft and winograd. among them, winograd convolution significantly reduces the multiplication operations in convolution, and it also takes up less memory space than fft convolution. therefore, winograd convolution has quickly become the first choice for fast convolution implementation within a few years. at present, there is no systematic summary of the convolution algorithm. this article aims to fill this gap and provide detailed references for follow-up researchers. this article summarizes the development of winograd convolution from the three aspects of algorithm expansion, algorithm optimization, implementation, and application, and finally makes a simple outlook on the possible future directions.",10.5121/csit.2021.111716,2021-11-01,,"['gan tong', 'libo huang']"
2111.00987,modelling the transition to a low-carbon energy supply,econ.gn cs.ai cs.lg cs.ma q-fin.ec,"a transition to a low-carbon electricity supply is crucial to limit the impacts of climate change. reducing carbon emissions could help prevent the world from reaching a tipping point, where runaway emissions are likely. runaway emissions could lead to extremes in weather conditions around the world -- especially in problematic regions unable to cope with these conditions. however, the movement to a low-carbon energy supply can not happen instantaneously due to the existing fossil-fuel infrastructure and the requirement to maintain a reliable energy supply. therefore, a low-carbon transition is required, however, the decisions various stakeholders should make over the coming decades to reduce these carbon emissions are not obvious. this is due to many long-term uncertainties, such as electricity, fuel and generation costs, human behaviour and the size of electricity demand. a well choreographed low-carbon transition is, therefore, required between all of the heterogenous actors in the system, as opposed to changing the behaviour of a single, centralised actor. the objective of this thesis is to create a novel, open-source agent-based model to better understand the manner in which the whole electricity market reacts to different factors using state-of-the-art machine learning and artificial intelligence methods. in contrast to other works, this thesis looks at both the long-term and short-term impact that different behaviours have on the electricity market by using these state-of-the-art methods.",,2021-09-25,,['alexander kell']
2111.00990,transfer learning approach to bicycle-sharing systems' station location   planning using openstreetmap data,cs.lg cs.ai,"bicycle-sharing systems (bss) have become a daily reality for many citizens of larger, wealthier cities in developed regions. however, planning the layout of bicycle-sharing stations usually requires expensive data gathering, surveying travel behavior and trip modelling followed by station layout optimization. many smaller cities and towns, especially in developing areas, may have difficulty financing such projects. planning a bss also takes a considerable amount of time. yet as the pandemic has shown us, municipalities will face the need to adapt rapidly to mobility shifts, which include citizens leaving public transport for bicycles. laying out a bike sharing system quickly will become critical in addressing the increase in bike demand. this paper addresses the problem of cost and time in bss layout design and proposes a new solution to streamline and facilitate the process of such planning by using spatial embedding methods. based only on publicly available data from openstreetmap, and station layouts from 34 cities in europe, a method has been developed to divide cities into micro-regions using the uber h3 discrete global grid system and to indicate regions where it is worth placing a station based on existing systems in different cities using transfer learning. the result of the work is a mechanism to support planners in their decision making when planning a station layout with a choice of reference cities.",10.1145/3486626.3493434,2021-11-01,,"['kamil raczycki', 'piotr szymański']"
2111.01016,gomoku: analysis of the game and of the player wine,cs.ai,"gomoku, also known as five in a row, is a classical board game, ideally suited for quickly testing novel artificial intelligence (ai) techniques. with the aim of facilitating a developer willing to write a new gomoku player, in this report we present an analysis of the main game concepts and strategies, which is wider and deeper than existing ones. moreover, after discussing the general structure of an artificial player, we present and analyse a strong gomoku player, named wine, the code of which is freely available on the internet and which is an excelent example of how a modern player is organised.",,2021-11-01,,"['lorenzo piazzo', 'michele scarpiniti', 'enzo baccarelli']"
2111.01026,introspective distillation for robust question answering,cs.cv cs.ai cs.cl,"question answering (qa) models are well-known to exploit data bias, e.g., the language prior in visual qa and the position bias in reading comprehension. recent debiasing methods achieve good out-of-distribution (ood) generalizability with a considerable sacrifice of the in-distribution (id) performance. therefore, they are only applicable in domains where the test distribution is known in advance. in this paper, we present a novel debiasing method called introspective distillation (introd) to make the best of both worlds for qa. our key technical contribution is to blend the inductive bias of ood and id by introspecting whether a training sample fits in the factual id world or the counterfactual ood one. experiments on visual qa datasets vqa v2, vqa-cp, and reading comprehension dataset squad demonstrate that our proposed introd maintains the competitive ood performance compared to other debiasing methods, while sacrificing little or even achieving better id performance compared to the non-debiasing ones.",,2021-11-01,,"['yulei niu', 'hanwang zhang']"
2111.01042,logic rules meet deep learning: a novel approach for ship type   classification,cs.ai,"the shipping industry is an important component of the global trade and economy, however in order to ensure law compliance and safety it needs to be monitored. in this paper, we present a novel ship type classification model that combines vessel transmitted data from the automatic identification system, with vessel imagery. the main components of our approach are the faster r-cnn deep neural network and a neuro-fuzzy system with if-then rules. we evaluate our model using real world data and showcase the advantages of this combination while also compare it with other methods. results show that our model can increase prediction scores by up to 15.4\% when compared with the next best model we considered, while also maintaining a level of explainability as opposed to common black box approaches.",,2021-11-01,,"['manolis pitsikalis', 'thanh-toan do', 'alexei lisitsa', 'shan luo']"
2111.01048,most-gan: 3d morphable stylegan for disentangled face image manipulation,cs.cv cs.ai cs.gr cs.lg,"recent advances in generative adversarial networks (gans) have led to remarkable achievements in face image synthesis. while methods that use style-based gans can generate strikingly photorealistic face images, it is often difficult to control the characteristics of the generated faces in a meaningful and disentangled way. prior approaches aim to achieve such semantic control and disentanglement within the latent space of a previously trained gan. in contrast, we propose a framework that a priori models physical attributes of the face such as 3d shape, albedo, pose, and lighting explicitly, thus providing disentanglement by design. our method, most-gan, integrates the expressive power and photorealism of style-based gans with the physical disentanglement and flexibility of nonlinear 3d morphable models, which we couple with a state-of-the-art 2d hair manipulation network. most-gan achieves photorealistic manipulation of portrait images with fully disentangled 3d control over their physical attributes, enabling extreme manipulation of lighting, facial expression, and pose variations up to full profile view.",,2021-11-01,,"['safa c. medin', 'bernhard egger', 'anoop cherian', 'ye wang', 'joshua b. tenenbaum', 'xiaoming liu', 'tim k. marks']"
2111.01100,investigation of independent reinforcement learning algorithms in   multi-agent environments,cs.ma cs.ai cs.lg,"independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. however, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. in this paper, we carry out an empirical comparison of the performance of independent algorithms on four pettingzoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. we show that in fully-observable environments, independent algorithms can perform on par with multi-agent algorithms in cooperative and competitive settings. for the mixed environments, we show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies. we also show that adding recurrence improves the learning of independent algorithms in cooperative partially observable environments.",,2021-11-01,,"['ken ming lee', 'sriram ganapathi subramanian', 'mark crowley']"
2111.01104,notmad: estimating bayesian networks with sample-specific structures and   parameters,stat.ml cs.ai cs.lg,"context-specific bayesian networks (i.e. directed acyclic graphs, dags) identify context-dependent relationships between variables, but the non-convexity induced by the acyclicity requirement makes it difficult to share information between context-specific estimators (e.g. with graph generator functions). for this reason, existing methods for inferring context-specific bayesian networks have favored breaking datasets into subsamples, limiting statistical power and resolution, and preventing the use of multidimensional and latent contexts. to overcome this challenge, we propose notears-optimized mixtures of archetypal dags (notmad). notmad models context-specific bayesian networks as the output of a function which learns to mix archetypal networks according to sample context. the archetypal networks are estimated jointly with the context-specific networks and do not require any prior knowledge. we encode the acyclicity constraint as a smooth regularization loss which is back-propagated to the mixing function; in this way, notmad shares information between context-specific acyclic graphs, enabling the estimation of bayesian network structures and parameters at even single-sample resolution. we demonstrate the utility of notmad and sample-specific network inference through analysis and experiments, including patient-specific gene expression networks which correspond to morphological variation in cancer.",,2021-11-01,,"['ben lengerich', 'caleb ellington', 'bryon aragam', 'eric p. xing', 'manolis kellis']"
2111.01118,rebooting acgan: auxiliary classifier gans with stable training,cs.cv cs.ai cs.lg,"conditional generative adversarial networks (cgan) generate realistic images by incorporating class information into gan. while one of the most popular cgans is an auxiliary classifier gan with softmax cross-entropy loss (acgan), it is widely known that training acgan is challenging as the number of classes in the dataset increases. acgan also tends to generate easily classifiable samples with a lack of diversity. in this paper, we introduce two cures for acgan. first, we identify that gradient exploding in the classifier can cause an undesirable collapse in early training, and projecting input vectors onto a unit hypersphere can resolve the problem. second, we propose the data-to-data cross-entropy loss (d2d-ce) to exploit relational information in the class-labeled dataset. on this foundation, we propose the rebooted auxiliary classifier generative adversarial network (reacgan). the experimental results show that reacgan achieves state-of-the-art generation results on cifar10, tiny-imagenet, cub200, and imagenet datasets. we also verify that reacgan benefits from differentiable augmentations and that d2d-ce harmonizes with stylegan2 architecture. model weights and a software package that provides implementations of representative cgans and all experiments in our paper are available at https://github.com/postech-cvlab/pytorch-studiogan.",,2021-11-01,,"['minguk kang', 'woohyeon shim', 'minsu cho', 'jaesik park']"
2111.01122,"stakeholder participation in ai: beyond ""add diverse stakeholders and   stir""",cs.ai cs.cy cs.hc,"there is a growing consensus in hci and ai research that the design of ai systems needs to engage and empower stakeholders who will be affected by ai. however, the manner in which stakeholders should participate in ai design is unclear. this workshop paper aims to ground what we dub a 'participatory turn' in ai design by synthesizing existing literature on participation and through empirical analysis of its current practices via a survey of recent published research and a dozen semi-structured interviews with ai researchers and practitioners. based on our literature synthesis and empirical research, this paper presents a conceptual framework for analyzing participatory approaches to ai design and articulates a set of empirical findings that in ensemble detail out the contemporary landscape of participatory practice in ai design. these findings can help bootstrap a more principled discussion on how pd of ai should move forward across ai, hci, and other research communities.",,2021-11-01,,"['fernando delgado', 'stephen yang', 'michael madaio', 'qian yang']"
2111.01124,when does contrastive learning preserve adversarial robustness from   pretraining to finetuning?,cs.cv cs.ai cs.lg,"contrastive learning (cl) can learn generalizable feature representations and achieve the state-of-the-art performance of downstream tasks by finetuning a linear classifier on top of it. however, as adversarial robustness becomes vital in image classification, it remains unclear whether or not cl is able to preserve robustness to downstream tasks. the main challenge is that in the self-supervised pretraining + supervised finetuning paradigm, adversarial robustness is easily forgotten due to a learning task mismatch from pretraining to finetuning. we call such a challenge 'cross-task robustness transferability'. to address the above problem, in this paper we revisit and advance cl principles through the lens of robustness enhancement. we show that (1) the design of contrastive views matters: high-frequency components of images are beneficial to improving model robustness; (2) augmenting cl with pseudo-supervision stimulus (e.g., resorting to feature clustering) helps preserve robustness without forgetting. equipped with our new designs, we propose advcl, a novel adversarial contrastive pretraining framework. we show that advcl is able to enhance cross-task robustness transferability without loss of model accuracy and finetuning efficiency. with a thorough experimental study, we demonstrate that advcl outperforms the state-of-the-art self-supervised robust learning methods across multiple datasets (cifar-10, cifar-100, and stl-10) and finetuning schemes (linear evaluation and full model finetuning).",,2021-11-01,,"['lijie fan', 'sijia liu', 'pin-yu chen', 'gaoyuan zhang', 'chuang gan']"
2111.01131,hierarchical decision ensembles- an inferential framework for uncertain   human-ai collaboration in forensic examinations,cs.hc cs.ai cs.lg stat.ap,"forensic examination of evidence like firearms and toolmarks, traditionally involves a visual and therefore subjective assessment of similarity of two questioned items. statistical models are used to overcome this subjectivity and allow specification of error rates. these models are generally quite complex and produce abstract results at different levels of the analysis. presenting such metrics and complicated results to examiners is challenging, as examiners generally do not have substantial statistical training to accurately interpret results. this creates distrust in statistical modelling and lowers the rate of acceptance of more objective measures that the discipline at large is striving for. we present an inferential framework for assessing the model and its output. the framework is designed to calibrate trust in forensic experts by bridging the gap between domain specific knowledge and predictive model results, allowing forensic examiners to validate the claims of the predictive model while critically assessing results.",,2021-10-31,,"['ganesh krishnan', 'heike hofmann']"
2111.01136,asmdd: arabic speech mispronunciation detection dataset,cs.cl cs.ai cs.lg cs.ni,"the largest dataset of arabic speech mispronunciation detections in egyptian dialogues is introduced. the dataset is composed of annotated audio files representing the top 100 words that are most frequently used in the arabic language, pronounced by 100 egyptian children (aged between 2 and 8 years old). the dataset is collected and annotated on segmental pronunciation error detections by expert listeners.",,2021-11-01,,"['salah a. aly', 'abdelrahman salah', 'hesham m. eraqi']"
2111.01186,combining latent space and structured kernels for bayesian optimization   over combinatorial spaces,cs.lg cs.ai,"we consider the problem of optimizing combinatorial spaces (e.g., sequences, trees, and graphs) using expensive black-box function evaluations. for example, optimizing molecules for drug design using physical lab experiments. bayesian optimization (bo) is an efficient framework for solving such problems by intelligently selecting the inputs with high utility guided by a learned surrogate model. a recent bo approach for combinatorial spaces is through a reduction to bo over continuous spaces by learning a latent representation of structures using deep generative models (dgms). the selected input from the continuous space is decoded into a discrete structure for performing function evaluation. however, the surrogate model over the latent space only uses the information learned by the dgm, which may not have the desired inductive bias to approximate the target black-box function. to overcome this drawback, this paper proposes a principled approach referred as ladder. the key idea is to define a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. our experiments on real-world benchmarks show that ladder significantly improves over the bo over latent space method, and performs better or similar to state-of-the-art methods.",,2021-11-01,,"['aryan deshwal', 'janardhan rao doppa']"
2111.01201,unintended selection: persistent qualification rate disparities and   interventions,cs.lg cs.ai cs.gt cs.sy eess.sy,"realistically -- and equitably -- modeling the dynamics of group-level disparities in machine learning remains an open problem. in particular, we desire models that do not suppose inherent differences between artificial groups of people -- but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. in this paper, agents each have a real-valued feature $x$ (e.g., credit score) informed by a ""true"" binary label $y$ representing qualification (e.g., for a loan). each agent alternately (1) receives a binary classification label $\hat{y}$ (e.g., loan approval) from a bayes-optimal machine learning classifier observing $x$ and (2) may update their qualification $y$ by imitating successful strategies (e.g., seek a raise) within an isolated group $g$ of agents to which they belong. we consider the disparity of qualification rates $\pr(y=1)$ between different groups and how this disparity changes subject to a sequence of bayes-optimal classifiers repeatedly retrained on the global population. we model the evolving qualification rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. we show that differences in qualification rates between subpopulations can persist indefinitely for a set of non-trivial equilibrium states due to uniformed classifier deployments, even when groups are identical in all aspects except initial qualification densities. we next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualification rate disparities. we conclude by discussing the limitations of our model and findings and by outlining potential future work.",,2021-11-01,,"['reilly raab', 'yang liu']"
2111.01203,one proxy device is enough for hardware-aware neural architecture search,cs.lg cs.ai,"convolutional neural networks (cnns) are used in numerous real-world applications such as vision-based autonomous driving and video content analysis. to run cnn inference on various target devices, hardware-aware neural architecture search (nas) is crucial. a key requirement of efficient hardware-aware nas is the fast evaluation of inference latencies in order to rank different architectures. while building a latency predictor for each target device has been commonly used in state of the art, this is a very time-consuming process, lacking scalability in the presence of extremely diverse devices. in this work, we address the scalability challenge by exploiting latency monotonicity -- the architecture latency rankings on different devices are often correlated. when strong latency monotonicity exists, we can re-use architectures searched for one proxy device on new target devices, without losing optimality. in the absence of strong latency monotonicity, we propose an efficient proxy adaptation technique to significantly boost the latency monotonicity. finally, we validate our approach and conduct experiments with devices of different platforms on multiple mainstream search spaces, including mobilenet-v2, mobilenet-v3, nas-bench-201, proxylessnas and fbnet. our results highlight that, by using just one proxy device, we can find almost the same pareto-optimal architectures as the existing per-device nas, while avoiding the prohibitive cost of building a latency predictor for each device. github: https://github.com/ren-research/oneproxy",10.1145/3491046,2021-11-01,2021-11-02,"['bingqian lu', 'jianyi yang', 'weiwen jiang', 'yiyu shi', 'shaolei ren']"
2111.01216,learning to generate piano music with sustain pedals,cs.sd cs.ai cs.lg eess.as,"recent years have witnessed a growing interest in research related to the detection of piano pedals from audio signals in the music information retrieval community. however, to our best knowledge, recent generative models for symbolic music have rarely taken piano pedals into account. in this work, we employ the transcription model proposed by kong et al. to get pedal information from the audio recordings of piano performance in the ailabs1k7 dataset, and then modify the compound word transformer proposed by hsiao et al. to build a transformer decoder that generates pedal-related tokens along with other musical tokens. while the work is done by using inferred sustain pedal information as training data, the result shows hope for further improvement and the importance of the involvement of sustain pedal in tasks of piano performance generations.",,2021-11-01,,"['joann ching', 'yi-hsuan yang']"
2111.01225,identifying causal associations in tweets using deep learning: use case   on diabetes-related tweets from 2017-2021,cs.cl cs.ai cs.lg,"objective: leveraging machine learning methods, we aim to extract both explicit and implicit cause-effect associations in patient-reported, diabetes-related tweets and provide a tool to better understand opinion, feelings and observations shared within the diabetes online community from a causality perspective. materials and methods: more than 30 million diabetes-related tweets in english were collected between april 2017 and january 2021. deep learning and natural language processing methods were applied to focus on tweets with personal and emotional content. a cause-effect-tweet dataset was manually labeled and used to train 1) a fine-tuned bertweet model to detect causal sentences containing a causal association 2) a crf model with bert based features to extract possible cause-effect associations. causes and effects were clustered in a semi-supervised approach and visualised in an interactive cause-effect-network. results: causal sentences were detected with a recall of 68% in an imbalanced dataset. a crf model with bert based features outperformed a fine-tuned bert model for cause-effect detection with a macro recall of 68%. this led to 96,676 sentences with cause-effect associations. ""diabetes"" was identified as the central cluster followed by ""death"" and ""insulin"". insulin pricing related causes were frequently associated with ""death"". conclusions: a novel methodology was developed to detect causal sentences and identify both explicit and implicit, single and multi-word cause and corresponding effect as expressed in diabetes-related tweets leveraging bert-based architectures and visualised as cause-effect-network. extracting causal associations on real-life, patient reported outcomes in social media data provides a useful complementary source of information in diabetes research.",,2021-11-01,2021-11-04,"['adrian ahne', 'vivek khetan', 'xavier tannier', 'md imbessat hassan rizvi', 'thomas czernichow', 'francisco orchard', 'charline bour', 'andrew fano', 'guy fagherazzi']"
2111.01235,low-cost algorithmic recourse for users with uncertain cost functions,cs.lg cs.ai cs.cl,"the problem of identifying algorithmic recourse for people affected by machine learning model decisions has received much attention recently. some recent works model user-incurred cost, which is directly linked to user satisfaction. but they assume a single global cost function that is shared across all users. this is an unrealistic assumption when users have dissimilar preferences about their willingness to act upon a feature and different costs associated with changing that feature. in this work, we formalize the notion of user-specific cost functions and introduce a new method for identifying actionable recourses for users. by default, we assume that users' cost functions are hidden from the recourse method, though our framework allows users to partially or completely specify their preferences or cost function. we propose an objective function, expected minimum cost (emc), based on two key ideas: (1) when presenting a set of options to a user, it is vital that there is at least one low-cost solution the user could adopt; (2) when we do not know the user's true cost function, we can approximately optimize for user satisfaction by first sampling plausible cost functions, then finding a set that achieves a good cost for the user in expectation. we optimize emc with a novel discrete optimization algorithm, cost-optimized local search (cols), which is guaranteed to improve the recourse set quality over iterations. experimental evaluation on popular real-world datasets with simulated user costs demonstrates that our method satisfies up to 25.89 percentage points more users compared to strong baseline methods. using standard fairness metrics, we also show that our method can provide more fair solutions across demographic groups than comparable methods, and we verify that our method is robust to misspecification of the cost function distribution.",,2021-11-01,,"['prateek yadav', 'peter hase', 'mohit bansal']"
2111.01236,hrvit: multi-scale high-resolution vision transformer,cs.cv cs.ai cs.lg,"vision transformers (vits) have attracted much attention for their superior performance on computer vision tasks. to address their limitations of single-scale low-resolution representations, prior work adapts vits to high-resolution dense prediction tasks with hierarchical architectures to generate pyramid features. however, multi-scale representation learning is still under-explored on vits, given their classification-like sequential topology. to enhance vits with more capability to learn semantically-rich and spatially-precise multi-scale representations, in this work, we present an efficient integration of high-resolution multi-branch architectures with vision transformers, dubbed hrvit, pushing the pareto front of dense prediction tasks to a new level. we explore heterogeneous branch design, reduce the redundancy in linear layers, and augment the model nonlinearity to balance the model performance and hardware efficiency. the proposed hrvit achieves 50.20% miou on ade20k and 83.16% miou on cityscapes for semantic segmentation tasks, surpassing state-of-the-art mit and cswin with an average of +1.78 miou improvement, 28% parameter reduction, and 21% flops reduction, demonstrating the potential of hrvit as strong vision backbones.",,2021-11-01,,"['jiaqi gu', 'hyoukjun kwon', 'dilin wang', 'wei ye', 'meng li', 'yu-hsin chen', 'liangzhen lai', 'vikas chandra', 'david z. pan']"
2111.01243,recent advances in natural language processing via large pre-trained   language models: a survey,cs.cl cs.ai cs.lg,"large, pre-trained transformer-based language models such as bert have drastically changed the natural language processing (nlp) field. we present a survey of recent work that uses these large language models to solve nlp tasks via pre-training then fine-tuning, prompting, or text generation approaches. we also present approaches that use pre-trained language models to generate data for training augmentation or other purposes. we conclude with discussions on limitations and suggested directions for future research.",,2021-11-01,,"['bonan min', 'hayley ross', 'elior sulem', 'amir pouran ben veyseh', 'thien huu nguyen', 'oscar sainz', 'eneko agirre', 'ilana heinz', 'dan roth']"
2111.01306,on the current and emerging challenges of developing fair and ethical ai   solutions in financial services,cs.cy cs.ai cs.ce,"artificial intelligence (ai) continues to find more numerous and more critical applications in the financial services industry, giving rise to fair and ethical ai as an industry-wide objective. while many ethical principles and guidelines have been published in recent years, they fall short of addressing the serious challenges that model developers face when building ethical ai solutions. we survey the practical and overarching issues surrounding model development, from design and implementation complexities, to the shortage of tools, and the lack of organizational constructs. we show how practical considerations reveal the gaps between high-level principles and concrete, deployed ai applications, with the aim of starting industry-wide conversations toward solution approaches.",10.1145/3490354.3494408,2021-11-01,,"['eren kurshan', 'jiahao chen', 'victor storchan', 'hongda shen']"
2111.01338,federated split vision transformer for covid-19 cxr diagnosis using   task-agnostic training,eess.iv cs.ai cs.cv,"federated learning, which shares the weights of the neural network across clients, is gaining attention in the healthcare sector as it enables training on a large corpus of decentralized data while maintaining data privacy. for example, this enables neural network training for covid-19 diagnosis on chest x-ray (cxr) images without collecting patient cxr data across multiple hospitals. unfortunately, the exchange of the weights quickly consumes the network bandwidth if highly expressive network architecture is employed. so-called split learning partially solves this problem by dividing a neural network into a client and a server part, so that the client part of the network takes up less extensive computation resources and bandwidth. however, it is not clear how to find the optimal split without sacrificing the overall network performance. to amalgamate these methods and thereby maximize their distinct strengths, here we show that the vision transformer, a recently developed deep learning architecture with straightforward decomposable configuration, is ideally suitable for split learning without sacrificing performance. even under the non-independent and identically distributed data distribution which emulates a real collaboration between hospitals using cxr datasets from multiple sources, the proposed framework was able to attain performance comparable to data-centralized training. in addition, the proposed framework along with heterogeneous multi-task clients also improves individual task performances including the diagnosis of covid-19, eliminating the need for sharing large weights with innumerable parameters. our results affirm the suitability of transformer for collaborative learning in medical imaging and pave the way forward for future real-world implementations.",,2021-11-01,2021-11-03,"['sangjoon park', 'gwanghyun kim', 'jeongsol kim', 'boah kim', 'jong chul ye']"
2111.01364,learning to explore by reinforcement over high-level options,cs.ai,"autonomous 3d environment exploration is a fundamental task for various applications such as navigation. the goal of exploration is to investigate a new environment and build its occupancy map efficiently. in this paper, we propose a new method which grants an agent two intertwined options of behaviors: ""look-around"" and ""frontier navigation"". this is implemented by an option-critic architecture and trained by reinforcement learning algorithms. in each timestep, an agent produces an option and a corresponding action according to the policy. we also take advantage of macro-actions by incorporating classic path-planning techniques to increase training efficiency. we demonstrate the effectiveness of the proposed method on two publicly available 3d environment datasets and the results show our method achieves higher coverage than competing techniques with better efficiency.",,2021-11-02,,"['liu juncheng', 'mccane brendan', 'mills steven']"
2111.01366,improved loss function-based prediction method of extreme temperatures   in greenhouses,cs.ai,"the prediction of extreme greenhouse temperatures to which crops are susceptible is essential in the field of greenhouse planting. it can help avoid heat or freezing damage and economic losses. therefore, it's important to develop models that can predict them accurately. due to the lack of extreme temperature data in datasets, it is challenging for models to accurately predict it. in this paper, we propose an improved loss function, which is suitable for a variety of machine learning models. by increasing the weight of extreme temperature samples and reducing the possibility of misjudging extreme temperature as normal, the proposed loss function can enhance the prediction results in extreme situations. to verify the effectiveness of the proposed method, we implement the improved loss function in lightgbm, long short-term memory, and artificial neural network and conduct experiments on a real-world greenhouse dataset. the results show that the performance of models with the improved loss function is enhanced compared to the original models in extreme cases. the improved models can be used to guarantee the timely judgment of extreme temperatures in agricultural greenhouses, thereby preventing unnecessary losses caused by incorrect predictions.",,2021-11-02,,"['liao qu', 'shuaiqi huang', 'yunsong jia', 'xiang li']"
2111.01371,envelope imbalance learning algorithm based on multilayer fuzzy c-means   clustering and minimum interlayer discrepancy,cs.ai,"imbalanced learning is important and challenging since the problem of the classification of imbalanced datasets is prevalent in machine learning and data mining fields. sampling approaches are proposed to address this issue, and cluster-based oversampling methods have shown great potential as they aim to simultaneously tackle between-class and within-class imbalance issues. however, all existing clustering methods are based on a one-time approach. due to the lack of a priori knowledge, improper setting of the number of clusters often exists, which leads to poor clustering performance. besides, the existing methods are likely to generate noisy instances. to solve these problems, this paper proposes a deep instance envelope network-based imbalanced learning algorithm with the multilayer fuzzy c-means (mlfcm) and a minimum interlayer discrepancy mechanism based on the maximum mean discrepancy (midmd). this algorithm can guarantee high quality balanced instances using a deep instance envelope network in the absence of prior knowledge. in the experimental section, thirty-three popular public datasets are used for verification, and over ten representative algorithms are used for comparison. the experimental results show that the proposed approach significantly outperforms other popular methods.",,2021-11-02,,"['fan li', 'xiaoheng zhang', 'pin wang', 'yongming li']"
2111.01394,solving partial differential equations with point source based on   physics-informed neural networks,cs.lg cs.ai physics.comp-ph,"in recent years, deep learning technology has been used to solve partial differential equations (pdes), among which the physics-informed neural networks (pinns) emerges to be a promising method for solving both forward and inverse pde problems. pdes with a point source that is expressed as a dirac delta function in the governing equations are mathematical models of many physical processes. however, they cannot be solved directly by conventional pinns method due to the singularity brought by the dirac delta function. we propose a universal solution to tackle this problem with three novel techniques. firstly the dirac delta function is modeled as a continuous probability density function to eliminate the singularity; secondly a lower bound constrained uncertainty weighting algorithm is proposed to balance the pinns losses between point source area and other areas; and thirdly a multi-scale deep neural network with periodic activation function is used to improve the accuracy and convergence speed of the pinns method. we evaluate the proposed method with three representative pdes, and the experimental results show that our method outperforms existing deep learning-based methods with respect to the accuracy, the efficiency and the versatility.",,2021-11-02,,"['xiang huang', 'hongsheng liu', 'beiji shi', 'zidong wang', 'kang yang', 'yang li', 'bingya weng', 'min wang', 'haotian chu', 'jing zhou', 'fan yu', 'bei hua', 'lei chen', 'bin dong']"
2111.01398,integrating pretrained language model for dialogue policy learning,cs.cl cs.ai,"reinforcement learning (rl) has been witnessed its potential for training a dialogue policy agent towards maximizing the accumulated rewards given from users. however, the reward can be very sparse for it is usually only provided at the end of a dialog session, which causes unaffordable interaction requirements for an acceptable dialog agent. distinguished from many efforts dedicated to optimizing the policy and recovering the reward alternatively which suffers from easily getting stuck in local optima and model collapse, we decompose the adversarial training into two steps: 1) we integrate a pre-trained language model as a discriminator to judge whether the current system action is good enough for the last user action (i.e., \textit{next action prediction}); 2) the discriminator gives and extra local dense reward to guide the agent's exploration. the experimental result demonstrates that our method significantly improves the complete rate (~4.4\%) and success rate (~8.0\%) of the dialogue system.",,2021-11-02,,"['hongru wang', 'huimin wang', 'zezhong wang', 'kam-fai wong']"
2111.01414,a review of dialogue systems: from trained monkeys to stochastic parrots,cs.cl cs.ai,"in spoken dialogue systems, we aim to deploy artificial intelligence to build automated dialogue agents that can converse with humans. dialogue systems are increasingly being designed to move beyond just imitating conversation and also improve from such interactions over time. in this survey, we present a broad overview of methods developed to build dialogue systems over the years. different use cases for dialogue systems ranging from task-based systems to open domain chatbots motivate and necessitate specific systems. starting from simple rule-based systems, research has progressed towards increasingly complex architectures trained on a massive corpus of datasets, like deep learning systems. motivated with the intuition of resembling human dialogues, progress has been made towards incorporating emotions into the natural language generator, using reinforcement learning. while we see a trend of highly marginal improvement on some metrics, we find that limited justification exists for the metrics, and evaluation practices are not uniform. to conclude, we flag these concerns and highlight possible research directions.",,2021-11-02,,"['atharv singh patlan', 'shiven tripathi', 'shubham korde']"
2111.01415,icallee: recovering call graphs for binaries,cs.se cs.ai cs.cr,"recovering programs' call graphs is crucial for inter-procedural analysis tasks and applications based on them. the core challenge is recognizing targets of indirect calls (i.e., indirect callees). it becomes more challenging if target programs are in binary forms, due to information loss in binaries. existing indirect callee recognition solutions for binaries all have high false positives and negatives, making call graphs inaccurate.   in this paper, we propose a new solution icallee based on the siamese neural network, inspired by the advances in question-answering applications. the key insight is that, neural networks can learn to answer whether a callee function is a potential target of an indirect callsite by comprehending their contexts, i.e., instructions nearby callsites and of callees. following this insight, we first preprocess target binaries to extract contexts of callsites and callees. then, we build a customized natural language processing (nlp) model applicable to assembly language. further, we collect abundant pairs of callsites and callees, and embed their contexts with the nlp model, then train a siamese network and a classifier to answer the callsite-callee question. we have implemented a prototype of icallee and evaluated it on several groups of targets. evaluation results showed that, our solution could match callsites to callees with an f1-measure of 93.7%, recall of 93.8%, and precision of 93.5%, much better than state-of-the-art solutions. to show its usefulness, we apply icallee to two specific applications - binary code similarity detection and binary program hardening, and found that it could greatly improve state-of-the-art solutions.",,2021-11-02,2021-11-02,"['wenyu zhu', 'zhiyao feng', 'zihan zhang', 'zhijian ou', 'min yang', 'chao zhang']"
2111.01431,associational deductive networks,cs.ai,"we introduce associational deductive networks(adns), a network that performs deductive reasoning. to have high-dimensional thinking, combining various axioms and putting the results back into another axiom is necessary to produce new relationships and results. for example, it would be given two propositions: ""socrates is a man."" and ""all men are mortals."" and two propositions could be used to infer the new proposition, ""therefore socrates is mortal."". to evaluate, we used mnist dataset, a handwritten numerical image dataset, to apply it to the group theory and show the results of performing deductive learning.",,2021-11-02,2021-11-17,"['seokjun kim', 'jaeeun jang', 'hyeoncheol kim']"
2111.01456,wavesense: efficient temporal convolutions with spiking neural networks   for keyword spotting,cs.lg cs.ai cs.ne,"ultra-low power local signal processing is a crucial aspect for edge applications on always-on devices. neuromorphic processors emulating spiking neural networks show great computational power while fulfilling the limited power budget as needed in this domain. in this work we propose spiking neural dynamics as a natural alternative to dilated temporal convolutions. we extend this idea to wavesense, a spiking neural network inspired by the wavenet architecture. wavesense uses simple neural dynamics, fixed time-constants and a simple feed-forward architecture and hence is particularly well suited for a neuromorphic implementation. we test the capabilities of this model on several datasets for keyword-spotting. the results show that the proposed network beats the state of the art of other spiking neural networks and reaches near state-of-the-art performance of artificial neural networks such as cnns and lstms.",,2021-11-02,,"['philipp weidel', 'sadique sheik']"
2111.01479,dealing with misspecification in fixed-confidence linear top-m   identification,cs.ai cs.lg math.st stat.th,"we study the problem of the identification of m arms with largest means under a fixed error rate $\delta$ (fixed-confidence top-m identification), for misspecified linear bandit models. this problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which data inevitably deviates from linearity. in this work, we first derive a tractable lower bound on the sample complexity of any $\delta$-correct algorithm for the general top-m identification problem. we show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem. we then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. we derive an upper bound to its sample complexity which confirms this adaptivity and that matches the lower bound when $\delta$ $\rightarrow$ 0. finally, we evaluate our algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines.",,2021-11-02,,"['clémence réda', 'andrea tirinzoni', 'rémy degenne']"
2111.01484,archabm: an agent-based simulator of human interaction with the built   environment. $co_2$ and viral load analysis for indoor air quality,cs.ma cs.ai cs.cy,"recent evidence suggests that sars-cov-2, which is the virus causing a global pandemic in 2020, is predominantly transmitted via airborne aerosols in indoor environments. this calls for novel strategies when assessing and controlling a building's indoor air quality (iaq). iaq can generally be controlled by ventilation and/or policies to regulate human-building-interaction. however, in a building, occupants use rooms in different ways, and it may not be obvious which measure or combination of measures leads to a cost- and energy-effective solution ensuring good iaq across the entire building. therefore, in this article, we introduce a novel agent-based simulator, archabm, designed to assist in creating new or adapt existing buildings by estimating adequate room sizes, ventilation parameters and testing the effect of policies while taking into account iaq as a result of complex human-building interaction patterns. a recently published aerosol model was adapted to calculate time-dependent carbon dioxide ($co_2$) and virus quanta concentrations in each room and inhaled $co_2$ and virus quanta for each occupant over a day as a measure of physiological response. archabm is flexible regarding the aerosol model and the building layout due to its modular architecture, which allows implementing further models, any number and size of rooms, agents, and actions reflecting human-building interaction patterns. we present a use case based on a real floor plan and working schedules adopted in our research center. this study demonstrates how advanced simulation tools can contribute to improving iaq across a building, thereby ensuring a healthy indoor environment.",,2021-11-02,,"['iñigo martinez', 'jan l. bruse', 'ane m. florez-tapia', 'elisabeth viles', 'igor g. olaizola']"
2111.01510,a hybrid approach for learning to shift and grasp with elaborate motion   primitives,cs.ro cs.ai,"many possible fields of application of robots in real world settings hinge on the ability of robots to grasp objects. as a result, robot grasping has been an active field of research for many years. with our publication we contribute to the endeavor of enabling robots to grasp, with a particular focus on bin picking applications. bin picking is especially challenging due to the often cluttered and unstructured arrangement of objects and the often limited graspability of objects by simple top down grasps. to tackle these challenges, we propose a fully self-supervised reinforcement learning approach based on a hybrid discrete-continuous adaptation of soft actor-critic (sac). we employ parametrized motion primitives for pushing and grasping movements in order to enable a flexibly adaptable behavior to the difficult setups we consider. furthermore, we use data augmentation to increase sample efficiency. we demonnstrate our proposed method on challenging picking scenarios in which planar grasp learning or action discretization methods would face a lot of difficulties",,2021-11-02,,"['zohar feldman', 'hanna ziesche', 'ngo anh vien', 'dotan di castro']"
2111.01526,a modified gravity model based on network efficiency for vital nodes   identification in complex networks,cs.si cs.ai,"vital nodes identification is an essential problem in network science. various methods have been proposed to solve this problem. in particular, based on the gravity model, a series of improved gravity models are proposed to find vital nodes better in complex networks. however, they still have the room to be improved. in this paper, a novel and improved gravity model, which is named network efficiency gravity centrality model (neg), integrates gravity model and network efficiency is proposed. compared to other methods based on different gravity models, the proposed method considers the effect of the nodes on structure robustness of the network better. to solidate the superiority of the proposed method, experiments on varieties of real-world networks are carried out.",,2021-10-12,,"['hanwen li', 'qiuyan shang', 'yong deng']"
2111.01531,generating synthetic transactional profiles,cs.lg cs.ai,"financial institutions use clients' payment transactions in numerous banking applications. transactions are very personal and rich in behavioural patterns, often unique to individuals, which make them equivalent to personally identifiable information in some cases. in this paper, we generate synthetic transactional profiles using machine learning techniques with the goal to preserve both data utility and privacy. a challenge we faced was to deal with sparse vectors due to the few spending categories a client uses compared to all the ones available. we measured data utility by calculating common insights used by the banking industry on both the original and the synthetic data-set. our approach shows that neural network models can generate valuable synthetic data in such context. finally, we tried privacy-preserving techniques and observed its effect on models' performances.",,2021-10-28,,"['hadrien lautraite', 'patrick mesana']"
2111.01543,uquad1.0: development of an urdu question answering training data for   machine reading comprehension,cs.cl cs.ai,"in recent years, low-resource machine reading comprehension (mrc) has made significant progress, with models getting remarkable performance on various language datasets. however, none of these models have been customized for the urdu language. this work explores the semi-automated creation of the urdu question answering dataset (uquad1.0) by combining machine-translated squad with human-generated samples derived from wikipedia articles and urdu rc worksheets from cambridge o-level books. uquad1.0 is a large-scale urdu dataset intended for extractive machine reading comprehension tasks consisting of 49k question answers pairs in question, passage, and answer format. in uquad1.0, 45000 pairs of qa were generated by machine translation of the original squad1.0 and approximately 4000 pairs via crowdsourcing. in this study, we used two types of mrc models: rule-based baseline and advanced transformer-based models. however, we have discovered that the latter outperforms the others; thus, we have decided to concentrate solely on transformer-based architectures. using xlmroberta and multi-lingual bert, we acquire an f1 score of 0.66 and 0.63, respectively.",,2021-11-02,,"['samreen kazi', 'shakeel khoja']"
2111.01566,strategyproof and proportionally fair facility location,cs.gt cs.ai cs.ma econ.th,"we focus on a simple, one-dimensional collective decision problem (often referred to as the facility location problem) and explore issues of strategyproofness and proportional fairness. we present several characterization results for mechanisms that satisfy strategyproofness and varying levels of proportional fairness. we also characterize one of the mechanisms as the unique equilibrium outcome for any mechanism that satisfies natural fairness and monotonicity properties. finally, we identify strategyproof and proportionally fair mechanisms that provide the best welfare-optimal approximation among all mechanisms that satisfy the corresponding fairness axiom.",,2021-11-02,,"['haris aziz', 'alexander lam', 'barton e. lee', 'toby walsh']"
2111.01584,fitness landscape footprint: a framework to compare neural architecture   search problems,cs.lg cs.ai cs.cv cs.ne,"neural architecture search is a promising area of research dedicated to automating the design of neural network models. this field is rapidly growing, with a surge of methodologies ranging from bayesian optimization,neuroevoltion, to differentiable search, and applications in various contexts. however, despite all great advances, few studies have presented insights on the difficulty of the problem itself, thus the success (or fail) of these methodologies remains unexplained. in this sense, the field of optimization has developed methods that highlight key aspects to describe optimization problems. the fitness landscape analysis stands out when it comes to characterize reliably and quantitatively search algorithms. in this paper, we propose to use fitness landscape analysis to study a neural architecture search problem. particularly, we introduce the fitness landscape footprint, an aggregation of eight (8)general-purpose metrics to synthesize the landscape of an architecture search problem. we studied two problems, the classical image classification benchmark cifar-10, and the remote-sensing problem so2sat lcz42. the results present a quantitative appraisal of the problems, allowing to characterize the relative difficulty and other characteristics, such as the ruggedness or the persistence, that helps to tailor a search strategy to the problem. also, the footprint is a tool that enables the comparison of multiple problems.",,2021-11-02,,"['kalifou rené traoré', 'andrés camero', 'xiao xiang zhu']"
2111.01587,procedural generalization by planning with self-supervised world models,cs.lg cs.ai,"one of the key promises of model-based reinforcement learning is the ability to generalize using an internal model of the world to make predictions in novel environments and tasks. however, the generalization ability of model-based agents is not well understood because existing work has focused on model-free agents when benchmarking generalization. here, we explicitly measure the generalization ability of model-based agents in comparison to their model-free counterparts. we focus our analysis on muzero (schrittwieser et al., 2020), a powerful model-based agent, and evaluate its performance on both procedural and task generalization. we identify three factors of procedural generalization -- planning, self-supervised representation learning, and procedural data diversity -- and show that by combining these techniques, we achieve state-of-the art generalization performance and data efficiency on procgen (cobbe et al., 2019). however, we find that these factors do not always provide the same benefits for the task generalization benchmarks in meta-world (yu et al., 2019), indicating that transfer remains a challenge and may require different approaches than procedural generalization. overall, we suggest that building generalizable agents requires moving beyond the single-task, model-free paradigm and towards self-supervised model-based agents that are trained in rich, procedural, multi-task environments.",,2021-11-02,,"['ankesh anand', 'jacob walker', 'yazhe li', 'eszter vértes', 'julian schrittwieser', 'sherjil ozair', 'théophane weber', 'jessica b. hamrick']"
2111.01625,learning robotic ultrasound scanning skills via human demonstrations and   guided explorations,cs.ro cs.ai,"medical ultrasound has become a routine examination approach nowadays and is widely adopted for different medical applications, so it is desired to have a robotic ultrasound system to perform the ultrasound scanning autonomously. however, the ultrasound scanning skill is considerably complex, which highly depends on the experience of the ultrasound physician. in this paper, we propose a learning-based approach to learn the robotic ultrasound scanning skills from human demonstrations. first, the robotic ultrasound scanning skill is encapsulated into a high-dimensional multi-modal model, which takes the ultrasound images, the pose/position of the probe and the contact force into account. second, we leverage the power of imitation learning to train the multi-modal model with the training data collected from the demonstrations of experienced ultrasound physicians. finally, a post-optimization procedure with guided explorations is proposed to further improve the performance of the learned model. robotic experiments are conducted to validate the advantages of our proposed framework and the learned models.",,2021-11-02,,"['xutian deng', 'yiting chen', 'fei chen', 'miao li']"
2111.01632,elucidating noisy data via uncertainty-aware robust learning,cs.lg cs.ai,"robust learning methods aim to learn a clean target distribution from noisy and corrupted training data where a specific corruption pattern is often assumed a priori. our proposed method can not only successfully learn the clean target distribution from a dirty dataset but also can estimate the underlying noise pattern. to this end, we leverage a mixture-of-experts model that can distinguish two different types of predictive uncertainty, aleatoric and epistemic uncertainty. we show that the ability to estimate the uncertainty plays a significant role in elucidating the corruption patterns as these two objectives are tightly intertwined. we also present a novel validation scheme for evaluating the performance of the corruption pattern estimation. our proposed method is extensively assessed in terms of both robustness and corruption pattern estimation through a number of domains, including computer vision and natural language processing.",,2021-11-02,,"['jeongeun park', 'seungyoun shin', 'sangheum hwang', 'sungjoon choi']"
2111.01633,neural program generation modulo static analysis,cs.lg cs.ai cs.pl,"state-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. we propose to address this deficiency using weak supervision from a static program analyzer. our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated. during training, the model observes these relationships and learns to generate programs conditioned on them. we apply our approach to the problem of generating entire java methods given the remainder of the class that contains the method. our experiments show that the approach substantially outperforms state-of-the-art transformers and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth.",,2021-10-26,,"['rohan mukherjee', 'yeming wen', 'dipak chaudhari', 'thomas w. reps', 'swarat chaudhuri', 'chris jermaine']"
2111.01654,modeling and automating public announcement logic with relativized   common knowledge as a fragment of hol in logikey,cs.ai cs.lo math.lo,"a shallow semantical embedding for public announcement logic with relativized common knowledge is presented. this embedding enables the first-time automation of this logic with off-the-shelf theorem provers for classical higher-order logic. it is demonstrated (i) how meta-theoretical studies can be automated this way, and (ii) how non-trivial reasoning in the target logic (public announcement logic), required e.g. to obtain a convincing encoding and automation of the wise men puzzle, can be realized.   key to the presented semantical embedding is that evaluation domains are modeled explicitly and treated as an additional parameter in the encodings of the constituents of the embedded target logic; in previous related works, e.g. on the embedding of normal modal logics, evaluation domains were implicitly shared between meta-logic and target logic.   the work presented in this article constitutes an important addition to the pluralist logikey knowledge engineering methodology, which enables experimentation with logics and their combinations, with general and domain knowledge, and with concrete use cases -- all at the same time.",,2021-11-02,2021-11-03,"['christoph benzmüller', 'sebastian reiche']"
2111.01662,osoa: one-shot online adaptation of deep generative models for lossless   compression,cs.lg cs.ai,"explicit deep generative models (dgms), e.g., vaes and normalizing flows, have shown to offer an effective data modelling alternative for lossless compression. however, dgms themselves normally require large storage space and thus contaminate the advantage brought by accurate data density estimation. to eliminate the requirement of saving separate models for different target datasets, we propose a novel setting that starts from a pretrained deep generative model and compresses the data batches while adapting the model with a dynamical system for only one epoch. we formalise this setting as that of one-shot online adaptation (osoa) of dgms for lossless compression and propose a vanilla algorithm under this setting. experimental results show that vanilla osoa can save significant time versus training bespoke models and space versus using one model for all targets. with the same adaptation step number or adaptation time, it is shown vanilla osoa can exhibit better space efficiency, e.g., $47\%$ less space, than fine-tuning the pretrained model and saving the fine-tuned model. moreover, we showcase the potential of osoa and motivate more sophisticated osoa algorithms by showing further space or time efficiency with multiple updates per batch and early stopping.",,2021-11-02,,"['chen zhang', 'shifeng zhang', 'fabio maria carlucci', 'zhenguo li']"
2111.01663,classification of goods using text descriptions with sentences retrieval,cs.ai cs.ir,"the task of assigning and validating internationally accepted commodity code (hs code) to traded goods is one of the critical functions at the customs office. this decision is crucial to importers and exporters, as it determines the tariff rate. however, similar to court decisions made by judges, the task can be non-trivial even for experienced customs officers. the current paper proposes a deep learning model to assist this seemingly challenging hs code classification. together with korea customs service, we built a decision model based on koelectra that suggests the most likely heading and subheadings (i.e., the first four and six digits) of the hs code. evaluation on 129,084 past cases shows that the top-3 suggestions made by our model have an accuracy of 95.5% in classifying 265 subheadings. this promising result implies algorithms may reduce the time and effort taken by customs officers substantially by assisting the hs code classification task.",,2021-11-02,,"['eunji lee', 'sundong kim', 'sihyun kim', 'sungwon park', 'meeyoung cha', 'soyeon jung', 'suyoung yang', 'yeonsoo choi', 'sungdae ji', 'minsoo song', 'heeja kim']"
2111.01674,minimizing energy consumption leads to the emergence of gaits in legged   robots,cs.ro cs.ai cs.cv cs.lg,"legged locomotion is commonly studied and expressed as a discrete set of gait patterns, like walk, trot, gallop, which are usually treated as given and pre-programmed in legged robots for efficient locomotion at different speeds. however, fixing a set of pre-programmed gaits limits the generality of locomotion. recent animal motor studies show that these conventional gaits are only prevalent in ideal flat terrain conditions while real-world locomotion is unstructured and more like bouts of intermittent steps. what principles could lead to both structured and unstructured patterns across mammals and how to synthesize them in robots? in this work, we take an analysis-by-synthesis approach and learn to move by minimizing mechanical energy. we demonstrate that learning to minimize energy consumption plays a key role in the emergence of natural locomotion gaits at different speeds in real quadruped robots. the emergent gaits are structured in ideal terrains and look similar to that of horses and sheep. the same approach leads to unstructured gaits in rough terrains which is consistent with the findings in animal motor control. we validate our hypothesis in both simulation and real hardware across natural terrains. videos at https://energy-locomotion.github.io",,2021-10-25,,"['zipeng fu', 'ashish kumar', 'jitendra malik', 'deepak pathak']"
2111.01683,using synthetic images to uncover population biases in facial landmarks   detection,cs.cv cs.ai,"in order to analyze a trained model performance and identify its weak spots, one has to set aside a portion of the data for testing. the test set has to be large enough to detect statistically significant biases with respect to all the relevant sub-groups in the target population. this requirement may be difficult to satisfy, especially in data-hungry applications. we propose to overcome this difficulty by generating synthetic test set. we use the face landmarks detection task to validate our proposal by showing that all the biases observed on real datasets are also seen on a carefully designed synthetic dataset. this shows that synthetic test sets can efficiently detect a model's weak spots and overcome limitations of real test set in terms of quantity and/or diversity.",,2021-11-01,,"['ran shadmi', 'jonathan laserson', 'gil elbaz']"
2111.01689,improving classifier training efficiency for automatic cyberbullying   detection with feature density,cs.cl cs.ai cs.cy,"we study the effectiveness of feature density (fd) using different linguistically-backed feature preprocessing methods in order to estimate dataset complexity, which in turn is used to comparatively estimate the potential performance of machine learning (ml) classifiers prior to any training. we hypothesise that estimating dataset complexity allows for the reduction of the number of required experiments iterations. this way we can optimize the resource-intensive training of ml models which is becoming a serious issue due to the increases in available dataset sizes and the ever rising popularity of models based on deep neural networks (dnn). the problem of constantly increasing needs for more powerful computational resources is also affecting the environment due to alarmingly-growing amount of co2 emissions caused by training of large-scale ml models. the research was conducted on multiple datasets, including popular datasets, such as yelp business review dataset used for training typical sentiment analysis models, as well as more recent datasets trying to tackle the problem of cyberbullying, which, being a serious social problem, is also a much more sophisticated problem form the point of view of linguistic representation. we use cyberbullying datasets collected for multiple languages, namely english, japanese and polish. the difference in linguistic complexity of datasets allows us to additionally discuss the efficacy of linguistically-backed word preprocessing.",10.1016/j.ipm.2021.102616,2021-11-02,2021-11-02,"['juuso eronen', 'michal ptaszynski', 'fumito masui', 'aleksander smywiński-pohl', 'gniewosz leliwa', 'michal wroczynski']"
2111.01690,recent advances in end-to-end automatic speech recognition,eess.as cs.ai cs.cl cs.sd,"recently, the speech community is seeing a significant trend of moving from deep neural network based hybrid modeling to end-to-end (e2e) modeling for automatic speech recognition (asr). while e2e models achieve the state-of-the-art results in most benchmarks in terms of asr accuracy, hybrid models are still used in a large proportion of commercial asr systems at the current time. there are lots of practical factors that affect the production model deployment decision. traditional hybrid models, being optimized for production for decades, are usually good at these factors. without providing excellent solutions to all these factors, it is hard for e2e models to be widely commercialized. in this paper, we will overview the recent advances in e2e models, focusing on technologies addressing those challenges from the industry's perspective.",,2021-11-02,,['jinyu li']
2111.01692,efficient hierarchical bayesian inference for spatio-temporal regression   models in neuroimaging,stat.ml cs.ai cs.lg eess.sp stat.ap,"several problems in neuroimaging and beyond require inference on the parameters of multi-task sparse hierarchical regression models. examples include m/eeg inverse problems, neural encoding models for task-based fmri analyses, and temperature monitoring of climate or cpu and gpu. in these domains, both the model parameters to be inferred and the measurement noise may exhibit a complex spatio-temporal structure. existing work either neglects the temporal structure or leads to computationally demanding inference schemes. overcoming these limitations, we devise a novel flexible hierarchical bayesian framework within which the spatio-temporal dynamics of model parameters and noise are modeled to have kronecker product covariance structure. inference in our framework is based on majorization-minimization optimization and has guaranteed convergence properties. our highly efficient algorithms exploit the intrinsic riemannian geometry of temporal autocovariance matrices. for stationary dynamics described by toeplitz matrices, the theory of circulant embeddings is employed. we prove convex bounding properties and derive update rules of the resulting algorithms. on both synthetic and real neural data from m/eeg, we demonstrate that our methods lead to improved performance.",,2021-11-02,,"['ali hashemi', 'yijing gao', 'chang cai', 'sanjay ghosh', 'klaus-robert müller', 'srikantan s. nagarajan', 'stefan haufe']"
2111.01705,ai ethics statements -- analysis and lessons learnt from neurips broader   impact statements,cs.cy cs.ai cs.lg,"ethics statements have been proposed as a mechanism to increase transparency and promote reflection on the societal impacts of published research. in 2020, the machine learning (ml) conference neurips broke new ground by requiring that all papers include a broader impact statement. this requirement was removed in 2021, in favour of a checklist approach. the 2020 statements therefore provide a unique opportunity to learn from the broader impact experiment: to investigate the benefits and challenges of this and similar governance mechanisms, as well as providing an insight into how ml researchers think about the societal impacts of their own work. such learning is needed as neurips and other venues continue to question and adapt their policies. to enable this, we have created a dataset containing the impact statements from all neurips 2020 papers, along with additional information such as affiliation type, location and subject area, and a simple visualisation tool for exploration. we also provide an initial quantitative analysis of the dataset, covering representation, engagement, common themes, and willingness to discuss potential harms alongside benefits. we investigate how these vary by geography, affiliation type and subject area. drawing on these findings, we discuss the potential benefits and negative outcomes of ethics statement requirements, and their possible causes and associated challenges. these lead us to several lessons to be learnt from the 2020 requirement: (i) the importance of creating the right incentives, (ii) the need for clear expectations and guidance, and (iii) the importance of transparency and constructive deliberation. we encourage other researchers to use our dataset to provide additional analysis, to further our understanding of how researchers responded to this requirement, and to investigate the benefits and challenges of this and related mechanisms.",,2021-11-02,,"['carolyn ashurst', 'emmie hine', 'paul sedille', 'alexis carlier']"
2111.01706,assessing effectiveness of using internal signals for check-worthy claim   identification in unlabeled data for automated fact-checking,cs.cl cs.ai cs.ir,"while recent work on automated fact-checking has focused mainly on verifying and explaining claims, for which the list of claims is readily available, identifying check-worthy claim sentences from a text remains challenging. current claim identification models rely on manual annotations for each sentence in the text, which is an expensive task and challenging to conduct on a frequent basis across multiple domains. this paper explores methodology to identify check-worthy claim sentences from fake news articles, irrespective of domain, without explicit sentence-level annotations. we leverage two internal supervisory signals - headline and the abstractive summary - to rank the sentences based on semantic similarity. we hypothesize that this ranking directly correlates to the check-worthiness of the sentences. to assess the effectiveness of this hypothesis, we build pipelines that leverage the ranking of sentences based on either the headline or the abstractive summary. the top-ranked sentences are used for the downstream fact-checking tasks of evidence retrieval and the article's veracity prediction by the pipeline. our findings suggest that the top 3 ranked sentences contain enough information for evidence-based fact-checking of a fake news article. we also show that while the headline has more gisting similarity with how a fact-checking website writes a claim, the summary-based pipeline is the most promising for an end-to-end fact-checking system.",,2021-11-02,,"['archita pathak', 'rohini k. srihari']"
2111.01714,meta-learning the search distribution of black-box random search based   adversarial attacks,cs.lg cs.ai cs.cv,"adversarial attacks based on randomized search schemes have obtained state-of-the-art results in black-box robustness evaluation recently. however, as we demonstrate in this work, their efficiency in different query budget regimes depends on manual design and heuristic tuning of the underlying proposal distributions. we study how this issue can be addressed by adapting the proposal distribution online based on the information obtained during the attack. we consider square attack, which is a state-of-the-art score-based black-box attack, and demonstrate how its performance can be improved by a learned controller that adjusts the parameters of the proposal distribution online during the attack. we train the controller using gradient-based end-to-end training on a cifar10 model with white box access. we demonstrate that plugging the learned controller into the attack consistently improves its black-box robustness estimate in different query regimes by up to 20% for a wide range of different models with black-box access. we further show that the learned adaptation principle transfers well to the other data distributions such as cifar100 or imagenet and to the targeted attack setting.",,2021-11-02,2021-11-16,"['maksym yatsura', 'jan hendrik metzen', 'matthias hein']"
2111.01722,predicting the location of bicycle-sharing stations using openstreetmap   data,cs.lg cs.ai cs.cy,"planning the layout of bicycle-sharing stations is a complex process, especially in cities where bicycle sharing systems are just being implemented. urban planners often have to make a lot of estimates based on both publicly available data and privately provided data from the administration and then use the location-allocation model popular in the field. many municipalities in smaller cities may have difficulty hiring specialists to carry out such planning. this thesis proposes a new solution to streamline and facilitate the process of such planning by using spatial embedding methods. based only on publicly available data from openstreetmap, and station layouts from 34 cities in europe, a method has been developed to divide cities into micro-regions using the uber h3 discrete global grid system and to indicate regions where it is worth placing a station based on existing systems in different cities using transfer learning. the result of the work is a mechanism to support planners in their decision making when planning a station layout with a choice of reference cities.",,2021-11-02,,['kamil raczycki']
2111.01726,"instructive artificial intelligence (ai) for human training, assistance,   and explainability",cs.ai,"we propose a novel approach to explainable ai (xai) based on the concept of ""instruction"" from neural networks. in this case study, we demonstrate how a superhuman neural network might instruct human trainees as an alternative to traditional approaches to xai. specifically, an ai examines human actions and calculates variations on the human strategy that lead to better performance. experiments with a jhu/apl-developed ai player for the cooperative card game hanabi suggest this technique makes unique contributions to explainability while improving human performance. one area of focus for instructive ai is in the significant discrepancies that can arise between a human's actual strategy and the strategy they profess to use. this inaccurate self-assessment presents a barrier for xai, since explanations of an ai's strategy may not be properly understood or implemented by human recipients. we have developed and are testing a novel, instructive ai approach that estimates human strategy by observing human actions. with neural networks, this allows a direct calculation of the changes in weights needed to improve the human strategy to better emulate a more successful ai. subjected to constraints (e.g. sparsity) these weight changes can be interpreted as recommended changes to human strategy (e.g. ""value a more, and value b less""). instruction from ai such as this functions both to help humans perform better at tasks, but also to better understand, anticipate, and correct the actions of an ai. results will be presented on ai instruction's ability to improve human decision-making and human-ai teaming in hanabi.",,2021-11-02,,"['nicholas kantack', 'nina cohen', 'nathan bos', 'corey lowman', 'james everett', 'timothy endres']"
2111.01742,logavgexp provides a principled and performant global pooling operator,cs.lg cs.ai cs.cv,"we seek to improve the pooling operation in neural networks, by applying a more theoretically justified operator. we demonstrate that logsumexp provides a natural or operator for logits. when one corrects for the number of elements inside the pooling operator, this becomes $\text{logavgexp} := \log(\text{mean}(\exp(x)))$. by introducing a single temperature parameter, logavgexp smoothly transitions from the max of its operands to the mean (found at the limiting cases $t \to 0^+$ and $t \to +\infty$). we experimentally tested logavgexp, both with and without a learnable temperature parameter, in a variety of deep neural network architectures for computer vision.",,2021-11-02,,"['scott c. lowe', 'thomas trappenberg', 'sageev oore']"
2111.01853,recursive bayesian networks: generalising and unifying probabilistic   context-free grammars and dynamic bayesian networks,cs.lg cs.ai cs.ir,"probabilistic context-free grammars (pcfgs) and dynamic bayesian networks (dbns) are widely used sequence models with complementary strengths and limitations. while pcfgs allow for nested hierarchical dependencies (tree structures), their latent variables (non-terminal symbols) have to be discrete. in contrast, dbns allow for continuous latent variables, but the dependencies are strictly sequential (chain structure). therefore, neither can be applied if the latent variables are assumed to be continuous and also to have a nested hierarchical dependency structure. in this paper, we present recursive bayesian networks (rbns), which generalise and unify pcfgs and dbns, combining their strengths and containing both as special cases. rbns define a joint distribution over tree-structured bayesian networks with discrete or continuous latent variables. the main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. we provide two solutions: 1) for arbitrary rbns, we generalise inside and outside probabilities from pcfgs to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. 2) for gaussian rbns, we additionally derive an analytic approximation, allowing for robust parameter optimisation and bayesian inference. the capacity and diverse applications of rbns are illustrated on two examples: in a quantitative evaluation on synthetic data, we demonstrate and discuss the advantage of rbns for segmentation and tree induction from noisy sequences, compared to change point detection and hierarchical clustering. in an application to musical data, we approach the unsolved problem of hierarchical music analysis from the raw note level and compare our results to expert annotations.",,2021-11-02,,"['robert lieck', 'martin rohrmeier']"
2111.01856,detecting logical relation in contract clauses,cs.ai,"contracts underlie most modern commercial transactions defining define the duties and obligations of the related parties in an agreement. ensuring such agreements are error free is crucial for modern society and their analysis of a contract requires understanding the logical relations between clauses and identifying potential contradictions. this analysis depends on error-prone human effort to understand each contract clause. in this work, we develop an approach to automate the extraction of logical relations between clauses in a contract. we address this problem as a natural language inference task to detect the entailment type between two clauses in a contract. the resulting approach should help contract authors detecting potential logical conflicts between clauses.",,2021-11-02,,"['alexandre yukio ichida', 'felipe meneguzzi']"
2111.01865,off-policy correction for deep deterministic policy gradient algorithms   via batch prioritized experience replay,cs.lg cs.ai,"the experience replay mechanism allows agents to use the experiences multiple times. in prior works, the sampling probability of the transitions was adjusted according to their importance. reassigning sampling probabilities for every transition in the replay buffer after each iteration is highly inefficient. therefore, experience replay prioritization algorithms recalculate the significance of a transition when the corresponding transition is sampled to gain computational efficiency. however, the importance level of the transitions changes dynamically as the policy and the value function of the agent are updated. in addition, experience replay stores the transitions are generated by the previous policies of the agent that may significantly deviate from the most recent policy of the agent. higher deviation from the most recent policy of the agent leads to more off-policy updates, which is detrimental for the agent. in this paper, we develop a novel algorithm, batch prioritizing experience replay via kl divergence (klper), which prioritizes batch of transitions rather than directly prioritizing each transition. moreover, to reduce the off-policyness of the updates, our algorithm selects one batch among a certain number of batches and forces the agent to learn through the batch that is most likely generated by the most recent policy of the agent. we combine our algorithm with deep deterministic policy gradient and twin delayed deep deterministic policy gradient and evaluate it on various continuous control tasks. klper provides promising improvements for deep deterministic continuous control algorithms in terms of sample efficiency, final performance, and stability of the policy during the training.",,2021-11-02,2021-11-12,"['dogan c. cicek', 'enes duran', 'baturay saglam', 'furkan b. mutlu', 'suleyman s. kozat']"
2111.01868,from strings to data science: a practical framework for automated string   handling,cs.lg cs.ai,"many machine learning libraries require that string features be converted to a numerical representation for the models to work as intended. categorical string features can represent a wide variety of data (e.g., zip codes, names, marital status), and are notoriously difficult to preprocess automatically. in this paper, we propose a framework to do so based on best practices, domain knowledge, and novel techniques. it automatically identifies different types of string features, processes them accordingly, and encodes them into numerical representations. we also provide an open source python implementation to automatically preprocess categorical string data in tabular datasets and demonstrate promising results on a wide range of datasets.",,2021-11-02,2021-11-04,"['john w. van lith', 'joaquin vanschoren']"
2111.01872,a survey of fairness-aware federated learning,cs.lg cs.ai cs.dc,"recent advances in federated learning (fl) have brought large-scale machine learning opportunities for massive distributed clients with performance and data privacy guarantees. however, most current works only focus on the interest of the central controller in fl, and ignore the interests of clients. this may result in unfairness which discourages clients from actively participating in the learning process and damages the sustainability of the whole fl system. therefore, the topic of ensuring fairness in an fl is attracting a great deal of research interest. in recent years, diverse fairness-aware fl (fafl) approaches have been proposed in an effort to achieve fairness in fl from different viewpoints. however, there is no comprehensive survey which helps readers gain insight into this interdisciplinary field. this paper aims to provide such a survey. by examining the fundamental and simplifying assumptions, as well as the notions of fairness adopted by existing literature in this field, we propose a taxonomy of fafl approaches covering major steps in fl, including client selection, optimization, contribution evaluation and incentive distribution. in addition, we discuss the main metrics for experimentally evaluating the performance of fafl approaches, and suggest some promising future research directions.",,2021-11-02,,"['yuxin shi', 'han yu', 'cyril leung']"
2111.01892,equivariant deep dynamical model for motion prediction,cs.lg cs.ai,"learning representations through deep generative modeling is a powerful approach for dynamical modeling to discover the most simplified and compressed underlying description of the data, to then use it for other tasks such as prediction. most learning tasks have intrinsic symmetries, i.e., the input transformations leave the output unchanged, or the output undergoes a similar transformation. the learning process is, however, usually uninformed of these symmetries. therefore, the learned representations for individually transformed inputs may not be meaningfully related. in this paper, we propose an so(3) equivariant deep dynamical model (eqddm) for motion prediction that learns a structured representation of the input space in the sense that the embedding varies with symmetry transformations. eqddm is equipped with equivariant networks to parameterize the state-space emission and transition models. we demonstrate the superior predictive performance of the proposed model on various motion data.",,2021-11-02,,"['bahar azari', 'deniz erdoğmuş']"
2111.01906,a trained humanoid robot can perform human-like crossmodal social   attention conflict resolution,cs.ro cs.ai cs.hc,"due to the covid-19 pandemic, robots could be seen as potential resources in tasks like helping people work remotely, sustaining social distancing, and improving mental or physical health. to enhance human-robot interaction, it is essential for robots to become more socialised, via processing multiple social cues in a complex real-world environment. our study adopted a neurorobotic paradigm of gaze-triggered audio-visual crossmodal integration to make an icub robot express human-like social attention responses. at first, a behavioural experiment was conducted on 37 human participants. to improve ecological validity, a round-table meeting scenario with three masked animated avatars was designed with the middle one capable of performing gaze shift, and the other two capable of generating sound. the gaze direction and the sound location are either congruent or incongruent. masks were used to cover all facial visual cues other than the avatars' eyes. we observed that the avatar's gaze could trigger crossmodal social attention with better human performance in the audio-visual congruent condition than in the incongruent condition. then, our computational model, gasp, was trained to implement social cue detection, audio-visual saliency prediction, and selective attention. after finishing the model training, the icub robot was exposed to similar laboratory conditions as human participants, demonstrating that it can replicate similar attention responses as humans regarding the congruency and incongruency performance, while overall the human performance was still superior. therefore, this interdisciplinary work provides new insights on mechanisms of crossmodal social attention and how it can be modelled in robots in a complex environment.",,2021-11-02,,"['di fu', 'fares abawi', 'hugo carneiro', 'matthias kerzel', 'ziwei chen', 'erik strahl', 'xun liu', 'stefan wermter']"
2111.01911,parameterized explanations for investor / company matching,cs.ir cs.ai q-fin.cp,"matching companies and investors is usually considered a highly specialized decision making process. building an ai agent that can automate such recommendation process can significantly help reduce costs, and eliminate human biases and errors. however, limited sample size of financial data-sets and the need for not only good recommendations, but also explaining why a particular recommendation is being made, makes this a challenging problem. in this work we propose a representation learning based recommendation engine that works extremely well with small datasets and demonstrate how it can be coupled with a parameterized explanation generation engine to build an explainable recommendation system for investor-company matching. we compare the performance of our system with human generated recommendations and demonstrate the ability of our algorithm to perform extremely well on this task. we also highlight how explainability helps with real-life adoption of our system.",,2021-10-27,,"['simerjot kaur', 'ivan brugere', 'andrea stefanucci', 'armineh nourbakhsh', 'sameena shah', 'manuela veloso']"
2111.01912,predicting cancer using supervised machine learning: mesothelioma,cs.lg cs.ai,"background: pleural mesothelioma (pm) is an unusual, belligerent tumor that rapidly develops into cancer in the pleura of the lungs. pleural mesothelioma is a common type of mesothelioma that accounts for about 75% of all mesothelioma diagnosed yearly in the u.s. diagnosis of mesothelioma takes several months and is expensive. given the risk and constraints associated with pm diagnosis, early identification of this ailment is essential for patient health. objective: in this study, we use artificial intelligence algorithms recommending the best fit model for early diagnosis and prognosis of mpm. methods: we retrospectively retrieved patients clinical data collected by dicle university, turkey, and applied multilayered perceptron (mlp), voted perceptron (vp), clojure classifier (cc), kernel logistic regression (klr), stochastic gradient decent sgd), adaptive boosting (adaboost), hoeffding tree (vfdt), and primal estimated sub-gradient solver for support vector machine (s-pegasos). we evaluated the models, compared and tested using paired t-test (corrected) at 0.05 significance based on their respective classification accuracy, f-measure, precision, recall, root mean squared error, receivers characteristic curve (roc), and precision-recall curve (prc). results: in phase-1, sgd, adaboost. m1, klr, mlp, vfdt generate optimal results with the highest possible performance measures. in phase 2, adaboost, with a classification accuracy of 71.29%, outperformed all other algorithms. c-reactive protein, platelet count, duration of symptoms, gender, and pleural protein were found to be the most relevant predictors that can prognosticate mesothelioma. conclusion: this study confirms that data obtained from biopsy and imagining tests are strong predictors of mesothelioma but are associated with a high cost; however, they can identify mesothelioma with optimal accuracy.",10.3233/thc-202237,2021-10-31,,['avishek choudhury']
2111.01919,discovering and exploiting sparse rewards in a learned behavior space,cs.lg cs.ai cs.ne cs.ro,"learning optimal policies in sparse rewards settings is difficult as the learning agent has little to no feedback on the quality of its actions. in these situations, a good strategy is to focus on exploration, hopefully leading to the discovery of a reward signal to improve on. a learning algorithm capable of dealing with this kind of settings has to be able to (1) explore possible agent behaviors and (2) exploit any possible discovered reward. efficient exploration algorithms have been proposed that require to define a behavior space, that associates to an agent its resulting behavior in a space that is known to be worth exploring. the need to define this space is a limitation of these algorithms. in this work, we introduce stax, an algorithm designed to learn a behavior space on-the-fly and to explore it while efficiently optimizing any reward discovered. it does so by separating the exploration and learning of the behavior space from the exploitation of the reward through an alternating two-steps process. in the first step, stax builds a repertoire of diverse policies while learning a low-dimensional representation of the high-dimensional observations generated during the policies evaluation. in the exploitation step, emitters are used to optimize the performance of the discovered rewarding solutions. experiments conducted on three different sparse reward environments show that stax performs comparably to existing baselines while requiring much less prior information about the task as it autonomously builds the behavior space.",,2021-11-02,,"['giuseppe paolo', 'alexandre coninx', 'alban laflaquière', 'stephane doncieux']"
2111.01932,hashtag: hash signatures for online detection of fault-injection attacks   on deep neural networks,cs.cr cs.ai cs.lg,"we propose hashtag, the first framework that enables high-accuracy detection of fault-injection attacks on deep neural networks (dnns) with provable bounds on detection performance. recent literature in fault-injection attacks shows the severe dnn accuracy degradation caused by bit flips. in this scenario, the attacker changes a few weight bits during dnn execution by tampering with the program's dram memory. to detect runtime bit flips, hashtag extracts a unique signature from the benign dnn prior to deployment. the signature is later used to validate the integrity of the dnn and verify the inference output on the fly. we propose a novel sensitivity analysis scheme that accurately identifies the most vulnerable dnn layers to the fault-injection attack. the dnn signature is then constructed by encoding the underlying weights in the vulnerable layers using a low-collision hash function. when the dnn is deployed, new hashes are extracted from the target layers during inference and compared against the ground-truth signatures. hashtag incorporates a lightweight methodology that ensures a low-overhead and real-time fault detection on embedded platforms. extensive evaluations with the state-of-the-art bit-flip attack on various dnns demonstrate the competitive advantage of hashtag in terms of both attack detection and execution overhead.",,2021-11-02,,"['mojan javaheripi', 'farinaz koushanfar']"
2111.01934,dehumanizing voice technology: phonetic & experiential consequences of   restricted human-machine interaction,cs.ai cs.hc,"the use of natural language and voice-based interfaces gradu-ally transforms how consumers search, shop, and express their preferences. the current work explores how changes in the syntactical structure of the interaction with conversational interfaces (command vs. request based expression modalities) negatively affects consumers' subjective task enjoyment and systematically alters objective vocal features in the human voice. we show that requests (vs. commands) lead to an in-crease in phonetic convergence and lower phonetic latency, and ultimately a more natural task experience for consumers. to the best of our knowledge, this is the first work docu-menting that altering the input modality of how consumers interact with smart objects systematically affects consumers' iot experience. we provide evidence that altering the required input to initiate a conversation with smart objects provokes systematic changes both in terms of consumers' subjective experience and objective phonetic changes in the human voice. the current research also makes a methodological con-tribution by highlighting the unexplored potential of feature extraction in human voice as a novel data format linking consumers' vocal features during speech formation and their sub-jective task experiences.",,2021-11-02,,"['christian hildebrand', 'donna hoffman', 'tom novak']"
2111.01983,obvious manipulability of voting rules,cs.gt cs.ai cs.ma econ.th,"the gibbard-satterthwaite theorem states that no unanimous and non-dictatorial voting rule is strategyproof. we revisit voting rules and consider a weaker notion of strategyproofness called not obvious manipulability that was proposed by troyan and morrill (2020). we identify several classes of voting rules that satisfy this notion. we also show that several voting rules including k-approval fail to satisfy this property. we characterize conditions under which voting rules are obviously manipulable. one of our insights is that certain rules are obviously manipulable when the number of alternatives is relatively large compared to the number of voters. in contrast to the gibbard-satterthwaite theorem, many of the rules we examined are not obviously manipulable. this reflects the relatively easier satisfiability of the notion and the zero information assumption of not obvious manipulability, as opposed to the perfect information assumption of strategyproofness. we also present algorithmic results for computing obvious manipulations and report on experiments.",10.1007/978-3-030-87756-9_12,2021-11-02,,"['haris aziz', 'alexander lam']"
2111.01998,openprompt: an open-source framework for prompt-learning,cs.cl cs.ai cs.lg,"prompt-learning has become a new paradigm in modern natural language processing, which directly adapts pre-trained language models (plms) to $cloze$-style prediction, autoregressive modeling, or sequence to sequence generation, resulting in promising performances on various tasks. however, no standard implementation framework of prompt-learning is proposed yet, and most existing prompt-learning codebases, often unregulated, only provide limited implementations for specific scenarios. since there are many details such as templating strategy, initializing strategy, and verbalizing strategy, etc. need to be considered in prompt-learning, practitioners face impediments to quickly adapting the desired prompt learning methods to their applications. in this paper, we present {openprompt}, a unified easy-to-use toolkit to conduct prompt-learning over plms. openprompt is a research-friendly framework that is equipped with efficiency, modularity, and extendibility, and its combinability allows the freedom to combine different plms, task formats, and prompting modules in a unified paradigm. users could expediently deploy prompt-learning frameworks and evaluate the generalization of them on different nlp tasks without constraints. openprompt is publicly released at {\url{ https://github.com/thunlp/openprompt}}.",,2021-11-02,,"['ning ding', 'shengding hu', 'weilin zhao', 'yulin chen', 'zhiyuan liu', 'hai-tao zheng', 'maosong sun']"
2111.02001,certifiable artificial intelligence through data fusion,cs.ai eess.iv,"this paper reviews and proposes concerns in adopting, fielding, and maintaining artificial intelligence (ai) systems. while the ai community has made rapid progress, there are challenges in certifying ai systems. using procedures from design and operational test and evaluation, there are opportunities towards determining performance bounds to manage expectations of intended use. a notional use case is presented with image data fusion to support ai object recognition certifiability considering precision versus distance.",,2021-11-02,,"['erik blasch', 'junchi bin', 'zheng liu']"
2111.02010,oblique and rotation double random forest,cs.lg cs.ai,"an ensemble of decision trees is known as random forest. as suggested by breiman, the strength of unstable learners and the diversity among them are the ensemble models' core strength. in this paper, we propose two approaches known as oblique and rotation double random forests. in the first approach, we propose a rotation based double random forest. in rotation based double random forests, transformation or rotation of the feature space is generated at each node. at each node different random feature subspace is chosen for evaluation, hence the transformation at each node is different. different transformations result in better diversity among the base learners and hence, better generalization performance. with the double random forest as base learner, the data at each node is transformed via two different transformations namely, principal component analysis and linear discriminant analysis. in the second approach, we propose oblique double random forest. decision trees in random forest and double random forest are univariate, and this results in the generation of axis parallel split which fails to capture the geometric structure of the data. also, the standard random forest may not grow sufficiently large decision trees resulting in suboptimal performance. to capture the geometric properties and to grow the decision trees of sufficient depth, we propose oblique double random forest. the oblique double random forest models are multivariate decision trees. at each non-leaf node, multisurface proximal support vector machine generates the optimal plane for better generalization performance. also, different regularization techniques (tikhonov regularisation and axis-parallel split regularisation) are employed for tackling the small sample size problems in the decision trees of oblique double random forest.",,2021-11-03,2021-11-06,"['m. a. ganaie', 'm. tanveer', 'p. n. suganthan', 'v. snasel']"
2111.02026,the powerful use of ai in the energy sector: intelligent forecasting,cs.ai eess.sp,"artificial intelligence (ai) techniques continue to broaden across governmental and public sectors, such as power and energy - which serve as critical infrastructures for most societal operations. however, due to the requirements of reliability, accountability, and explainability, it is risky to directly apply ai-based methods to power systems because society cannot afford cascading failures and large-scale blackouts, which easily cost billions of dollars. to meet society requirements, this paper proposes a methodology to develop, deploy, and evaluate ai systems in the energy sector by: (1) understanding the power system measurements with physics, (2) designing ai algorithms to forecast the need, (3) developing robust and accountable ai methods, and (4) creating reliable measures to evaluate the performance of the ai model. the goal is to provide a high level of confidence to energy utility users. for illustration purposes, the paper uses power system event forecasting (pef) as an example, which carefully analyzes synchrophasor patterns measured by the phasor measurement units (pmus). such a physical understanding leads to a data-driven framework that reduces the dimensionality with physics and forecasts the event with high credibility. specifically, for dimensionality reduction, machine learning arranges physical information from different dimensions, resulting inefficient information extraction. for event forecasting, the supervised learning model fuses the results of different models to increase the confidence. finally, comprehensive experiments demonstrate the high accuracy, efficiency, and reliability as compared to other state-of-the-art machine learning methods.",,2021-11-03,,"['erik blasch', 'haoran li', 'zhihao ma', 'yang weng']"
2111.02034,building legal datasets,cs.lg cs.ai,"data-centric ai calls for better, not just bigger, datasets. as data protection laws with extra-territorial reach proliferate worldwide, ensuring datasets are legal is an increasingly crucial yet overlooked component of ``better''. to help dataset builders become more willing and able to navigate this complex legal space, this paper reviews key legal obligations surrounding ml datasets, examines the practical impact of data laws on ml pipelines, and offers a framework for building legal datasets.",,2021-11-03,,['jerrold soh']
2111.02044,categorical difference and related brain regions of the attentional   blink effect,cs.ai cs.cv q-bio.nc,"attentional blink (ab) is a biological effect, showing that for 200 to 500ms after paying attention to one visual target, it is difficult to notice another target that appears next, and attentional blink magnitude (abm) is a indicating parameter to measure the degree of this effect. researchers have shown that different categories of images can access the consciousness of human mind differently, and produce different ranges of abm values. so in this paper, we compare two different types of images, categorized as animal and object, by predicting abm values directly from image features extracted from convolutional neural network (cnn), and indirectly from functional magnetic resonance imaging (fmri) data. first, for two sets of images, we separately extract their average features from layers of alexnet, a classic model of cnn, then input the features into a trained linear regression model to predict abm values, and we find higher-level instead of lower-level image features determine the categorical difference in ab effect, and mid-level image features predict abm values more correctly than low-level and high-level image features. then we employ fmri data from different brain regions collected when the subjects viewed 50 test images to predict abm values, and conclude that brain regions covering relatively broader areas, like lvc, hvc and vc, perform better than other smaller brain regions, which means ab effect is more related to synthetic impact of several visual brain regions than only one particular visual regions.",,2021-11-03,,"['renzhou gui', 'xiaohong ji']"
2111.02056,curriculum offline imitation learning,cs.lg cs.ai,"offline reinforcement learning (rl) tasks require the agent to learn from a pre-collected dataset with no further interactions with the environment. despite the potential to surpass the behavioral policies, rl-based methods are generally impractical due to the training instability and bootstrapping the extrapolation errors, which always require careful hyperparameter tuning via online evaluation. in contrast, offline imitation learning (il) has no such issues since it learns the policy directly without estimating the value function by bootstrapping. however, il is usually limited in the capability of the behavioral policy and tends to learn a mediocre behavior from the dataset collected by the mixture of policies. in this paper, we aim to take advantage of il but mitigate such a drawback. observing that behavior cloning is able to imitate neighboring policies with less data, we propose \textit{curriculum offline imitation learning (coil)}, which utilizes an experience picking strategy for imitating from adaptive neighboring policies with a higher return, and improves the current policy along curriculum stages. on continuous control benchmarks, we compare coil against both imitation-based and rl-based methods, showing that it not only avoids just learning a mediocre behavior on mixed datasets but is also even competitive with state-of-the-art offline rl methods.",,2021-11-03,,"['minghuan liu', 'hanye zhao', 'zhengyu yang', 'jian shen', 'weinan zhang', 'li zhao', 'tie-yan liu']"
2111.02058,rethinking the image feature biases exhibited by deep cnn models,cs.cv cs.ai,"in recent years, convolutional neural networks (cnns) have been applied successfully in many fields. however, such deep neural models are still regarded as black box in most tasks. one of the fundamental issues underlying this problem is understanding which features are most influential in image recognition tasks and how they are processed by cnns. it is widely accepted that cnn models combine low-level features to form complex shapes until the object can be readily classified, however, several recent studies have argued that texture features are more important than other features. in this paper, we assume that the importance of certain features varies depending on specific tasks, i.e., specific tasks exhibit a feature bias. we designed two classification tasks based on human intuition to train deep neural models to identify anticipated biases. we devised experiments comprising many tasks to test these biases for the resnet and densenet models. from the results, we conclude that (1) the combined effect of certain features is typically far more influential than any single feature; (2) in different tasks, neural models can perform different biases, that is, we can design a specific task to make a neural model biased toward a specific anticipated feature.",,2021-11-03,,"['dawei dai', 'yutang li', 'huanan bao', 'sy xia', 'guoyin wang', 'xiaoli ma']"
2111.02083,federated expectation maximization with heterogeneity mitigation and   variance reduction,math.oc cs.ai cs.lg,"the expectation maximization (em) algorithm is the default algorithm for inference in latent variable models. as in any other field of machine learning, applications of latent variable models to very large datasets make the use of advanced parallel and distributed architectures mandatory. this paper introduces fedem, which is the first extension of the em algorithm to the federated learning context. fedem is a new communication efficient method, which handles partial participation of local devices, and is robust to heterogeneous distributions of the datasets. to alleviate the communication bottleneck, fedem compresses appropriately defined complete data sufficient statistics. we also develop and analyze an extension of fedem to further incorporate a variance reduction scheme. in all cases, we derive finite-time complexity bounds for smooth non-convex problems. numerical results are presented to support our theoretical findings, as well as an application to federated missing values imputation for biodiversity monitoring.",,2021-11-03,2021-11-10,"['aymeric dieuleveut', 'gersende fort', 'eric moulines', 'geneviève robin']"
2111.02104,model-based episodic memory induces dynamic hybrid controls,cs.lg cs.ai,"episodic control enables sample efficiency in reinforcement learning by recalling past experiences from an episodic memory. we propose a new model-based episodic memory of trajectories addressing current limitations of episodic control. our memory estimates trajectory values, guiding the agent towards good policies. built upon the memory, we construct a complementary learning model via a dynamic hybrid control unifying model-based, episodic and habitual learning into a single architecture. experiments demonstrate that our model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments including stochastic and non-markovian settings.",,2021-11-03,2021-11-06,"['hung le', 'thommen karimpanal george', 'majid abdolshah', 'truyen tran', 'svetha venkatesh']"
2111.02115,multistep traffic speed prediction: a deep learning based approach using   latent space mapping considering spatio-temporal dependencies,cs.lg cs.ai,"traffic management in a city has become a major problem due to the increasing number of vehicles on roads. intelligent transportation system (its) can help the city traffic managers to tackle the problem by providing accurate traffic forecasts. for this, its requires a reliable traffic prediction algorithm that can provide accurate traffic prediction at multiple time steps based on past and current traffic data. in recent years, a number of different methods for traffic prediction have been proposed which have proved their effectiveness in terms of accuracy. however, most of these methods have either considered spatial information or temporal information only and overlooked the effect of other. in this paper, to address the above problem a deep learning based approach has been developed using both the spatial and temporal dependencies. to consider spatio-temporal dependencies, nearby road sensors at a particular instant are selected based on the attributes like traffic similarity and distance. two pre-trained deep auto-encoders were cross-connected using the concept of latent space mapping and the resultant model was trained using the traffic data from the selected nearby sensors as input. the proposed deep learning based approach was trained using the real-world traffic data collected from loop detector sensors installed on different highways of los angeles and bay area. the traffic data is freely available from the web portal of the california department of transportation performance measurement system (pems). the effectiveness of the proposed approach was verified by comparing it with a number of machine/deep learning approaches. it has been found that the proposed approach provides accurate traffic prediction results even for 60-min ahead prediction with least error than other techniques.",10.1016/j.eswa.2021.116140,2021-11-03,,"['shatrughan modi', 'jhilik bhattacharya', 'prasenjit basak']"
2111.02120,lingua custodia's participation at the wmt 2021 machine translation   using terminologies shared task,cs.cl cs.ai,"this paper describes lingua custodia's submission to the wmt21 shared task on machine translation using terminologies. we consider three directions, namely english to french, russian, and chinese. we rely on a transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies. the first one consists in augmenting the training data in such a way as to encourage the model to learn a copy behavior when it encounters terminology constraint terms. the second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization. empirical results show that our method satisfies most terminology constraints while maintaining high translation quality.",,2021-11-03,,"['melissa ailem', 'jinghsu liu', 'raheel qader']"
2111.02123,marriage is a peach and a chalice: modelling cultural symbolism on the   semanticweb,cs.ai,"in this work, we fill the gap in the semantic web in the context of cultural symbolism. building upon earlier work in, we introduce the simulation ontology, an ontology that models the background knowledge of symbolic meanings, developed by combining the concepts taken from the authoritative theory of simulacra and simulations of jean baudrillard with symbolic structures and content taken from ""symbolism: a comprehensive dictionary"" by steven olderr. we re-engineered the symbolic knowledge already present in heterogeneous resources by converting it into our ontology schema to create hyperreal, the first knowledge graph completely dedicated to cultural symbolism. a first experiment run on the knowledge graph is presented to show the potential of quantitative research on symbolism.",10.1145/3460210.3493552,2021-11-03,,"['bruno sartini', 'marieke van erp', 'aldo gangemi']"
2111.02149,deployment optimization for shared e-mobility systems with multi-agent   deep neural search,cs.ai cs.lg,"shared e-mobility services have been widely tested and piloted in cities across the globe, and already woven into the fabric of modern urban planning. this paper studies a practical yet important problem in those systems: how to deploy and manage their infrastructure across space and time, so that the services are ubiquitous to the users while sustainable in profitability. however, in real-world systems evaluating the performance of different deployment strategies and then finding the optimal plan is prohibitively expensive, as it is often infeasible to conduct many iterations of trial-and-error. we tackle this by designing a high-fidelity simulation environment, which abstracts the key operation details of the shared e-mobility systems at fine-granularity, and is calibrated using data collected from the real-world. this allows us to try out arbitrary deployment plans to learn the optimal given specific context, before actually implementing any in the real-world systems. in particular, we propose a novel multi-agent neural search approach, in which we design a hierarchical controller to produce tentative deployment plans. the generated deployment plans are then tested using a multi-simulation paradigm, i.e., evaluated in parallel, where the results are used to train the controller with deep reinforcement learning. with this closed loop, the controller can be steered to have higher probability of generating better deployment plans in future iterations. the proposed approach has been evaluated extensively in our simulation environment, and experimental results show that it outperforms baselines e.g., human knowledge, and state-of-the-art heuristic-based optimization approaches in both service coverage and net revenue.",,2021-11-03,,"['man luo', 'bowen du', 'konstantin klemmer', 'hongming zhu', 'hongkai wen']"
2111.02161,data synthesis for testing black-box machine learning models,cs.lg cs.ai,"the increasing usage of machine learning models raises the question of the reliability of these models. the current practice of testing with limited data is often insufficient. in this paper, we provide a framework for automated test data synthesis to test black-box ml/dl models. we address an important challenge of generating realistic user-controllable data with model agnostic coverage criteria to test a varied set of properties, essentially to increase trust in machine learning models. we experimentally demonstrate the effectiveness of our technique.",,2021-11-03,,"['diptikalyan saha', 'aniya aggarwal', 'sandeep hans']"
2111.02167,image-guided navigation of a robotic ultrasound probe for autonomous   spinal sonography using a shadow-aware dual-agent framework,cs.ro cs.ai,"ultrasound (us) imaging is commonly used to assist in the diagnosis and interventions of spine diseases, while the standardized us acquisitions performed by manually operating the probe require substantial experience and training of sonographers. in this work, we propose a novel dual-agent framework that integrates a reinforcement learning (rl) agent and a deep learning (dl) agent to jointly determine the movement of the us probe based on the real-time us images, in order to mimic the decision-making process of an expert sonographer to achieve autonomous standard view acquisitions in spinal sonography. moreover, inspired by the nature of us propagation and the characteristics of the spinal anatomy, we introduce a view-specific acoustic shadow reward to utilize the shadow information to implicitly guide the navigation of the probe toward different standard views of the spine. our method is validated in both quantitative and qualitative experiments in a simulation environment built with us data acquired from 17 volunteers. the average navigation accuracy toward different standard views achieves 5.18mm/5.25deg and 12.87mm/17.49deg in the intra- and inter-subject settings, respectively. the results demonstrate that our method can effectively interpret the us images and navigate the probe to acquire multiple standard views of the spine.",,2021-11-03,2021-11-10,"['keyu li', 'yangxin xu', 'jian wang', 'dong ni', 'li liu', 'max q. -h. meng']"
2111.02194,learning implicit sentiment in aspect-based sentiment analysis with   supervised contrastive pre-training,cs.cl cs.ai,"aspect-based sentiment analysis aims to identify the sentiment polarity of a specific aspect in product reviews. we notice that about 30% of reviews do not contain obvious opinion words, but still convey clear human-aware sentiment orientation, which is known as implicit sentiment. however, recent neural network-based approaches paid little attention to implicit sentiment entailed in the reviews. to overcome this issue, we adopt supervised contrastive pre-training on large-scale sentiment-annotated corpora retrieved from in-domain language resources. by aligning the representation of implicit sentiment expressions to those with the same sentiment label, the pre-training process leads to better capture of both implicit and explicit sentiment orientation towards aspects in reviews. experimental results show that our method achieves state-of-the-art performance on semeval2014 benchmarks, and comprehensive analysis validates its effectiveness on learning implicit sentiment.",,2021-11-03,,"['zhengyan li', 'yicheng zou', 'chong zhang', 'qi zhang', 'zhongyu wei']"
2111.02202,proximal policy optimization with continuous bounded action space via   the beta distribution,cs.lg cs.ai,"reinforcement learning methods for continuous control tasks have evolved in recent years generating a family of policy gradient methods that rely primarily on a gaussian distribution for modeling a stochastic policy. however, the gaussian distribution has an infinite support, whereas real world applications usually have a bounded action space. this dissonance causes an estimation bias that can be eliminated if the beta distribution is used for the policy instead, as it presents a finite support. in this work, we investigate how this beta policy performs when it is trained by the proximal policy optimization (ppo) algorithm on two continuous control tasks from openai gym. for both tasks, the beta policy is superior to the gaussian policy in terms of agent's final expected reward, also showing more stability and faster convergence of the training process. for the carracing environment with high-dimensional image input, the agent's success rate was improved by 63% over the gaussian policy.",,2021-11-03,,"['irving g. b. petrazzini', 'eric a. antonelo']"
2111.02244,exploring explainable ai in the financial sector: perspectives of banks   and supervisory authorities,cs.ai,"explainable artificial intelligence (xai) is seen as a solution to making ai systems less of a black box. it is essential to ensure transparency, fairness, and accountability, which are especially paramount in the financial sector. the aim of this study was a preliminary investigation of the perspectives of supervisory authorities and regulated entities regarding the application of xai in the fi-nancial sector. three use cases (consumer credit, credit risk, and anti-money laundering) were examined using semi-structured interviews at three banks and two supervisory authorities in the netherlands. we found that for the investigated use cases a disparity exists between supervisory authorities and banks regarding the desired scope of explainability of ai systems. we argue that the financial sector could benefit from clear differentiation between technical ai (model) ex-plainability requirements and explainability requirements of the broader ai system in relation to applicable laws and regulations.",,2021-11-03,,"['ouren kuiper', 'martin van den berg', 'joost van der burgt', 'stefan leijnen']"
2111.02272,convolutional motif kernel networks,cs.lg cs.ai,"artificial neural networks are exceptionally good in learning to detect correlations within data that are associated with specified outcomes. however to deepen knowledge and support further research, researchers have to be able to explain predicted outcomes within the data's domain. furthermore, domain experts like healthcare providers need these explanations to assess whether a predicted outcome can be trusted in high stakes scenarios and to help them incorporating a model into their own routine. in this paper we introduce convolutional motif kernel networks, a neural network architecture that incorporates learning a feature representation within a subspace of the reproducing kernel hilbert space of the motif kernel function. the resulting model has state-of-the-art performance and enables researchers and domain experts to directly interpret and verify prediction outcomes without the need for a post hoc explainability method.",,2021-11-03,,"['jonas c. ditz', 'bernhard reuter', 'nico pfeifer']"
2111.02303,on the effectiveness of interpretable feedforward neural network,cs.lg cs.ai,"deep learning models have achieved state-of-the-art performance in many classification tasks. however, most of them cannot provide an interpretation for their classification results. machine learning models that are interpretable are usually linear or piecewise linear and yield inferior performance. non-linear models achieve much better classification performance, but it is hard to interpret their classification results. this may have been changed by an interpretable feedforward neural network (iffnn) proposed that achieves both high classification performance and interpretability for malware detection. if the iffnn can perform well in a more flexible and general form for other classification tasks while providing meaningful interpretations, it may be of great interest to the applied machine learning community. in this paper, we propose a way to generalize the interpretable feedforward neural network to multi-class classification scenarios and any type of feedforward neural networks, and evaluate its classification performance and interpretability on intrinsic interpretable datasets. we conclude by finding that the generalized iffnns achieve comparable classification performance to their normal feedforward neural network counterparts and provide meaningful interpretations. thus, this kind of neural network architecture has great practical use.",,2021-11-03,,"['miles q. li', 'benjamin c. m. fung', 'adel abusitta']"
2111.02306,a causality-based graphical test to obtain an optimal blocking set for   randomized experiments,stat.me cs.ai cs.lg econ.em stat.ml,randomized experiments are often performed to study the causal effects of interest. blocking is a technique to precisely estimate the causal effects when the experimental material is not homogeneous. we formalize the problem of obtaining a statistically optimal set of covariates to be used to create blocks while performing a randomized experiment. we provide a graphical test to obtain such a set for a general semi-markovian causal model. we also propose and provide ideas towards solving a more general problem of obtaining an optimal blocking set that considers both the statistical and economic costs of blocking.,,2021-11-03,,['abhishek k. umrawal']
2111.02329,implicit deep adaptive design: policy-based experimental design without   likelihoods,stat.ml cs.ai cs.lg stat.co,"we introduce implicit deep adaptive design (idad), a new method for performing adaptive experiments in real-time with implicit models. idad amortizes the cost of bayesian optimal experimental design (boed) by learning a design policy network upfront, which can then be deployed quickly at the time of the experiment. the idad network can be trained on any model which simulates differentiable samples, unlike previous design policy work that requires a closed form likelihood and conditionally independent experiments. at deployment, idad allows design decisions to be made in milliseconds, in contrast to traditional boed approaches that require heavy computation during the experiment itself. we illustrate the applicability of idad on a number of experiments, and show that it provides a fast and effective mechanism for performing adaptive design with implicit models.",,2021-11-03,,"['desi r. ivanova', 'adam foster', 'steven kleinegesse', 'michael u. gutmann', 'tom rainforth']"
2111.02353,associational memory networks,cs.ai,"we introduce associational memory networks(amns) that memorize and remember any data. this neural network has two memories. one consists of a queue-structured short-term memory to solve the class imbalance problem and long-term memory to store the distribution of objects, introducing the contents of storing and generating various datasets.",,2021-11-03,2021-11-17,"['seokjun kim', 'jaeeun jang', 'yeonju jang', 'seongyune choi', 'hyeoncheol kim']"
2111.02354,smooth imitation learning via smooth costs and smooth policies,cs.lg cs.ai,"imitation learning (il) is a popular approach in the continuous control setting as among other reasons it circumvents the problems of reward mis-specification and exploration in reinforcement learning (rl). in il from demonstrations, an important challenge is to obtain agent policies that are smooth with respect to the inputs. learning through imitation a policy that is smooth as a function of a large state-action ($s$-$a$) space (typical of high dimensional continuous control environments) can be challenging. we take a first step towards tackling this issue by using smoothness inducing regularizers on \textit{both} the policy and the cost models of adversarial imitation learning. our regularizers work by ensuring that the cost function changes in a controlled manner as a function of $s$-$a$ space; and the agent policy is well behaved with respect to the state space. we call our new smooth il algorithm \textit{smooth policy and cost imitation learning} (spacil, pronounced 'special'). we introduce a novel metric to quantify the smoothness of the learned policies. we demonstrate spacil's superior performance on continuous control tasks from mujoco. the algorithm not just outperforms the state-of-the-art il algorithm on our proposed smoothness metric, but, enjoys added benefits of faster learning and substantially higher average return.",10.1145/3493700.3493716,2021-11-03,,"['sapana chaudhary', 'balaraman ravindran']"
2111.02357,multivariate feature ranking of gene expression data,cs.lg cs.ai,"gene expression datasets are usually of high dimensionality and therefore require efficient and effective methods for identifying the relative importance of their attributes. due to the huge size of the search space of the possible solutions, the attribute subset evaluation feature selection methods tend to be not applicable, so in these scenarios feature ranking methods are used. most of the feature ranking methods described in the literature are univariate methods, so they do not detect interactions between factors. in this paper we propose two new multivariate feature ranking methods based on pairwise correlation and pairwise consistency, which we have applied in three gene expression classification problems. we statistically prove that the proposed methods outperform the state of the art feature ranking methods clustering variation, chi squared, correlation, information gain, relieff and significance, as well as feature selection methods of attribute subset evaluation based on correlation and consistency with multi-objective evolutionary search strategy.",,2021-11-03,2021-11-16,"['fernando jiménez', 'gracia sánchez', 'josé palma', 'luis miralles-pechuán', 'juan botía']"
2111.02364,honeycar: a framework to configure honeypot vulnerabilities on the   internet of vehicles,cs.cr cs.ai,"the internet of vehicles (iov), whereby interconnected vehicles communicate with each other and with road infrastructure on a common network, has promising socio-economic benefits but also poses new cyber-physical threats. data on vehicular attackers can be realistically gathered through cyber threat intelligence using systems like honeypots. admittedly, configuring honeypots introduces a trade-off between the level of honeypot-attacker interactions and any incurred overheads and costs for implementing and monitoring these honeypots. we argue that effective deception can be achieved through strategically configuring the honeypots to represent components of the iov and engage attackers to collect cyber threat intelligence. in this paper, we present honeycar, a novel decision support framework for honeypot deception in iov. honeycar builds upon a repository of known vulnerabilities of the autonomous and connected vehicles found in the common vulnerabilities and exposure (cve) data within the national vulnerability database (nvd) to compute optimal honeypot configuration strategies. by taking a game-theoretic approach, we model the adversarial interaction as a repeated imperfect-information zero-sum game in which the iov network administrator chooses a set of vulnerabilities to offer in a honeypot and a strategic attacker chooses a vulnerability of the iov to exploit under uncertainty. our investigation is substantiated by examining two different versions of the game, with and without the re-configuration cost to empower the network administrator to determine optimal honeypot configurations. we evaluate honeycar in a realistic use case to support decision makers with determining optimal honeypot configuration strategies for strategic deployment in iov.",,2021-11-03,,"['sakshyam panda', 'stefan rass', 'sotiris moschoyiannis', 'kaitai liang', 'george loukas', 'emmanouil panaousis']"
2111.02374,can i use this publicly available dataset to build commercial ai   software? most likely not,cs.lg cs.ai cs.se,"publicly available datasets are one of the key drivers for commercial ai software. the use of publicly available datasets (particularly for commercial purposes) is governed by dataset licenses. these dataset licenses outline the rights one is entitled to on a given dataset and the obligations that one must fulfil to enjoy such rights without any license compliance violations. however, unlike standardized open source software (oss) licenses, existing dataset licenses are defined in an ad-hoc manner and do not clearly outline the rights and obligations associated with their usage. this makes checking for potential license compliance violations difficult. further, a public dataset may be hosted in multiple locations and created from multiple data sources each of which may have different licenses. hence, existing approaches on checking oss license compliance cannot be used. in this paper, we propose a new approach to assess the potential license compliance violations if a given publicly available dataset were to be used for building commercial ai software. we conduct trials of our approach on two product groups within huawei on 6 commonly used publicly available datasets. our results show that there are risks of license violations on 5 of these 6 studied datasets if they were used for commercial purposes. consequently, we provide recommendations for ai engineers on how to better assess publicly available datasets for license compliance violations.",,2021-11-03,2021-11-09,"['gopi krishnan rajbahadur', 'erika tuck', 'li zi', 'zhang wei', 'dayi lin', 'boyuan chen', 'zhen ming', 'n/a jiang', 'daniel morales german']"
2111.02398,transparency of deep neural networks for medical image analysis: a   review of interpretability methods,eess.iv cs.ai cs.cv cs.lg,"artificial intelligence has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. deep neural networks have shown same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. in order to conform to the principles of trustworthy ai, it is essential that the ai system be transparent, robust, fair and ensure accountability. current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision making process. therefore, there is a need to ensure interpretability of deep neural networks before they can be incorporated in the routine clinical workflow. in this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. finally we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis.",,2021-10-31,,"['zohaib salahuddin', 'henry c woodruff', 'avishek chatterjee', 'philippe lambin']"
2111.02400,deep auc maximization for medical image classification: challenges and   opportunities,cs.lg cs.ai cs.cv eess.iv math.oc,"in this extended abstract, we will present and discuss opportunities and challenges brought about by a new deep learning method by auc maximization (aka \underline{\bf d}eep \underline{\bf a}uc \underline{\bf m}aximization or {\bf dam}) for medical image classification. since auc (aka area under roc curve) is a standard performance measure for medical image classification, hence directly optimizing auc could achieve a better performance for learning a deep neural network than minimizing a traditional loss function (e.g., cross-entropy loss). recently, there emerges a trend of using deep auc maximization for large-scale medical image classification. in this paper, we will discuss these recent results by highlighting (i) the advancements brought by stochastic non-convex optimization algorithms for dam; (ii) the promising results on various medical image classification problems. then, we will discuss challenges and opportunities of dam for medical image classification from three perspectives, feature learning, large-scale optimization, and learning trustworthy ai models.",,2021-11-01,,['tianbao yang']
2111.02408,partial supervision for the feta challenge 2021,eess.iv cs.ai cs.cv cs.lg,"this paper describes our method for our participation in the feta challenge2021 (team name: trabit). the performance of convolutional neural networks for medical image segmentation is thought to correlate positively with the number of training data. the feta challenge does not restrict participants to using only the provided training data but also allows for using other publicly available sources. yet, open access fetal brain data remains limited. an advantageous strategy could thus be to expand the training data to cover broader perinatal brain imaging sources. perinatal brain mris, other than the feta challenge data, that are currently publicly available, span normal and pathological fetal atlases as well as neonatal scans. however, perinatal brain mris segmented in different datasets typically come with different annotation protocols. this makes it challenging to combine those datasets to train a deep neural network. we recently proposed a family of loss functions, the label-set loss functions, for partially supervised learning. label-set loss functions allow to train deep neural networks with partially segmented images, i.e. segmentations in which some classes may be grouped into super-classes. we propose to use label-set loss functions to improve the segmentation performance of a state-of-the-art deep learning pipeline for multi-class fetal brain segmentation by merging several publicly available datasets. to promote generalisability, our approach does not introduce any additional hyper-parameters tuning.",,2021-11-03,,"['lucas fidon', 'michael aertsen', 'suprosanna shit', 'philippe demaerel', 'sébastien ourselin', 'jan deprest', 'tom vercauteren']"
2111.02445,autonomous attack mitigation for industrial control systems,cs.cr cs.ai cs.lg,"defending computer networks from cyber attack requires timely responses to alerts and threat intelligence. decisions about how to respond involve coordinating actions across multiple nodes based on imperfect indicators of compromise while minimizing disruptions to network operations. currently, playbooks are used to automate portions of a response process, but often leave complex decision-making to a human analyst. in this work, we present a deep reinforcement learning approach to autonomous response and recovery in large industrial control networks. we propose an attention-based neural architecture that is flexible to the size of the network under protection. to train and evaluate the autonomous defender agent, we present an industrial control network simulation environment suitable for reinforcement learning. experiments show that the learned agent can effectively mitigate advanced attacks that progress with few observable signals over several months before execution. the proposed deep reinforcement learning approach outperforms a fully automated playbook method in simulation, taking less disruptive actions while also defending more nodes on the network. the learned policy is also more robust to changes in attacker behavior than playbook approaches.",,2021-11-03,,"['john mern', 'kyle hatch', 'ryan silva', 'cameron hickert', 'tamim sookoor', 'mykel j. kochenderfer']"
2111.02450,unified 3d mesh recovery of humans and animals by learning animal   exercise,cs.cv cs.ai,"we propose an end-to-end unified 3d mesh recovery of humans and quadruped animals trained in a weakly-supervised way. unlike recent work focusing on a single target class only, we aim to recover 3d mesh of broader classes with a single multi-task model. however, there exists no dataset that can directly enable multi-task learning due to the absence of both human and animal annotations for a single object, e.g., a human image does not have animal pose annotations; thus, we have to devise a new way to exploit heterogeneous datasets. to make the unstable disjoint multi-task learning jointly trainable, we propose to exploit the morphological similarity between humans and animals, motivated by animal exercise where humans imitate animal poses. we realize the morphological similarity by semantic correspondences, called sub-keypoint, which enables joint training of human and animal mesh regression branches. besides, we propose class-sensitive regularization methods to avoid a mean-shape bias and to improve the distinctiveness across multi-classes. our method performs favorably against recent uni-modal models on various human and animal datasets while being far more compact.",,2021-11-03,,"['kim youwang', 'kim ji-yeon', 'kyungdon joo', 'tae-hyun oh']"
2111.02461,automatic ultrasound vessel segmentation with deep spatiotemporal   context learning,eess.iv cs.ai cs.cv cs.lg,"accurate, real-time segmentation of vessel structures in ultrasound image sequences can aid in the measurement of lumen diameters and assessment of vascular diseases. this, however, remains a challenging task, particularly for extremely small vessels that are difficult to visualize. we propose to leverage the rich spatiotemporal context available in ultrasound to improve segmentation of small-scale lower-extremity arterial vasculature. we describe efficient deep learning methods that incorporate temporal, spatial, and feature-aware contextual embeddings at multiple resolution scales while jointly utilizing information from b-mode and color doppler signals. evaluating on femoral and tibial artery scans performed on healthy subjects by an expert ultrasonographer, and comparing to consensus expert ground-truth annotations of inner lumen boundaries, we demonstrate real-time segmentation using the context-aware models and show that they significantly outperform comparable baseline approaches.",,2021-11-03,,"['baichuan jiang', 'alvin chen', 'shyam bharat', 'mingxin zheng']"
2111.02493,roadmap on signal processing for next generation measurement systems,eess.sp cs.ai cs.cv physics.ins-det,"signal processing is a fundamental component of almost any sensor-enabled system, with a wide range of applications across different scientific disciplines. time series data, images, and video sequences comprise representative forms of signals that can be enhanced and analysed for information extraction and quantification. the recent advances in artificial intelligence and machine learning are shifting the research attention towards intelligent, data-driven, signal processing. this roadmap presents a critical overview of the state-of-the-art methods and applications aiming to highlight future challenges and research opportunities towards next generation measurement systems. it covers a broad spectrum of topics ranging from basic to industrial research, organized in concise thematic sections that reflect the trends and the impacts of current and future developments per research field. furthermore, it offers guidance to researchers and funding agencies in identifying new prospects.",10.1088/1361-6501/ac2dbd,2021-11-03,2021-11-09,"['d. k. iakovidis', 'm. ooi', 'y. c. kuang', 's. demidenko', 'a. shestakov', 'v. sinitsin', 'm. henry', 'a. sciacchitano', 'a. discetti', 's. donati', 'm. norgia', 'a. menychtas', 'i. maglogiannis', 's. c. wriessnegger', 'l. a. barradas chacon', 'g. dimas', 'd. filos', 'a. h. aletras', 'j. töger', 'f. dong', 's. ren', 'a. uhl', 'j. paziewski', 'j. geng', 'f. fioranelli', 'r. m. narayanan', 'c. fernandez', 'c. stiller', 'k. malamousi', 's. kamnis', 'k. delibasis', 'd. wang', 'j. zhang', 'r. x. gao']"
2111.02513,evaluation of tree based regression over multiple linear regression for   non-normally distributed data in battery performance,cs.lg cs.ai,"battery performance datasets are typically non-normal and multicollinear. extrapolating such datasets for model predictions needs attention to such characteristics. this study explores the impact of data normality in building machine learning models. in this work, tree-based regression models and multiple linear regressions models are each built from a highly skewed non-normal dataset with multicollinearity and compared. several techniques are necessary, such as data transformation, to achieve a good multiple linear regression model with this dataset; the most useful techniques are discussed. with these techniques, the best multiple linear regression model achieved an r^2 = 81.23% and exhibited no multicollinearity effect for the dataset used in this study. tree-based models perform better on this dataset, as they are non-parametric, capable of handling complex relationships among variables and not affected by multicollinearity. we show that bagging, in the use of random forests, reduces overfitting. our best tree-based model achieved accuracy of r^2 = 97.73%. this study explains why tree-based regressions promise as a machine learning model for non-normally distributed, multicollinear data.",,2021-11-03,,"['shovan chowdhury', 'yuxiao lin', 'boryann liaw', 'leslie kerby']"
2111.02520,resampling and super-resolution of hexagonally sampled images using deep   learning,eess.iv cs.ai cs.cv cs.lg,"super-resolution (sr) aims to increase the resolution of imagery. applications include security, medical imaging, and object recognition. we propose a deep learning-based sr system that takes a hexagonally sampled low-resolution image as an input and generates a rectangularly sampled sr image as an output. for training and testing, we use a realistic observation model that includes optical degradation from diffraction and sensor degradation from detector integration. our sr approach first uses non-uniform interpolation to partially upsample the observed hexagonal imagery and convert it to a rectangular grid. we then leverage a state-of-the-art convolutional neural network (cnn) architecture designed for sr known as residual channel attention network (rcan). in particular, we use rcan to further upsample and restore the imagery to produce the final sr image estimate. we demonstrate that this system is superior to applying rcan directly to rectangularly sampled lr imagery with equivalent sample density. the theoretical advantages of hexagonal sampling are well known. however, to the best of our knowledge, the practical benefit of hexagonal sampling in light of modern processing techniques such as rcan sr is heretofore untested. our sr system demonstrates a notable advantage of hexagonally sampled imagery when employing a modified rcan for hexagonal sr.",10.1117/1.oe.60.10.103105,2021-11-03,,"['dylan flaute', 'russell c. hardie', 'hamed elwarfalli']"
2111.02552,is bang-bang control all you need? solving continuous control with   bernoulli policies,cs.lg cs.ai cs.ro,"reinforcement learning (rl) for continuous control typically employs distributions whose support covers the entire action space. in this work, we investigate the colloquially known phenomenon that trained agents often prefer actions at the boundaries of that space. we draw theoretical connections to the emergence of bang-bang behavior in optimal control, and provide extensive empirical evaluation across a variety of recent rl algorithms. we replace the normal gaussian by a bernoulli distribution that solely considers the extremes along each action dimension - a bang-bang controller. surprisingly, this achieves state-of-the-art performance on several continuous control benchmarks - in contrast to robotic hardware, where energy and maintenance cost affect controller choices. since exploration, learning,and the final solution are entangled in rl, we provide additional imitation learning experiments to reduce the impact of exploration on our analysis. finally, we show that our observations generalize to environments that aim to model real-world challenges and evaluate factors to mitigate the emergence of bang-bang solutions. our findings emphasize challenges for benchmarking continuous control algorithms, particularly in light of potential real-world applications.",,2021-11-03,,"['tim seyde', 'igor gilitschenski', 'wilko schwarting', 'bartolomeo stellato', 'martin riedmiller', 'markus wulfmeier', 'daniela rus']"
2111.02557,a meta-learned neuron model for continual learning,cs.lg cs.ai cs.ne,"continual learning is the ability to acquire new knowledge without forgetting the previously learned one, assuming no further access to past training data. neural network approximators trained with gradient descent are known to fail in this setting as they must learn from a stream of data-points sampled from a stationary distribution to converge. in this work, we replace the standard neuron by a meta-learned neuron model whom inference and update rules are optimized to minimize catastrophic interference. our approach can memorize dataset-length sequences of training samples, and its learning capabilities generalize to any domain. unlike previous continual learning methods, our method does not make any assumption about how tasks are constructed, delivered and how they relate to each other: it simply absorbs and retains training samples one by one, whether the stream of input data is time-correlated or not.",,2021-11-03,,['rodrigue siry']
2111.02603,"on semantic cognition, inductive generalization, and language models",cs.cl cs.ai,"my doctoral research focuses on understanding semantic knowledge in neural network models trained solely to predict natural language (referred to as language models, or lms), by drawing on insights from the study of concepts and categories grounded in cognitive science. i propose a framework inspired by 'inductive reasoning,' a phenomenon that sheds light on how humans utilize background knowledge to make inductive leaps and generalize from new pieces of information about concepts and their properties. drawing from experiments that study inductive reasoning, i propose to analyze semantic inductive generalization in lms using phenomena observed in human-induction literature, investigate inductive behavior on tasks such as implicit reasoning and emergent feature recognition, and analyze and relate induction dynamics to the learned conceptual representation space.",,2021-11-03,,['kanishka misra']
2111.02625,qimera: data-free quantization with synthetic boundary supporting   samples,cs.lg cs.ai cs.cv,"model quantization is known as a promising method to compress deep neural networks, especially for inferences on lightweight mobile or edge devices. however, model quantization usually requires access to the original training data to maintain the accuracy of the full-precision models, which is often infeasible in real-world scenarios for security and privacy issues. a popular approach to perform quantization without access to the original data is to use synthetically generated samples, based on batch-normalization statistics or adversarial learning. however, the drawback of such approaches is that they primarily rely on random noise input to the generator to attain diversity of the synthetic samples. we find that this is often insufficient to capture the distribution of the original data, especially around the decision boundaries. to this end, we propose qimera, a method that uses superposed latent embeddings to generate synthetic boundary supporting samples. for the superposed embeddings to better reflect the original distribution, we also propose using an additional disentanglement mapping layer and extracting information from the full-precision model. the experimental results show that qimera achieves state-of-the-art performances for various settings on data-free quantization. code is available at https://github.com/iamkanghyunchoi/qimera.",,2021-11-04,,"['kanghyun choi', 'deokki hong', 'noseong park', 'youngsok kim', 'jinho lee']"
2111.02626,characterizing human explanation strategies to inform the design of   explainable ai for building damage assessment,cs.hc cs.ai,"explainable ai (xai) is a promising means of supporting human-ai collaborations for high-stakes visual detection tasks, such as damage detection tasks from satellite imageries, as fully-automated approaches are unlikely to be perfectly safe and reliable. however, most existing xai techniques are not informed by the understandings of task-specific needs of humans for explanations. thus, we took a first step toward understanding what forms of xai humans require in damage detection tasks. we conducted an online crowdsourced study to understand how people explain their own assessments, when evaluating the severity of building damage based on satellite imagery. through the study with 60 crowdworkers, we surfaced six major strategies that humans utilize to explain their visual damage assessments. we present implications of our findings for the design of xai methods for such visual detection contexts, and discuss opportunities for future research.",,2021-11-04,,"['donghoon shin', 'sachin grover', 'kenneth holstein', 'adam perer']"
2111.02636,a control method for solving high-dimensional hamiltonian systems   through deep neural networks,math.oc cs.ai,"in this paper, we mainly focus on solving high-dimensional stochastic hamiltonian systems with boundary condition, and propose a novel method from the view of the stochastic control. in order to obtain the approximated solution of the hamiltonian system, we first introduce a corresponding stochastic optimal control problem such that the hamiltonian system of control problem is exactly what we need to solve, then develop two different algorithms suitable for different cases of the control problem and approximate the stochastic control via deep neural networks. from the numerical results, comparing with the deep fbsde method which was developed previously from the view of solving fbsdes, the novel algorithms converge faster, which means that they require fewer training steps, and demonstrate more stable convergences for different hamiltonian systems.",,2021-11-04,,"['shaolin ji', 'shige peng', 'ying peng', 'xichuan zhang']"
2111.02666,sensory attenuation develops as a result of sensorimotor experience,q-bio.nc cs.ai cs.lg cs.ro,"the brain attenuates its responses to self-produced exteroceptions (e.g., we cannot tickle ourselves). is this phenomenon, called sensory attenuation, enabled innately, or is it acquired through learning? to explore the latter possibility, we created a neural network model consisting of sensory (proprioceptive and exteroceptive), association, and executive areas. a simulated robot controlled by the network learned to acquire motor patterns with self-produced or externally produced exteroceptive feedback. we found that the robot first increased responses in sensory and association areas for both self-produced and externally produced conditions in the early stage of learning, but then, gradually it attenuated responses in sensory areas only for self-produced conditions. the robot spontaneously acquired a capacity to switch (attenuate or amplify) responses in sensory areas depending on the conditions by switching the neural state of the executive area. this suggests that proactive control of sensory-information flow inside the network was self-organized through learning. we also found that innate alterations in the modulation of sensory-information flow induced some characteristics analogous to schizophrenia and autism spectrum disorder. this study provides a novel perspective on neural mechanisms underlying perceptual phenomena and psychiatric disorders.",,2021-11-04,,"['hayato idei', 'wataru ohata', 'yuichi yamashita', 'tetsuya ogata', 'jun tani']"
2111.02671,graphsearchnet: enhancing gnns via capturing global dependency for   semantic code search,cs.se cs.ai,"code search aims to retrieve the relevant code fragments based on a natural language query to improve the software productivity and quality. however, automatic code search is challenging due to the semantic gap between the source code and the query. most existing approaches mainly consider the sequential information for embedding, where the structure information behind the text is not fully considered. in this paper, we design a novel neural network framework, named graphsearchnet, to enable an effective and accurate source code search by jointly learning rich semantics of both source code and queries. specifically, we propose to encode both source code and queries into two graphs with bidirectional ggnn to capture the local structure information of the graphs. furthermore, we enhance biggnn by utilizing the effective multi-head attention to supplement the global dependency that biggnn missed. the extensive experiments on both java and python datasets illustrate that graphsearchnet outperforms current state-of-the-art works by a significant margin.",,2021-11-04,,"['shangqing liu', 'xiaofei xie', 'lei ma', 'jingkai siow', 'yang liu']"
2111.02687,corelm: coreference-aware language model fine-tuning,cs.cl cs.ai cs.lg,"language models are the underpin of all modern natural language processing (nlp) tasks. the introduction of the transformers architecture has contributed significantly into making language modeling very effective across many nlp task, leading to significant advancements in the field. however, transformers come with a big computational cost, which grows quadratically with respect to the input length. this presents a challenge as to understand long texts requires a lot of context. in this paper, we propose a fine-tuning framework, named corelm, that extends the architecture of current pretrained language models so that they incorporate explicit entity information. by introducing entity representations, we make available information outside the contextual space of the model, which results in a better language model for a fraction of the computational cost. we implement our approach using gpt2 and compare the fine-tuned model to the original. our proposed model achieves a lower perplexity in gumby and lambdada datasets when compared to gpt2 and a fine-tuned version of gpt2 without any changes. we also compare the models' performance in terms of accuracy in lambada and children's book test, with and without the use of model-created coreference annotations.",,2021-11-04,,"['nikolaos stylianou', 'ioannis vlahavas']"
2111.02692,human age estimation from gene expression data using artificial neural   networks,q-bio.gn cs.ai,"the study of signatures of aging in terms of genomic biomarkers can be uniquely helpful in understanding the mechanisms of aging and developing models to accurately predict the age. prior studies have employed gene expression and dna methylation data aiming at accurate prediction of age. in this line, we propose a new framework for human age estimation using information from human dermal fibroblast gene expression data. first, we propose a new spatial representation as well as a data augmentation approach for gene expression data. next in order to predict the age, we design an architecture of neural network and apply it to this new representation of the original and augmented data, as an ensemble classification approach. our experimental results suggest the superiority of the proposed framework over state-of-the-art age estimation methods using dna methylation and gene expression data.",,2021-11-04,2021-11-04,"['salman mohamadi', 'gianfranco. doretto', 'nasser m. nasrabadi', 'donald a. adjeroh']"
2111.02724,tea chrysanthemum detection under unstructured environments using the   tc-yolo model,cs.cv cs.ai,"tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. however, it is a challenge to detect flowering chrysanthemums under unstructured field environments given the variations on illumination, occlusion and object scale. in this context, we propose a highly fused and lightweight deep learning architecture based on yolo for tea chrysanthemum detection (tc-yolo). first, in the backbone component and neck component, the method uses the cross-stage partially dense network (cspdensenet) as the main network, and embeds custom feature fusion modules to guide the gradient flow. in the final head component, the method combines the recursive feature pyramid (rfp) multiscale fusion reflow structure and the atrous spatial pyramid pool (aspp) module with cavity convolution to achieve the detection task. the resulting model was tested on 300 field images, showing that under the nvidia tesla p100 gpu environment, if the inference speed is 47.23 fps for each image (416 * 416), tc-yolo can achieve the average precision (ap) of 92.49% on our own tea chrysanthemum dataset. in addition, this method (13.6m) can be deployed on a single mobile gpu, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.",,2021-11-04,,"['chao qi', 'junfeng gao', 'simon pearson', 'helen harman', 'kunjie chen', 'lei shu']"
2111.02736,deep learning methods for daily wildfire danger forecasting,cs.lg cs.ai cs.cv,"wildfire forecasting is of paramount importance for disaster risk reduction and environmental sustainability. we approach daily fire danger prediction as a machine learning task, using historical earth observation data from the last decade to predict next-day's fire danger. to that end, we collect, pre-process and harmonize an open-access datacube, featuring a set of covariates that jointly affect the fire occurrence and spread, such as weather conditions, satellite-derived products, topography features and variables related to human activity. we implement a variety of deep learning (dl) models to capture the spatial, temporal or spatio-temporal context and compare them against a random forest (rf) baseline. we find that either spatial or temporal context is enough to surpass the rf, while a convlstm that exploits the spatio-temporal context performs best with a test area under the receiver operating characteristic of 0.926. our dl-based proof-of-concept provides national-scale daily fire danger maps at a much higher spatial resolution than existing operational solutions.",,2021-11-04,,"['ioannis prapas', 'spyros kondylatos', 'ioannis papoutsis', 'gustau camps-valls', 'michele ronco', 'miguel-ángel fernández-torres', 'maria piles guillem', 'nuno carvalhais']"
2111.02787,balanced q-learning: combining the influence of optimistic and   pessimistic targets,cs.lg cs.ai,"the optimistic nature of the q-learning target leads to an overestimation bias, which is an inherent problem associated with standard $q-$learning. such a bias fails to account for the possibility of low returns, particularly in risky scenarios. however, the existence of biases, whether overestimation or underestimation, need not necessarily be undesirable. in this paper, we analytically examine the utility of biased learning, and show that specific types of biases may be preferable, depending on the scenario. based on this finding, we design a novel reinforcement learning algorithm, balanced q-learning, in which the target is modified to be a convex combination of a pessimistic and an optimistic term, whose associated weights are determined online, analytically. we prove the convergence of this algorithm in a tabular setting, and empirically demonstrate its superior learning performance in various environments.",,2021-11-03,,"['thommen george karimpanal', 'hung le', 'majid abdolshah', 'santu rana', 'sunil gupta', 'truyen tran', 'svetha venkatesh']"
2111.02791,a cyber threat intelligence sharing scheme based on federated learning   for network intrusion detection,cs.lg cs.ai cs.cr cs.ni,"the uses of machine learning (ml) in detection of network attacks have been effective when designed and evaluated in a single organisation. however, it has been very challenging to design an ml-based detection system by utilising heterogeneous network data samples originating from several sources. this is mainly due to privacy concerns and the lack of a universal format of datasets. in this paper, we propose a collaborative federated learning scheme to address these issues. the proposed framework allows multiple organisations to join forces in the design, training, and evaluation of a robust ml-based network intrusion detection system. the threat intelligence scheme utilises two critical aspects for its application; the availability of network data traffic in a common format to allow for the extraction of meaningful patterns across data sources. secondly, the adoption of a federated learning mechanism to avoid the necessity of sharing sensitive users' information between organisations. as a result, each organisation benefits from other organisations cyber threat intelligence while maintaining the privacy of its data internally. the model is trained locally and only the updated weights are shared with the remaining participants in the federated averaging process. the framework has been designed and evaluated in this paper by using two key datasets in a netflow format known as nf-unsw-nb15-v2 and nf-bot-iot-v2. two other common scenarios are considered in the evaluation process; a centralised training method where the local data samples are shared with other organisations and a localised training method where no threat intelligence is shared. the results demonstrate the efficiency and effectiveness of the proposed framework by designing a universal ml model effectively classifying benign and intrusive traffic originating from multiple organisations without the need for local data exchange.",,2021-11-04,,"['mohanad sarhan', 'siamak layeghy', 'nour moustafa', 'marius portmann']"
2111.02823,convolutional generative adversarial imputation networks for   spatio-temporal missing data in storm surge simulations,cs.lg cs.ai cs.ce,"imputation of missing data is a task that plays a vital role in a number of engineering and science applications. often such missing data arise in experimental observations from limitations of sensors or post-processing transformation errors. other times they arise from numerical and algorithmic constraints in computer simulations. one such instance and the application emphasis of this paper are numerical simulations of storm surge. the simulation data corresponds to time-series surge predictions over a number of save points within the geographic domain of interest, creating a spatio-temporal imputation problem where the surge points are heavily correlated spatially and temporally, and the missing values regions are structurally distributed at random. very recently, machine learning techniques such as neural network methods have been developed and employed for missing data imputation tasks. generative adversarial nets (gans) and gan-based techniques have particularly attracted attention as unsupervised machine learning methods. in this study, the generative adversarial imputation nets (gain) performance is improved by applying convolutional neural networks instead of fully connected layers to better capture the correlation of data and promote learning from the adjacent surge points. another adjustment to the method needed specifically for the studied data is to consider the coordinates of the points as additional features to provide the model more information through the convolutional layers. we name our proposed method as convolutional generative adversarial imputation nets (conv-gain). the proposed method's performance by considering the improvements and adaptations required for the storm surge data is assessed and compared to the original gain and a few other techniques. the results show that conv-gain has better performance than the alternative methods on the studied data.",,2021-11-02,,"['ehsan adeli', 'jize zhang', 'alexandros a. taflanidis']"
2111.02825,whistleblower protection in the digital age -- why 'anonymous' is not   enough. towards an interdisciplinary view of ethical dilemmas,cs.ai cs.cy,"when technology enters applications and processes with a long tradition of controversial societal debate, multi-faceted new ethical and legal questions arise. this paper focusses on the process of whistleblowing, an activity with large impacts on democracy and business. computer science can, for the first time in history, provide for truly anonymous communication. we investigate this in relation to the values and rights of accountability, fairness and data protection, focusing on opportunities and limitations of the anonymity that can be provided computationally; possible consequences of outsourcing whistleblowing support; and challenges for the interpretation and use of some relevant laws. we conclude that to address these questions, whistleblowing and anonymous whistleblowing must rest on three pillars, forming a 'triangle of whistleblowing protection and incentivisation' that combines anonymity in a formal and technical sense; whistleblower protection through laws; and organisational and political error culture.",,2021-11-04,2021-11-11,"['bettina berendt', 'stefan schiffner']"
2111.02839,optimised playout implementations for the ludii general game system,cs.ai,"this paper describes three different optimised implementations of playouts, as commonly used by game-playing algorithms such as monte-carlo tree search. each of the optimised implementations is applicable only to specific sets of games, based on their rules. the ludii general game system can automatically infer, based on a game's description in its general game description language, whether any optimised implementations are applicable. an empirical evaluation demonstrates major speedups over a standard implementation, with a median result of running playouts 5.08 times as fast, over 145 different games in ludii for which one of the optimised implementations is applicable.",,2021-11-04,,"['dennis j. n. j. soemers', 'éric piette', 'matthew stephenson', 'cameron browne']"
2111.02842,adversarial attacks on graph classification via bayesian optimisation,stat.ml cs.ai cs.cr cs.lg,"graph neural networks, a popular class of models effective in a wide range of graph-based learning tasks, have been shown to be vulnerable to adversarial attacks. while the majority of the literature focuses on such vulnerability in node-level classification tasks, little effort has been dedicated to analysing adversarial attacks on graph-level classification, an important problem with numerous real-life applications such as biochemistry and social network analysis. the few existing methods often require unrealistic setups, such as access to internal information of the victim models, or an impractically-large number of queries. we present a novel bayesian optimisation-based attack method for graph classification models. our method is black-box, query-efficient and parsimonious with respect to the perturbation applied. we empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. finally, we analyse common interpretable patterns behind the adversarial samples produced, which may shed further light on the adversarial robustness of graph classification models.",,2021-11-04,,"['xingchen wan', 'henry kenlay', 'binxin ru', 'arno blaas', 'michael a. osborne', 'xiaowen dong']"
2111.02844,a text autoencoder from transformer for fast encoding language   representation,cs.cl cs.ai,"in recent years bert shows apparent advantages and great potential in natural language processing tasks. however, both training and applying bert requires intensive time and resources for computing contextual language representations, which hinders its universality and applicability. to overcome this bottleneck, we propose a deep bidirectional language model by using window masking mechanism at attention layer. this work computes contextual language representations without random masking as does in bert and maintains the deep bidirectional architecture like bert. to compute the same sentence representation, our method shows o(n) complexity less compared to other transformer-based models with o($n^2$). to further demonstrate its superiority, computing context language representations on cpu environments is conducted, by using the embeddings from the proposed method, logistic regression shows much higher accuracy in terms of sms classification. moverover, the proposed method also achieves significant higher performance in semantic similarity tasks.",,2021-11-04,,['tan huang']
2111.02845,attacking deep reinforcement learning-based traffic signal control   systems with colluding vehicles,cs.lg cs.ai cs.cr,"the rapid advancements of internet of things (iot) and artificial intelligence (ai) have catalyzed the development of adaptive traffic signal control systems (atcs) for smart cities. in particular, deep reinforcement learning (drl) methods produce the state-of-the-art performance and have great potentials for practical applications. in the existing drl-based atcs, the controlled signals collect traffic state information from nearby vehicles, and then optimal actions (e.g., switching phases) can be determined based on the collected information. the drl models fully ""trust"" that vehicles are sending the true information to the signals, making the atcs vulnerable to adversarial attacks with falsified information. in view of this, this paper first time formulates a novel task in which a group of vehicles can cooperatively send falsified information to ""cheat"" drl-based atcs in order to save their total travel time. to solve the proposed task, we develop collusionveh, a generic and effective vehicle-colluding framework composed of a road situation encoder, a vehicle interpreter, and a communication mechanism. we employ our method to attack established drl-based atcs and demonstrate that the total travel time for the colluding vehicles can be significantly reduced with a reasonable number of learning episodes, and the colluding effect will decrease if the number of colluding vehicles increases. additionally, insights and suggestions for the real-world deployment of drl-based atcs are provided. the research outcomes could help improve the reliability and robustness of the atcs and better protect the smart mobility systems.",,2021-11-04,,"['ao qu', 'yihong tang', 'wei ma']"
2111.02853,"big data testing techniques: taxonomy, challenges and future trends",cs.ai cs.se,"big data is reforming many industrial domains by providing decision support through analyzing large volumes of data. big data testing aims to ensure that big data systems run smoothly and error-free while maintaining the performance and quality of data. however, because of the diversity and complexity of data, testing big data is challenging. though numerous researches deal with big data testing, a comprehensive review to address testing techniques and challenges is not conflate yet. therefore, we have conducted a systematic review of the big data testing techniques period (2010 - 2021). this paper discusses the processing of testing data by highlighting the techniques used in every processing phase. furthermore, we discuss the challenges and future directions. our finding shows that diverse functional, non-functional and combined (functional and non-functional) testing techniques have been used to solve specific problems related to big data. at the same time, most of the testing challenges have been faced during the mapreduce validation phase. in addition, the combinatorial testing technique is one of the most applied techniques in combination with other techniques (i.e., random testing, mutation testing, input space partitioning and equivalence testing) to solve various functional faults challenges faced during big data testing.",,2021-11-04,,"['iram arshad', 'saeed hamood alsamhi']"
2111.02859,large scale diverse combinatorial optimization: espn fantasy football   player trades,cs.ai,"even skilled fantasy football managers can be disappointed by their mid-season rosters as some players inevitably fall short of draft day expectations. team managers can quickly discover that their team has a low score ceiling even if they start their best active players. a novel and diverse combinatorial optimization system proposes high volume and unique player trades between complementary teams to balance trade fairness. several algorithms create the valuation of each fantasy football player with an ensemble of computing models: quantum support vector classifier with permutation importance (qsvc-pi), quantum support vector classifier with accumulated local effects (qsvc-ale), variational quantum circuit with permutation importance (vqc-pi), hybrid quantum neural network with permutation importance (hqnn-pi), extreme gradient boosting classifier (xgb), and subject matter expert (sme) rules. the valuation of each player is personalized based on league rules, roster, and selections. the cost of trading away a player is related to a team's roster, such as the depth at a position, slot count, and position importance. teams are paired together for trading based on a cosine dissimilarity score so that teams can offset their strengths and weaknesses. a knapsack 0-1 algorithm computes outgoing players for each team. postprocessors apply analytics and deep learning models to measure 6 different objective measures about each trade. over the 2020 and 2021 national football league (nfl) seasons, a group of 24 experts from ibm and espn evaluated trade quality through 10 football error analysis tool (feat) sessions. our system started with 76.9% of high-quality trades and was deployed for the 2021 season with 97.3% of high-quality trades. to increase trade quantity, our quantum, classical, and rules-based computing have 100% trade uniqueness. we use qiskit's quantum simulators throughout our work.",,2021-11-04,2021-11-04,"['aaron baughman', 'daniel bohm', 'micah forster', 'eduardo morales', 'jeff powell', 'shaun mcpartlin', 'raja hebbar', 'kavitha yogaraj', 'yoshika chhabra', 'sudeep ghosh', 'rukhsan ul haq', 'arjun kashyap']"
2111.02874,deep artificial intelligence for fantasy football language understanding,cs.ai cs.lg,"fantasy sports allow fans to manage a team of their favorite athletes and compete with friends. the fantasy platform aligns the real-world statistical performance of athletes to fantasy scoring and has steadily risen in popularity to an estimated 9.1 million players per month with 4.4 billion player card views on the espn fantasy football platform from 2018-2019. in parallel, the sports media community produces news stories, blogs, forum posts, tweets, videos, podcasts and opinion pieces that are both within and outside the context of fantasy sports. however, human fantasy football players can only analyze an average of 3.9 sources of information. our work discusses the results of a machine learning pipeline to manage an espn fantasy football team. the use of trained statistical entity detectors and document2vector models applied to over 100,000 news sources and 2.3 million articles, videos and podcasts each day enables the system to comprehend natural language with an analogy test accuracy of 100% and keyword test accuracy of 80%. deep learning feedforward neural networks provide player classifications such as if a player will be a bust, boom, play with a hidden injury or play meaningful touches with a cumulative 72% accuracy. finally, a multiple regression ensemble uses the deep learning output and espn projection data to provide a point projection for each of the top 500+ fantasy football players in 2018. the point projection maintained a rmse of 6.78 points. the best fit probability density function from a set of 24 is selected to visualize score spreads. within the first 6 weeks of the product launch, the total number of users spent a cumulative time of over 4.6 years viewing our ai insights. the training data for our models was provided by a 2015 to 2016 web archive from webhose, espn statistics, and rotowire injury reports. we used 2017 fantasy football data as a test set.",,2021-11-04,,"['aaron baughman', 'micah forester', 'jeff powell', 'eduardo morales', 'shaun mcpartlin', 'daniel bohm']"
2111.02916,a unified view of relational deep learning for drug pair scoring,cs.lg cs.ai cs.si,"in recent years, numerous machine learning models which attempt to solve polypharmacy side effect identification, drug-drug interaction prediction and combination therapy design tasks have been proposed. here, we present a unified theoretical view of relational machine learning models which can address these tasks. we provide fundamental definitions, compare existing model architectures and discuss performance metrics, datasets and evaluation protocols. in addition, we emphasize possible high impact applications and important future research directions in this domain.",,2021-11-04,2021-11-14,"['benedek rozemberczki', 'stephen bonner', 'andriy nikolov', 'michael ughetto', 'sebastian nilsson', 'eliseo papa']"
2111.03003,"scanflow: a multi-graph framework for machine learning workflow   management, supervision, and debugging",cs.lg cs.ai,"machine learning (ml) is more than just training models, the whole workflow must be considered. once deployed, a ml model needs to be watched and constantly supervised and debugged to guarantee its validity and robustness in unexpected situations. debugging in ml aims to identify (and address) the model weaknesses in not trivial contexts. several techniques have been proposed to identify different types of model weaknesses, such as bias in classification, model decay, adversarial attacks, etc., yet there is not a generic framework that allows them to work in a collaborative, modular, portable, iterative way and, more importantly, flexible enough to allow both human- and machine-driven techniques. in this paper, we propose a novel containerized directed graph framework to support and accelerate end-to-end ml workflow management, supervision, and debugging. the framework allows defining and deploying ml workflows in containers, tracking their metadata, checking their behavior in production, and improving the models by using both learned and human-provided knowledge. we demonstrate these capabilities by integrating in the framework two hybrid systems to detect data drift distribution which identify the samples that are far from the latent space of the original distribution, ask for human intervention, and whether retrain the model or wrap it with a filter to remove the noise of corrupted data at inference time. we test these systems on mnist-c, cifar-10-c, and fashionmnist-c datasets, obtaining promising accuracy results with the help of human involvement.",,2021-11-04,,"['gusseppe bravo-rocca', 'peini liu', 'jordi guitart', 'ajay dholakia', 'david ellison', 'jeffrey falkanger', 'miroslav hodak']"
2111.03026,b-pref: benchmarking preference-based reinforcement learning,cs.lg cs.ai cs.hc,"reinforcement learning (rl) requires access to a reward function that incentivizes the right behavior, but these are notoriously hard to specify for complex tasks. preference-based rl provides an alternative: learning policies using a teacher's preferences without pre-defined rewards, thus overcoming concerns associated with reward engineering. however, it is difficult to quantify the progress in preference-based rl due to the lack of a commonly adopted benchmark. in this paper, we introduce b-pref: a benchmark specially designed for preference-based rl. a key challenge with such a benchmark is providing the ability to evaluate candidate algorithms quickly, which makes relying on real human input for evaluation prohibitive. at the same time, simulating human input as giving perfect preferences for the ground truth reward function is unrealistic. b-pref alleviates this by simulating teachers with a wide array of irrationalities, and proposes metrics not solely for performance but also for robustness to these potential irrationalities. we showcase the utility of b-pref by using it to analyze algorithmic design choices, such as selecting informative queries, for state-of-the-art preference-based rl algorithms. we hope that b-pref can serve as a common starting point to study preference-based rl more systematically. source code is available at https://github.com/rll-research/b-pref.",,2021-11-04,,"['kimin lee', 'laura smith', 'anca dragan', 'pieter abbeel']"
2111.03042,unsupervised learning of compositional energy concepts,cs.cv cs.ai cs.lg,"humans are able to rapidly understand scenes by utilizing concepts extracted from prior experience. such concepts are diverse, and include global scene descriptors, such as the weather or lighting, as well as local scene descriptors, such as the color or size of a particular object. so far, unsupervised discovery of concepts has focused on either modeling the global scene-level or the local object-level factors of variation, but not both. in this work, we propose comet, which discovers and represents concepts as separate energy functions, enabling us to represent both global concepts as well as objects under a unified framework. comet discovers energy functions through recomposing the input image, which we find captures independent factors without additional supervision. sample generation in comet is formulated as an optimization process on underlying energy functions, enabling us to generate images with permuted and composed concepts. finally, discovered visual concepts in comet generalize well, enabling us to compose concepts between separate modalities of images as well as with other concepts discovered by a separate instance of comet trained on a different dataset. code and data available at https://energy-based-model.github.io/comet/.",,2021-11-04,,"['yilun du', 'shuang li', 'yash sharma', 'joshua b. tenenbaum', 'igor mordatch']"
2111.03043,a system for general in-hand object re-orientation,cs.ro cs.ai cs.lg,in-hand object reorientation has been a challenging problem in robotics due to high dimensional actuation space and the frequent change in contact state between the fingers and the objects. we present a simple model-free framework that can learn to reorient objects with both the hand facing upwards and downwards. we demonstrate the capability of reorienting over 2000 geometrically different objects in both cases. the learned policies show strong zero-shot transfer performance on new objects. we provide evidence that these policies are amenable to real-world operation by distilling them to use observations easily available in the real world. the videos of the learned policies are available at: https://taochenshh.github.io/projects/in-hand-reorientation.,,2021-11-04,,"['tao chen', 'jie xu', 'pulkit agrawal']"
2111.03048,imagine networks,cs.ai,"in this paper, we introduce an imagine network that can simulate itself through artificial association networks. association, deduction, and memory networks are learned, and a network is created by combining the discriminator and reinforcement learning models. this model can learn various datasets or data samples generated in environments and generate new data samples.",,2021-11-04,2021-11-17,"['seokjun kim', 'jaeeun jang', 'hyeoncheol kim']"
2111.03059,engagement decision support for beyond visual range air combat,cs.ai,"this work aims to provide an engagement decision support tool for beyond visual range (bvr) air combat in the context of defensive counter air (dca) missions. in bvr air combat, engagement decision refers to the choice of the moment the pilot engages a target by assuming an offensive stance and executing corresponding maneuvers. to model this decision, we use the brazilian air force's aerospace simulation environment (ambiente de simula\c{c}\~ao aeroespacial - asa in portuguese), which generated 3,729 constructive simulations lasting 12 minutes each and a total of 10,316 engagements. we analyzed all samples by an operational metric called the dca index, which represents, based on the experience of subject matter experts, the degree of success in this type of mission. this metric considers the distances of the aircraft of the same team and the opposite team, the point of combat air patrol, and the number of missiles used. by defining the engagement status right before it starts and the average of the dca index throughout the engagement, we create a supervised learning model to determine the quality of a new engagement. an algorithm based on decision trees, working with the xgboost library, provides a regression model to predict the dca index with a coefficient of determination close to 0.8 and a root mean square error of 0.05 that can furnish parameters to the bvr pilot to decide whether or not to engage. thus, using data obtained through simulations, this work contributes by building a decision support system based on machine learning for bvr air combat.",,2021-11-04,2021-11-17,"['joao p. a. dantas', 'andre n. costa', 'diego geraldo', 'marcos r. o. a. maximo', 'takashi yoneyama']"
2111.03062,generalization in dexterous manipulation via geometry-aware multi-task   learning,cs.ro cs.ai cs.cv cs.lg cs.sy eess.sy,"dexterous manipulation of arbitrary objects, a fundamental daily task for humans, has been a grand challenge for autonomous robotic systems. although data-driven approaches using reinforcement learning can develop specialist policies that discover behaviors to control a single object, they often exhibit poor generalization to unseen ones. in this work, we show that policies learned by existing reinforcement learning algorithms can in fact be generalist when combined with multi-task learning and a well-chosen object representation. we show that a single generalist policy can perform in-hand manipulation of over 100 geometrically-diverse real-world objects and generalize to new objects with unseen shape or size. interestingly, we find that multi-task learning with object point cloud representations not only generalizes better but even outperforms the single-object specialist policies on both training as well as held-out test objects. video results at https://huangwl18.github.io/geometry-dex",,2021-11-04,,"['wenlong huang', 'igor mordatch', 'pieter abbeel', 'deepak pathak']"
2111.03106,skeleton-split framework using spatial temporal graph convolutional   networks for action recogntion,cs.cv cs.ai,"there has been a dramatic increase in the volume of videos and their related content uploaded to the internet. accordingly, the need for efficient algorithms to analyse this vast amount of data has attracted significant research interest. an action recognition system based upon human body motions has been proven to interpret videos contents accurately. this work aims to recognize activities of daily living using the st-gcn model, providing a comparison between four different partitioning strategies: spatial configuration partitioning, full distance split, connection split, and index split. to achieve this aim, we present the first implementation of the st-gcn framework upon the hmdb-51 dataset. we have achieved 48.88 % top-1 accuracy by using the connection split partitioning approach. through experimental simulation, we show that our proposals have achieved the highest accuracy performance on the ucf-101 dataset using the st-gcn framework than the state-of-the-art approach. finally, accuracy of 73.25 % top-1 is achieved by using the index split partitioning strategy.",,2021-11-04,,"['motasem alsawadi', 'miguel rio']"
2111.03110,successor feature neural episodic control,cs.lg cs.ai,"a longstanding goal in reinforcement learning is to build intelligent agents that show fast learning and a flexible transfer of skills akin to humans and animals. this paper investigates the integration of two frameworks for tackling those goals: episodic control and successor features. episodic control is a cognitively inspired approach relying on episodic memory, an instance-based memory model of an agent's experiences. meanwhile, successor features and generalized policy improvement (sf&gpi) is a meta and transfer learning framework allowing to learn policies for tasks that can be efficiently reused for later tasks which have a different reward function. individually, these two techniques have shown impressive results in vastly improving sample efficiency and the elegant reuse of previously learned policies. thus, we outline a combination of both approaches in a single reinforcement learning framework and empirically illustrate its benefits.",,2021-11-04,,"['david emukpere', 'xavier alameda-pineda', 'chris reinke']"
2111.03120,adversarial attacks on knowledge graph embeddings via instance   attribution methods,cs.lg cs.ai cs.cl cs.ne,"despite the widespread use of knowledge graph embeddings (kge), little is known about the security vulnerabilities that might disrupt their intended behaviour. we study data poisoning attacks against kge models for link prediction. these attacks craft adversarial additions or deletions at training time to cause model failure at test time. to select adversarial deletions, we propose to use the model-agnostic instance attribution methods from interpretable machine learning, which identify the training instances that are most influential to a neural model's predictions on test instances. we use these influential triples as adversarial deletions. we further propose a heuristic method to replace one of the two entities in each influential triple to generate adversarial additions. our experiments show that the proposed strategies outperform the state-of-art data poisoning attacks on kge models and improve the mrr degradation due to the attacks by up to 62% over the baselines.",,2021-11-04,,"['peru bhardwaj', 'john kelleher', 'luca costabello', ""declan o'sullivan""]"
2111.03126,generative adversarial network for probabilistic forecast of random   dynamical system,cs.lg cs.ai math.ds physics.data-an stat.ml,"we present a deep learning model for data-driven simulations of random dynamical systems without a distributional assumption. the deep learning model consists of a recurrent neural network, which aims to learn the time marching structure, and a generative adversarial network to learn and sample from the probability distribution of the random dynamical system. although generative adversarial networks provide a powerful tool to model a complex probability distribution, the training often fails without a proper regularization. here, we propose a regularization strategy for a generative adversarial network based on consistency conditions for the sequential inference problems. first, the maximum mean discrepancy (mmd) is used to enforce the consistency between conditional and marginal distributions of a stochastic process. then, the marginal distributions of the multiple-step predictions are regularized by using mmd or from multiple discriminators. the behavior of the proposed model is studied by using three stochastic processes with complex noise structures.",,2021-11-04,,"['kyongmin yeo', 'zan li', 'wesley m. gifford']"
2111.03140,multi-objective constrained optimization for energy applications via   tree ensembles,stat.ml cs.ai cs.lg math.oc,"energy systems optimization problems are complex due to strongly non-linear system behavior and multiple competing objectives, e.g. economic gain vs. environmental impact. moreover, a large number of input variables and different variable types, e.g. continuous and categorical, are challenges commonly present in real-world applications. in some cases, proposed optimal solutions need to obey explicit input constraints related to physical properties or safety-critical operating conditions. this paper proposes a novel data-driven strategy using tree ensembles for constrained multi-objective optimization of black-box problems with heterogeneous variable spaces for which underlying system dynamics are either too complex to model or unknown. in an extensive case study comprised of synthetic benchmarks and relevant energy applications we demonstrate the competitive performance and sampling efficiency of the proposed algorithm compared to other state-of-the-art tools, making it a useful all-in-one solution for real-world applications with limited evaluation budgets.",10.1016/j.apenergy.2021.118061,2021-11-04,,"['alexander thebelt', 'calvin tsay', 'robert m. lee', 'nathan sudermann-merx', 'david walz', 'tom tranter', 'ruth misener']"
2111.03160,predictive machine learning of objective boundaries for solving cops,cs.ai cs.lg,"solving constraint optimization problems (cops) can be dramatically simplified by boundary estimation, that is, providing tight boundaries of cost functions. by feeding a supervised machine learning (ml) model with data composed of known boundaries and extracted features of cops, it is possible to train the model to estimate boundaries of a new cop instance. in this paper, we first give an overview of the existing body of knowledge on ml for constraint programming (cp) which learns from problem instances. second, we introduce a boundary estimation framework that is applied as a tool to support a cp solver. within this framework, different ml models are discussed and evaluated regarding their suitability for boundary estimation, and countermeasures to avoid unfeasible estimations that avoid the solver to find an optimal solution are shown. third, we present an experimental study with distinct cp solvers on seven cops. our results show that near-optimal boundaries can be learned for these cops with only little overhead. these estimated boundaries reduce the objective domain size by 60-88% and can help the solver to find near-optimal solutions early during search.",10.3390/ai2040033,2021-11-04,,"['helge spieker', 'arnaud gotlieb']"
2111.03186,editgan: high-precision semantic image editing,cs.cv cs.ai,"generative adversarial networks (gans) have recently found applications in image editing. however, most gan based image editing methods often require large scale datasets with semantic segmentation annotations for training, only provide high level control, or merely interpolate between different images. here, we propose editgan, a novel method for high quality, high precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. editgan builds on a gan framework that jointly models images and their semantic segmentations, requiring only a handful of labeled examples, making it a scalable tool for editing. specifically, we embed an image into the gan latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. to amortize optimization, we find editing vectors in latent space that realize the edits. the framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. we experimentally show that editgan can manipulate images with an unprecedented level of detail and freedom, while preserving full image quality.we can also easily combine multiple edits and perform plausible edits beyond editgan training data. we demonstrate editgan on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks.",,2021-11-04,,"['huan ling', 'karsten kreis', 'daiqing li', 'seung wook kim', 'antonio torralba', 'sanja fidler']"
2111.03189,value function spaces: skill-centric state abstractions for long-horizon   reasoning,cs.lg cs.ai cs.ro,"reinforcement learning can train policies that effectively perform complex tasks. however for long-horizon tasks, the performance of these methods degrades with horizon, often necessitating reasoning over and composing lower-level skills. hierarchical reinforcement learning aims to enable this by providing a bank of low-level skills as action abstractions. hierarchies can further improve on this by abstracting the space states as well. we posit that a suitable state abstraction should depend on the capabilities of the available lower-level policies. we propose value function spaces: a simple approach that produces such a representation by using the value functions corresponding to each lower-level skill. these value functions capture the affordances of the scene, thus forming a representation that compactly abstracts task relevant information and robustly ignores distractors. empirical evaluations for maze-solving and robotic manipulation tasks demonstrate that our approach improves long-horizon performance and enables better zero-shot generalization than alternative model-free and model-based methods.",,2021-11-04,,"['dhruv shah', 'peng xu', 'yao lu', 'ted xiao', 'alexander toshev', 'sergey levine', 'brian ichter']"
2111.03204,learning model predictive controllers for real-time ride-hailing vehicle   relocation and pricing decisions,cs.ai,"large-scale ride-hailing systems often combine real-time routing at the individual request level with a macroscopic model predictive control (mpc) optimization for dynamic pricing and vehicle relocation. the mpc relies on a demand forecast and optimizes over a longer time horizon to compensate for the myopic nature of the routing optimization. however, the longer horizon increases computational complexity and forces the mpc to operate at coarser spatial-temporal granularity, degrading the quality of its decisions. this paper addresses these computational challenges by learning the mpc optimization. the resulting machine-learning model then serves as the optimization proxy and predicts its optimal solutions. this makes it possible to use the mpc at higher spatial-temporal fidelity, since the optimizations can be solved and learned offline. experimental results show that the proposed approach improves quality of service on challenging instances from the new york city dataset.",,2021-11-04,,"['enpeng yuan', 'pascal van hentenryck']"
2111.03205,lila: language-informed latent actions,cs.ro cs.ai cs.cl cs.hc cs.lg,"we introduce language-informed latent actions (lila), a framework for learning natural language interfaces in the context of human-robot collaboration. lila falls under the shared autonomy paradigm: in addition to providing discrete language inputs, humans are given a low-dimensional controller $-$ e.g., a 2 degree-of-freedom (dof) joystick that can move left/right and up/down $-$ for operating the robot. lila learns to use language to modulate this controller, providing users with a language-informed control space: given an instruction like ""place the cereal bowl on the tray,"" lila may learn a 2-dof space where one dimension controls the distance from the robot's end-effector to the bowl, and the other dimension controls the robot's end-effector pose relative to the grasp point on the bowl. we evaluate lila with real-world user studies, where users can provide a language instruction while operating a 7-dof franka emika panda arm to complete a series of complex manipulation tasks. we show that lila models are not only more sample efficient and performant than imitation learning and end-effector control baselines, but that they are also qualitatively preferred by users.",,2021-11-04,,"['siddharth karamcheti', 'megha srivastava', 'percy liang', 'dorsa sadigh']"
2111.03212,an overview of event extraction and its applications,cs.cl cs.ai cs.lg,"with the rapid development of information technology, online platforms have produced enormous text resources. as a particular form of information extraction (ie), event extraction (ee) has gained increasing popularity due to its ability to automatically extract events from human language. however, there are limited literature surveys on event extraction. existing review works either spend much effort describing the details of various approaches or focus on a particular field. this study provides a comprehensive overview of the state-of-the-art event extraction methods and their applications from text, including closed-domain and open-domain event extraction. a trait of this survey is that it provides an overview in moderate complexity, avoiding involving too many details of particular approaches. this study focuses on discussing the common characters, application fields, advantages, and disadvantages of representative works, ignoring the specificities of individual approaches. finally, we summarize the common issues, current solutions, and future research directions. we hope this work could help researchers and practitioners obtain a quick overview of recent event extraction.",,2021-11-04,,"['jiangwei liu', 'liangyu min', 'xiaohong huang']"
2111.03260,remote sensing image super-resolution and object detection: benchmark   and state of the art,cs.cv cs.ai cs.lg eess.iv,"for the past two decades, there have been significant efforts to develop methods for object detection in remote sensing (rs) images. in most cases, the datasets for small object detection in remote sensing images are inadequate. many researchers used scene classification datasets for object detection, which has its limitations; for example, the large-sized objects outnumber the small objects in object categories. thus, they lack diversity; this further affects the detection performance of small object detectors in rs images. this paper reviews current datasets and object detection methods (deep learning-based) for remote sensing images. we also propose a large-scale, publicly available benchmark remote sensing super-resolution object detection (rssod) dataset. the rssod dataset consists of 1,759 hand-annotated images with 22,091 instances of very high resolution (vhr) images with a spatial resolution of ~0.05 m. there are five classes with varying frequencies of labels per class. the image patches are extracted from satellite images, including real image distortions such as tangential scale distortion and skew distortion. we also propose a novel multi-class cyclic super-resolution generative adversarial network with residual feature aggregation (mcgr) and auxiliary yolov5 detector to benchmark image super-resolution-based object detection and compare with the existing state-of-the-art methods based on image super-resolution (sr). the proposed mcgr achieved state-of-the-art performance for image sr with an improvement of 1.2db psnr compared to the current state-of-the-art nlsn method. mcgr achieved best object detection maps of 0.758, 0.881, 0.841, and 0.983, respectively, for five-class, four-class, two-class, and single classes, respectively surpassing the performance of the state-of-the-art object detectors yolov5, efficientdet, faster rcnn, ssd, and retinanet.",,2021-11-05,,"['yi wang', 'syed muhammad arsalan bashir', 'mahrukh khan', 'qudrat ullah', 'rui wang', 'yilin song', 'zhe guo', 'yilong niu']"
2111.03262,collaborative graph contrastive learning: data augmentation composition   may not be necessary for graph representation learning,cs.lg cs.ai,"unsupervised graph representation learning is a non-trivial topic for graph data. the success of contrastive learning and self-supervised learning in the unsupervised representation learning of structured data inspires similar attempts on the graph. the current unsupervised graph representation learning and pre-training using the contrastive loss are mainly based on the contrast between handcrafted augmented graph data. however, the graph data augmentation is still not well-explored due to the unpredictable invariance. in this paper, we propose a novel collaborative graph neural networks contrastive learning framework (cgcl), which uses multiple graph encoders to observe the graph. features observed from different views act as the graph augmentation for contrastive learning between graph encoders, avoiding any perturbation to guarantee the invariance. cgcl is capable of handling both graph-level and node-level representation learning. extensive experiments demonstrate the advantages of cgcl in unsupervised graph representation learning and the non-necessity of handcrafted data augmentation composition for graph representation learning.",,2021-11-05,,"['yuxiang ren', 'jiawei zhang']"
2111.03284,dialogue inspectional summarization with factual inconsistency awareness,cs.cl cs.ai,"dialogue summarization has been extensively studied and applied, where the prior works mainly focused on exploring superior model structures to align the input dialogue and the output summary. however, for professional dialogues (e.g., legal debate and medical diagnosis), semantic/statistical alignment can hardly fill the logical/factual gap between input dialogue discourse and summary output with external knowledge. in this paper, we mainly investigate the factual inconsistency problem for dialogue inspectional summarization (dis) under non-pretraining and pretraining settings. an innovative end-to-end dialogue summary generation framework is proposed with two auxiliary tasks: expectant factual aspect regularization (efar) and missing factual entity discrimination (mfed). comprehensive experiments demonstrate that the proposed model can generate a more readable summary with accurate coverage of factual aspects as well as informing the user with potential missing facts detected from the input dialogue for further human intervention.",,2021-11-05,,"['leilei gan', 'yating zhang', 'kun kuang', 'lin yuan', 'shuo li', 'changlong sun', 'xiaozhong liu', 'fei wu']"
2111.03320,on the impact of temporal representations on metaphor detection,cs.cl cs.ai,"state-of-the-art approaches for metaphor detection compare their literal - or core - meaning and their contextual meaning using sequential metaphor classifiers based on neural networks. the signal that represents the literal meaning is often represented by (non-contextual) word embeddings. however, metaphorical expressions evolve over time due to various reasons, such as cultural and societal impact. metaphorical expressions are known to co-evolve with language and literal word meanings, and even drive, to some extent, this evolution. this rises the question whether different, possibly time-specific, representations of literal meanings may impact on the metaphor detection task. to the best of our knowledge, this is the first study which examines the metaphor detection task with a detailed exploratory analysis where different temporal and static word embeddings are used to account for different representations of literal meanings. our experimental analysis is based on three popular benchmarks used for metaphor detection and word embeddings extracted from different corpora and temporally aligned to different state-of-the-art approaches. the results suggest that different word embeddings do impact on the metaphor detection task and some temporal word embeddings slightly outperform static methods on some performance measures. however, results also suggest that temporal word embeddings may provide representations of words' core meaning even too close to their metaphorical meaning, thus confusing the classifier. overall, the interaction between temporal language evolution and metaphor detection appears tiny in the benchmark datasets used in our experiments. this suggests that future work for the computational analysis of this important linguistic phenomenon should first start by creating a new dataset where this interaction is better represented.",,2021-11-05,,"['giorgio ottolina', 'matteo palmonari', 'mehwish alam', 'manuel vimercati']"
2111.03341,dvfl: a vertical federated learning method for dynamic data,cs.lg cs.ai,"federated learning, which solves the problem of data island by connecting multiple computational devices into a decentralized system, has become a promising paradigm for privacy-preserving machine learning. this paper studies vertical federated learning (vfl), which tackles the scenarios where collaborating organizations share the same set of users but disjoint features. contemporary vfl methods are mainly used in static scenarios where the active party and the passive party have all the data from the beginning and will not change. however, the data in real life often changes dynamically. to alleviate this problem, we propose a new vertical federation learning method, dvfl, which adapts to dynamic data distribution changes through knowledge distillation. in dvfl, most of the computations are held locally to improve data security and model efficiency. our extensive experimental results show that dvfl can not only obtain results close to existing vfl methods in static scenes, but also adapt to changes in data distribution in dynamic scenarios.",,2021-11-05,,"['yuzhi liang', 'yixiang chen']"
2111.03383,epidemic inference through generative neural networks,cs.si cond-mat.stat-mech cs.ai cs.lg,"reconstructing missing information in epidemic spreading on contact networks can be essential in prevention and containment strategies. for instance, identifying and warning infective but asymptomatic individuals (e.g., manual contact tracing) helped contain outbreaks in the covid-19 pandemic. the number of possible epidemic cascades typically grows exponentially with the number of individuals involved. the challenge posed by inference problems in the epidemics processes originates from the difficulty of identifying the almost negligible subset of those compatible with the evidence (for instance, medical tests). here we present a new generative neural networks framework that can sample the most probable infection cascades compatible with observations. moreover, the framework can infer the parameters governing the spreading of infections. the proposed method obtains better or comparable results with existing methods on the patient zero problem, risk assessment, and inference of infectious parameters in synthetic and real case scenarios like spreading infections in workplaces and hospitals.",,2021-11-05,2021-11-08,"['indaco biazzo', 'alfredo braunstein', ""luca dall'asta"", 'fabio mazza']"
2111.03414,structure-aware image inpainting with two parallel streams,cs.cv cs.ai,"recent works in image inpainting have shown that structural information plays an important role in recovering visually pleasing results. in this paper, we propose an end-to-end architecture composed of two parallel unet-based streams: a main stream (ms) and a structure stream (ss). with the assistance of ss, ms can produce plausible results with reasonable structures and realistic details. specifically, ms reconstructs detailed images by inferring missing structures and textures simultaneously, and ss restores only missing structures by processing the hierarchical information from the encoder of ms. by interacting with ss in the training process, ms can be implicitly encouraged to exploit structural cues. in order to help ss focus on structures and prevent textures in ms from being affected, a gated unit is proposed to depress structure-irrelevant activations in the information flow between ms and ss. furthermore, the multi-scale structure feature maps in ss are utilized to explicitly guide the structure-reasonable image reconstruction in the decoder of ms through the fusion block. extensive experiments on celeba, paris streetview and places2 datasets demonstrate that our proposed method outperforms state-of-the-art methods.",,2021-11-05,,"['zhilin huang', 'chujun qin', 'ruixin liu', 'zhenyu weng', 'yuesheng zhu']"
2111.03418,meta-forecasting by combining global deep representations with local   adaptation,cs.lg cs.ai stat.ml,"while classical time series forecasting considers individual time series in isolation, recent advances based on deep learning showed that jointly learning from a large pool of related time series can boost the forecasting accuracy. however, the accuracy of these methods suffers greatly when modeling out-of-sample time series, significantly limiting their applicability compared to classical forecasting methods. to bridge this gap, we adopt a meta-learning view of the time series forecasting problem. we introduce a novel forecasting method, called meta global-local auto-regression (meta-glar), that adapts to each time series by learning in closed-form the mapping from the representations produced by a recurrent neural network (rnn) to one-step-ahead forecasts. crucially, the parameters ofthe rnn are learned across multiple time series by backpropagating through the closed-form adaptation mechanism. in our extensive empirical evaluation we show that our method is competitive with the state-of-the-art in out-of-sample forecasting accuracy reported in earlier work.",,2021-11-05,2021-11-12,"['riccardo grazzi', 'valentin flunkert', 'david salinas', 'tim januschowski', 'matthias seeger', 'cedric archambeau']"
2111.03421,solving traffic4cast competition with u-net and temporal domain   adaptation,cs.cv cs.ai cs.lg,"in this technical report, we present our solution to the traffic4cast 2021 core challenge, in which participants were asked to develop algorithms for predicting a traffic state 60 minutes ahead, based on the information from the previous hour, in 4 different cities. in contrast to the previously held competitions, this year's challenge focuses on the temporal domain shift in traffic due to the covid-19 pandemic. following the past success of u-net, we utilize it for predicting future traffic maps. additionally, we explore the usage of pre-trained encoders such as densenet and efficientnet and employ multiple domain adaptation techniques to fight the domain shift. our solution has ranked third in the final competition. the code is available at https://github.com/jbr-ai-labs/traffic4cast-2021.",,2021-11-05,,"['vsevolod konyakhin', 'nina lukashina', 'aleksei shpilman']"
2111.03431,learning to cooperate with unseen agent via meta-reinforcement learning,cs.ai cs.lg cs.ma,"ad hoc teamwork problem describes situations where an agent has to cooperate with previously unseen agents to achieve a common goal. for an agent to be successful in these scenarios, it has to have a suitable cooperative skill. one could implement cooperative skills into an agent by using domain knowledge to design the agent's behavior. however, in complex domains, domain knowledge might not be available. therefore, it is worthwhile to explore how to directly learn cooperative skills from data. in this work, we apply meta-reinforcement learning (meta-rl) formulation in the context of the ad hoc teamwork problem. our empirical results show that such a method could produce robust cooperative agents in two cooperative environments with different cooperative circumstances: social compliance and language interpretation. (this is a full paper of the extended abstract version.)",,2021-11-05,,"['rujikorn charakorn', 'poramate manoonpong', 'nat dilokthanakul']"
2111.03433,"numerisation d'un siecle de paysage ferroviaire fran\c{c}ais : recul du   rail, cons\'equences territoriales et co\^ut environnemental",physics.soc-ph cs.ai cs.cv cs.db,"the reconstruction of geographical data over a century, allows to figuring out the evolution of the french railway landscape, and how it has been impacted by major events (eg.: wwii), or longer time span processes : industry outsourcing, metropolization, public transport policies or absence of them. this work is resulting from the fusion of several public geographical data (sncf, ign), enriched with the computer-assisted addition of multiple data gathered on the internet (wikipedia, volunteer geographic information). the dataset compounds almost every rail stations (even simple stops) and railway branch nodes, whose link to their respective rail lines allows to build the underlying consistent graph of the network. every rail line has a ""valid to"" date (or approx) so that time evolution can be displayed. the present progress of that reconstruction sums up to roughly 90% of what is expected (exact total unknown). this allows to consider temporal demographic analysis (how many cities and towns served by the railway since 1925 up on today), and environmental simulations as well (co2 cost by given destination ).",,2021-10-05,,['robert jeansoulin']
2111.03463,radams: resilient and adaptive alert and attention management strategy   against informational denial-of-service (idos) attacks,cs.cr cs.ai cs.hc cs.lg cs.na math.na,"attacks exploiting human attentional vulnerability have posed severe threats to cybersecurity. in this work, we identify and formally define a new type of proactive attentional attacks called informational denial-of-service (idos) attacks that generate a large volume of feint attacks to overload human operators and hide real attacks among feints. we incorporate human factors (e.g., levels of expertise, stress, and efficiency) and empirical results (e.g., the yerkes-dodson law and the sunk cost fallacy) to model the operators' attention dynamics and their decision-making processes along with the real-time alert monitoring and inspection.   to assist human operators in timely and accurately dismissing the feints and escalating the real attacks, we develop a resilient and adaptive data-driven alert and attention management strategy (radams) that de-emphasizes alerts selectively based on the alerts' observable features. radams uses reinforcement learning to achieve a customized and transferable design for various human operators and evolving idos attacks.   the integrated modeling and theoretical analysis lead to the product principle of attention (ppoa), fundamental limits, and the tradeoff among crucial human and economic factors. experimental results corroborate that the proposed strategy outperforms the default strategy and can reduce the idos risk by as much as 20%. besides, the strategy is resilient to large variations of costs, attack frequencies, and human attention capacities. we have recognized interesting phenomena such as attentional risk equivalency, attacker's dilemma, and the half-truth optimal attack strategy.",,2021-11-01,,"['linan huang', 'quanyan zhu']"
2111.03465,spatio-temporal urban knowledge graph enabled mobility prediction,cs.si cs.ai cs.ir cs.sy eess.sy,"with the rapid development of the mobile communication technology, mobile trajectories of humans are massively collected by internet service providers (isps) and application service providers (asps). on the other hand, the rising paradigm of knowledge graph (kg) provides us a promising solution to extract structured ""knowledge"" from massive trajectory data. in this paper, we focus on modeling users' spatio-temporal mobility patterns based on knowledge graph techniques, and predicting users' future movement based on the ""knowledge'' extracted from multiple sources in a cohesive manner. specifically, we propose a new type of knowledge graph, i.e., spatio-temporal urban knowledge graph (stkg), where mobility trajectories, category information of venues, and temporal information are jointly modeled by the facts with different relation types in stkg. the mobility prediction problem is converted to the knowledge graph completion problem in stkg. further, a complex embedding model with elaborately designed scoring functions is proposed to measure the plausibility of facts in stkg to solve the knowledge graph completion problem, which considers temporal dynamics of the mobility patterns and utilizes poi categories as the auxiliary information and background knowledge. extensive evaluations confirm the high accuracy of our model in predicting users' mobility, i.e., improving the accuracy by 5.04% compared with the state-of-the-art algorithms. in addition, poi categories as the background knowledge and auxiliary information are confirmed to be helpful by improving the performance by 3.85% in terms of accuracy. additionally, experiments show that our proposed method is time-efficient by reducing the computational time by over 43.12% compared with existing methods.",,2021-11-01,2021-11-10,"['huandong wang', 'qiaohong yu', 'yu liu', 'depeng jin', 'yong li']"
2111.03466,learning large neighborhood search policy for integer programming,cs.ai cs.lg math.oc,"we propose a deep reinforcement learning (rl) method to learn large neighborhood search (lns) policy for integer programming (ip). the rl policy is trained as the destroy operator to select a subset of variables at each step, which is reoptimized by an ip solver as the repair operator. however, the combinatorial number of variable subsets prevents direct application of typical rl algorithms. to tackle this challenge, we represent all subsets by factorizing them into binary decisions on each variable. we then design a neural network to learn policies for each variable in parallel, trained by a customized actor-critic algorithm. we evaluate the proposed method on four representative ip problems. results show that it can find better solutions than scip in much less time, and significantly outperform other lns baselines with the same runtime. moreover, these advantages notably persist when the policies generalize to larger problems. further experiments with gurobi also reveal that our method can outperform this state-of-the-art commercial solver within the same time limit.",,2021-11-01,,"['yaoxin wu', 'wen song', 'zhiguang cao', 'jie zhang']"
2111.03480,driveguard: robustification of automated driving systems with deep   spatio-temporal convolutional autoencoder,cs.cv cs.ai cs.ro,"autonomous vehicles increasingly rely on cameras to provide the input for perception and scene understanding and the ability of these models to classify their environment and objects, under adverse conditions and image noise is crucial. when the input is, either unintentionally or through targeted attacks, deteriorated, the reliability of autonomous vehicle is compromised. in order to mitigate such phenomena, we propose driveguard, a lightweight spatio-temporal autoencoder, as a solution to robustify the image segmentation process for autonomous vehicles. by first processing camera images with driveguard, we offer a more universal solution than having to re-train each perception model with noisy input. we explore the space of different autoencoder architectures and evaluate them on a diverse dataset created with real and synthetic images demonstrating that by exploiting spatio-temporal information combined with multi-component loss we significantly increase robustness against adverse image effects reaching within 5-6% of that of the original model on clean images.",10.1109/wacvw52041.2021.00016,2021-11-05,,"['andreas papachristodoulou', 'christos kyrkou', 'theocharis theocharides']"
2111.03495,automated supervised feature selection for differentiated patterns of   care,cs.lg cs.ai eess.sp,"an automated feature selection pipeline was developed using several state-of-the-art feature selection techniques to select optimal features for differentiating patterns of care (dpoc). the pipeline included three types of feature selection techniques; filters, wrappers and embedded methods to select the top k features. five different datasets with binary dependent variables were used and their different top k optimal features selected. the selected features were tested in the existing multi-dimensional subset scanning (mdss) where the most anomalous subpopulations, most anomalous subsets, propensity scores, and effect of measures were recorded to test their performance. this performance was compared with four similar metrics gained after using all covariates in the dataset in the mdss pipeline. we found out that despite the different feature selection techniques used, the data distribution is key to note when determining the technique to use.",,2021-11-05,,"['catherine wanjiru', 'william ogallo', 'girmaw abebe tadesse', 'charles wachira', ""isaiah onando mulang'"", 'aisha walcott-bryant']"
2111.03505,visualizing the emergence of intermediate visual patterns in dnns,cs.cv cs.ai cs.lg,"this paper proposes a method to visualize the discrimination power of intermediate-layer visual patterns encoded by a dnn. specifically, we visualize (1) how the dnn gradually learns regional visual patterns in each intermediate layer during the training process, and (2) the effects of the dnn using non-discriminative patterns in low layers to construct disciminative patterns in middle/high layers through the forward propagation. based on our visualization method, we can quantify knowledge points (i.e., the number of discriminative visual patterns) learned by the dnn to evaluate the representation capacity of the dnn. furthermore, this method also provides new insights into signal-processing behaviors of existing deep-learning techniques, such as adversarial attacks and knowledge distillation.",,2021-11-05,,"['mingjie li', 'shaobo wang', 'quanshi zhang']"
2111.03514,socialvec: social entity embeddings,cs.si cs.ai cs.lg,"this paper introduces socialvec, a general framework for eliciting social world knowledge from social networks, and applies this framework to twitter. socialvec learns low-dimensional embeddings of popular accounts, which represent entities of general interest, based on their co-occurrences patterns within the accounts followed by individual users, thus modeling entity similarity in socio-demographic terms. similar to word embeddings, which facilitate tasks that involve text processing, we expect social entity embeddings to benefit tasks of social flavor. we have learned social embeddings for roughly 200,000 popular accounts from a sample of the twitter network that includes more than 1.3 million users and the accounts that they follow, and evaluate the resulting embeddings on two different tasks. the first task involves the automatic inference of personal traits of users from their social media profiles. in another study, we exploit socialvec embeddings for gauging the political bias of news sources in twitter. in both cases, we prove socialvec embeddings to be advantageous compared with existing entity embedding schemes. we will make the socialvec entity embeddings publicly available to support further exploration of social world knowledge as reflected in twitter.",,2021-11-05,,"['nir lotan', 'einat minkov']"
2111.03516,solving the class imbalance problem using a counterfactual method for   data augmentation,cs.lg cs.ai,"learning from class imbalanced datasets poses challenges for many machine learning algorithms. many real-world domains are, by definition, class imbalanced by virtue of having a majority class that naturally has many more instances than its minority class (e.g. genuine bank transactions occur much more often than fraudulent ones). many methods have been proposed to solve the class imbalance problem, among the most popular being oversampling techniques (such as smote). these methods generate synthetic instances in the minority class, to balance the dataset, performing data augmentations that improve the performance of predictive machine learning (ml) models. in this paper we advance a novel data augmentation method (adapted from explainable ai), that generates synthetic, counterfactual instances in the minority class. unlike other oversampling techniques, this method adaptively combines exist-ing instances from the dataset, using actual feature-values rather than interpolating values between instances. several experiments using four different classifiers and 25 datasets are reported, which show that this counterfactual augmentation method (cfa) generates useful synthetic data points in the minority class. the experiments also show that cfa is competitive with many other oversampling methods many of which are variants of smote. the basis for cfas performance is discussed, along with the conditions under which it is likely to perform better or worse in future tests.",,2021-11-05,,"['mohammed temraz', 'mark t. keane']"
2111.03524,a data-driven approach to neural architecture search initialization,cs.lg cs.ai cs.ne,"algorithmic design in neural architecture search (nas) has received a lot of attention, aiming to improve performance and reduce computational cost. despite the great advances made, few authors have proposed to tailor initialization techniques for nas. however, literature shows that a good initial set of solutions facilitate finding the optima. therefore, in this study, we propose a data-driven technique to initialize a population-based nas algorithm. particularly, we proposed a two-step methodology. first, we perform a calibrated clustering analysis of the search space, and second, we extract the centroids and use them to initialize a nas algorithm. we benchmark our proposed approach against random and latin hypercube sampling initialization using three population-based algorithms, namely a genetic algorithm, evolutionary algorithm, and aging evolution, on cifar-10. more specifically, we use nas-bench-101 to leverage the availability of nas benchmarks. the results show that compared to random and latin hypercube sampling, the proposed initialization technique enables achieving significant long-term improvements for two of the search baselines, and sometimes in various search scenarios (various training budgets). moreover, we analyze the distributions of solutions obtained and find that that the population provided by the data-driven initialization technique enables retrieving local optima (maxima) of high fitness and similar configurations.",,2021-11-05,,"['kalifou rené traoré', 'andrés camero', 'xiao xiang zhu']"
2111.03536,a unified game-theoretic interpretation of adversarial robustness,cs.lg cs.ai cs.cv,"this paper provides a unified view to explain different adversarial attacks and defense methods, \emph{i.e.} the view of multi-order interactions between input variables of dnns. based on the multi-order interaction, we discover that adversarial attacks mainly affect high-order interactions to fool the dnn. furthermore, we find that the robustness of adversarially trained dnns comes from category-specific low-order interactions. our findings provide a potential method to unify adversarial perturbations and robustness, which can explain the existing defense methods in a principle way. besides, our findings also make a revision of previous inaccurate understanding of the shape bias of adversarially learned features.",,2021-11-05,2021-11-08,"['jie ren', 'die zhang', 'yisen wang', 'lu chen', 'zhanpeng zhou', 'yiting chen', 'xu cheng', 'xin wang', 'meng zhou', 'jie shi', 'quanshi zhang']"
2111.03543,an empirical study of neural kernel bandits,cs.lg cs.ai stat.ml,"neural bandits have enabled practitioners to operate efficiently on problems with non-linear reward functions. while in general contextual bandits commonly utilize gaussian process (gp) predictive distributions for decision making, the most successful neural variants use only the last layer parameters in the derivation. research on neural kernels (nk) has recently established a correspondence between deep networks and gps that take into account all the parameters of a nn and can be trained more efficiently than most bayesian nns. we propose to directly apply nk-induced distributions to guide an upper confidence bound or thompson sampling-based policy. we show that nk bandits achieve state-of-the-art performance on highly non-linear structured data. furthermore, we analyze practical considerations such as training frequency and model partitioning. we believe our work will help better understand the impact of utilizing nks in applied settings.",,2021-11-05,,"['michal lisicki', 'arash afkanpour', 'graham w. taylor']"
2111.03547,poshan: cardinal pos pattern guided attention for news headline   incongruence,cs.cl cs.ai cs.ir,"automatic detection of click-bait and incongruent news headlines is crucial to maintaining the reliability of the web and has raised much research attention. however, most existing methods perform poorly when news headlines contain contextually important cardinal values, such as a quantity or an amount. in this work, we focus on this particular case and propose a neural attention based solution, which uses a novel cardinal part of speech (pos) tag pattern based hierarchical attention network, namely poshan, to learn effective representations of sentences in a news article. in addition, we investigate a novel cardinal phrase guided attention, which uses word embeddings of the contextually-important cardinal value and neighbouring words. in the experiments conducted on two publicly available datasets, we observe that the proposed methodgives appropriate significance to cardinal values and outperforms all the baselines. an ablation study of poshan shows that the cardinal pos-tag pattern-based hierarchical attention is very effective for the cases in which headlines contain cardinal values.",10.1145/3459637.3482376,2021-11-05,,"['rahul mishra', 'shuo zhang']"
2111.03549,interpreting representation quality of dnns for 3d point cloud   processing,cs.cv cs.ai cs.lg,"in this paper, we evaluate the quality of knowledge representations encoded in deep neural networks (dnns) for 3d point cloud processing. we propose a method to disentangle the overall model vulnerability into the sensitivity to the rotation, the translation, the scale, and local 3d structures. besides, we also propose metrics to evaluate the spatial smoothness of encoding 3d structures, and the representation complexity of the dnn. based on such analysis, experiments expose representation problems with classic dnns, and explain the utility of the adversarial training.",,2021-11-05,,"['wen shen', 'qihan ren', 'dongrui liu', 'quanshi zhang']"
2111.03602,nas-bench-x11 and the power of learning curves,cs.lg cs.ai cs.ne stat.ml,"while early research in neural architecture search (nas) required extreme computational resources, the recent releases of tabular and surrogate benchmarks have greatly increased the speed and reproducibility of nas research. however, two of the most popular benchmarks do not provide the full training information for each architecture. as a result, on these benchmarks it is not possible to run many types of multi-fidelity techniques, such as learning curve extrapolation, that require evaluating architectures at arbitrary epochs. in this work, we present a method using singular value decomposition and noise modeling to create surrogate benchmarks, nas-bench-111, nas-bench-311, and nas-bench-nlp11, that output the full training information for each architecture, rather than just the final validation accuracy. we demonstrate the power of using the full training information by introducing a learning curve extrapolation framework to modify single-fidelity algorithms, showing that it leads to improvements over popular single-fidelity algorithms which claimed to be state-of-the-art upon release. our code and pretrained models are available at https://github.com/automl/nas-bench-x11.",,2021-11-05,,"['shen yan', 'colin white', 'yash savani', 'frank hutter']"
2111.03628,exploiting a zoo of checkpoints for unseen tasks,cs.ai stat.ml,"there are so many models in the literature that it is difficult for practitioners to decide which combinations are likely to be effective for a new task. this paper attempts to address this question by capturing relationships among checkpoints published on the web. we model the space of tasks as a gaussian process. the covariance can be estimated from checkpoints and unlabeled probing data. with the gaussian process, we can identify representative checkpoints by a maximum mutual information criterion. this objective is submodular. a greedy method identifies representatives that are likely to ""cover"" the task space. these representatives generalize to new tasks with superior performance. empirical evidence is provided for applications from both computational linguistics as well as computer vision.",,2021-11-05,,"['jiaji huang', 'qiang qiu', 'kenneth church']"
2111.03630,dynamic human-robot role allocation based on human ergonomics risk   prediction and robot actions adaptation,cs.ro cs.ai,"despite cobots have high potential in bringing several benefits in the manufacturing and logistic processes, but their rapid (re-)deployment in changing environments is still limited. to enable fast adaptation to new product demands and to boost the fitness of the human workers to the allocated tasks, we propose a novel method that optimizes assembly strategies and distributes the effort among the workers in human-robot cooperative tasks. the cooperation model exploits and/or graphs that we adapted to solve also the role allocation problem. the allocation algorithm considers quantitative measurements that are computed online to describe human operator's ergonomic status and task properties. we conducted preliminary experiments to demonstrate that the proposed approach succeeds in controlling the task allocation process to ensure safe and ergonomic conditions for the human worker.",,2021-11-05,,"['elena merlo', 'edoardo lamon', 'fabio fusaro', 'marta lorenzini', 'alessandro carfì', 'fulvio mastrogiovanni', 'arash ajoudani', 'n/a .']"
2111.03638,increasing fairness in predictions using bias parity score based loss   function regularization,cs.lg cs.ai,"increasing utilization of machine learning based decision support systems emphasizes the need for resulting predictions to be both accurate and fair to all stakeholders. in this work we present a novel approach to increase a neural network model's fairness during training. we introduce a family of fairness enhancing regularization components that we use in conjunction with the traditional binary-cross-entropy based accuracy loss. these loss functions are based on bias parity score (bps), a score that helps quantify bias in the models with a single number. in the current work we investigate the behavior and effect of these regularization components on bias. we deploy them in the context of a recidivism prediction task as well as on a census-based adult income dataset. the results demonstrate that with a good choice of fairness loss function we can reduce the trained model's bias without deteriorating accuracy even in unbalanced dataset.",,2021-11-05,,"['bhanu jain', 'manfred huber', 'ramez elmasri']"
2111.03647,regular decision processes for grid worlds,cs.ai,"markov decision processes are typically used for sequential decision making under uncertainty. for many aspects however, ranging from constrained or safe specifications to various kinds of temporal (non-markovian) dependencies in task and reward structures, extensions are needed. to that end, in recent years interest has grown into combinations of reinforcement learning and temporal logic, that is, combinations of flexible behavior learning methods with robust verification and guarantees. in this paper we describe an experimental investigation of the recently introduced regular decision processes that support both non-markovian reward functions as well as transition functions. in particular, we provide a tool chain for regular decision processes, algorithmic extensions relating to online, incremental learning, an empirical evaluation of model-free and model-based solution algorithms, and applications in regular, but non-markovian, grid worlds.",,2021-11-05,2021-11-09,"['nicky lenaers', 'martijn van otterlo']"
2111.03687,ai and blackness: towards moving beyond bias and representation,cs.cy cs.ai,"in this paper, we argue that ai ethics must move beyond the concepts of race-based representation and bias, and towards those that probe the deeper relations that impact how these systems are designed, developed, and deployed. many recent discussions on ethical considerations of bias in ai systems have centered on racial bias. we contend that antiblackness in ai requires more of an examination of the ontological space that provides a foundation for the design, development, and deployment of ai systems. we examine what this contention means from the perspective of the sociocultural context in which ai systems are designed, developed, and deployed and focus on intersections with anti-black racism (antiblackness). to bring these multiple perspectives together and show an example of antiblackness in the face of attempts at de-biasing, we discuss results from auditing an existing open-source semantic network (conceptnet). we use this discussion to further contextualize antiblackness in design, development, and deployment of ai systems and suggest questions one may ask when attempting to combat antiblackness in ai systems.",,2021-11-05,,"['christopher l. dancy', 'p. khalil saucier']"
2111.03699,a space of goals: the cognitive geometry of informationally bounded   agents,cs.ai cs.it cs.sy eess.sy math.it,"traditionally, euclidean geometry is treated by scientists as a priori and objective. however, when we take the position of an agent, the problem of selecting a best route should also factor in the abilities of the agent, its embodiment and particularly its cognitive effort. in this paper we consider geometry in terms of travel between states within a world by incorporating information processing costs with the appropriate spatial distances. this induces a geometry that increasingly differs from the original geometry of the given world, as information costs become increasingly important. we visualize this \textit{""cognitive geometry""} by projecting it onto 2- and 3-dimensional spaces showing distinct distortions reflecting the emergence of epistemic and information-saving strategies as well as pivot states. the analogies between traditional cost-based geometries and those induced by additional informational costs invite a generalization of the traditional notion of geodesics as cheapest routes towards the notion of \textit{infodesics}. crucially, the concept of infodesics approximates the usual geometric property that, travelling from a start to a goal along a geodesic, not only the goal, but all intermediate points are equally visited at optimal cost from the start.",,2021-11-05,,"['karen archer', 'nicola catenacci volpi', 'franziska bröker', 'daniel polani']"
2111.03702,reconstructing training data from diverse ml models by ensemble   inversion,cs.lg cs.ai cs.cv,"model inversion (mi), in which an adversary abuses access to a trained machine learning (ml) model attempting to infer sensitive information about its original training data, has attracted increasing research attention. during mi, the trained model under attack (mua) is usually frozen and used to guide the training of a generator, such as a generative adversarial network (gan), to reconstruct the distribution of the original training data of that model. this might cause leakage of original training samples, and if successful, the privacy of dataset subjects will be at risk if the training data contains personally identifiable information (pii). therefore, an in-depth investigation of the potentials of mi techniques is crucial for the development of corresponding defense techniques. high-quality reconstruction of training data based on a single model is challenging. however, existing mi literature does not explore targeting multiple models jointly, which may provide additional information and diverse perspectives to the adversary.   we propose the ensemble inversion technique that estimates the distribution of original training data by training a generator constrained by an ensemble (or set) of trained models with shared subjects or entities. this technique leads to noticeable improvements of the quality of the generated samples with distinguishable features of the dataset entities compared to mi of a single ml model. we achieve high quality results without any dataset and show how utilizing an auxiliary dataset that's similar to the presumed training data improves the results. the impact of model diversity in the ensemble is thoroughly investigated and additional constraints are utilized to encourage sharp predictions and high activations for the reconstructed samples, leading to more accurate reconstruction of training images.",,2021-11-05,,"['qian wang', 'daniel kurz']"
2111.03728,shared model of sense-making for human-machine collaboration,cs.ai,"we present a model of sense-making that greatly facilitates the collaboration between an intelligent analyst and a knowledge-based agent. it is a general model grounded in the science of evidence and the scientific method of hypothesis generation and testing, where sense-making hypotheses that explain an observation are generated, relevant evidence is then discovered, and the hypotheses are tested based on the discovered evidence. we illustrate how the model enables an analyst to directly instruct the agent to understand situations involving the possible production of weapons (e.g., chemical warfare agents) and how the agent becomes increasingly more competent in understanding other situations from that domain (e.g., possible production of centrifuge-enriched uranium or of stealth fighter aircraft).",,2021-11-05,,"['gheorghe tecuci', 'dorin marcu', 'louis kaiser', 'mihai boicu']"
2111.03743,increasing data diversity with iterative sampling to improve performance,cs.lg cs.ai,"as a part of the data-centric ai competition, we propose a data-centric approach to improve the diversity of the training samples by iterative sampling. the method itself relies strongly on the fidelity of augmented samples and the diversity of the augmentation methods. moreover, we improve the performance further by introducing more samples for the difficult classes especially providing closer samples to edge cases potentially those the model at hand misclassifies.",,2021-11-05,,"['devrim cavusoglu', 'ogulcan eryuksel', 'sinan altinuc']"
2111.03745,an algorithmic theory of metacognition in minds and machines,cs.ai cs.lg,"humans sometimes choose actions that they themselves can identify as sub-optimal, or wrong, even in the absence of additional information. how is this possible? we present an algorithmic theory of metacognition based on a well-understood trade-off in reinforcement learning (rl) between value-based rl and policy-based rl. to the cognitive (neuro)science community, our theory answers the outstanding question of why information can be used for error detection but not for action selection. to the machine learning community, our proposed theory creates a novel interaction between the actor and critic in actor-critic agents and notes a novel connection between rl and bayesian optimization. we call our proposed agent the metacognitive actor critic (mac). we conclude with showing how to create metacognition in machines by implementing a deep mac and showing that it can detect (some of) its own suboptimal actions without external information or delay.",,2021-11-05,,['rylan schaeffer']
2111.03751,asynchronous collaborative localization by integrating spatiotemporal   graph learning with model-based estimation,cs.ro cs.ai,"collaborative localization is an essential capability for a team of robots such as connected vehicles to collaboratively estimate object locations from multiple perspectives with reliant cooperation. to enable collaborative localization, four key challenges must be addressed, including modeling complex relationships between observed objects, fusing observations from an arbitrary number of collaborating robots, quantifying localization uncertainty, and addressing latency of robot communications. in this paper, we introduce a novel approach that integrates uncertainty-aware spatiotemporal graph learning and model-based state estimation for a team of robots to collaboratively localize objects. specifically, we introduce a new uncertainty-aware graph learning model that learns spatiotemporal graphs to represent historical motions of the objects observed by each robot over time and provides uncertainties in object localization. moreover, we propose a novel method for integrated learning and model-based state estimation, which fuses asynchronous observations obtained from an arbitrary number of robots for collaborative localization. we evaluate our approach in two collaborative object localization scenarios in simulations and on real robots. experimental results show that our approach outperforms previous methods and achieves state-of-the-art performance on asynchronous collaborative localization.",,2021-11-05,,"['peng gao', 'brian reily', 'rui guo', 'hongsheng lu', 'qingzhao zhu', 'hao zhang']"
2111.03780,artifact- and content-specific quality assessment for mri with image   rulers,eess.iv cs.ai cs.cv,"in clinical practice mr images are often first seen by radiologists long after the scan. if image quality is inadequate either patients have to return for an additional scan, or a suboptimal interpretation is rendered. an automatic image quality assessment (iqa) would enable real-time remediation. existing iqa works for mri give only a general quality score, agnostic to the cause of and solution to low-quality scans. furthermore, radiologists' image quality requirements vary with the scan type and diagnostic task. therefore, the same score may have different implications for different scans. we propose a framework with multi-task cnn model trained with calibrated labels and inferenced with image rulers. labels calibrated by human inputs follow a well-defined and efficient labeling task. image rulers address varying quality standards and provide a concrete way of interpreting raw scores from the cnn. the model supports assessments of two of the most common artifacts in mri: noise and motion. it achieves accuracies of around 90%, 6% better than the best previous method examined, and 3% better than human experts on noise assessment. our experiments show that label calibration, image rulers, and multi-task training improve the model's performance and generalizability.",,2021-11-05,,"['ke lei', 'john m. pauly', 'shreyas s. vasanawala']"
2111.03782,confidence composition for monitors of verification assumptions,cs.lo cs.ai cs.se,"closed-loop verification of cyber-physical systems with neural network controllers offers strong safety guarantees under certain assumptions. it is, however, difficult to determine whether these guarantees apply at run time because verification assumptions may be violated. to predict safety violations in a verified system, we propose a three-step framework for monitoring the confidence in verification assumptions. first, we represent the sufficient condition for verified safety with a propositional logical formula over assumptions. second, we build calibrated confidence monitors that evaluate the probability that each assumption holds. third, we obtain the confidence in the verification guarantees by composing the assumption monitors using a composition function suitable for the logical formula. our framework provides theoretical bounds on the calibration and conservatism of compositional monitors. in two case studies, we demonstrate that the composed monitors improve over their constituents and successfully predict safety violations.",,2021-11-03,,"['ivan ruchkin', 'matthew cleaveland', 'radoslav ivanov', 'pengyuan lu', 'taylor carpenter', 'oleg sokolsky', 'insup lee']"
2111.03788,d3rlpy: an offline deep reinforcement learning library,cs.lg cs.ai,"in this paper, we introduce d3rlpy, an open-sourced offline deep reinforcement learning (rl) library for python. d3rlpy supports a number of offline deep rl algorithms as well as online algorithms via a user-friendly api. to assist deep rl research and development projects, d3rlpy provides practical and unique features such as data collection, exporting policies for deployment, preprocessing and postprocessing, distributional q-functions, multi-step learning and a convenient command-line interface. furthermore, d3rlpy additionally provides a novel graphical interface that enables users to train offline rl algorithms without coding programs. lastly, the implemented algorithms are benchmarked with d4rl datasets to ensure the implementation quality. the d3rlpy source code can be found on github: \url{https://github.com/takuseno/d3rlpy}.",,2021-11-05,,"['takuma seno', 'michita imai']"
2111.03789,generation of microbial colonies dataset with deep learning style   transfer,cs.cv cs.ai q-bio.qm,"we introduce an effective strategy to generate a synthetic dataset of microbiological images of petri dishes that can be used to train deep learning models. the developed generator employs traditional computer vision algorithms together with a neural style transfer method for data augmentation. we show that the method is able to synthesize a dataset of realistic looking images that can be used to train a neural network model capable of localising, segmenting, and classifying five different microbial species. our method requires significantly fewer resources to obtain a useful dataset than collecting and labeling a whole large set of real images with annotations. we show that starting with only 100 real images, we can generate data to train a detector that achieves comparable results to the same detector but trained on a real, several dozen times bigger dataset. we prove the usefulness of the method in microbe detection and segmentation, but we expect that it is general and flexible and can also be applicable in other domains of science and industry to detect various objects.",,2021-11-05,,"['jarosław pawłowski', 'sylwia majchrowska', 'tomasz golan']"
2111.03796,development of collective behavior in newborn artificial agents,cs.ai,"collective behavior is widespread across the animal kingdom. to date, however, the developmental and mechanistic foundations of collective behavior have not been formally established. what learning mechanisms drive the development of collective behavior in newborn animals? here, we used deep reinforcement learning and curiosity-driven learning -- two learning mechanisms deeply rooted in psychological and neuroscientific research -- to build newborn artificial agents that develop collective behavior. like newborn animals, our agents learn collective behavior from raw sensory inputs in naturalistic environments. our agents also learn collective behavior without external rewards, using only intrinsic motivation (curiosity) to drive learning. specifically, when we raise our artificial agents in natural visual environments with groupmates, the agents spontaneously develop ego-motion, object recognition, and a preference for groupmates, rapidly learning all of the core skills required for collective behavior. this work bridges the divide between high-dimensional sensory inputs and collective action, resulting in a pixels-to-actions model of collective animal behavior. more generally, we show that two generic learning mechanisms -- deep reinforcement learning and curiosity-driven learning -- are sufficient to learn collective behavior from unsupervised natural experience.",,2021-11-05,,"['donsuk lee', 'samantha m. w. wood', 'justin n. wood']"
2111.03811,sig-vc: a speaker information guided zero-shot voice conversion system   for both human beings and machines,cs.sd cs.ai eess.as,"nowadays, as more and more systems achieve good performance in traditional voice conversion (vc) tasks, people's attention gradually turns to vc tasks under extreme conditions. in this paper, we propose a novel method for zero-shot voice conversion. we aim to obtain intermediate representations for speaker-content disentanglement of speech to better remove speaker information and get pure content information. accordingly, our proposed framework contains a module that removes the speaker information from the acoustic feature of the source speaker. moreover, speaker information control is added to our system to maintain the voice cloning performance. the proposed system is evaluated by subjective and objective metrics. results show that our proposed system significantly reduces the trade-off problem in zero-shot voice conversion, while it also manages to have high spoofing power to the speaker verification system.",,2021-11-06,,"['zhang haozhe', 'cai zexin', 'qin xiaoyi', 'li ming']"
2111.03848,multimodal pet/ct tumour segmentation and prediction of progression-free   survival using a full-scale unet with attention,eess.iv cs.ai cs.cv,"segmentation of head and neck (h\&n) tumours and prediction of patient outcome are crucial for patient's disease diagnosis and treatment monitoring. current developments of robust deep learning models are hindered by the lack of large multi-centre, multi-modal data with quality annotations. the miccai 2021 head and neck tumor (hecktor) segmentation and outcome prediction challenge creates a platform for comparing segmentation methods of the primary gross target volume on fluoro-deoxyglucose (fdg)-pet and computed tomography images and prediction of progression-free survival in h\&n oropharyngeal cancer.for the segmentation task, we proposed a new network based on an encoder-decoder architecture with full inter- and intra-skip connections to take advantage of low-level and high-level semantics at full scales. additionally, we used conditional random fields as a post-processing step to refine the predicted segmentation maps. we trained multiple neural networks for tumor volume segmentation, and these segmentations were ensembled achieving an average dice similarity coefficient of 0.75 in cross-validation, and 0.76 on the challenge testing data set. for prediction of patient progression free survival task, we propose a cox proportional hazard regression combining clinical, radiomic, and deep learning features. our survival prediction model achieved a concordance index of 0.82 in cross-validation, and 0.62 on the challenge testing data set.",,2021-11-06,,"['emmanuelle bourigault', 'daniel r. mcgowan', 'abolfazl mehranian', 'bartłomiej w. papież']"
2111.03861,what augmentations are sensitive to hyper-parameters and why?,cs.cv cs.ai cs.lg,"we apply augmentations to our dataset to enhance the quality of our predictions and make our final models more resilient to noisy data and domain drifts. yet the question remains, how are these augmentations going to perform with different hyper-parameters? in this study we evaluate the sensitivity of augmentations with regards to the model's hyper parameters along with their consistency and influence by performing a local surrogate (lime) interpretation on the impact of hyper-parameters when different augmentations are applied to a machine learning model. we have utilized linear regression coefficients for weighing each augmentation. our research has proved that there are some augmentations which are highly sensitive to hyper-parameters and others which are more resilient and reliable.",,2021-11-06,,"['ch muhammad awais', 'imad eddine ibrahim bekkouch']"
2111.03892,tnd-nas: towards non-differentiable objectives in progressive   differentiable nas framework,cs.lg cs.ai,"differentiable architecture search has gradually become the mainstream research topic in the field of neural architecture search (nas) for its capability to improve efficiency compared with the early nas (ea-based, rl-based) methods. recent differentiable nas also aims at further improving search efficiency, reducing the gpu-memory consumption, and addressing the ""depth gap"" issue. however, these methods are no longer capable of tackling the non-differentiable objectives, let alone multi-objectives, e.g., performance, robustness, efficiency, and other metrics. we propose an end-to-end architecture search framework towards non-differentiable objectives, tnd-nas, with the merits of the high efficiency in differentiable nas framework and the compatibility among non-differentiable metrics in multi-objective nas (mnas). under differentiable nas framework, with the continuous relaxation of the search space, tnd-nas has the architecture parameters ($\alpha$) been optimized in discrete space, while resorting to the search policy of progressively shrinking the supernetwork by $\alpha$. our representative experiment takes two objectives (parameters, accuracy) as an example, we achieve a series of high-performance compact architectures on cifar10 (1.09m/3.3%, 2.4m/2.95%, 9.57m/2.54%) and cifar100 (2.46m/18.3%, 5.46/16.73%, 12.88/15.20%) datasets. favorably, under real-world scenarios (resource-constrained, platform-specialized), the pareto-optimal solutions can be conveniently reached by tnd-nas.",,2021-11-06,,"['bo lyu', 'shiping wen', 'zheng yan', 'kaibo shi', 'ke li', 'tingwen huang']"
2111.03915,robust deep reinforcement learning for quadcopter control,cs.ro cs.ai cs.lg cs.sy eess.sy math.oc,"deep reinforcement learning (rl) has made it possible to solve complex robotics problems using neural networks as function approximators. however, the policies trained on stationary environments suffer in terms of generalization when transferred from one environment to another. in this work, we use robust markov decision processes (rmdp) to train the drone control policy, which combines ideas from robust control and rl. it opts for pessimistic optimization to handle potential gaps between policy transfer from one environment to another. the trained control policy is tested on the task of quadcopter positional control. rl agents were trained in a mujoco simulator. during testing, different environment parameters (unseen during the training) were used to validate the robustness of the trained policy for transfer from one environment to another. the robust policy outperformed the standard agents in these environments, suggesting that the added robustness increases generality and can adapt to non-stationary environments.   codes: https://github.com/adipandas/gym_multirotor",,2021-11-06,,"['aditya m. deshpande', 'ali a. minai', 'manish kumar']"
2111.03917,optimal and efficient dynamic regret algorithms for non-stationary   dueling bandits,cs.lg cs.ai,"we study the problem of \emph{dynamic regret minimization} in $k$-armed dueling bandits under non-stationary or time varying preferences. this is an online learning setup where the agent chooses a pair of items at each round and observes only a relative binary `win-loss' feedback for this pair, sampled from an underlying preference matrix at that round. we first study the problem of static-regret minimization for adversarial preference sequences and design an efficient algorithm with $o(\sqrt{kt})$ high probability regret. we next use similar algorithmic ideas to propose an efficient and provably optimal algorithm for dynamic-regret minimization under two notions of non-stationarities. in particular, we establish $\to(\sqrt{skt})$ and $\to({v_t^{1/3}k^{1/3}t^{2/3}})$ dynamic-regret guarantees, $s$ being the total number of `effective-switches' in the underlying preference relations and $v_t$ being a measure of `continuous-variation' non-stationarity. the complexity of these problems have not been studied prior to this work despite the practicability of non-stationary environments in real world systems. we justify the optimality of our algorithms by proving matching lower bound guarantees under both the above-mentioned notions of non-stationarities. finally, we corroborate our results with extensive simulations and compare the efficacy of our algorithms over state-of-the-art baselines.",,2021-11-06,,"['shubham gupta', 'aadirupa saha']"
2111.03937,transformer based bengali chatbot using general knowledge dataset,cs.cl cs.ai,"an ai chatbot provides an impressive response after learning from the trained dataset. in this decade, most of the research work demonstrates that deep neural models superior to any other model. rnn model regularly used for determining the sequence-related problem like a question and it answers. this approach acquainted with everyone as seq2seq learning. in a seq2seq model mechanism, it has encoder and decoder. the encoder embedded any input sequence, and the decoder embedded output sequence. for reinforcing the seq2seq model performance, attention mechanism added into the encoder and decoder. after that, the transformer model has introduced itself as a high-performance model with multiple attention mechanism for solving the sequence-related dilemma. this model reduces training time compared with rnn based model and also achieved state-of-the-art performance for sequence transduction. in this research, we applied the transformer model for bengali general knowledge chatbot based on the bengali general knowledge question answer (qa) dataset. it scores 85.0 bleu on the applied qa data. to check the comparison of the transformer model performance, we trained the seq2seq model with attention on our dataset that scores 23.5 bleu.",,2021-11-06,2021-11-08,"['abu kaisar mohammad masum', 'sheikh abujar', 'sharmin akter', 'nushrat jahan ria', 'syed akhter hossain']"
2111.03940,convolutional gated mlp: combining convolutions & gmlp,cs.cv cs.ai cs.lg,"to the best of our knowledge, this is the first paper to introduce convolutions to gated multilayer perceptron and contributes an implementation of this novel deep learning architecture. google brain introduced the gmlp in may 2021. microsoft introduced convolutions in vision transformer in mar 2021. inspired by both gmlp and cvt, we introduce convolutional layers in gmlp. cvt combined the power of convolutions and attention. our implementation combines the best of convolutional learning along with spatial gated mlp. further, the paper visualizes how cgmlp learns. visualizations show how cgmlp learns from features such as outline of a car. while attention was the basis of much of recent progress in deep learning, gmlp proposed an approach that doesn't use attention computation. in transformer based approaches, a whole lot of attention matrixes need to be learnt using vast amount of training data. in gmlp, the fine tunning for new tasks can be challenging by transfer learning with smaller datasets. we implement cgmlp and compares it with gmlp on cifar dataset. experimental results explore the power of generaliza-tion of cgmlp, while gmlp tend to drastically overfit the training data.   to summarize, the paper contributes a novel deep learning architecture and demonstrates the learning mechanism of cgmlp through visualizations, for the first time in literature.",,2021-11-06,,"['a. rajagopal', 'v. nirmala']"
2111.03941,time discretization-invariant safe action repetition for policy gradient   methods,cs.lg cs.ai cs.ro,"in reinforcement learning, continuous time is often discretized by a time scale $\delta$, to which the resulting performance is known to be highly sensitive. in this work, we seek to find a $\delta$-invariant algorithm for policy gradient (pg) methods, which performs well regardless of the value of $\delta$. we first identify the underlying reasons that cause pg methods to fail as $\delta \to 0$, proving that the variance of the pg estimator can diverge to infinity in stochastic environments under a certain assumption of stochasticity. while durative actions or action repetition can be employed to have $\delta$-invariance, previous action repetition methods cannot immediately react to unexpected situations in stochastic environments. we thus propose a novel $\delta$-invariant method named safe action repetition (sar) applicable to any existing pg algorithm. sar can handle the stochasticity of environments by adaptively reacting to changes in states during action repetition. we empirically show that our method is not only $\delta$-invariant but also robust to stochasticity, outperforming previous $\delta$-invariant approaches on eight mujoco environments with both deterministic and stochastic settings. our code is available at https://vision.snu.ac.kr/projects/sar.",,2021-11-06,,"['seohong park', 'jaekyeom kim', 'gunhee kim']"
2111.03963,profitable trade-off between memory and performance in multi-domain   chatbot architectures,cs.cl cs.ai,"text classification problem is a very broad field of study in the field of natural language processing. in short, the text classification problem is to determine which of the previously determined classes the given text belongs to. successful studies have been carried out in this field in the past studies. in the study, bidirectional encoder representations for transformers (bert), which is a frequently preferred method for solving the classification problem in the field of natural language processing, is used. by solving classification problems through a single model to be used in a chatbot architecture, it is aimed to alleviate the load on the server that will be created by more than one model used for solving more than one classification problem. at this point, with the masking method applied during the estimation of a single bert model, which was created for classification in more than one subject, the estimation of the model was provided on a problem-based basis. three separate data sets covering different fields from each other are divided by various methods in order to complicate the problem, and classification problems that are very close to each other in terms of field are also included in this way. the dataset used in this way consists of five classification problems with 154 classes. a bert model containing all classification problems and other bert models trained specifically for the problems were compared with each other in terms of performance and the space they occupied on the server.",,2021-11-06,,"['d emre tasar', 'sukru ozan', 'm fatih akca', 'oguzhan olmez', 'semih gulum', 'secilay kutay', 'ceren belhan']"
2111.03987,v-mao: generative modeling for multi-arm manipulation of articulated   objects,cs.ro cs.ai cs.cv cs.lg,"manipulating articulated objects requires multiple robot arms in general. it is challenging to enable multiple robot arms to collaboratively complete manipulation tasks on articulated objects. in this paper, we present $\textbf{v-mao}$, a framework for learning multi-arm manipulation of articulated objects. our framework includes a variational generative model that learns contact point distribution over object rigid parts for each robot arm. the training signal is obtained from interaction with the simulation environment which is enabled by planning and a novel formulation of object-centric control for articulated objects. we deploy our framework in a customized mujoco simulation environment and demonstrate that our framework achieves a high success rate on six different objects and two different robots. we also show that generative modeling can effectively learn the contact point distribution on articulated objects.",,2021-11-06,,"['xingyu liu', 'kris m. kitani']"
2111.03995,explainable deep reinforcement learning for portfolio management: an   empirical approach,q-fin.pm cs.ai,"deep reinforcement learning (drl) has been widely studied in the portfolio management task. however, it is challenging to understand a drl-based trading strategy because of the black-box nature of deep neural networks. in this paper, we propose an empirical approach to explain the strategies of drl agents for the portfolio management task. first, we use a linear model in hindsight as the reference model, which finds the best portfolio weights by assuming knowing actual stock returns in foresight. in particular, we use the coefficients of a linear model in hindsight as the reference feature weights. secondly, for drl agents, we use integrated gradients to define the feature weights, which are the coefficients between reward and features under a linear regression model. thirdly, we study the prediction power in two cases, single-step prediction and multi-step prediction. in particular, we quantify the prediction power by calculating the linear correlations between the feature weights of a drl agent and the reference feature weights, and similarly for machine learning methods. finally, we evaluate a portfolio management task on dow jones 30 constituent stocks during 01/01/2009 to 09/01/2021. our approach empirically reveals that a drl agent exhibits a stronger multi-step prediction power than machine learning methods.",,2021-11-07,,"['mao guan', 'xiao-yang liu']"
2111.03997,the three-dimensional structural configuration of the central retinal   vessel trunk and branches as a glaucoma biomarker,eess.iv cs.ai cs.cv physics.med-ph,"purpose: to assess whether the three-dimensional (3d) structural configuration of the central retinal vessel trunk and its branches (crvt&b) could be used as a diagnostic marker for glaucoma. method: we trained a deep learning network to automatically segment the crvt&b from the b-scans of the optical coherence tomography (oct) volume of the optic nerve head (onh). subsequently, two different approaches were used for glaucoma diagnosis using the structural configuration of the crvt&b as extracted from the oct volumes. in the first approach, we aimed to provide a diagnosis using only 3d cnn and the 3d structure of the crvt&b. for the second approach, we projected the 3d structure of the crvt&b orthographically onto three planes to obtain 2d images, and then a 2d cnn was used for diagnosis. the segmentation accuracy was evaluated using the dice coefficient, whereas the diagnostic accuracy was assessed using the area under the receiver operating characteristic curves (auc). the diagnostic performance of the crvt&b was also compared with that of retinal nerve fiber layer (rnfl) thickness. results: our segmentation network was able to efficiently segment retinal blood vessels from oct scans. on a test set, we achieved a dice coefficient of 0.81\pm0.07. the 3d and 2d diagnostic networks were able to differentiate glaucoma from non-glaucoma subjects with accuracies of 82.7% and 83.3%, respectively. the corresponding aucs for crvt&b were 0.89 and 0.90, higher than those obtained with rnfl thickness alone. conclusions: our work demonstrated that the diagnostic power of the crvt&b is superior to that of a gold-standard glaucoma parameter, i.e., rnfl thickness. our work also suggested that the major retinal blood vessels form a skeleton -- the configuration of which may be representative of major onh structural changes as typically observed with the development and progression of glaucoma.",,2021-11-07,2021-11-08,"['satish k. panda', 'haris cheong', 'tin a. tun', 'thanadet chuangsuwanich', 'aiste kadziauskiene', 'vijayalakshmi senthil', 'ramaswami krishnadas', 'martin l. buist', 'shamira perera', 'ching-yu cheng', 'tin aung', 'alexandre h. thiery', 'michael j. a. girard']"
2111.04051,coordinated proximal policy optimization,cs.ai,"we present coordinated proximal policy optimization (coppo), an algorithm that extends the original proximal policy optimization (ppo) to the multi-agent setting. the key idea lies in the coordinated adaptation of step size during the policy update process among multiple agents. we prove the monotonicity of policy improvement when optimizing a theoretically-grounded joint objective, and derive a simplified optimization objective based on a set of approximations. we then interpret that such an objective in coppo can achieve dynamic credit assignment among agents, thereby alleviating the high variance issue during the concurrent update of agent policies. finally, we demonstrate that coppo outperforms several strong baselines and is competitive with the latest multi-agent ppo method (i.e. mappo) under typical multi-agent settings, including cooperative matrix games and the starcraft ii micromanagement tasks.",,2021-11-07,,"['zifan wu', 'chao yu', 'deheng ye', 'junge zhang', 'haiyin piao', 'hankz hankui zhuo']"
2111.04068,crowdsourcing with meta-workers: a new way to save the budget,cs.lg cs.ai cs.hc,"due to the unreliability of internet workers, it's difficult to complete a crowdsourcing project satisfactorily, especially when the tasks are multiple and the budget is limited. recently, meta learning has brought new vitality to few-shot learning, making it possible to obtain a classifier with a fair performance using only a few training samples. here we introduce the concept of \emph{meta-worker}, a machine annotator trained by meta learning for types of tasks (i.e., image classification) that are well-fit for ai. unlike regular crowd workers, meta-workers can be reliable, stable, and more importantly, tireless and free. we first cluster unlabeled data and ask crowd workers to repeatedly annotate the instances nearby the cluster centers; we then leverage the annotated data and meta-training datasets to build a cluster of meta-workers using different meta learning algorithms. subsequently, meta-workers are asked to annotate the remaining crowdsourced tasks. the jensen-shannon divergence is used to measure the disagreement among the annotations provided by the meta-workers, which determines whether or not crowd workers should be invited for further annotation of the same task. finally, we model meta-workers' preferences and compute the consensus annotation by weighted majority voting. our empirical study confirms that, by combining machine and human intelligence, we can accomplish a crowdsourcing project with a lower budget than state-of-the-art task assignment methods, while achieving a superior or comparable quality.",,2021-11-07,,"['guangyang han', 'guoxian yu', 'lizhen cui', 'carlotta domeniconi', 'xiangliang zhang']"
2111.04071,dvs: deep visibility series and its application in construction cost   index forecasting,cs.lg cs.ai,"time series forecasting has always been a hot spot in scientific research. with the development of artificial intelligence, new time series forecasting methods have obtained better forecasting effects and forecasting performance through bionic research and improvements to the past methods. visibility graph (vg) algorithm is often used for time series prediction in previous research, but the prediction effect is not as good as deep learning prediction methods such as artificial neural network (ann), convolutional neural network (cnn) and long short-term memory network (lstm) prediction. the vg algorithm contains a wealth of network information, but previous studies did not effectively use the network information to make predictions, resulting in relatively large prediction errors. in order to solve this problem, this paper proposes the deep visibility series (dvs) module through the bionic design of vg and the expansion of the past research, which is the first time to combine vg with bionic design and deep network. by applying the bionic design of biological vision to vg, the time series of dvs has obtained superior forecast accuracy, which has made a contribution to time series forecasting. at the same time, this paper applies the dvs forecasting method to the construction cost index forecast, which has practical significance.",,2021-11-07,,"['tianxiang zhan', 'yuanpeng he', 'hanwen li', 'fuyuan xiao']"
2111.04080,cross-modal zero-shot hashing by label attributes embedding,cs.cv cs.ai cs.lg cs.mm,"cross-modal hashing (cmh) is one of the most promising methods in cross-modal approximate nearest neighbor search. most cmh solutions ideally assume the labels of training and testing set are identical. however, the assumption is often violated, causing a zero-shot cmh problem. recent efforts to address this issue focus on transferring knowledge from the seen classes to the unseen ones using label attributes. however, the attributes are isolated from the features of multi-modal data. to reduce the information gap, we introduce an approach called laeh (label attributes embedding for zero-shot cross-modal hashing). laeh first gets the initial semantic attribute vectors of labels by word2vec model and then uses a transformation network to transform them into a common subspace. next, it leverages the hash vectors and the feature similarity matrix to guide the feature extraction network of different modalities. at the same time, laeh uses the attribute similarity as the supplement of label similarity to rectify the label embedding and common subspace. experiments show that laeh outperforms related representative zero-shot and cross-modal hashing methods.",,2021-11-07,,"['runmin wang', 'guoxian yu', 'lei liu', 'lizhen cui', 'carlotta domeniconi', 'xiangliang zhang']"
2111.04085,modelling and optimisation of resource usage in an iot enabled smart   campus,cs.cy cs.ai,"university campuses are essentially a microcosm of a city. they comprise diverse facilities such as residences, sport centres, lecture theatres, parking spaces, and public transport stops. universities are under constant pressure to improve efficiencies while offering a better experience to various stakeholders including students, staff, and visitors. nonetheless, anecdotal evidence indicates that campus assets are not being utilised efficiently, often due to the lack of data collection and analysis, thereby limiting the ability to make informed decisions on the allocation and management of resources. advances in the internet of things (iot) technologies that can sense and communicate data from the physical world, coupled with data analytics and artificial intelligence (ai) that can predict usage patterns, have opened up new opportunities for organisations to lower cost and improve user experience. this thesis explores this opportunity via theory and experimentation using unsw sydney as a living laboratory.",,2021-11-07,,['thanchanok sutjarittham']
2111.04086,meta cross-modal hashing on long-tailed data,cs.lg cs.ai cs.db cs.ma,"due to the advantage of reducing storage while speeding up query time on big heterogeneous data, cross-modal hashing has been extensively studied for approximate nearest neighbor search of multi-modal data. most hashing methods assume that training data is class-balanced.however, in practice, real world data often have a long-tailed distribution. in this paper, we introduce a meta-learning based cross-modal hashing method (metacmh) to handle long-tailed data. due to the lack of training samples in the tail classes, metacmh first learns direct features from data in different modalities, and then introduces an associative memory module to learn the memory features of samples of the tail classes. it then combines the direct and memory features to obtain meta features for each sample. for samples of the head classes of the long tail distribution, the weight of the direct features is larger, because there are enough training data to learn them well; while for rare classes, the weight of the memory features is larger. finally, metacmh uses a likelihood loss function to preserve the similarity in different modalities and learns hash functions in an end-to-end fashion. experiments on long-tailed datasets show that metacmh performs significantly better than state-of-the-art methods, especially on the tail classes.",,2021-11-07,,"['runmin wang', 'guoxian yu', 'carlotta domeniconi', 'xiangliang zhang']"
2111.04092,consistency and consensus driven for hesitant fuzzy linguistic decision   making with pairwise comparisons,cs.ai cs.it math.it,"hesitant fuzzy linguistic preference relation (hflpr) is of interest because it provides an efficient way for opinion expression under uncertainty. for enhancing the theory of decision making with hflpr, the paper introduces an algorithm for group decision making with hflprs based on the acceptable consistency and consensus measurements, which involves (1) defining a hesitant fuzzy linguistic geometric consistency index (hflgci) and proposing a procedure for consistency checking and inconsistency improving for hflpr; (2) measuring the group consensus based on the similarity between the original individual hflprs and the overall perfect hflpr, then establishing a procedure for consensus ensuring including the determination of decision-makers weights. the convergence and monotonicity of the proposed two procedures have been proved. some experiments are furtherly performed to investigate the critical values of the defined hflgci, and comparative analyses are conducted to show the effectiveness of the proposed algorithm. a case concerning the performance evaluation of venture capital guiding funds is given to illustrate the availability of the proposed algorithm. as an application of our work, an online decision-making portal is finally provided for decision-makers to utilize the proposed algorithms to solve decision-making problems.",,2021-11-07,,"['peijia ren', 'zixu liu', 'wei-guo zhang', 'xilan wu']"
2111.04095,iterative causal discovery in the possible presence of latent   confounders and selection bias,cs.lg cs.ai stat.me stat.ml,"we present a sound and complete algorithm, called iterative causal discovery (icd), for recovering causal graphs in the presence of latent confounders and selection bias. icd relies on the causal markov and faithfulness assumptions and recovers the equivalence class of the underlying causal graph. it starts with a complete graph, and consists of a single iterative stage that gradually refines this graph by identifying conditional independence (ci) between connected nodes. independence and causal relations entailed after any iteration are correct, rendering icd anytime. essentially, we tie the size of the ci conditioning set to its distance on the graph from the tested nodes, and increase this value in the successive iteration. thus, each iteration refines a graph that was recovered by previous iterations having smaller conditioning sets -- a higher statistical power -- which contributes to stability. we demonstrate empirically that icd requires significantly fewer ci tests and learns more accurate causal graphs compared to fci, fci+, and rfci algorithms.",,2021-11-07,,"['raanan y. rohekar', 'shami nisimov', 'yaniv gurwicz', 'gal novik']"
2111.04112,metamiml: meta multi-instance multi-label learning,cs.lg cs.ai,"multi-instance multi-label learning (miml) models complex objects (bags), each of which is associated with a set of interrelated labels and composed with a set of instances. current miml solutions still focus on a single-type of objects and assumes an iid distribution of training data. but these objects are linked with objects of other types, %(i.e., pictures in facebook link with various users), which also encode the semantics of target objects. in addition, they generally need abundant labeled data for training. to effectively mine interdependent miml objects of different types, we propose a network embedding and meta learning based approach (metamiml). metamiml introduces the context learner with network embedding to capture semantic information of objects of different types, and the task learner to extract the meta knowledge for fast adapting to new tasks. in this way, metamiml can naturally deal with miml objects at data level improving, but also exploit the power of meta-learning at the model enhancing. experiments on benchmark datasets demonstrate that metamiml achieves a significantly better performance than state-of-the-art algorithms.",,2021-11-07,,"['yuanlin yang', 'guoxian yu', 'jun wang', 'lei liu', 'carlotta domeniconi', 'maozu guo']"
2111.04120,automatic goal generation using dynamical distance learning,cs.ai cs.ro,"reinforcement learning (rl) agents can learn to solve complex sequential decision making tasks by interacting with the environment. however, sample efficiency remains a major challenge. in the field of multi-goal rl, where agents are required to reach multiple goals to solve complex tasks, improving sample efficiency can be especially challenging. on the other hand, humans or other biological agents learn such tasks in a much more strategic way, following a curriculum where tasks are sampled with increasing difficulty level in order to make gradual and efficient learning progress. in this work, we propose a method for automatic goal generation using a dynamical distance function (ddf) in a self-supervised fashion. ddf is a function which predicts the dynamical distance between any two states within a markov decision process (mdp). with this, we generate a curriculum of goals at the appropriate difficulty level to facilitate efficient learning throughout the training process. we evaluate this approach on several goal-conditioned robotic manipulation and navigation tasks, and show improvements in sample efficiency over a baseline method which only uses random goal sampling.",,2021-11-07,,"['bharat prakash', 'nicholas waytowich', 'tinoosh mohsenin', 'tim oates']"
2111.04123,neurint : learning to interpolate through neural odes,cs.cv cs.ai cs.lg,"a wide range of applications require learning image generation models whose latent space effectively captures the high-level factors of variation present in the data distribution. the extent to which a model represents such variations through its latent space can be judged by its ability to interpolate between images smoothly. however, most generative models mapping a fixed prior to the generated images lead to interpolation trajectories lacking smoothness and containing images of reduced quality. in this work, we propose a novel generative model that learns a flexible non-parametric prior over interpolation trajectories, conditioned on a pair of source and target images. instead of relying on deterministic interpolation methods (such as linear or spherical interpolation in latent space), we devise a framework that learns a distribution of trajectories between two given images using latent second-order neural ordinary differential equations. through a hybrid combination of reconstruction and adversarial losses, the generator is trained to map the sampled points from these trajectories to sequences of realistic images that smoothly transition from the source to the target image. through comprehensive qualitative and quantitative experiments, we demonstrate our approach's effectiveness in generating images of improved quality as well as its ability to learn a diverse distribution over smooth interpolation trajectories for any pair of real source and target images.",,2021-11-07,,"['avinandan bose', 'aniket das', 'yatin dandi', 'piyush rai']"
2111.04138,look at the variance! efficient black-box explanations with sobol-based   sensitivity analysis,cs.cv cs.ai cs.cl cs.lg,"we describe a novel attribution method which is grounded in sensitivity analysis and uses sobol indices. beyond modeling the individual contributions of image regions, sobol indices provide an efficient way to capture higher-order interactions between image regions and their contributions to a neural network's prediction through the lens of variance. we describe an approach that makes the computation of these indices efficient for high-dimensional problems by using perturbation masks coupled with efficient estimators to handle the high dimensionality of images. importantly, we show that the proposed method leads to favorable scores on standard benchmarks for vision (and language models) while drastically reducing the computing time compared to other black-box methods -- even surpassing the accuracy of state-of-the-art white-box methods which require access to internal representations. our code is freely available: https://github.com/fel-thomas/sobol-attribution-method",,2021-11-07,,"['thomas fel', 'remi cadene', 'mathieu chalvidal', 'matthieu cord', 'david vigouroux', 'thomas serre']"
2111.04147,learning finite linear temporal logic specifications with a specialized   neural operator,cs.ai cs.fl,"finite linear temporal logic ($\mathsf{ltl}_f$) is a powerful formal representation for modeling temporal sequences. we address the problem of learning a compact $\mathsf{ltl}_f$ formula from labeled traces of system behavior. we propose a novel neural network operator and evaluate the resulting architecture, neural$\mathsf{ltl}_f$. our approach includes a specialized recurrent filter, designed to subsume $\mathsf{ltl}_f$ temporal operators, to learn a highly accurate classifier for traces. then, it discretizes the activations and extracts the truth table represented by the learned weights. this truth table is converted to symbolic form and returned as the learned formula. experiments on randomly generated $\mathsf{ltl}_f$ formulas show neural$\mathsf{ltl}_f$ scales to larger formula sizes than existing approaches and maintains high accuracy even in the presence of noise.",,2021-11-07,,"['homer walke', 'daniel ritter', 'carl trimbach', 'michael littman']"
2111.04158,a word on machine ethics: a response to jiang et al. (2021),cs.cl cs.ai,"ethics is one of the longest standing intellectual endeavors of humanity. in recent years, the fields of ai and nlp have attempted to wrangle with how learning systems that interact with humans should be constrained to behave ethically. one proposal in this vein is the construction of morality models that can take in arbitrary text and output a moral judgment about the situation described. in this work, we focus on a single case study of the recently proposed delphi model and offer a critique of the project's proposed method of automating morality judgments. through an audit of delphi, we examine broader issues that would be applicable to any similar attempt. we conclude with a discussion of how machine ethics could usefully proceed, by focusing on current and near-future uses of technology, in a way that centers around transparency, democratic values, and allows for straightforward accountability.",,2021-11-07,,"['zeerak talat', 'hagen blix', 'josef valvoda', 'maya indira ganesh', 'ryan cotterell', 'adina williams']"
2111.04165,on the limits of design: what are the conceptual constraints on   designing artificial intelligence for social good?,econ.gn cs.ai cs.cy q-fin.ec,"artificial intelligence ai can bring substantial benefits to society by helping to reduce costs, increase efficiency and enable new solutions to complex problems. using floridi's notion of how to design the 'infosphere' as a starting point, in this chapter i consider the question: what are the limits of design, i.e. what are the conceptual constraints on designing ai for social good? the main argument of this chapter is that while design is a useful conceptual tool to shape technologies and societies, collective efforts towards designing future societies are constrained by both internal and external factors. internal constraints on design are discussed by evoking hardin's thought experiment regarding 'the tragedy of the commons'. further, hayek's classical distinction between 'cosmos' and 'taxis' is used to demarcate external constraints on design. finally, five design principles are presented which are aimed at helping policymakers manage the internal and external constraints on design. a successful approach to designing future societies needs to account for the emergent properties of complex systems by allowing space for serendipity and socio-technological coevolution.",10.1007/978-3-030-80083-3_5,2021-11-07,,['jakob mokander']
2111.04190,vizai : selecting accurate visualizations of numerical data,cs.hc cs.ai cs.lg,"a good data visualization is not only a distortion-free graphical representation of data but also a way to reveal underlying statistical properties of the data. despite its common use across various stages of data analysis, selecting a good visualization often is a manual process involving many iterations. recently there has been interest in reducing this effort by developing models that can recommend visualizations, but they are of limited use since they require large training samples (data and visualization pairs) and focus primarily on the design aspects rather than on assessing the effectiveness of the selected visualization.   in this paper, we present vizai, a generative-discriminative framework that first generates various statistical properties of the data from a number of alternative visualizations of the data. it is linked to a discriminative model that selects the visualization that best matches the true statistics of the data being visualized. vizai can easily be trained with minimal supervision and adapts to settings with varying degrees of supervision easily. using crowd-sourced judgements and a large repository of publicly available visualizations, we demonstrate that vizai outperforms the state of the art methods that learn to recommend visualizations.",,2021-11-07,,"['ritvik vij', 'rohit raj', 'madhur singhal', 'manish tanwar', 'srikanta bedathur']"
2111.04212,dense representative tooth landmark/axis detection network on 3d model,eess.iv cs.ai cs.cv cs.gr,"artificial intelligence (ai) technology is increasingly used for digital orthodontics, but one of the challenges is to automatically and accurately detect tooth landmarks and axes. this is partly because of sophisticated geometric definitions of them, and partly due to large variations among individual tooth and across different types of tooth. as such, we propose a deep learning approach with a labeled dataset by professional dentists to the tooth landmark/axis detection on tooth model that are crucial for orthodontic treatments. our method can extract not only tooth landmarks in the form of point (e.g. cusps), but also axes that measure the tooth angulation and inclination. the proposed network takes as input a 3d tooth model and predicts various types of the tooth landmarks and axes. specifically, we encode the landmarks and axes as dense fields defined on the surface of the tooth model. this design choice and a set of added components make the proposed network more suitable for extracting sparse landmarks from a given 3d tooth model. extensive evaluation of the proposed method was conducted on a set of dental models prepared by experienced dentists. results show that our method can produce tooth landmarks with high accuracy. our method was examined and justified via comparison with the state-of-the-art methods as well as the ablation studies.",,2021-11-07,2021-11-08,"['guangshun wei', 'zhiming cui', 'jie zhu', 'lei yang', 'yuanfeng zhou', 'pradeep singh', 'min gu', 'wenping wang']"
2111.04224,automated detection of gdpr disclosure requirements in privacy policies   using deep active learning,cs.cr cs.ai,"since gdpr came into force in may 2018, companies have worked on their data practices to comply with this privacy law. in particular, since the privacy policy is the essential communication channel for users to understand and control their privacy, many companies updated their privacy policies after gdpr was enforced. however, most privacy policies are verbose, full of jargon, and vaguely describe companies' data practices and users' rights. therefore, it is unclear if they comply with gdpr. in this paper, we create a privacy policy dataset of 1,080 websites labeled with the 18 gdpr requirements and develop a convolutional neural network (cnn) based model which can classify the privacy policies with an accuracy of 89.2%. we apply our model to perform a measurement on the compliance in the privacy policies. our results show that even after gdpr went into effect, 97% of websites still fail to comply with at least one requirement of gdpr.",,2021-11-07,,"['tamjid al rahat', 'tu le', 'yuan tian']"
2111.04225,representation learning via quantum neural tangent kernels,quant-ph cs.ai cs.lg stat.ml,"variational quantum circuits are used in quantum machine learning and variational quantum simulation tasks. designing good variational circuits or predicting how well they perform for given learning or optimization tasks is still unclear. here we discuss these problems, analyzing variational quantum circuits using the theory of neural tangent kernels. we define quantum neural tangent kernels, and derive dynamical equations for their associated loss function in optimization and learning tasks. we analytically solve the dynamics in the frozen limit, or lazy training regime, where variational angles change slowly and a linear perturbation is good enough. we extend the analysis to a dynamical setting, including quadratic corrections in the variational angles. we then consider hybrid quantum-classical architecture and define a large-width limit for hybrid kernels, showing that a hybrid quantum-classical neural network can be approximately gaussian. the results presented here show limits for which analytical understandings of the training dynamics for variational quantum circuits, used for quantum machine learning and optimization problems, are possible. these analytical results are supported by numerical simulations of quantum machine learning experiments.",,2021-11-07,2021-11-13,"['junyu liu', 'francesco tacchino', 'jennifer r. glick', 'liang jiang', 'antonio mezzacapo']"
2111.04248,trust-aware control for intelligent transportation systems,cs.ai cs.ma,"many intelligent transportation systems are multi-agent systems, i.e., both the traffic participants and the subsystems within the transportation infrastructure can be modeled as interacting agents. the use of ai-based methods to achieve coordination among the different agents systems can provide greater safety over transportation systems containing only human-operated vehicles, and also improve the system efficiency in terms of traffic throughput, sensing range, and enabling collaborative tasks. however, increased autonomy makes the transportation infrastructure vulnerable to compromised vehicular agents or infrastructure. this paper proposes a new framework by embedding the trust authority into transportation infrastructure to systematically quantify the trustworthiness of agents using an epistemic logic known as subjective logic. in this paper, we make the following novel contributions: (i) we propose a framework for using the quantified trustworthiness of agents to enable trust-aware coordination and control. (ii) we demonstrate how to synthesize trust-aware controllers using an approach based on reinforcement learning. (iii) we comprehensively analyze an autonomous intersection management (aim) case study and develop a trust-aware version called aim-trust that leads to lower accident rates in scenarios consisting of a mixture of trusted and untrusted agents.",,2021-11-07,,"['mingxi cheng', 'junyao zhang', 'shahin nazarian', 'jyotirmoy deshmukh', 'paul bogdan']"
2111.04260,personalized benchmarking with the ludwig benchmarking toolkit,cs.lg cs.ai,"the rapid proliferation of machine learning models across domains and deployment settings has given rise to various communities (e.g. industry practitioners) which seek to benchmark models across tasks and objectives of personal value. unfortunately, these users cannot use standard benchmark results to perform such value-driven comparisons as traditional benchmarks evaluate models on a single objective (e.g. average accuracy) and fail to facilitate a standardized training framework that controls for confounding variables (e.g. computational budget), making fair comparisons difficult. to address these challenges, we introduce the open-source ludwig benchmarking toolkit (lbt), a personalized benchmarking toolkit for running end-to-end benchmark studies (from hyperparameter optimization to evaluation) across an easily extensible set of tasks, deep learning models, datasets and evaluation metrics. lbt provides a configurable interface for controlling training and customizing evaluation, a standardized training framework for eliminating confounding variables, and support for multi-objective evaluation. we demonstrate how lbt can be used to create personalized benchmark studies with a large-scale comparative analysis for text classification across 7 models and 9 datasets. we explore the trade-offs between inference latency and performance, relationships between dataset attributes and performance, and the effects of pretraining on convergence and robustness, showing how lbt can be used to satisfy various benchmarking objectives.",,2021-11-07,,"['avanika narayan', 'piero molino', 'karan goel', 'willie neiswanger', 'christopher ré']"
2111.04261,jamie: a pipeline japanese medical information extraction system,cs.cl cs.ai,"we present an open-access natural language processing toolkit for japanese medical information extraction. we first propose a novel relation annotation schema for investigating the medical and temporal relations between medical entities in japanese medical reports. we experiment with the practical annotation scenarios by separately annotating two different types of reports. we design a pipeline system with three components for recognizing medical entities, classifying entity modalities, and extracting relations. the empirical results show accurate analyzing performance and suggest the satisfactory annotation quality, the effective annotation strategy for targeting report types, and the superiority of the latest contextual embedding models.",,2021-11-07,,"['fei cheng', 'shuntaro yada', 'ribeka tanaka', 'eiji aramaki', 'sadao kurohashi']"
2111.04271,group-aware threshold adaptation for fair classification,cs.lg cs.ai,"the fairness in machine learning is getting increasing attention, as its applications in different fields continue to expand and diversify. to mitigate the discriminated model behaviors between different demographic groups, we introduce a novel post-processing method to optimize over multiple fairness constraints through group-aware threshold adaptation. we propose to learn adaptive classification thresholds for each demographic group by optimizing the confusion matrix estimated from the probability distribution of a classification model output. as we only need an estimated probability distribution of model output instead of the classification model structure, our post-processing model can be applied to a wide range of classification models and improve fairness in a model-agnostic manner and ensure privacy. this even allows us to post-process existing fairness methods to further improve the trade-off between accuracy and fairness. moreover, our model has low computational cost. we provide rigorous theoretical analysis on the convergence of our optimization algorithm and the trade-off between accuracy and fairness of our method. our method theoretically enables a better upper bound in near optimality than existing method under same condition. experimental results demonstrate that our method outperforms state-of-the-art methods and obtains the result that is closest to the theoretical accuracy-fairness trade-off boundary.",,2021-11-07,,"['taeuk jang', 'pengyi shi', 'xiaoqian wang']"
2111.04273,mimic: an adaptive algorithm for multivariate time series classification,cs.lg cs.ai,"time series data are valuable but are often inscrutable. gaining trust in time series classifiers for finance, healthcare, and other critical applications may rely on creating interpretable models. researchers have previously been forced to decide between interpretable methods that lack predictive power and deep learning methods that lack transparency. in this paper, we propose a novel mimic algorithm that retains the predictive accuracy of the strongest classifiers while introducing interpretability. mimic mirrors the learning method of an existing multivariate time series classifier while simultaneously producing a visual representation that enhances user understanding of the learned model. experiments on 26 time series datasets support mimic's ability to imitate a variety of time series classifiers visually and accurately.",,2021-11-07,,"['yuhui wang', 'diane j. cook']"
2111.04279,batch reinforcement learning from crowds,cs.lg cs.ai,"a shortcoming of batch reinforcement learning is its requirement for rewards in data, thus not applicable to tasks without reward functions. existing settings for lack of reward, such as behavioral cloning, rely on optimal demonstrations collected from humans. unfortunately, extensive expertise is required for ensuring optimality, which hinder the acquisition of large-scale data for complex tasks. this paper addresses the lack of reward in a batch reinforcement learning setting by learning a reward function from preferences. generating preferences only requires a basic understanding of a task. being a mental process, generating preferences is faster than performing demonstrations. so preferences can be collected at scale from non-expert humans using crowdsourcing. this paper tackles a critical challenge that emerged when collecting data from non-expert humans: the noise in preferences. a novel probabilistic model is proposed for modelling the reliability of labels, which utilizes labels collaboratively. moreover, the proposed model smooths the estimation with a learned reward function. evaluation on atari datasets demonstrates the effectiveness of the proposed model, followed by an ablation study to analyze the relative importance of the proposed ideas.",,2021-11-08,,"['guoxi zhang', 'hisashi kashima']"
2111.04286,deep unsupervised active learning on learnable graphs,cs.lg cs.ai,"recently deep learning has been successfully applied to unsupervised active learning. however, current method attempts to learn a nonlinear transformation via an auto-encoder while ignoring the sample relation, leaving huge room to design more effective representation learning mechanisms for unsupervised active learning. in this paper, we propose a novel deep unsupervised active learning model via learnable graphs, named allg. allg benefits from learning optimal graph structures to acquire better sample representation and select representative samples. to make the learnt graph structure more stable and effective, we take into account $k$-nearest neighbor graph as a priori, and learn a relation propagation graph structure. we also incorporate shortcut connections among different layers, which can alleviate the well-known over-smoothing problem to some extent. to the best of our knowledge, this is the first attempt to leverage graph structure learning for unsupervised active learning. extensive experiments performed on six datasets demonstrate the efficacy of our method.",,2021-11-08,,"['handong ma', 'changsheng li', 'xinchu shi', 'ye yuan', 'guoren wang']"
2111.04303,defense against explanation manipulation,cs.lg cs.ai,"explainable machine learning attracts increasing attention as it improves transparency of models, which is helpful for machine learning to be trusted in real applications. however, explanation methods have recently been demonstrated to be vulnerable to manipulation, where we can easily change a model's explanation while keeping its prediction constant. to tackle this problem, some efforts have been paid to use more stable explanation methods or to change model configurations. in this work, we tackle the problem from the training perspective, and propose a new training scheme called adversarial training on explanations (atex) to improve the internal explanation stability of a model regardless of the specific explanation method being applied. instead of directly specifying explanation values over data instances, atex only puts requirement on model predictions which avoids involving second-order derivatives in optimization. as a further discussion, we also find that explanation stability is closely related to another property of the model, i.e., the risk of being exposed to adversarial attack. through experiments, besides showing that atex improves model robustness against manipulation targeting explanation, it also brings additional benefits including smoothing explanations and improving the efficacy of adversarial training if applied to the model.",,2021-11-08,,"['ruixiang tang', 'ninghao liu', 'fan yang', 'na zou', 'xia hu']"
2111.04313,a relational model for one-shot classification,cs.lg cs.ai cs.cv,"we show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation. the proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. our approach solves perfectly the one-shot image classification omniglot challenge. our model exceeds human level accuracy, as well as the previous state of the art, with no data augmentation.",10.14428/esann/2021.es2021-75,2021-11-08,,"['arturs polis', 'alexander ilin']"
2111.04314,graph robustness benchmark: benchmarking the adversarial robustness of   graph machine learning,cs.lg cs.ai cs.cr,"adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (gml) models. naturally, there is an ever-escalating arms race between attackers and defenders. however, the strategies behind both sides are often not fairly compared under the same and realistic conditions. to bridge this gap, we present the graph robustness benchmark (grb) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of gml models. grb standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. by leveraging the grb pipeline, the end-users can focus on the development of robust gml models with automated data processing and experimental evaluations. to support open and reproducible research on graph adversarial learning, grb also hosts public leaderboards across different scenarios. as a starting point, we conduct extensive experiments to benchmark baseline techniques. grb is open-source and welcomes contributions from the community. datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.",,2021-11-08,,"['qinkai zheng', 'xu zou', 'yuxiao dong', 'yukuo cen', 'da yin', 'jiarong xu', 'yang yang', 'jie tang']"
2111.04318,auto-encoding knowledge graph for unsupervised medical report generation,cs.lg cs.ai cs.cl cs.cv,"medical report generation, which aims to automatically generate a long and coherent report of a given medical image, has been receiving growing research interests. existing approaches mainly adopt a supervised manner and heavily rely on coupled image-report pairs. however, in the medical domain, building a large-scale image-report paired dataset is both time-consuming and expensive. to relax the dependency on paired data, we propose an unsupervised model knowledge graph auto-encoder (kgae) which accepts independent sets of images and reports in training. kgae consists of a pre-constructed knowledge graph, a knowledge-driven encoder and a knowledge-driven decoder. the knowledge graph works as the shared latent space to bridge the visual and textual domains; the knowledge-driven encoder projects medical images and reports to the corresponding coordinates in this latent space and the knowledge-driven decoder generates a medical report given a coordinate in this space. since the knowledge-driven encoder and decoder can be trained with independent sets of images and reports, kgae is unsupervised. the experiments show that the unsupervised kgae generates desirable medical reports without using any image-report training pairs. moreover, kgae can also work in both semi-supervised and supervised settings, and accept paired images and reports in training. by further fine-tuning with image-report pairs, kgae consistently outperforms the current state-of-the-art models on two datasets.",,2021-11-08,2021-11-15,"['fenglin liu', 'chenyu you', 'xian wu', 'shen ge', 'sheng wang', 'xu sun']"
2111.04394,get a model! model hijacking attack against machine learning models,cs.cr cs.ai cs.cv cs.lg,"machine learning (ml) has established itself as a cornerstone for various critical applications ranging from autonomous driving to authentication systems. however, with this increasing adoption rate of machine learning models, multiple attacks have emerged. one class of such attacks is training time attack, whereby an adversary executes their attack before or during the machine learning model training. in this work, we propose a new training time attack against computer vision based machine learning models, namely model hijacking attack. the adversary aims to hijack a target model to execute a different task than its original one without the model owner noticing. model hijacking can cause accountability and security risks since a hijacked model owner can be framed for having their model offering illegal or unethical services. model hijacking attacks are launched in the same way as existing data poisoning attacks. however, one requirement of the model hijacking attack is to be stealthy, i.e., the data samples used to hijack the target model should look similar to the model's original training dataset. to this end, we propose two different model hijacking attacks, namely chameleon and adverse chameleon, based on a novel encoder-decoder style ml model, namely the camouflager. our evaluation shows that both of our model hijacking attacks achieve a high attack success rate, with a negligible drop in model utility.",,2021-11-08,,"['ahmed salem', 'michael backes', 'yang zhang']"
2111.04418,"a survey of human activity recognition in smart homes based on iot   sensors algorithms: taxonomies, challenges, and opportunities with deep   learning",cs.hc cs.ai cs.lg eess.sp,"recent advances in internet of things (iot) technologies and the reduction in the cost of sensors have encouraged the development of smart environments, such as smart homes. smart homes can offer home assistance services to improve the quality of life, autonomy and health of their residents, especially for the elderly and dependent. to provide such services, a smart home must be able to understand the daily activities of its residents. techniques for recognizing human activity in smart homes are advancing daily. but new challenges are emerging every day. in this paper, we present recent algorithms, works, challenges and taxonomy of the field of human activity recognition in a smart home through ambient sensors. moreover, since activity recognition in smart homes is a young field, we raise specific problems, missing and needed contributions. but also propose directions, research opportunities and solutions to accelerate advances in this field.",10.3390/s21186037,2021-10-18,,"['damien bouchabou', 'sao mai nguyen', 'christophe lohr', 'benoit leduc', 'ioannis kanellos']"
2111.04424,the problem of zombie datasets:a framework for deprecating datasets,cs.cy cs.ai,"what happens when a machine learning dataset is deprecated for legal, ethical, or technical reasons, but continues to be widely used? in this paper, we examine the public afterlives of several prominent deprecated or redacted datasets, including imagenet, 80 million tiny images, ms-celeb-1m, duke mtmc, brainwash, and hrt transgender, in order to inform a framework for more consistent, ethical, and accountable dataset deprecation. building on prior research, we find that there is a lack of consistency, transparency, and centralized sourcing of information on the deprecation of datasets, and as such, these datasets and their derivatives continue to be cited in papers and circulate online. these datasets that never die -- which we term ""zombie datasets"" -- continue to inform the design of production-level systems, causing technical, legal, and ethical challenges; in so doing, they risk perpetuating the harms that prompted their supposed withdrawal, including concerns around bias, discrimination, and privacy. based on this analysis, we propose a dataset deprecation framework that includes considerations of risk, mitigation of impact, appeal mechanisms, timeline, post-deprecation protocol, and publication checks that can be adapted and implemented by the machine learning community. drawing on work on datasheets and checklists, we further offer two sample dataset deprecation sheets and propose a centralized repository that tracks which datasets have been deprecated and could be incorporated into the publication protocols of venues like neurips.",,2021-10-18,,"['frances corry', 'hamsini sridharan', 'alexandra sasha luccioni', 'mike ananny', 'jason schultz', 'kate crawford']"
2111.04455,systematic review for ai-based language learning tools,cs.cy cs.ai,"the second language acquisition field has been significantly impacted by a greater emphasis on individualized learning and rapid developments in artificial intelligence (ai). although increasingly adaptive language learning tools are being developed with the application of ai to the computer assisted language learning field, there have been concerns regarding insufficient information and teacher preparation. to effectively utilize these tools, teachers need an in-depth overview on recently developed ai-based language learning tools. therefore, this review synthesized information on ai tools that were developed between 2017 and 2020. a majority of these tools utilized machine learning and natural language processing, and were used to identify errors, provide feedback, and assess language abilities. after using these tools, learners demonstrated gains in their language abilities and knowledge. this review concludes by presenting pedagogical implications and emerging themes in the future research of ai-based language learning tools.",,2021-10-29,,"['jin ha woo', 'heeyoul choi']"
2111.04462,creating a coefficient of change in the built environment after a   natural disaster,cs.cy cs.ai,"this study proposes a novel method to assess damages in the built environment using a deep learning workflow to quantify it. thanks to an automated crawler, aerial images from before and after a natural disaster of 50 epicenters worldwide were obtained from google earth, generating a 10,000 aerial image database with a spatial resolution of 2 m per pixel. the study utilizes the algorithm seg-net to perform semantic segmentation of the built environment from the satellite images in both instances (prior and post-natural disasters). for image segmentation, seg-net is one of the most popular and general cnn architectures. the seg-net algorithm used reached an accuracy of 92% in the segmentation. after the segmentation, we compared the disparity between both cases represented as a percentage of change. such coefficient of change represents the damage numerically an urban environment had to quantify the overall damage in the built environment. such an index can give the government an estimate of the number of affected households and perhaps the extent of housing damage.",,2021-10-31,2021-11-09,['karla saldana ochoa']
2111.04465,iot to monitor people flow in areas of public interest,cs.cy cs.ai,"the unexpected historical period we are living has abruptly pushed us to loosen any sort of interaction between individuals, gradually forcing us to deal with new ways to allow compliance with safety distances; indeed the present situation has demonstrated more than ever how critical it is to be able to properly organize our travel plans, put people in safe conditions, and avoid harmful circumstances. the aim of this research is to set up a system to monitor the flow of people inside public places and facilities of interest (museums, theatres, cinemas, etc.) without collecting personal or sensitive data. weak monitoring of people flows (i.e. monitoring without personal identification of the monitored subjects) through internet of things tools might be a viable solution to minimize lineups and overcrowding. our study, which began as an experiment in the umbria region of italy, aims to be one of several answers to automated planning of people's flows in order to make our land more liveable. we intend to show that the internet of things gives almost unlimited tools and possibilities, from developing a basic information process to implementing a true portal which enables business people to connect with interested consumers.",10.1007/978-3-030-87016-4_47,2021-11-02,,"['damiano perri', 'marco simonetti', 'alex bordini', 'simone cimarelli', 'osvaldo gervasi']"
2111.04466,improving peer assessment with graph convolutional networks,cs.cy cs.ai,"peer assessment systems are emerging in many social and multi-agent settings, such as peer grading in large (online) classes, peer review in conferences, peer art evaluation, etc. however, peer assessments might not be as accurate as expert evaluations, thus rendering these systems unreliable. the reliability of peer assessment systems is influenced by various factors such as assessment ability of peers, their strategic assessment behaviors, and the peer assessment setup (e.g., peer evaluating group work or individual work of others). in this work, we first model peer assessment as multi-relational weighted networks that can express a variety of peer assessment setups, plus capture conflicts of interest and strategic behaviors. leveraging our peer assessment network model, we introduce a graph convolutional network which can learn assessment patterns and user behaviors to more accurately predict expert evaluations. our extensive experiments on real and synthetic datasets demonstrate the efficacy of our proposed approach, which outperforms existing peer assessment methods.",,2021-11-03,,"['alireza a. namanloo', 'julie thorpe', 'amirali salehi-abari']"
2111.04471,flight demand forecasting with transformers,cs.lg cs.ai,"transformers have become the de-facto standard in the natural language processing (nlp) field. they have also gained momentum in computer vision and other domains. transformers can enable artificial intelligence (ai) models to dynamically focus on certain parts of their input and thus reason more effectively. inspired by the success of transformers, we adopted this technique to predict strategic flight departure demand in multiple horizons. this work was conducted in support of a mitre-developed mobile application, pacer, which displays predicted departure demand to general aviation (ga) flight operators so they can have better situation awareness of the potential for departure delays during busy periods. field demonstrations involving pacer's previously designed rule-based prediction method showed that the prediction accuracy of departure demand still has room for improvement. this research strives to improve prediction accuracy from two key aspects: better data sources and robust forecasting algorithms. we leveraged two data sources, aviation system performance metrics (aspm) and system wide information management (swim), as our input. we then trained forecasting models with temporal fusion transformer (tft) for five different airports. case studies show that tfts can perform better than traditional forecasting methods by large margins, and they can result in better prediction across diverse airports and with better interpretability.",,2021-11-04,,"['liya wang', 'amy mykityshyn', 'craig johnson', 'jillian cheng']"
2111.04472,ten conceptual dimensions of context,cs.hc cs.ai,"this paper attempts to synthesize various conceptualizations of the term ""context"" as found in computing literature. ten conceptual dimensions of context thus emerge -- location; user, task, and system characteristics; physical, social, organizational, and cultural environments; time-related aspects, and historical information. together, the ten dimensions of context provide a comprehensive view of the notion of context, and allow for a more systematic examination of the influence of context and contextual information on human-system or human-ai interactions.",,2021-11-03,,['hashai papneja']
2111.04473,deskew-lsh based code-to-code recommendation engine,cs.se cs.ai,"machine learning on source code (mloncode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. code-to-code recommendation is a task in mloncode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (ide). code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the ide and increasing code-reuse. existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. in addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. we address both of these weaknesses with \emph{senatus}, a new code-to-code recommendation engine. at the core of senatus is \emph{de-skew} lsh a new locality sensitive hashing (lsh) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. we evaluate senatus via automatic evaluation and with an expert developer user study and find the recommendations to be of higher quality than competing baselines, while achieving faster search. for example, on the codesearchnet dataset we show that senatus improves performance by 6.7\% f1 and query time 16x is faster compared to facebook aroma on the task of code-to-code recommendation.",,2021-11-05,,"['fran silavong', 'sean moran', 'antonios georgiadis', 'rohan saphal', 'robert otter']"
2111.04474,weapon engagement zone maximum launch range estimation using a deep   neural network,cs.lg cs.ai,"this work investigates the use of a deep neural network (dnn) to perform an estimation of the weapon engagement zone (wez) maximum launch range. the wez allows the pilot to identify an airspace in which the available missile has a more significant probability of successfully engaging a particular target, i.e., a hypothetical area surrounding an aircraft in which an adversary is vulnerable to a shot. we propose an approach to determine the wez of a given missile using 50,000 simulated launches in variate conditions. these simulations are used to train a dnn that can predict the wez when the aircraft finds itself on different firing conditions, with a coefficient of determination of 0.99. it provides another procedure concerning preceding research since it employs a non-discretized model, i.e., it considers all directions of the wez at once, which has not been done previously. additionally, the proposed method uses an experimental design that allows for fewer simulation runs, providing faster model training.",,2021-11-04,2021-11-17,"['joao p. a. dantas', 'andre n. costa', 'diego geraldo', 'marcos r. o. a. maximo', 'takashi yoneyama']"
2111.04475,identifying the leading factors of significant weight gains using a new   rule discovery method,cs.lg cs.ai,"overweight and obesity remain a major global public health concern and identifying the individualized patterns that increase the risk of future weight gains has a crucial role in preventing obesity and numerous sub-sequent diseases associated with obesity. in this work, we use a rule discovery method to study this problem, by presenting an approach that offers genuine interpretability and concurrently optimizes the accuracy(being correct often) and support (applying to many samples) of the identified patterns. specifically, we extend an established subgroup-discovery method to generate the desired rules of type x -> y and show how top features can be extracted from the x side, functioning as the best predictors of y. in our obesity problem, x refers to the extracted features from very large and multi-site ehr data, and y indicates significant weight gains. using our method, we also extensively compare the differences and inequities in patterns across 22 strata determined by the individual's gender, age, race, insurance type, neighborhood type, and income level. through extensive series of experiments, we show new and complementary findings regarding the predictors of future dangerous weight gains.",,2021-11-04,,"['mina samizadeh', 'jessica c jones-smith', 'bethany sheridan', 'rahmatollah beheshti']"
2111.04494,multi-airport delay prediction with transformers,cs.lg cs.ai,"airport performance prediction with a reasonable look-ahead time is a challenging task and has been attempted by various prior research. traffic, demand, weather, and traffic management actions are all critical inputs to any prediction model. in this paper, a novel approach based on temporal fusion transformer (tft) was proposed to predict departure and arrival delays simultaneously for multiple airports at once. this approach can capture complex temporal dynamics of the inputs known at the time of prediction and then forecast selected delay metrics up to four hours into the future. when dealing with weather inputs, a self-supervised learning (ssl) model was developed to encode high-dimensional weather data into a much lower-dimensional representation to make the training of tft more efficiently and effectively. the initial results show that the tft-based delay prediction model achieves satisfactory performance measured by smaller prediction errors on a testing dataset. in addition, the interpretability analysis of the model outputs identifies the important input factors for delay prediction. the proposed approach is expected to help air traffic managers or decision makers gain insights about traffic management actions on delay mitigation and once operationalized, provide enough lead time to plan for predicted performance degradation.",,2021-11-04,,"['liya wang', 'alex tien', 'jason chou']"
2111.04504,improving rna secondary structure design using deep reinforcement   learning,cs.lg cs.ai,"rising costs in recent years of developing new drugs and treatments have led to extensive research in optimization techniques in biomolecular design. currently, the most widely used approach in biomolecular design is directed evolution, which is a greedy hill-climbing algorithm that simulates biological evolution. in this paper, we propose a new benchmark of applying reinforcement learning to rna sequence design, in which the objective function is defined to be the free energy in the sequence's secondary structure. in addition to experimenting with the vanilla implementations of each reinforcement learning algorithm from standard libraries, we analyze variants of each algorithm in which we modify the algorithm's reward function and tune the model's hyperparameters. we show results of the ablation analysis that we do for these algorithms, as well as graphs indicating the algorithm's performance across batches and its ability to search the possible space of rna sequences. we find that our dqn algorithm performs by far the best in this setting, contrasting with, in which ppo performs the best among all tested algorithms. our results should be of interest to those in the biomolecular design community and should serve as a baseline for future experiments involving machine learning in molecule design.",,2021-11-04,,"['alexander whatley', 'zhekun luo', 'xiangru tang']"
2111.04551,sexism prediction in spanish and english tweets using monolingual and   multilingual bert and ensemble models,cs.cl cs.ai cs.cy cs.lg,"the popularity of social media has created problems such as hate speech and sexism. the identification and classification of sexism in social media are very relevant tasks, as they would allow building a healthier social environment. nevertheless, these tasks are considerably challenging. this work proposes a system to use multilingual and monolingual bert and data points translation and ensemble strategies for sexism identification and classification in english and spanish. it was conducted in the context of the sexism identification in social networks shared 2021 (exist 2021) task, proposed by the iberian languages evaluation forum (iberlef). the proposed system and its main components are described, and an in-depth hyperparameters analysis is conducted. the main results observed were: (i) the system obtained better results than the baseline model (multilingual bert); (ii) ensemble models obtained better results than monolingual models; and (iii) an ensemble model considering all individual models and the best standardized values obtained the best accuracies and f1-scores for both tasks. this work obtained first place in both tasks at exist, with the highest accuracies (0.780 for task 1 and 0.658 for task 2) and f1-scores (f1-binary of 0.780 for task 1 and f1-macro of 0.579 for task 2).",,2021-11-08,,"['angel felipe magnossão de paula', 'roberto fray da silva', 'ipek baris schlicht']"
2111.04564,human activity recognition using attribute-based neural networks and   context information,eess.sp cs.ai cs.lg,"we consider human activity recognition (har) from wearable sensor data in manual-work processes, like warehouse order-picking. such structured domains can often be partitioned into distinct process steps, e.g., packaging or transporting. each process step can have a different prior distribution over activity classes, e.g., standing or walking, and different system dynamics. here, we show how such context information can be integrated systematically into a deep neural network-based har system. specifically, we propose a hybrid architecture that combines a deep neural network-that estimates high-level movement descriptors, attributes, from the raw-sensor data-and a shallow classifier, which predicts activity classes from the estimated attributes and (optional) context information, like the currently executed process step. we empirically show that our proposed architecture increases har performance, compared to state-of-the-art methods. additionally, we show that har performance can be further increased when information about process steps is incorporated, even when that information is only partially correct.",,2021-10-28,,"['stefan lüdtke', 'fernando moya rueda', 'waqas ahmed', 'gernot a. fink', 'thomas kirste']"
2111.04576,coco games: graphical game-theoretic swarm control for   communication-aware coverage,cs.ro cs.ai cs.sy eess.sy,"we present a novel approach to maximize the communication-aware coverage for robots operating over large-scale geographical regions of interest (rois). our approach complements the underlying network topology in neighborhood selection and control, rendering it highly robust in dynamic environments. we formulate the coverage as a multi-stage, cooperative graphical game and employ variational inference (vi) to reach the equilibrium. we experimentally validate our approach in an mobile ad-hoc wireless network scenario using unmanned aerial vehicles (uav) and user equipment (ue) robots. we show that it can cater to rois defined by stationary and moving user equipment (ue) robots under realistic network conditions.",,2021-11-08,,"['malintha fernando', 'ransalu senanayake', 'martin swany']"
2111.04625,deepsteal: advanced model extractions leveraging efficient weight   stealing in memories,cs.cr cs.ai cs.cv cs.lg,"recent advancements of deep neural networks (dnns) have seen widespread deployment in multiple security-sensitive domains. the need of resource-intensive training and use of valuable domain-specific training data have made these models a top intellectual property (ip) for model owners. one of the major threats to the dnn privacy is model extraction attacks where adversaries attempt to steal sensitive information in dnn models. recent studies show hardware-based side channel attacks can reveal internal knowledge about dnn models (e.g., model architectures) however, to date, existing attacks cannot extract detailed model parameters (e.g., weights/biases). in this work, for the first time, we propose an advanced model extraction attack framework deepsteal that effectively steals dnn weights with the aid of memory side-channel attack. our proposed deepsteal comprises two key stages. firstly, we develop a new weight bit information extraction method, called hammerleak, through adopting the rowhammer based hardware fault technique as the information leakage vector. hammerleak leverages several novel system-level techniques tailed for dnn applications to enable fast and efficient weight stealing. secondly, we propose a novel substitute model training algorithm with mean clustering weight penalty, which leverages the partial leaked bit information effectively and generates a substitute prototype of the target victim model. we evaluate this substitute model extraction method on three popular image datasets (e.g., cifar-10/100/gtsrb) and four dnn architectures (e.g., resnet-18/34/wide-resnet/vgg-11). the extracted substitute model has successfully achieved more than 90 % test accuracy on deep residual networks for the cifar-10 dataset. moreover, our extracted substitute model could also generate effective adversarial input samples to fool the victim model.",,2021-11-08,,"['adnan siraj rakin', 'md hafizul islam chowdhuryy', 'fan yao', 'deliang fan']"
2111.04646,intelligent reflecting surfaces for enhanced noma-based visible light   communications,cs.it cs.ai math.it,"the emerging intelligent reflecting surface (irs) technology introduces the potential of controlled light propagation in visible light communication (vlc) systems. this concept opens the door for new applications in which the channel itself can be altered to achieve specific key performance indicators. in this paper, for the first time in the open literature, we investigate the role that irss can play in enhancing the link reliability in vlc systems employing non-orthogonal multiple access (noma). we propose a framework for the joint optimisation of the noma and irs parameters and show that it provides significant enhancements in link reliability. the enhancement is even more pronounced when the vlc channel is subject to blockage and random device orientation.",,2021-11-08,,"['hanaa abumarshoud', 'bassant selim', 'mallik tatipamula', 'harald haas']"
2111.04665,evaluating predictive uncertainty and robustness to distributional shift   using real world data,cs.lg cs.ai,"most machine learning models operate under the assumption that the training, testing and deployment data is independent and identically distributed (i.i.d.). this assumption doesn't generally hold true in a natural setting. usually, the deployment data is subject to various types of distributional shifts. the magnitude of a model's performance is proportional to this shift in the distribution of the dataset. thus it becomes necessary to evaluate a model's uncertainty and robustness to distributional shifts to get a realistic estimate of its expected performance on real-world data. present methods to evaluate uncertainty and model's robustness are lacking and often fail to paint the full picture. moreover, most analysis so far has primarily focused on classification tasks. in this paper, we propose more insightful metrics for general regression tasks using the shifts weather prediction dataset. we also present an evaluation of the baseline methods using these metrics.",,2021-11-08,,"['kumud lakara', 'akshat bhandari', 'pratinav seth', 'ujjwal verma']"
2111.04682,smu: smooth activation function for deep networks using smoothing   maximum technique,cs.lg cs.ai cs.cv cs.ne,"deep learning researchers have a keen interest in proposing two new novel activation functions which can boost network performance. a good choice of activation function can have significant consequences in improving network performance. a handcrafted activation is the most common choice in neural network models. relu is the most common choice in the deep learning community due to its simplicity though relu has some serious drawbacks. in this paper, we have proposed a new novel activation function based on approximation of known activation functions like leaky relu, and we call this function smooth maximum unit (smu). replacing relu by smu, we have got 6.22% improvement in the cifar100 dataset with the shufflenet v2 model.",,2021-11-08,,"['koushik biswas', 'sandeep kumar', 'shilpak banerjee', 'ashish kumar pandey']"
2111.04683,revisiting methods for finding influential examples,cs.lg cs.ai,"several instance-based explainability methods for finding influential training examples for test-time decisions have been proposed recently, including influence functions, tracein, representer point selection, grad-dot, and grad-cos. typically these methods are evaluated using loo influence (cook's distance) as a gold standard, or using various heuristics. in this paper, we show that all of the above methods are unstable, i.e., extremely sensitive to initialization, ordering of the training data, and batch size. we suggest that this is a natural consequence of how in the literature, the influence of examples is assumed to be independent of model state and other examples -- and argue it is not. we show that loo influence and heuristics are, as a result, poor metrics to measure the quality of instance-based explanations, and instead propose to evaluate such explanations by their ability to detect poisoning attacks. further, we provide a simple, yet effective baseline to improve all of the above methods and show how it leads to very significant improvements on downstream tasks.",,2021-11-08,,"['karthikeyan k', 'anders søgaard']"
2111.04686,reinforcement learning for mixed autonomy intersections,cs.ai cs.lg cs.ma cs.sy eess.sy,"we propose a model-free reinforcement learning method for controlling mixed autonomy traffic in simulated traffic networks with through-traffic-only two-way and four-way intersections. our method utilizes multi-agent policy decomposition which allows decentralized control based on local observations for an arbitrary number of controlled vehicles. we demonstrate that, even without reward shaping, reinforcement learning learns to coordinate the vehicles to exhibit traffic signal-like behaviors, achieving near-optimal throughput with 33-50% controlled vehicles. with the help of multi-task learning and transfer learning, we show that this behavior generalizes across inflow rates and size of the traffic network. our code, models, and videos of results are available at https://github.com/zhongxiayan/mixed_autonomy_intersections.",10.1109/itsc48978.2021.9565000,2021-11-08,,"['zhongxia yan', 'cathy wu']"
2111.04689,a comparison of model-free and model predictive control for price   responsive water heaters,eess.sy cs.ai cs.sy,"we present a careful comparison of two model-free control algorithms, evolution strategies (es) and proximal policy optimization (ppo), with receding horizon model predictive control (mpc) for operating simulated, price responsive water heaters. four mpc variants are considered: a one-shot controller with perfect forecasting yielding optimal control; a limited-horizon controller with perfect forecasting; a mean forecasting-based controller; and a two-stage stochastic programming controller using historical scenarios. in all cases, the mpc model for water temperature and electricity price are exact; only water demand is uncertain. for comparison, both es and ppo learn neural network-based policies by directly interacting with the simulated environment under the same scenarios used by mpc. all methods are then evaluated on a separate one-week continuation of the demand time series. we demonstrate that optimal control for this problem is challenging, requiring more than 8-hour lookahead for mpc with perfect forecasting to attain the minimum cost. despite this challenge, both es and ppo learn good general purpose policies that outperform mean forecast and two-stage stochastic mpc controllers in terms of average cost and are more than two orders of magnitude faster at computing actions. we show that es in particular can leverage parallelism to learn a policy in under 90 seconds using 1150 cpu cores.",10.1145/3427773.3427872,2021-11-08,,"['david j. biagioni', 'xiangyu zhang', 'peter graf', 'devon sigler', 'wesley jones']"
2111.04714,understanding the effects of dataset characteristics on offline   reinforcement learning,cs.lg cs.ai,"in real world, affecting the environment by a weak policy can be expensive or very risky, therefore hampers real world applications of reinforcement learning. offline reinforcement learning (rl) can learn policies from a given dataset without interacting with the environment. however, the dataset is the only source of information for an offline rl algorithm and determines the performance of the learned policy. we still lack studies on how dataset characteristics influence different offline rl algorithms. therefore, we conducted a comprehensive empirical analysis of how dataset characteristics effect the performance of offline rl algorithms for discrete action environments. a dataset is characterized by two metrics: (1) the average dataset return measured by the trajectory quality (tq) and (2) the coverage measured by the state-action coverage (saco). we found that variants of the off-policy deep q-network family require datasets with high saco to perform well. algorithms that constrain the learned policy towards the given dataset perform well for datasets with high tq or saco. for datasets with high tq, behavior cloning outperforms or performs similarly to the best offline rl algorithms.",,2021-11-08,,"['kajetan schweighofer', 'markus hofmarcher', 'marius-constantin dinu', 'philipp renz', 'angela bitto-nemling', 'vihang patil', 'sepp hochreiter']"
2111.04731,survey of deep learning methods for inverse problems,cs.cv cs.ai cs.lg,"in this paper we investigate a variety of deep learning strategies for solving inverse problems. we classify existing deep learning solutions for inverse problems into three categories of direct mapping, data consistency optimizer, and deep regularizer. we choose a sample of each inverse problem type, so as to compare the robustness of the three categories, and report a statistical analysis of their differences. we perform extensive experiments on the classic problem of linear regression and three well-known inverse problems in computer vision, namely image denoising, 3d human face inverse rendering, and object tracking, selected as representative prototypes for each class of inverse problems. the overall results and the statistical analyses show that the solution categories have a robustness behaviour dependent on the type of inverse problem domain, and specifically dependent on whether or not the problem includes measurement outliers. based on our experimental results, we conclude by proposing the most robust solution category for each inverse problem class.",,2021-11-07,2021-11-13,"['shima kamyab', 'zohreh azimifar', 'rasool sabzi', 'paul fieguth']"
2111.04732,use of 1d-cnn for input data size reduction of lstm in hourly   rainfall-runoff modeling,cs.lg cs.ai physics.ao-ph,"an architecture consisting of a serial coupling of the one-dimensional convolutional neural network (1d-cnn) and the long short-term memory (lstm) network, which is referred as cnnslstm, was proposed for hourly-scale rainfall-runoff modeling in this study. in cnnsltsm, the cnn component receives the hourly meteorological time series data for a long duration, and then the lstm component receives the extracted features from 1d-cnn and the hourly meteorological time series data for a short-duration. as a case study, cnnslstm was implemented for hourly rainfall-runoff modeling at the ishikari river watershed, japan. the meteorological dataset, consists of precipitation, air temperature, evapotranspiration, and long- and short-wave radiation, were utilized as input, and the river flow was used as the target data. to evaluate the performance of proposed cnnslstm, results of cnnslstm were compared with those of 1d-cnn, lstm only with hourly inputs (lstmwhour), parallel architecture of 1d-cnn and lstm (cnnplstm), and the lstm architecture which uses both daily and hourly input data (lstmwdph). cnnslstm showed clear improvements on the estimation accuracy compared to the three conventional architectures (1d-cnn, lstmwhour, and cnnplstm), and recently proposed lstmwdph. in comparison to observed flows, the median of the nse values for the test period are 0.455-0.469 for 1d-cnn (based on nchf=8, 16, and 32, the numbers of the channels of the feature map of the first layer of cnn), 0.639-0.656 for cnnplstm (based on nchf=8, 16, and 32), 0.745 for lstmwhour, 0.831 for lstmwdph, and 0.865-0.873 for cnnslstm (based on nchf=8, 16, and 32). furthermore, the proposed cnnslstm reduces the median rmse of 1d-cnn by 50.2%-51.4%, cnnplstm by 37.4%-40.8%, lstmwhour by 27.3%-29.5%, and lstmwdph by 10.6%-13.4%.",,2021-11-07,,"['kei ishida', 'ali ercan', 'takeyoshi nagasato', 'masato kiyama', 'motoki amagasaki']"
2111.04734,mixed transformer u-net for medical image segmentation,eess.iv cs.ai cs.cv,"though u-net has achieved tremendous success in medical image segmentation tasks, it lacks the ability to explicitly model long-range dependencies. therefore, vision transformers have emerged as alternative segmentation structures recently, for their innate ability of capturing long-range correlations through self-attention (sa). however, transformers usually rely on large-scale pre-training and have high computational complexity. furthermore, sa can only model self-affinities within a single sample, ignoring the potential correlations of the overall dataset. to address these problems, we propose a novel transformer module named mixed transformer module (mtm) for simultaneous inter- and intra- affinities learning. mtm first calculates self-affinities efficiently through our well-designed local-global gaussian-weighted self-attention (lgg-sa). then, it mines inter-connections between data samples through external attention (ea). by using mtm, we construct a u-shaped model named mixed transformer u-net (mt-unet) for accurate medical image segmentation. we test our method on two different public datasets, and the experimental results show that the proposed method achieves better performance over other state-of-the-art methods. the code is available at: https://github.com/dootmaan/mt-unet.",,2021-11-08,2021-11-11,"['hongyi wang', 'shiao xie', 'lanfen lin', 'yutaro iwamoto', 'xian-hua han', 'yen-wei chen', 'ruofeng tong']"
2111.04740,bracs: a dataset for breast carcinoma subtyping in h&e histology images,q-bio.qm cs.ai cs.cv eess.iv,"breast cancer is the most commonly diagnosed cancer and registers the highest number of deaths for women with cancer. recent advancements in diagnostic activities combined with large-scale screening policies have significantly lowered the mortality rates for breast cancer patients. however, the manual inspection of tissue slides by the pathologists is cumbersome, time-consuming, and is subject to significant inter- and intra-observer variability. recently, the advent of whole-slide scanning systems have empowered the rapid digitization of pathology slides, and enabled to develop digital workflows. these advances further enable to leverage artificial intelligence (ai) to assist, automate, and augment pathological diagnosis. but the ai techniques, especially deep learning (dl), require a large amount of high-quality annotated data to learn from. constructing such task-specific datasets poses several challenges, such as, data-acquisition level constrains, time-consuming and expensive annotations, and anonymization of private information. in this paper, we introduce the breast carcinoma subtyping (bracs) dataset, a large cohort of annotated hematoxylin & eosin (h&e)-stained images to facilitate the characterization of breast lesions. bracs contains 547 whole-slide images (wsis), and 4539 regions of interest (rois) extracted from the wsis. each wsi, and respective rois, are annotated by the consensus of three board-certified pathologists into different lesion categories. specifically, bracs includes three lesion types, i.e., benign, malignant and atypical, which are further subtyped into seven categories. it is, to the best of our knowledge, the largest annotated dataset for breast cancer subtyping both at wsi- and roi-level. further, by including the understudied atypical lesions, bracs offers an unique opportunity for leveraging ai to better understand their characteristics.",,2021-11-08,,"['nadia brancati', 'anna maria anniciello', 'pushpak pati', 'daniel riccio', 'giosuè scognamiglio', 'guillaume jaume', 'giuseppe de pietro', 'maurizio di bonito', 'antonio foncubierta', 'gerardo botti', 'maria gabrani', 'florinda feroce', 'maria frucci']"
2111.04779,ml-exray: visibility into ml deployment on the edge,cs.dc cs.ai cs.lg,"benefiting from expanding cloud infrastructure, deep neural networks (dnns) today have increasingly high performance when trained in the cloud. researchers spend months of effort competing for an extra few percentage points of model accuracy. however, when these models are actually deployed on edge devices in practice, very often, the performance can abruptly drop over 10% without obvious reasons. the key challenge is that there is not much visibility into ml inference execution on edge devices, and very little awareness of potential issues during the edge deployment process. we present ml-exray, an end-to-end framework, which provides visibility into layer-level details of the ml execution, and helps developers analyze and debug cloud-to-edge deployment issues. more often than not, the reason for sub-optimal edge performance does not only lie in the model itself, but every operation throughout the data flow and the deployment process. evaluations show that ml-exray can effectively catch deployment issues, such as pre-processing bugs, quantization issues, suboptimal kernels, etc. using ml-exray, users need to write less than 15 lines of code to fully examine the edge deployment pipeline. eradicating these issues, ml-exray can correct model performance by up to 30%, pinpoint error-prone layers, and guide users to optimize kernel execution latency by two orders of magnitude. code and apis will be released as an open-source multi-lingual instrumentation library and a python deployment validation library.",,2021-11-08,,"['hang qiu', 'ioanna vavelidou', 'jian li', 'evgenya pergament', 'pete warden', 'sandeep chinchali', 'zain asgar', 'sachin katti']"
2111.04785,visual question answering based on formal logic,cs.cv cs.ai cs.cl,"visual question answering (vqa) has been gaining a lot of traction in the machine learning community in the recent years due to the challenges posed in understanding information coming from multiple modalities (i.e., images, language). in vqa, a series of questions are posed based on a set of images and the task at hand is to arrive at the answer. to achieve this, we take a symbolic reasoning based approach using the framework of formal logic. the image and the questions are converted into symbolic representations on which explicit reasoning is performed. we propose a formal logic framework where (i) images are converted to logical background facts with the help of scene graphs, (ii) the questions are translated to first-order predicate logic clauses using a transformer based deep learning model, and (iii) perform satisfiability checks, by using the background knowledge and the grounding of predicate clauses, to obtain the answer. our proposed method is highly interpretable and each step in the pipeline can be easily analyzed by a human. we validate our approach on the clevr and the gqa dataset. we achieve near perfect accuracy of 99.6% on the clevr dataset comparable to the state of art models, showcasing that formal logic is a viable tool to tackle visual question answering. our model is also data efficient, achieving 99.1% accuracy on clevr dataset when trained on just 10% of the training data.",,2021-11-08,,"['muralikrishnna g. sethuraman', 'ali payani', 'faramarz fekri', 'j. clayton kerce']"
2111.04794,deep learning approach for aggressive driving behaviour detection,cs.lg cs.ai,"driving behaviour is one of the primary causes of road crashes and accidents, and these can be decreased by identifying and minimizing aggressive driving behaviour. this study identifies the timesteps when a driver in different circumstances (rush, mental conflicts, reprisal) begins to drive aggressively. an observer (real or virtual) is needed to examine driving behaviour to discover aggressive driving occasions; we overcome this problem by using a smartphone's gps sensor to detect locations and classify drivers' driving behaviour every three minutes. to detect timeseries patterns in our dataset, we employ rnn (gru, lstm) algorithms to identify patterns during the driving course. the algorithm is independent of road, vehicle, position, or driver characteristics. we conclude that three minutes (or more) of driving (120 seconds of gps data) is sufficient to identify driver behaviour. the results show high accuracy and a high f1 score.",,2021-11-08,,"['farid talebloo', 'emad a. mohammed', 'behrouz far']"
2111.04833,solving marginal map exactly by probabilistic circuit transformations,cs.ai cs.lg,"probabilistic circuits (pcs) are a class of tractable probabilistic models that allow efficient, often linear-time, inference of queries such as marginals and most probable explanations (mpe). however, marginal map, which is central to many decision-making problems, remains a hard query for pcs unless they satisfy highly restrictive structural constraints. in this paper, we develop a pruning algorithm that removes parts of the pc that are irrelevant to a marginal map query, shrinking the pc while maintaining the correct solution. this pruning technique is so effective that we are able to build a marginal map solver based solely on iteratively transforming the circuit -- no search is required. we empirically demonstrate the efficacy of our approach on real-world datasets.",,2021-11-08,,"['yoojung choi', 'tal friedman', 'guy van den broeck']"
2111.04838,efficient estimates of optimal transport via low-dimensional embeddings,cs.lg cs.ai stat.ml,"optimal transport distances (ot) have been widely used in recent work in machine learning as ways to compare probability distributions. these are costly to compute when the data lives in high dimension. recent work by paty et al., 2019, aims specifically at reducing this cost by computing ot using low-rank projections of the data (seen as discrete measures). we extend this approach and show that one can approximate ot distances by using more general families of maps provided they are 1-lipschitz. the best estimate is obtained by maximising ot over the given family. as ot calculations are done after mapping data to a lower dimensional space, our method scales well with the original data dimension. we demonstrate the idea with neural networks.",,2021-11-08,,"['patric m. fulop', 'vincent danos']"
2111.04845,hybrid byol-vit: efficient approach to deal with small datasets,cs.cv cs.ai,"supervised learning can learn large representational spaces, which are crucial for handling difficult learning tasks. however, due to the design of the model, classical image classification approaches struggle to generalize to new problems and new situations when dealing with small datasets. in fact, supervised learning can lose the location of image features which leads to supervision collapse in very deep architectures. in this paper, we investigate how self-supervision with strong and sufficient augmentation of unlabeled data can train effectively the first layers of a neural network even better than supervised learning, with no need for millions of labeled data. the main goal is to disconnect pixel data from annotation by getting generic task-agnostic low-level features. furthermore, we look into vision transformers (vit) and show that the low-level features derived from a self-supervised architecture can improve the robustness and the overall performance of this emergent architecture. we evaluated our method on one of the smallest open-source datasets stl-10 and we obtained a significant boost of performance from 41.66% to 83.25% when inputting low-level features from a self-supervised learning architecture to the vit instead of the raw images.",,2021-11-08,2021-11-15,"['safwen naimi', 'rien van leeuwen', 'wided souidene', 'slim ben saoud']"
2111.04862,explaining face presentation attack detection using natural language,cs.cv cs.ai cs.cl cs.cr,"a large number of deep neural network based techniques have been developed to address the challenging problem of face presentation attack detection (pad). whereas such techniques' focus has been on improving pad performance in terms of classification accuracy and robustness against unseen attacks and environmental conditions, there exists little attention on the explainability of pad predictions. in this paper, we tackle the problem of explaining pad predictions through natural language. our approach passes feature representations of a deep layer of the pad model to a language model to generate text describing the reasoning behind the pad prediction. due to the limited amount of annotated data in our study, we apply a light-weight lstm network as our natural language generation model. we investigate how the quality of the generated explanations is affected by different loss functions, including the commonly used word-wise cross entropy loss, a sentence discriminative loss, and a sentence semantic loss. we perform our experiments using face images from a dataset consisting of 1,105 bona-fide and 924 presentation attack samples. our quantitative and qualitative results show the effectiveness of our model for generating proper pad explanations through text as well as the power of the sentence-wise losses. to the best of our knowledge, this is the first introduction of a joint biometrics-nlp task. our dataset can be obtained through our github page.",,2021-11-08,,"['hengameh mirzaalian', 'mohamed e. hussein', 'leonidas spinoulas', 'jonathan may', 'wael abd-almageed']"
2111.04873,an instance-dependent analysis for the cooperative multi-player   multi-armed bandit,cs.lg cs.ai stat.ml,"we study the problem of information sharing and cooperation in multi-player multi-armed bandits. we propose the first algorithm that achieves logarithmic regret for this problem. our results are based on two innovations. first, we show that a simple modification to a successive elimination strategy can be used to allow the players to estimate their suboptimality gaps, up to constant factors, in the absence of collisions. second, we leverage the first result to design a communication protocol that successfully uses the small reward of collisions to coordinate among players, while preserving meaningful instance-dependent logarithmic regret guarantees.",,2021-11-08,,"['aldo pacchiano', 'peter bartlett', 'michael i. jordan']"
2111.04879,evolearner: learning description logics with evolutionary algorithms,cs.ai cs.lg cs.ne,"classifying nodes in knowledge graphs is an important task, e.g., predicting missing types of entities, predicting which molecules cause cancer, or predicting which drugs are promising treatment candidates. while black-box models often achieve high predictive performance, they are only post-hoc and locally explainable and do not allow the learned model to be easily enriched with domain knowledge. towards this end, learning description logic concepts from positive and negative examples has been proposed. however, learning such concepts often takes a long time and state-of-the-art approaches provide limited support for literal data values, although they are crucial for many applications. in this paper, we propose evolearner - an evolutionary approach to learn alcq(d), which is the attributive language with complement (alc) paired with qualified cardinality restrictions (q) and data properties (d). we contribute a novel initialization method for the initial population: starting from positive examples (nodes in the knowledge graph), we perform biased random walks and translate them to description logic concepts. moreover, we improve support for data properties by maximizing information gain when deciding where to split the data. we show that our approach significantly outperforms the state of the art on the benchmarking framework sml-bench for structured machine learning. our ablation study confirms that this is due to our novel initialization method and support for data properties.",,2021-11-08,,"['stefan heindorf', 'lukas blübaum', 'nick düsterhus', 'till werner', 'varun nandkumar golani', 'caglar demir', 'axel-cyrille ngonga ngomo']"
2111.04880,user centered design (vi): human factors approaches for intelligent   human-computer interaction,cs.hc cs.ai,"starting from the design philosophy of ""user-centered design"", this paper analyzes the human factors characteristics of intelligent human-computer interaction (ihci) and proposes a concept of ""user-oriented ihci"". it further proposes a new human factors framework for ihci based on the theories of joint cognitive systems, situation awareness, and intelligent agents. with the help of the new concept and framework, the paper analyzes the human factors issues in the ecosystem of autonomous vehicle co-driving and layouts future research agenda. finally, the paper analyzes the two important research areas in ihci (i.e., user intention recognition, human-computer collaboration) and points out the focus of human factors research in the future.",,2021-11-08,,['wei xu']
2111.04885,lymph node detection in t2 mri with transformers,eess.iv cs.ai cs.cv physics.med-ph,"identification of lymph nodes (ln) in t2 magnetic resonance imaging (mri) is an important step performed by radiologists during the assessment of lymphoproliferative diseases. the size of the nodes play a crucial role in their staging, and radiologists sometimes use an additional contrast sequence such as diffusion weighted imaging (dwi) for confirmation. however, lymph nodes have diverse appearances in t2 mri scans, making it tough to stage for metastasis. furthermore, radiologists often miss smaller metastatic lymph nodes over the course of a busy day. to deal with these issues, we propose to use the detection transformer (detr) network to localize suspicious metastatic lymph nodes for staging in challenging t2 mri scans acquired by different scanners and exam protocols. false positives (fp) were reduced through a bounding box fusion technique, and a precision of 65.41\% and sensitivity of 91.66\% at 4 fp per image was achieved. to the best of our knowledge, our results improve upon the current state-of-the-art for lymph node detection in t2 mri scans.",,2021-11-08,,"['tejas sudharshan mathai', 'sungwon lee', 'daniel c. elton', 'thomas c. shen', 'yifan peng', 'zhiyong lu', 'ronald m. summers']"
2111.04894,safe policy optimization with local generalized linear function   approximations,cs.lg cs.ai cs.ro,"safe exploration is a key to applying reinforcement learning (rl) in safety-critical systems. existing safe exploration methods guaranteed safety under the assumption of regularity, and it has been difficult to apply them to large-scale real problems. we propose a novel algorithm, spo-lf, that optimizes an agent's policy while learning the relation between a locally available feature obtained by sensors and environmental reward/safety using generalized linear function approximations. we provide theoretical guarantees on its safety and optimality. we experimentally show that our algorithm is 1) more efficient in terms of sample complexity and computational cost and 2) more applicable to large-scale problems than previous safe rl methods with theoretical guarantees, and 3) comparably sample-efficient and safer compared with existing advanced deep rl methods with safety constraints.",,2021-11-08,,"['akifumi wachi', 'yunyue wei', 'yanan sui']"
2111.04909,fpm: a collection of large-scale foundation pre-trained language models,cs.cl cs.ai,"recent work in language modeling has shown that training large-scale transformer models has promoted the latest developments in natural language processing applications. however, there is very little work to unify the current effective models. in this work, we use the current effective model structure to launch a model set through the current most mainstream technology. we think this will become the basic model in the future. for chinese, using the gpt-2[9] model, a 10.3 billion parameter language model was trained on the chinese dataset, and, in particular, a 2.9 billion parameter language model based on dialogue data was trained; the bert model was trained on the chinese dataset with 495 million parameters; the transformer model has trained a language model with 5.6 billion parameters on the chinese dataset. in english, corresponding training work has also been done. using the gpt-2 model, a language model with 6.4 billion parameters was trained on the english dataset; the bert[3] model trained a language model with 1.24 billion parameters on the english dataset, and in particular, it trained a 688 million parameter based on single card training technology language model; transformer model trained a language model with 5.6 billion parameters on the english dataset. in the tnews classification task evaluated by clue[13], the bert-c model exceeded the 59.46% accuracy of albert-xxlarge with an accuracy rate of 59.99%, an increase of 0.53%. in the qqp classification task evaluated by glue[11], the accuracy rate of 78.95% surpassed the accuracy rate of bert-large of 72.1%, an increase of 6.85%. compared with the current accuracy rate of ernie, the first place in the glue evaluation of 75.2%, an increase of 3.75%.",,2021-11-08,2021-11-15,['dezhou shen']
2111.04916,building an ai-ready rse workforce,cs.se cs.ai,"artificial intelligence has been transforming industries and academic research across the globe, and research software development is no exception. machine learning and deep learning are being applied in every aspect of the research software development lifecycles, from new algorithm design paradigms to software development processes. in this paper, we discuss our views on today's challenges and opportunities that ai has presented on research software development and engineers, and the approaches we, at the university of florida, are taking to prepare our workforce for the new era of ai.",,2021-11-08,,"['ying zhang', 'matthew a. gitzendanner', 'dan s. maxwell', 'justin w. richardson', 'kaleb e. smith', 'eric a. stubbs', 'brian j. stucky', 'jingchao zhang', 'erik deumens']"
2111.04933,dsbert:unsupervised dialogue structure learning with bert,cs.cl cs.ai,"unsupervised dialogue structure learning is an important and meaningful task in natural language processing. the extracted dialogue structure and process can help analyze human dialogue, and play a vital role in the design and evaluation of dialogue systems. the traditional dialogue system requires experts to manually design the dialogue structure, which is very costly. but through unsupervised dialogue structure learning, dialogue structure can be automatically obtained, reducing the cost of developers constructing dialogue process. the learned dialogue structure can be used to promote the dialogue generation of the downstream task system, and improve the logic and consistency of the dialogue robot's reply.in this paper, we propose a bert-based unsupervised dialogue structure learning algorithm dsbert (dialogue structure bert). different from the previous sota models vrnn and svrnn, we combine bert and autoencoder, which can effectively combine context information. in order to better prevent the model from falling into the local optimal solution and make the dialogue state distribution more uniform and reasonable, we also propose three balanced loss functions that can be used for dialogue structure learning. experimental results show that dsbert can generate a dialogue structure closer to the real structure, can distinguish sentences with different semantics and map them to different hidden states.",,2021-11-08,,"['bingkun chen', 'shaobing dai', 'shenghua zheng', 'lei liao', 'yang li']"
2111.04941,solving pde-constrained control problems using operator learning,math.oc cs.ai cs.lg cs.na math.na physics.comp-ph,"the modeling and control of complex physical dynamics are essential in real-world problems. we propose a novel framework that is generally applicable to solving pde-constrained optimal control problems by introducing surrogate models for pde solution operators with special regularizers. the procedure of the proposed framework is divided into two phases: solution operator learning for pde constraints (phase 1) and searching for optimal control (phase 2). once the surrogate model is trained in phase 1, the optimal control can be inferred in phase 2 without intensive computations. our framework can be applied to both data-driven and data-free cases. we demonstrate the successful application of our method to various optimal control problems for different control variables with diverse pde constraints from the poisson equation to burgers' equation.",,2021-11-08,,"['rakhoon hwang', 'jae yong lee', 'jin young shin', 'hyung ju hwang']"
2111.04949,how to train your neural network: a comparative evaluation,cs.lg cs.ai cs.dc,"the field of deep learning has witnessed a remarkable shift towards extremely compute- and memory-intensive neural networks. these newer larger models have enabled researchers to advance state-of-the-art tools across a variety of fields. this phenomenon has spurred the development of algorithms for distributed training of neural networks over a larger number of hardware accelerators. in this paper, we discuss and compare current state-of-the-art frameworks for large scale distributed deep learning. first, we survey current practices in distributed learning and identify the different types of parallelism used. then, we present empirical results comparing their performance on large image and language training tasks. additionally, we address their statistical efficiency and memory consumption behavior. based on our results, we discuss algorithmic and implementation portions of each framework which hinder performance.",,2021-11-08,,"['shu-huai lin', 'daniel nichols', 'siddharth singh', 'abhinav bhatele']"
2111.04951,american hate crime trends prediction with event extraction,cs.cl cs.ai econ.gn q-fin.ec stat.ap,"social media platforms may provide potential space for discourses that contain hate speech, and even worse, can act as a propagation mechanism for hate crimes. the fbi's uniform crime reporting (ucr) program collects hate crime data and releases statistic report yearly. these statistics provide information in determining national hate crime trends. the statistics can also provide valuable holistic and strategic insight for law enforcement agencies or justify lawmakers for specific legislation. however, the reports are mostly released next year and lag behind many immediate needs. recent research mainly focuses on hate speech detection in social media text or empirical studies on the impact of a confirmed crime. this paper proposes a framework that first utilizes text mining techniques to extract hate crime events from new york times news, then uses the results to facilitate predicting american national-level and state-level hate crime trends. experimental results show that our method can significantly enhance the prediction performance compared with time series or regression methods without event-related factors. our framework broadens the methods of national-level and state-level hate crime trends prediction.",,2021-11-08,,"['songqiao han', 'hailiang huang', 'jiangwei liu', 'shengsheng xiao']"
2111.04983,dynamic parameterized network for ctr prediction,cs.ir cs.ai,"learning to capture feature relations effectively and efficiently is essential in click-through rate (ctr) prediction of modern recommendation systems. most existing ctr prediction methods model such relations either through tedious manually-designed low-order interactions or through inflexible and inefficient high-order interactions, which both require extra dnn modules for implicit interaction modeling. in this paper, we proposed a novel plug-in operation, dynamic parameterized operation (dpo), to learn both explicit and implicit interaction instance-wisely. we showed that the introduction of dpo into dnn modules and attention modules can respectively benefit two main tasks in ctr prediction, enhancing the adaptiveness of feature-based modeling and improving user behavior modeling with the instance-wise locality. our dynamic parameterized networks significantly outperforms state-of-the-art methods in the offline experiments on the public dataset and real-world production dataset, together with an online a/b test. furthermore, the proposed dynamic parameterized networks has been deployed in the ranking system of one of the world's largest e-commerce companies, serving the main traffic of hundreds of millions of active users.",,2021-11-09,,"['jian zhu', 'congcong liu', 'pei wang', 'xiwei zhao', 'guangpeng chen', 'junsheng jin', 'changping peng', 'zhangang lin', 'jingping shao']"
2111.04988,ultra-low power keyword spotting at the edge,cs.sd cs.ai eess.as,"keyword spotting (kws) has become an indispensable part of many intelligent devices surrounding us, as audio is one of the most efficient ways of interacting with these devices. the accuracy and performance of kws solutions have been the main focus of the researchers, and thanks to deep learning, substantial progress has been made in this domain. however, as the use of kws spreads into iot devices, energy efficiency becomes a very critical requirement besides the performance. we believe kws solutions that would seek power optimization both in the hardware and the neural network (nn) model architecture are advantageous over many solutions in the literature where mostly the architecture side of the problem is considered. in this work, we designed an optimized kws cnn model by considering end-to-end energy efficiency for the deployment at max78000, an ultra-low-power cnn accelerator. with the combined hardware and model optimization approach, we achieve 96.3\% accuracy for 12 classes while only consuming 251 uj per inference. we compare our results with other small-footprint neural network-based kws solutions in the literature. additionally, we share the energy consumption of our model in power-optimized arm cortex-m4f to depict the effectiveness of the chosen hardware for the sake of clarity.",,2021-11-09,,"['mehmet gorkem ulkar', 'osman erman okman']"
2111.04997,learning numerical action models from noisy input data,cs.ai,"this paper presents the planminer-n algorithm, a domain learning technique based on the planminer domain learning algorithm. the algorithm presented here improves the learning capabilities of planminer when using noisy data as input. the planminer algorithm is able to infer arithmetic and logical expressions to learn numerical planning domains from the input data, but it was designed to work under situations of incompleteness making it unreliable when facing noisy input data. in this paper, we propose a series of enhancements to the learning process of planminer to expand its capabilities to learn from noisy data. these methods preprocess the input data by detecting noise and filtering it and study the learned action models learned to find erroneous preconditions/effects in them. the methods proposed in this paper were tested using a set of domains from the international planning competition (ipc). the results obtained indicate that planminer-n improves the performance of planminer greatly when facing noisy input data.",,2021-11-09,,"['josé á. segura-muros', 'juan fernández-olivares', 'raúl pérez']"
2111.05002,phantom: a high-performance computational core for sparse convolutional   neural networks,cs.ar cs.ai,"sparse convolutional neural networks (cnns) have gained significant traction over the past few years as sparse cnns can drastically decrease the model size and computations, if exploited befittingly, as compared to their dense counterparts. sparse cnns often introduce variations in the layer shapes and sizes, which can prevent dense accelerators from performing well on sparse cnn models. recently proposed sparse accelerators like scnn, eyeriss v2, and sparten, actively exploit the two-sided or full sparsity, that is, sparsity in both weights and activations, for performance gains. these accelerators, however, either have inefficient micro-architecture, which limits their performance, have no support for non-unit stride convolutions and fully-connected (fc) layers, or suffer massively from systematic load imbalance. to circumvent these issues and support both sparse and dense models, we propose phantom, a multi-threaded, dynamic, and flexible neural computational core. phantom uses sparse binary mask representation to actively lookahead into sparse computations, and dynamically schedule its computational threads to maximize the thread utilization and throughput. we also generate a two-dimensional (2d) mesh architecture of phantom neural computational cores, which we refer to as phantom-2d accelerator, and propose a novel dataflow that supports all layers of a cnn, including unit and non-unit stride convolutions, and fc layers. in addition, phantom-2d uses a two-level load balancing strategy to minimize the computational idling, thereby, further improving the hardware utilization. to show support for different types of layers, we evaluate the performance of the phantom architecture on vgg16 and mobilenet. our simulations show that the phantom-2d accelerator attains a performance gain of 12x, 4.1x, 1.98x, and 2.36x, over dense architectures, scnn, sparten, and eyeriss v2, respectively.",,2021-11-09,,"['mahmood azhar qureshi', 'arslan munir']"
2111.05008,misspecified gaussian process bandit optimization,cs.lg cs.ai stat.ml,"we consider the problem of optimizing a black-box function based on noisy bandit feedback. kernelized bandit algorithms have shown strong empirical and theoretical performance for this problem. they heavily rely on the assumption that the model is well-specified, however, and can fail without it. instead, we introduce a \emph{misspecified} kernelized bandit setting where the unknown function can be $\epsilon$--uniformly approximated by a function with a bounded norm in some reproducing kernel hilbert space (rkhs). we design efficient and practical algorithms whose performance degrades minimally in the presence of model misspecification. specifically, we present two algorithms based on gaussian process (gp) methods: an optimistic ec-gp-ucb algorithm that requires knowing the misspecification error, and phased gp uncertainty sampling, an elimination-type algorithm that can adapt to unknown model misspecification. we provide upper bounds on their cumulative regret in terms of $\epsilon$, the time horizon, and the underlying kernel, and we show that our algorithm achieves optimal dependence on $\epsilon$ with no prior knowledge of misspecification. in addition, in a stochastic contextual setting, we show that ec-gp-ucb can be effectively combined with the regret bound balancing strategy and attain similar regret bounds despite not knowing $\epsilon$.",,2021-11-09,,"['ilija bogunovic', 'andreas krause']"
2111.05014,gdca: gan-based single image super resolution with dual discriminators   and channel attention,eess.iv cs.ai cs.cv,single image super-resolution (sisr) is a very active research field. this paper addresses sisr by using a gan-based approach with dual discriminators and incorporating it with an attention mechanism. the experimental results show that gdca can generate sharper and high pleasing images compare to other conventional methods.,,2021-11-09,,"['thanh nguyen', 'hieu hoang', 'chang d. yoo']"
2111.05017,an effective hybrid search algorithm for the multiple traveling   repairman problem with profits,cs.ne cs.ai,"as an extension of the traveling repairman problem with profits, the multiple traveling repairman problem with profits consists of multiple repairmen who visit a subset of all customers to maximize the revenues collected through the visited customers. to solve this challenging problem, an effective hybrid search algorithm based on the memetic algorithm framework is proposed. it integrates two distinguished features: a dedicated arc-based crossover to generate high-quality offspring solutions and a fast evaluation technique to reduce the complexity of exploring the classical neighborhoods. we show the competitiveness of the algorithm on 470 benchmark instances compared to the leading reference algorithms and report new best records for 137 instances as well as equal best results for other 330 instances. we investigate the importance of the key search components for the algorithm.",,2021-11-09,,"['jintong ren', 'jin-kao hao', 'feng wu', 'zhang-hua fu']"
2111.05063,tightening the approximation error of adversarial risk with auto loss   function search,cs.lg cs.ai,"numerous studies have demonstrated that deep neural networks are easily misled by adversarial examples. effectively evaluating the adversarial robustness of a model is important for its deployment in practical applications. currently, a common type of evaluation is to approximate the adversarial risk of a model as a robustness indicator by constructing malicious instances and executing attacks. unfortunately, there is an error (gap) between the approximate value and the true value. previous studies manually design attack methods to achieve a smaller error, which is inefficient and may miss a better solution. in this paper, we establish the tightening of the approximation error as an optimization problem and try to solve it with an algorithm. more specifically, we first analyze that replacing the non-convex and discontinuous 0-1 loss with a surrogate loss, a necessary compromise in calculating the approximation, is one of the main reasons for the error. then we propose autoloss-ar, the first method for searching loss functions for tightening the approximation error of adversarial risk. extensive experiments are conducted in multiple settings. the results demonstrate the effectiveness of the proposed method: the best-discovered loss functions outperform the handcrafted baseline by 0.9%-2.9% and 0.7%-2.0% on mnist and cifar-10, respectively. besides, we also verify that the searched losses can be transferred to other settings and explore why they are better than the baseline by visualizing the local loss landscape.",,2021-11-09,,"['pengfei xia', 'ziqiang li', 'bin li']"
2111.05068,neural news recommendation with event extraction,cs.ir cs.ai cs.cl,"a key challenge of online news recommendation is to help users find articles they are interested in. traditional news recommendation methods usually use single news information, which is insufficient to encode news and user representation. recent research uses multiple channel news information, e.g., title, category, and body, to enhance news and user representation. however, these methods only use various attention mechanisms to fuse multi-view embeddings without considering deep digging higher-level information contained in the context. these methods encode news content on the word level and jointly train the attention parameters in the recommendation network, leading to more corpora being required to train the model. we propose an event extraction-based news recommendation (eenr) framework to overcome these shortcomings, utilizing event extraction to abstract higher-level information. eenr also uses a two-stage strategy to reduce parameters in subsequent parts of the recommendation network. we train the event extraction module by external corpora in the first stage and apply the trained model to the news recommendation dataset to predict event-level information, including event types, roles, and arguments, in the second stage. then we fuse multiple channel information, including event information, news title, and category, to encode news and users. extensive experiments on a real-world dataset show that our eenr method can effectively improve the performance of news recommendations. finally, we also explore the reasonability of utilizing higher abstract level information to substitute news body content.",,2021-11-09,,"['songqiao han', 'hailiang huang', 'jiangwei liu']"
2111.05070,almost optimal universal lower bound for learning causal dags with   atomic interventions,cs.lg cs.ai cs.dm stat.me stat.ml,"a well-studied challenge that arises in the structure learning problem of causal directed acyclic graphs (dag) is that using observational data, one can only learn the graph up to a ""markov equivalence class"" (mec). the remaining undirected edges have to be oriented using interventions, which can be very expensive to perform in applications. thus, the problem of minimizing the number of interventions needed to fully orient the mec has received a lot of recent attention, and is also the focus of this work. we prove two main results. the first is a new universal lower bound on the number of atomic interventions that any algorithm (whether active or passive) would need to perform in order to orient a given mec. our second result shows that this bound is, in fact, within a factor of two of the size of the smallest set of atomic interventions that can orient the mec. our lower bound is provably better than previously known lower bounds. the proof of our lower bound is based on the new notion of cbsp orderings, which are topological orderings of dags without v-structures and satisfy certain special properties. further, using simulations on synthetic graphs and by giving examples of special graph families, we show that our bound is often significantly better.",,2021-11-09,,"['vibhor porwal', 'piyush srivastava', 'gaurav sinha']"
2111.05071,conformity assessments and post-market monitoring: a guide to the role   of auditing in the proposed european ai regulation,cs.cy cs.ai,"the proposed european artificial intelligence act (aia) is the first attempt to elaborate a general legal framework for ai carried out by any major global economy. as such, the aia is likely to become a point of reference in the larger discourse on how ai systems can (and should) be regulated. in this article, we describe and discuss the two primary enforcement mechanisms proposed in the aia: the conformity assessments that providers of high-risk ai systems are expected to conduct, and the post-market monitoring plans that providers must establish to document the performance of high-risk ai systems throughout their lifetimes. we argue that aia can be interpreted as a proposal to establish a europe-wide ecosystem for conducting ai auditing, albeit in other words. our analysis offers two main contributions. first, by describing the enforcement mechanisms included in the aia in terminology borrowed from existing literature on ai auditing, we help providers of ai systems understand how they can prove adherence to the requirements set out in the aia in practice. second, by examining the aia from an auditing perspective, we seek to provide transferable lessons from previous research about how to refine further the regulatory approach outlined in the aia. we conclude by highlighting seven aspects of the aia where amendments (or simply clarifications) would be helpful. these include, above all, the need to translate vague concepts into verifiable criteria and to strengthen the institutional safeguards concerning conformity assessments based on internal checks.",10.1007/s11023-021-09577-4,2021-11-09,,"['jakob mokander', 'maria axente', 'federico casolari', 'luciano floridi']"
2111.05073,mixacm: mixup-based robustness transfer via distillation of activated   channel maps,cs.lg cs.ai cs.cv,"deep neural networks are susceptible to adversarially crafted, small and imperceptible changes in the natural inputs. the most effective defense mechanism against these examples is adversarial training which constructs adversarial examples during training by iterative maximization of loss. the model is then trained to minimize the loss on these constructed examples. this min-max optimization requires more data, larger capacity models, and additional computing resources. it also degrades the standard generalization performance of a model. can we achieve robustness more efficiently? in this work, we explore this question from the perspective of knowledge transfer. first, we theoretically show the transferability of robustness from an adversarially trained teacher model to a student model with the help of mixup augmentation. second, we propose a novel robustness transfer method called mixup-based activated channel maps (mixacm) transfer. mixacm transfers robustness from a robust teacher to a student by matching activated channel maps generated without expensive adversarial perturbations. finally, extensive experiments on multiple datasets and different learning scenarios show our method can transfer robustness while also improving generalization on natural images.",,2021-11-09,,"['muhammad awais', 'fengwei zhou', 'chuanlong xie', 'jiawei li', 'sung-ho bae', 'zhenguo li']"
2111.05108,"""how does it detect a malicious app?"" explaining the predictions of   ai-based android malware detector",cs.cr cs.ai cs.lg,"ai methods have been proven to yield impressive performance on android malware detection. however, most ai-based methods make predictions of suspicious samples in a black-box manner without transparency on models' inference. the expectation on models' explainability and transparency by cyber security and ai practitioners to assure the trustworthiness increases. in this article, we present a novel model-agnostic explanation method for ai models applied for android malware detection. our proposed method identifies and quantifies the data features relevance to the predictions by two steps: i) data perturbation that generates the synthetic data by manipulating features' values; and ii) optimization of features attribution values to seek significant changes of prediction scores on the perturbed data with minimal feature values changes. the proposed method is validated by three experiments. we firstly demonstrate that our proposed model explanation method can aid in discovering how ai models are evaded by adversarial samples quantitatively. in the following experiments, we compare the explainability and fidelity of our proposed method with state-of-the-arts, respectively.",,2021-11-06,,"['zhi lu', 'vrizlynn l. l. thing']"
2111.05120,a deep learning technique using low sampling rate for residential non   intrusive load monitoring,eess.sp cs.ai cs.lg,"individual device loads and energy consumption feedback is one of the important approaches for pursuing users to save energy in residences. this can help in identifying faulty devices and wasted energy by devices when left on unused. the main challenge is to identity and estimate the energy consumption of individual devices without intrusive sensors on each device. non-intrusive load monitoring (nilm) or energy disaggregation, is a blind source separation problem which requires a system to estimate the electricity usage of individual appliances from the aggregated household energy consumption. in this paper, we propose a novel deep neural network-based approach for performing load disaggregation on low frequency power data obtained from residential households. we combine a series of one-dimensional convolutional neural networks and long short term memory (1d cnn-lstm) to extract features that can identify active appliances and retrieve their power consumption given the aggregated household power value. we used cnns to extract features from main readings in a given time frame and then used those features to classify if a given appliance is active at that time period or not. following that, the extracted features are used to model a generation problem using lstm. we train the lstm to generate the disaggregated energy consumption of a particular appliance. our neural network is capable of generating detailed feedback of demand-side, providing vital insights to the end-user about their electricity consumption. the algorithm was designed for low power offline devices such as esp32. empirical calculations show that our model outperforms the state-of-the-art on the reference energy disaggregation dataset (redd).",,2021-11-07,,"['ronak aghera', 'sahil chilana', 'vishal garg', 'raghunath reddy']"
2111.05128,"losses, dissonances, and distortions",cs.lg cs.ai cs.hc cs.sd eess.as,"in this paper i present a study in using the losses and gradients obtained during the training of a simple function approximator as a mechanism for creating musical dissonance and visual distortion in a solo piano performance setting. these dissonances and distortions become part of an artistic performance not just by affecting the visualizations, but also by affecting the artistic musical performance. the system is designed such that the performer can in turn affect the training process itself, thereby creating a closed feedback loop between two processes: the training of a machine learning model and the performance of an improvised piano piece.",,2021-11-08,,['pablo samuel castro']
2111.05157,self-checking logical agents,cs.ai,"this paper presents a comprehensive framework for run-time self-checking of logical agents, by means of temporal axioms to be dynamically checked. these axioms are specified by using an agent-oriented interval temporal logic defined to this purpose. we define syntax, semantics and pragmatics for this new logic, specifically tailored for application to agents. in the resulting framework, we encompass and extend our past work.",,2021-11-09,,['stefania costantini']
2111.05191,does thermal data make the detection systems more reliable?,cs.cv cs.ai cs.lg eess.iv,"deep learning-based detection networks have made remarkable progress in autonomous driving systems (ads). ads should have reliable performance across a variety of ambient lighting and adverse weather conditions. however, luminance degradation and visual obstructions (such as glare, fog) result in poor quality images by the visual camera which leads to performance decline. to overcome these challenges, we explore the idea of leveraging a different data modality that is disparate yet complementary to the visual data. we propose a comprehensive detection system based on a multimodal-collaborative framework that learns from both rgb (from visual cameras) and thermal (from infrared cameras) data. this framework trains two networks collaboratively and provides flexibility in learning optimal features of its own modality while also incorporating the complementary knowledge of the other. our extensive empirical results show that while the improvement in accuracy is nominal, the value lies in challenging and extremely difficult edge cases which is crucial in safety-critical applications such as ad. we provide a holistic view of both merits and limitations of using a thermal imaging system in detection.",,2021-11-09,,"['shruthi gowda', 'bahram zonooz', 'elahe arani']"
2111.05204,"reason first, then respond: modular generation for knowledge-infused   dialogue",cs.cl cs.ai cs.lg,"large language models can produce fluent dialogue but often hallucinate factual inaccuracies. while retrieval-augmented models help alleviate this issue, they still face a difficult challenge of both reasoning to provide correct knowledge and generating conversation simultaneously. in this work, we propose a modular model, knowledge to response (k2r), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps. k2r first generates a knowledge sequence, given a dialogue context, as an intermediate step. after this ""reasoning step"", the model then attends to its own generated knowledge sequence, as well as the dialogue context, to produce a final response. in detailed experiments, we find that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity. in particular, it can be used to fuse qa and dialogue systems together to enable dialogue agents to give knowledgeable answers, or qa models to give conversational responses in a zero-shot setting.",,2021-11-09,,"['leonard adolphs', 'kurt shuster', 'jack urbanek', 'arthur szlam', 'jason weston']"
2111.05251,learning perceptual concepts by bootstrapping from human queries,cs.ro cs.ai cs.hc cs.lg,"robots need to be able to learn concepts from their users in order to adapt their capabilities to each user's unique task. but when the robot operates on high-dimensional inputs, like images or point clouds, this is impractical: the robot needs an unrealistic amount of human effort to learn the new concept. to address this challenge, we propose a new approach whereby the robot learns a low-dimensional variant of the concept and uses it to generate a larger data set for learning the concept in the high-dimensional space. this lets it take advantage of semantically meaningful privileged information only accessible at training time, like object poses and bounding boxes, that allows for richer human interaction to speed up learning. we evaluate our approach by learning prepositional concepts that describe object state or multi-object relationships, like above, near, or aligned, which are key to user specification of task goals and execution constraints for robots. using a simulated human, we show that our approach improves sample complexity when compared to learning concepts directly in the high-dimensional space. we also demonstrate the utility of the learned concepts in motion planning tasks on a 7-dof franka panda robot.",,2021-11-09,,"['andreea bobu', 'chris paxton', 'wei yang', 'balakumar sundaralingam', 'yu-wei chao', 'maya cakmak', 'dieter fox']"
2111.05264,unsupervised learning for identifying high eigenvector centrality nodes:   a graph neural network approach,cs.si cs.ai cs.lg,"the existing methods to calculate the eigenvector centrality(ec) tend to not be robust enough for determination of ec in low time complexity or not well-scalable for large networks, hence rendering them practically unreliable/ computationally expensive. so, it is of the essence to develop a method that is scalable in low computational time. hence, we propose a deep learning model for the identification of nodes with high eigenvector centrality. there have been a few previous works in identifying the high ranked nodes with supervised learning methods, but in real-world cases, the graphs are not labelled and hence deployment of supervised learning methods becomes a hazard and its usage becomes impractical. so, we devise cul(centrality with unsupervised learning) method to learn the relative ec scores in a network in an unsupervised manner. to achieve this, we develop an encoder-decoder based framework that maps the nodes to their respective estimated ec scores. extensive experiments were conducted on different synthetic and real-world networks. we compared cul against a baseline supervised method for ec estimation similar to some of the past works. it was observed that even with training on a minuscule number of training datasets, cul delivers a relatively better accuracy score when identifying the higher ranked nodes than its supervised counterpart. we also show that cul is much faster and has a smaller runtime than the conventional baseline method for ec computation. the code is available at https://github.com/codexhammer/cul.",,2021-11-08,,"['appan rakaraddi', 'mahardhika pratama']"
2111.05297,sliced recursive transformer,cs.cv cs.ai cs.lg,"we present a neat yet effective recursive operation on vision transformers that can improve parameter utilization without involving additional parameters. this is achieved by sharing weights across depth of transformer networks. the proposed method can obtain a substantial gain (~2%) simply using na\""ive recursive operation, requires no special or sophisticated knowledge for designing principles of networks, and introduces minimum computational overhead to the training procedure. to reduce the additional computation caused by recursive operation while maintaining the superior accuracy, we propose an approximating method through multiple sliced group self-attentions across recursive layers which can reduce the cost consumption by 10~30% with minimal performance loss. we call our model sliced recursive transformer (sret), which is compatible with a broad range of other designs for efficient vision transformers. our best model establishes significant improvement on imagenet over state-of-the-art methods while containing fewer parameters. the proposed sliced recursive operation allows us to build a transformer with more than 100 or even 1000 layers effortlessly under a still small size (13~15m), to avoid difficulties in optimization when the model size is too large. the flexible scalability has shown great potential for scaling up and constructing extremely deep and large dimensionality vision transformers. our code and models are available at https://github.com/szq0214/sret.",,2021-11-09,,"['zhiqiang shen', 'zechun liu', 'eric xing']"
2111.05299,can information flows suggest targets for interventions in neural   circuits?,cs.it cs.ai cs.lg math.it q-bio.nc stat.ml,"motivated by neuroscientific and clinical applications, we empirically examine whether observational measures of information flow can suggest interventions. we do so by performing experiments on artificial neural networks in the context of fairness in machine learning, where the goal is to induce fairness in the system through interventions. using our recently developed $m$-information flow framework, we measure the flow of information about the true label (responsible for accuracy, and hence desirable), and separately, the flow of information about a protected attribute (responsible for bias, and hence undesirable) on the edges of a trained neural network. we then compare the flow magnitudes against the effect of intervening on those edges by pruning. we show that pruning edges that carry larger information flows about the protected attribute reduces bias at the output to a greater extent. this demonstrates that $m$-information flow can meaningfully suggest targets for interventions, answering the title's question in the affirmative. we also evaluate bias-accuracy tradeoffs for different intervention strategies, to analyze how one might use estimates of desirable and undesirable information flows (here, accuracy and bias flows) to inform interventions that preserve the former while reducing the latter.",,2021-11-09,,"['praveen venkatesh', 'sanghamitra dutta', 'neil mehta', 'pulkit grover']"
2111.05318,a differentiable recipe for learning visual non-prehensile planar   manipulation,cs.ro cs.ai,"specifying tasks with videos is a powerful technique towards acquiring novel and general robot skills. however, reasoning over mechanics and dexterous interactions can make it challenging to scale learning contact-rich manipulation. in this work, we focus on the problem of visual non-prehensile planar manipulation: given a video of an object in planar motion, find contact-aware robot actions that reproduce the same object motion. we propose a novel architecture, differentiable learning for manipulation (\ours), that combines video decoding neural models with priors from contact mechanics by leveraging differentiable optimization and finite difference based simulation. through extensive simulated experiments, we investigate the interplay between traditional model-based techniques and modern deep learning approaches. we find that our modular and fully differentiable architecture performs better than learning-only methods on unseen objects and motions. \url{https://github.com/baceituno/dlm}.",,2021-11-09,,"['bernardo aceituno', 'alberto rodriguez', 'shubham tulsiani', 'abhinav gupta', 'mustafa mukadam']"
2111.05321,turing-universal learners with optimal scaling laws,cs.lg cs.ai cs.cc math.st stat.ml stat.th,"for a given distribution, learning algorithm, and performance metric, the rate of convergence (or data-scaling law) is the asymptotic behavior of the algorithm's test performance as a function of number of train samples. many learning methods in both theory and practice have power-law rates, i.e. performance scales as $n^{-\alpha}$ for some $\alpha > 0$. moreover, both theoreticians and practitioners are concerned with improving the rates of their learning algorithms under settings of interest. we observe the existence of a ""universal learner"", which achieves the best possible distribution-dependent asymptotic rate among all learning algorithms within a specified runtime (e.g. $o(n^2)$), while incurring only polylogarithmic slowdown over this runtime. this algorithm is uniform, and does not depend on the distribution, and yet achieves best-possible rates for all distributions. the construction itself is a simple extension of levin's universal search (levin, 1973). and much like universal search, the universal learner is not at all practical, and is primarily of theoretical and philosophical interest.",,2021-11-09,,['preetum nakkiran']
2111.05364,"towards tractable mathematical reasoning: challenges, strategies, and   opportunities for solving math word problems",cs.cl cs.ai,"mathematical reasoning would be one of the next frontiers for artificial intelligence to make significant progress. the ongoing surge to solve math word problems (mwps) and hence achieve better mathematical reasoning ability would continue to be a key line of research in the coming time. we inspect non-neural and neural methods to solve math word problems narrated in a natural language. we also highlight the ability of these methods to be generalizable, mathematically reasonable, interpretable, and explainable. neural approaches dominate the current state of the art, and we survey them highlighting three strategies to mwp solving: (1) direct answer generation, (2) expression tree generation for inferring answers, and (3) template retrieval for answer computation. moreover, we discuss technological approaches, review the evolution of intuitive design choices to solve mwps, and examine them for mathematical reasoning ability. we finally identify several gaps that warrant the need for external knowledge and knowledge-infused learning, among several other opportunities in solving mwps.",,2021-10-29,,"['keyur faldu', 'amit sheth', 'prashant kikani', 'manas gaur', 'aditi avasthi']"
2111.05384,"datawords: getting contrarian with text, structured data and   explanations",cs.lg cs.ai cs.cl,"our goal is to build classification models using a combination of free-text and structured data. to do this, we represent structured data by text sentences, datawords, so that similar data items are mapped into the same sentence. this permits modeling a mixture of text and structured data by using only text-modeling algorithms. several examples illustrate that it is possible to improve text classification performance by first running extraction tools (named entity recognition), then converting the output to datawords, and adding the datawords to the original text -- before model building and classification. this approach also allows us to produce explanations for inferences in terms of both free text and structured data.",,2021-11-09,,"['stephen i. gallant', 'mirza nasir hossain']"
2111.05391,statistical perspectives on reliability of artificial intelligence   systems,cs.se cs.ai stat.ap,"artificial intelligence (ai) systems have become increasingly popular in many areas. nevertheless, ai technologies are still in their developing stages, and many issues need to be addressed. among those, the reliability of ai systems needs to be demonstrated so that the ai systems can be used with confidence by the general public. in this paper, we provide statistical perspectives on the reliability of ai systems. different from other considerations, the reliability of ai systems focuses on the time dimension. that is, the system can perform its designed functionality for the intended period. we introduce a so-called smart statistical framework for ai reliability research, which includes five components: structure of the system, metrics of reliability, analysis of failure causes, reliability assessment, and test planning. we review traditional methods in reliability data analysis and software reliability, and discuss how those existing methods can be transformed for reliability modeling and assessment of ai systems. we also describe recent developments in modeling and analysis of ai reliability and outline statistical research challenges in this area, including out-of-distribution detection, the effect of the training set, adversarial attacks, model accuracy, and uncertainty quantification, and discuss how those topics can be related to ai reliability, with illustrative examples. finally, we discuss data collection and test planning for ai reliability assessment and how to improve system designs for higher ai reliability. the paper closes with some concluding remarks.",,2021-11-09,,"['yili hong', 'jiayi lian', 'li xu', 'jie min', 'yueyao wang', 'laura j. freeman', 'xinwei deng']"
2111.05409,pipeline for 3d reconstruction of the human body from ar/vr headset   mounted egocentric cameras,cs.cv cs.ai,"in this paper, we propose a novel pipeline for the 3d reconstruction of the full body from egocentric viewpoints. 3-d reconstruction of the human body from egocentric viewpoints is a challenging task as the view is skewed and the body parts farther from the cameras are occluded. one such example is the view from cameras installed below vr headsets. to achieve this task, we first make use of conditional gans to translate the egocentric views to full body third-person views. this increases the comprehensibility of the image and caters to occlusions. the generated third-person view is further sent through the 3d reconstruction module that generates a 3d mesh of the body. we also train a network that can take the third person full-body view of the subject and generate the texture maps for applying on the mesh. the generated mesh has fairly realistic body proportions and is fully rigged allowing for further applications such as real-time animation and pose transfer in games. this approach can be key to a new domain of mobile human telepresence.",,2021-11-09,,"['shivam grover', 'kshitij sidana', 'vanita jain']"
2111.05410,convolutional neural network dynamics: a graph perspective,cs.lg cs.ai,"the success of neural networks (nns) in a wide range of applications has led to increased interest in understanding the underlying learning dynamics of these models. in this paper, we go beyond mere descriptions of the learning dynamics by taking a graph perspective and investigating the relationship between the graph structure of nns and their performance. specifically, we propose (1) representing the neural network learning process as a time-evolving graph (i.e., a series of static graph snapshots over epochs), (2) capturing the structural changes of the nn during the training phase in a simple temporal summary, and (3) leveraging the structural summary to predict the accuracy of the underlying nn in a classification or regression task. for the dynamic graph representation of nns, we explore structural representations for fully-connected and convolutional layers, which are key components of powerful nn models. our analysis shows that a simple summary of graph statistics, such as weighted degree and eigenvector centrality, over just a few epochs can be used to accurately predict the performance of nns. for example, a weighted degree-based summary of the time-evolving graph that is constructed based on 5 training epochs of the lenet architecture achieves classification accuracy of over 93%. our findings are consistent for different nn architectures, including lenet, vgg, alexnet and resnet.",,2021-11-09,,"['fatemeh vahedian', 'ruiyu li', 'puja trivedi', 'di jin', 'danai koutra']"
2111.05431,multi-task prediction of clinical outcomes in the intensive care unit   using flexible multimodal transformers,cs.lg cs.ai,"recent deep learning research based on transformer model architectures has demonstrated state-of-the-art performance across a variety of domains and tasks, mostly within the computer vision and natural language processing domains. while some recent studies have implemented transformers for clinical tasks using electronic health records data, they are limited in scope, flexibility, and comprehensiveness. in this study, we propose a flexible transformer-based ehr embedding pipeline and predictive model framework that introduces several novel modifications of existing workflows that capitalize on data attributes unique to the healthcare domain. we showcase the feasibility of our flexible design in a case study in the intensive care unit, where our models accurately predict seven clinical outcomes pertaining to readmission and patient mortality over multiple future time horizons.",,2021-11-09,,"['benjamin shickel', 'patrick j. tighe', 'azra bihorac', 'parisa rashidi']"
2111.05479,spatially and seamlessly hierarchical reinforcement learning for state   space and policy space in autonomous driving,cs.lg cs.ai,"despite advances in hierarchical reinforcement learning, its applications to path planning in autonomous driving on highways are challenging. one reason is that conventional hierarchical reinforcement learning approaches are not amenable to autonomous driving due to its riskiness: the agent must move avoiding multiple obstacles such as other agents that are highly unpredictable, thus safe regions are small, scattered, and changeable over time. to overcome this challenge, we propose a spatially hierarchical reinforcement learning method for state space and policy space. the high-level policy selects not only behavioral sub-policy but also regions to pay mind to in state space and for outline in policy space. subsequently, the low-level policy elaborates the short-term goal position of the agent within the outline of the region selected by the high-level command. the network structure and optimization suggested in our method are as concise as those of single-level methods. experiments on the environment with various shapes of roads showed that our method finds the nearly optimal policies from early episodes, outperforming a baseline hierarchical reinforcement learning method, especially in narrow and complex roads. the resulting trajectories on the roads were similar to those of human strategies on the behavioral planning level.",,2021-11-09,,"['jaehyun kim', 'jaeseung jeong']"
2111.05498,attention approximates sparse distributed memory,cs.lg cs.ai,"while attention has come to be an important mechanism in deep learning, there remains limited intuition for why it works so well. here, we show that transformer attention can be closely related under certain data conditions to kanerva's sparse distributed memory (sdm), a biologically plausible associative memory model. we confirm that these conditions are satisfied in pre-trained gpt2 transformer models. we discuss the implications of the attention-sdm map and provide new computational and biological interpretations of attention.",,2021-11-09,,"['trenton bricken', 'cengiz pehlevan']"
2111.05501,inclusive speaker verification with adaptive thresholding,cs.sd cs.ai cs.lg,"while using a speaker verification (sv) based system in a commercial application, it is important that customers have an inclusive experience irrespective of their gender, age, or ethnicity. in this paper, we analyze the impact of gender and age on sv and find that for a desired common false acceptance rate (far) across different gender and age groups, the false rejection rate (frr) is different for different gender and age groups. to optimize frr for all users for a desired far, we propose a context (e.g. gender, age) adaptive thresholding framework for sv. the context can be available as prior information for many practical applications. we also propose a concatenated gender/age detection model to algorithmically derive the context in absence of such prior information. we experimentally show that our context-adaptive thresholding method is effective in building a more efficient inclusive sv system. specifically, we show that we can reduce frr for specific gender for a desired far on the voxceleb1 test set by using gender-specific thresholds. similar analysis on ogi kids' speech corpus shows that by using an age-specific threshold, we can significantly reduce frr for certain age groups for desired far.",,2021-11-09,,"['navdeep jain', 'hongcheng wang']"
2111.05508,training generative adversarial networks with adaptive composite   gradient,cs.lg cs.ai cs.gt math.ds math.oc,"the wide applications of generative adversarial networks benefit from the successful training methods, guaranteeing that an object function converges to the local minima. nevertheless, designing an efficient and competitive training method is still a challenging task due to the cyclic behaviors of some gradient-based ways and the expensive computational cost of these methods based on the hessian matrix. this paper proposed the adaptive composite gradients (acg) method, linearly convergent in bilinear games under suitable settings. theory and toy-function experiments suggest that our approach can alleviate the cyclic behaviors and converge faster than recently proposed algorithms. significantly, the acg method is not only used to find stable fixed points in bilinear games as well as in general games. the acg method is a novel semi-gradient-free algorithm since it does not need to calculate the gradient of each step, reducing the computational cost of gradient and hessian by utilizing the predictive information in future iterations. we conducted two mixture of gaussians experiments by integrating acg to existing algorithms with linear gans. results show acg is competitive with the previous algorithms. realistic experiments on four prevalent data sets (mnist, fashion-mnist, cifar-10, and celeba) with dcgans show that our acg method outperforms several baselines, which illustrates the superiority and efficacy of our method.",,2021-11-09,,"['huiqing qi', 'fang li', 'shengli tan', 'xiangyun zhang']"
2111.05514,discovering latent representations of relations for interacting systems,cs.ai,"systems whose entities interact with each other are common. in many interacting systems, it is difficult to observe the relations between entities which is the key information for analyzing the system. in recent years, there has been increasing interest in discovering the relationships between entities using graph neural networks. however, existing approaches are difficult to apply if the number of relations is unknown or if the relations are complex. we propose the discovering latent relation (dslr) model, which is flexibly applicable even if the number of relations is unknown or many types of relations exist. the flexibility of our dslr model comes from the design concept of our encoder that represents the relation between entities in a latent space rather than a discrete variable and a decoder that can handle many types of relations. we performed the experiments on synthetic and real-world graph data with various relationships between entities, and compared the qualitative and quantitative results with other approaches. the experiments show that the proposed method is suitable for analyzing dynamic graphs with an unknown number of complex relations.",10.1109/access.2021.3125335,2021-11-09,,"['dohae lee', 'young jin oh', 'in-kwon lee']"
2111.05527,luminous: indoor scene generation for embodied ai challenges,cs.ai,"learning-based methods for training embodied agents typically require a large number of high-quality scenes that contain realistic layouts and support meaningful interactions. however, current simulators for embodied ai (eai) challenges only provide simulated indoor scenes with a limited number of layouts. this paper presents luminous, the first research framework that employs state-of-the-art indoor scene synthesis algorithms to generate large-scale simulated scenes for embodied ai challenges. further, we automatically and quantitatively evaluate the quality of generated indoor scenes via their ability to support complex household tasks. luminous incorporates a novel scene generation algorithm (constrained stochastic scene generation (cssg)), which achieves competitive performance with human-designed scenes. within luminous, the eai task executor, task instruction generation module, and video rendering toolkit can collectively generate a massive multimodal dataset of new scenes for the training and evaluation of embodied ai agents. extensive experimental results demonstrate the effectiveness of the data generated by luminous, enabling the comprehensive assessment of embodied agents on generalization and robustness.",,2021-11-09,,"['yizhou zhao', 'kaixiang lin', 'zhiwei jia', 'qiaozi gao', 'govind thattai', 'jesse thomason', 'gaurav s. sukhatme']"
2111.05528,lightweight machine unlearning in neural network,cs.lg cs.ai,"in recent years, machine learning neural network has penetrated deeply into people's life. as the price of convenience, people's private information also has the risk of disclosure. the ""right to be forgotten"" was introduced in a timely manner, stipulating that individuals have the right to withdraw their consent from personal information processing activities based on their consent. to solve this problem, machine unlearning is proposed, which allows the model to erase all memory of private information. previous studies, including retraining and incremental learning to update models, often take up extra storage space or are difficult to apply to neural networks. our method only needs to make a small perturbation of the weight of the target model and make it iterate in the direction of the model trained with the remaining data subset until the contribution of the unlearning data to the model is completely eliminated. in this paper, experiments on five datasets prove the effectiveness of our method for machine unlearning, and our method is 15 times faster than retraining.",,2021-11-09,,"['kongyang chen', 'yiwen wang', 'yao huang']"
2111.05548,deep attention-guided graph clustering with dual self-supervision,cs.cv cs.ai,"existing deep embedding clustering works only consider the deepest layer to learn a feature embedding and thus fail to well utilize the available discriminative information from cluster assignments, resulting performance limitation. to this end, we propose a novel method, namely deep attention-guided graph clustering with dual self-supervision (dagc). specifically, dagc first utilizes a heterogeneity-wise fusion module to adaptively integrate the features of an auto-encoder and a graph convolutional network in each layer and then uses a scale-wise fusion module to dynamically concatenate the multi-scale features in different layers. such modules are capable of learning a discriminative feature embedding via an attention-based mechanism. in addition, we design a distribution-wise fusion module that leverages cluster assignments to acquire clustering results directly. to better explore the discriminative information from the cluster assignments, we develop a dual self-supervision solution consisting of a soft self-supervision strategy with a triplet kullback-leibler divergence loss and a hard self-supervision strategy with a pseudo supervision loss. extensive experiments validate that our method consistently outperforms state-of-the-art methods on six benchmark datasets. especially, our method improves the ari by more than 18.14% over the best baseline.",,2021-11-10,,"['zhihao peng', 'hui liu', 'yuheng jia', 'junhui hou']"
2111.05578,conversational recommendation: theoretical model and complexity analysis,cs.ai cs.cc cs.ir,"recommender systems are software applications that help users find items of interest in situations of information overload in a personalized way, using knowledge about the needs and preferences of individual users. in conversational recommendation approaches, these needs and preferences are acquired by the system in an interactive, multi-turn dialog. a common approach in the literature to drive such dialogs is to incrementally ask users about their preferences regarding desired and undesired item features or regarding individual items. a central research goal in this context is efficiency, evaluated with respect to the number of required interactions until a satisfying item is found. this is usually accomplished by making inferences about the best next question to ask to the user. today, research on dialog efficiency is almost entirely empirical, aiming to demonstrate, for example, that one strategy for selecting questions is better than another one in a given application. with this work, we complement empirical research with a theoretical, domain-independent model of conversational recommendation. this model, which is designed to cover a range of application scenarios, allows us to investigate the efficiency of conversational approaches in a formal way, in particular with respect to the computational complexity of devising optimal interaction strategies. through such a theoretical analysis we show that finding an efficient conversational strategy is np-hard, and in pspace in general, but for particular kinds of catalogs the upper bound lowers to polylogspace. from a practical point of view, this result implies that catalog characteristics can strongly influence the efficiency of individual conversational strategies and should therefore be considered when designing new strategies. a preliminary empirical analysis on datasets derived from a real-world one aligns with our findings.",,2021-11-10,2021-11-12,"['tommaso di noia', 'francesco donini', 'dietmar jannach', 'fedelucio narducci', 'claudio pomo']"
2111.05628,"machine learning models disclosure from trusted research environments   (tre), challenges and opportunities",cs.cr cs.ai cs.cy,"trusted research environments (tre)s are safe and secure environments in which researchers can access sensitive data. with the growth and diversity of medical data such as electronic health records (ehr), medical imaging and genomic data, there is an increase in the use of artificial intelligence (ai) in general and the subfield of machine learning (ml) in particular in the healthcare domain. this generates the desire to disclose new types of outputs from tres, such as trained machine learning models. although specific guidelines and policies exists for statistical disclosure controls in tres, they do not satisfactorily cover these new types of output request. in this paper, we define some of the challenges around the application and disclosure of machine learning for healthcare within tres. we describe various vulnerabilities the introduction of ai brings to tres. we also provide an introduction to the different types and levels of risks associated with the disclosure of trained ml models. we finally describe the new research opportunities in developing and adapting policies and tools for safely disclosing machine learning outputs from tres.",,2021-11-10,,"['esma mansouri-benssassi', 'simon rogers', 'jim smith', 'felix ritchie', 'emily jefferson', 'university of dundee', 'nhs national services scotland', 'university of the west of england']"
2111.05645,"social fraud detection review: methods, challenges and analysis",cs.lg cs.ai,"social reviews have dominated the web and become a plausible source of product information. people and businesses use such information for decision-making. businesses also make use of social information to spread fake information using a single user, groups of users, or a bot trained to generate fraudulent content. many studies proposed approaches based on user behaviors and review text to address the challenges of fraud detection. to provide an exhaustive literature review, social fraud detection is reviewed using a framework that considers three key components: the review itself, the user who carries out the review, and the item being reviewed. as features are extracted for the component representation, a feature-wise review is provided based on behavioral, text-based features and their combination. with this framework, a comprehensive overview of approaches is presented including supervised, semi-supervised, and unsupervised learning. the supervised approaches for fraud detection are introduced and categorized into two sub-categories; classical, and deep learning. the lack of labeled datasets is explained and potential solutions are suggested. to help new researchers in the area develop a better understanding, a topic analysis and an overview of future directions is provided in each step of the proposed systematic framework.",,2021-11-10,,"['saeedreza shehnepoor', 'roberto togneri', 'wei liu', 'mohammed bennamoun']"
2111.05685,efficient neural network training via forward and backward propagation   sparsification,cs.lg cs.ai cs.cv,"sparse training is a natural idea to accelerate the training speed of deep neural networks and save the memory usage, especially since large modern neural networks are significantly over-parameterized. however, most of the existing methods cannot achieve this goal in practice because the chain rule based gradient (w.r.t. structure parameters) estimators adopted by previous methods require dense computation at least in the backward propagation step. this paper solves this problem by proposing an efficient sparse training method with completely sparse forward and backward passes. we first formulate the training process as a continuous minimization problem under global sparsity constraint. we then separate the optimization process into two steps, corresponding to weight update and structure parameter update. for the former step, we use the conventional chain rule, which can be sparse via exploiting the sparse structure. for the latter step, instead of using the chain rule based gradient estimators as in existing methods, we propose a variance reduced policy gradient estimator, which only requires two forward passes without backward propagation, thus achieving completely sparse training. we prove that the variance of our gradient estimator is bounded. extensive experimental results on real-world datasets demonstrate that compared to previous methods, our algorithm is much more effective in accelerating the training process, up to an order of magnitude faster.",,2021-11-10,,"['xiao zhou', 'weizhong zhang', 'zonghao chen', 'shizhe diao', 'tong zhang']"
2111.05691,hasa-net: a non-intrusive hearing-aid speech assessment network,eess.as cs.ai cs.sd,"without the need of a clean reference, non-intrusive speech assessment methods have caught great attention for objective evaluations. recently, deep neural network (dnn) models have been applied to build non-intrusive speech assessment approaches and confirmed to provide promising performance. however, most dnn-based approaches are designed for normal-hearing listeners without considering hearing-loss factors. in this study, we propose a dnn-based hearing aid speech assessment network (hasa-net), formed by a bidirectional long short-term memory (blstm) model, to predict speech quality and intelligibility scores simultaneously according to input speech signals and specified hearing-loss patterns. to the best of our knowledge, hasa-net is the first work to incorporate quality and intelligibility assessments utilizing a unified dnn-based non-intrusive model for hearing aids. experimental results show that the predicted speech quality and intelligibility scores of hasa-net are highly correlated to two well-known intrusive hearing-aid evaluation metrics, hearing aid speech quality index (hasqi) and hearing aid speech perception index (haspi), respectively.",,2021-11-10,,"['hsin-tien chiang', 'yi-chiao wu', 'cheng yu', 'tomoki toda', 'hsin-min wang', 'yih-chun hu', 'yu tsao']"
2111.05694,lsp : acceleration and regularization of graph neural networks via   locality sensitive pruning of graphs,cs.lg cs.ai,"graph neural networks (gnns) have emerged as highly successful tools for graph-related tasks. however, real-world problems involve very large graphs, and the compute resources needed to fit gnns to those problems grow rapidly. moreover, the noisy nature and size of real-world graphs cause gnns to over-fit if not regularized properly. surprisingly, recent works show that large graphs often involve many redundant components that can be removed without compromising the performance too much. this includes node or edge removals during inference through gnns layers or as a pre-processing step that sparsifies the input graph. this intriguing phenomenon enables the development of state-of-the-art gnns that are both efficient and accurate. in this paper, we take a further step towards demystifying this phenomenon and propose a systematic method called locality-sensitive pruning (lsp) for graph pruning based on locality-sensitive hashing. we aim to sparsify a graph so that similar local environments of the original graph result in similar environments in the resulting sparsified graph, which is an essential feature for graph-related tasks. to justify the application of pruning based on local graph properties, we exemplify the advantage of applying pruning based on locality properties over other pruning strategies in various scenarios. extensive experiments on synthetic and real-world datasets demonstrate the superiority of lsp, which removes a significant amount of edges from large graphs without compromising the performance, accompanied by a considerable acceleration.",,2021-11-10,,"['eitan kosman', 'joel oren', 'dotan di castro']"
2111.05711,counterfactual explanations for models of code,cs.se cs.ai cs.lg,"machine learning (ml) models play an increasingly prevalent role in many software engineering tasks. however, because most models are now powered by opaque deep neural networks, it can be difficult for developers to understand why the model came to a certain conclusion and how to act upon the model's prediction. motivated by this problem, this paper explores counterfactual explanations for models of source code. such counterfactual explanations constitute minimal changes to the source code under which the model ""changes its mind"". we integrate counterfactual explanation generation to models of source code in a real-world setting. we describe considerations that impact both the ability to find realistic and plausible counterfactual explanations, as well as the usefulness of such explanation to the user of the model. in a series of experiments we investigate the efficacy of our approach on three different models, each based on a bert-like architecture operating over source code.",,2021-11-10,,"['jürgen cito', 'isil dillig', 'vijayaraghavan murali', 'satish chandra']"
2111.05721,critical sentence identification in legal cases using multi-class   classification,cs.cl cs.ai cs.lg,"inherently, the legal domain contains a vast amount of data in text format. therefore it requires the application of natural language processing (nlp) to cater to the analytically demanding needs of the domain. the advancement of nlp is spreading through various domains, such as the legal domain, in forms of practical applications and academic research. identifying critical sentences, facts and arguments in a legal case is a tedious task for legal professionals. in this research we explore the usage of sentence embeddings for multi-class classification to identify critical sentences in a legal case, in the perspective of the main parties present in the case. in addition, a task-specific loss function is defined in order to improve the accuracy restricted by the straightforward use of categorical cross entropy loss.",,2021-11-10,2021-11-14,"['sahan jayasinghe', 'lakith rambukkanage', 'ashan silva', 'nisansa de silva', 'amal shehan perera']"
2111.05754,prune once for all: sparse pre-trained language models,cs.cl cs.ai cs.lg,"transformer-based language models are applied to a wide range of applications in natural language processing. however, they are inefficient and difficult to deploy. in recent years, many compression algorithms have been proposed to increase the implementation efficiency of large transformer-based models on target hardware. in this work we present a new method for training sparse pre-trained transformer language models by integrating weight pruning and model distillation. these sparse pre-trained models can be used to transfer learning for a wide range of tasks while maintaining their sparsity pattern. we demonstrate our method with three known architectures to create sparse pre-trained bert-base, bert-large and distilbert. we show how the compressed sparse pre-trained models we trained transfer their knowledge to five different downstream natural language tasks with minimal accuracy loss. moreover, we show how to further compress the sparse models' weights to 8bit precision using quantization-aware training. for example, with our sparse pre-trained bert-large fine-tuned on squadv1.1 and quantized to 8bit we achieve a compression ratio of $40$x for the encoder with less than $1\%$ accuracy loss. to the best of our knowledge, our results show the best compression-to-accuracy ratio for bert-base, bert-large, and distilbert.",,2021-11-10,,"['ofir zafrir', 'ariel larey', 'guy boudoukh', 'haihao shen', 'moshe wasserblat']"
2111.05764,a framework for comprehensible multi-modal detection of cyber threats,cs.cr cs.ai cs.lg,"detection of malicious activities in corporate environments is a very complex task and much effort has been invested into research of its automation. however, vast majority of existing methods operate only in a narrow scope which limits them to capture only fragments of the evidence of malware's presence. consequently, such approach is not aligned with the way how the cyber threats are studied and described by domain experts. in this work, we discuss these limitations and design a detection framework which combines observed events from different sources of data. thanks to this, it provides full insight into the attack life cycle and enables detection of threats that require this coupling of observations from different telemetries to identify the full scope of the incident. we demonstrate applicability of the framework on a case study of a real malware infection observed in a corporate network.",,2021-11-10,,"['jan kohout', 'čeněk škarda', 'kyrylo shcherbin', 'martin kopp', 'jan brabec']"
2111.05790,early myocardial infarction detection over multi-view echocardiography,eess.iv cs.ai cs.cv cs.lg physics.med-ph,"myocardial infarction (mi) is the leading cause of mortality in the world that occurs due to a blockage of the coronary arteries feeding the myocardium. an early diagnosis of mi and its localization can mitigate the extent of myocardial damage by facilitating early therapeutic interventions. following the blockage of a coronary artery, the regional wall motion abnormality (rwma) of the ischemic myocardial segments is the earliest change to set in. echocardiography is the fundamental tool to assess any rwma. assessing the motion of the left ventricle (lv) wall only from a single echocardiography view may lead to missing the diagnosis of mi as the rwma may not be visible on that specific view. therefore, in this study, we propose to fuse apical 4-chamber (a4c) and apical 2-chamber (a2c) views in which a total of 11 myocardial segments can be analyzed for mi detection. the proposed method first estimates the motion of the lv wall by active polynomials (aps), which extract and track the endocardial boundary to compute myocardial segment displacements. the features are extracted from the a4c and a2c view displacements, which are fused and fed into the classifiers to detect mi. the main contributions of this study are 1) creation of a new benchmark dataset by including both a4c and a2c views in a total of 260 echocardiography recordings, which is publicly shared with the research community, 2) improving the performance of the prior work of threshold-based aps by a machine learning based approach, and 3) a pioneer mi detection approach via multi-view echocardiography by fusing the information of a4c and a2c views. experimental results show that the proposed method achieves 90.91% sensitivity and 86.36% precision for mi detection over multi-view echocardiography.",,2021-11-09,,"['aysen degerli', 'serkan kiranyaz', 'tahir hamid', 'rashid mazhar', 'moncef gabbouj']"
2111.05794,pimip: an open source platform for pathology information management and   integration,cs.hc cs.ai cs.cv,"digital pathology plays a crucial role in the development of artificial intelligence in the medical field. the digital pathology platform can make the pathological resources digital and networked, and realize the permanent storage of visual data and the synchronous browsing processing without the limitation of time and space. it has been widely used in various fields of pathology. however, there is still a lack of an open and universal digital pathology platform to assist doctors in the management and analysis of digital pathological sections, as well as the management and structured description of relevant patient information. most platforms cannot integrate image viewing, annotation and analysis, and text information management. to solve the above problems, we propose a comprehensive and extensible platform pimip. our pimip has developed the image annotation functions based on the visualization of digital pathological sections. our annotation functions support multi-user collaborative annotation and multi-device annotation, and realize the automation of some annotation tasks. in the annotation task, we invited a professional pathologist for guidance. we introduce a machine learning module for image analysis. the data we collected included public data from local hospitals and clinical examples. our platform is more clinical and suitable for clinical use. in addition to image data, we also structured the management and display of text information. so our platform is comprehensive. the platform framework is built in a modular way to support users to add machine learning modules independently, which makes our platform extensible.",,2021-11-09,,"['jialun wu', 'anyu mao', 'xinrui bao', 'haichuan zhang', 'zeyu gao', 'chunbao wang', 'tieliang gong', 'chen li']"
2111.05808,bagbert: bert-based bagging-stacking for multi-topic classification,cs.cl cs.ai cs.lg,"this paper describes our submission on the covid-19 literature annotation task at biocreative vii. we proposed an approach that exploits the knowledge of the globally non-optimal weights, usually rejected, to build a rich representation of each label. our proposed approach consists of two stages: (1) a bagging of various initializations of the training data that features weakly trained weights, (2) a stacking of heterogeneous vocabulary models based on bert and roberta embeddings. the aggregation of these weak insights performs better than a classical globally efficient model. the purpose is the distillation of the richness of knowledge to a simpler and lighter model. our system obtains an instance-based f1 of 92.96 and a label-based micro-f1 of 91.35.",,2021-11-10,,"['loïc rakotoson', 'charles letaillieur', 'sylvain massip', 'fréjus laleye']"
2111.05819,look before you leap: safe model-based reinforcement learning with human   intervention,cs.ai,"safety has become one of the main challenges of applying deep reinforcement learning to real world systems. currently, the incorporation of external knowledge such as human oversight is the only means to prevent the agent from visiting the catastrophic state. in this paper, we propose mbhi, a novel framework for safe model-based reinforcement learning, which ensures safety in the state-level and can effectively avoid both ""local"" and ""non-local"" catastrophes. an ensemble of supervised learners are trained in mbhi to imitate human blocking decisions. similar to human decision-making process, mbhi will roll out an imagined trajectory in the dynamics model before executing actions to the environment, and estimate its safety. when the imagination encounters a catastrophe, mbhi will block the current action and use an efficient mpc method to output a safety policy. we evaluate our method on several safety tasks, and the results show that mbhi achieved better performance in terms of sample efficiency and number of catastrophes compared to the baselines.",,2021-11-10,2021-11-16,"['yunkun xu', 'zhenyu liu', 'guifang duan', 'jiangcheng zhu', 'xiaolong bai', 'jianrong tan']"
2111.05825,a two-stage approach towards generalization in knowledge base question   answering,cs.cl cs.ai,"most existing approaches for knowledge base question answering (kbqa) focus on a specific underlying knowledge base either because of inherent assumptions in the approach, or because evaluating it on a different knowledge base requires non-trivial changes. however, many popular knowledge bases share similarities in their underlying schemas that can be leveraged to facilitate generalization across knowledge bases. to achieve this generalization, we introduce a kbqa framework based on a 2-stage architecture that explicitly separates semantic parsing from the knowledge base interaction, facilitating transfer learning across datasets and knowledge graphs. we show that pretraining on datasets with a different underlying knowledge base can nevertheless provide significant performance gains and reduce sample complexity. our approach achieves comparable or state-of-the-art performance for lc-quad (dbpedia), webqsp (freebase), simplequestions (wikidata) and metaqa (wikimovies-kg).",,2021-11-10,2021-11-17,"['srinivas ravishankar', 'june thai', 'ibrahim abdelaziz', 'nandana mihidukulasooriya', 'tahira naseem', 'pavan kapanipathi', 'gaetano rossiello', 'achille fokoue']"
2111.05827,data-driven and se-assisted ai model signal-awareness enhancement and   introspection,cs.se cs.ai,"ai modeling for source code understanding tasks has been making significant progress, and is being adopted in production development pipelines. however, reliability concerns, especially whether the models are actually learning task-related aspects of source code, are being raised. while recent model-probing approaches have observed a lack of signal awareness in many ai-for-code models, i.e. models not capturing task-relevant signals, they do not offer solutions to rectify this problem. in this paper, we explore data-driven approaches to enhance models' signal-awareness: 1) we combine the se concept of code complexity with the ai technique of curriculum learning; 2) we incorporate se assistance into ai models by customizing delta debugging to generate simplified signal-preserving programs, augmenting them to the training dataset. with our techniques, we achieve up to 4.8x improvement in model signal awareness. using the notion of code complexity, we further present a novel model learning introspection approach from the perspective of the dataset.",,2021-11-10,,"['sahil suneja', 'yufan zhuang', 'yunhui zheng', 'jim laredo', 'alessandro morari']"
2111.05884,search in imperfect information games,cs.ai,"from the very dawn of the field, search with value functions was a fundamental concept of computer games research. turing's chess algorithm from 1950 was able to think two moves ahead, and shannon's work on chess from $1950$ includes an extensive section on evaluation functions to be used within a search. samuel's checkers program from 1959 already combines search and value functions that are learned through self-play and bootstrapping. td-gammon improves upon those ideas and uses neural networks to learn those complex value functions -- only to be again used within search. the combination of decision-time search and value functions has been present in the remarkable milestones where computers bested their human counterparts in long standing challenging games -- deepblue for chess and alphago for go. until recently, this powerful framework of search aided with (learned) value functions has been limited to perfect information games. as many interesting problems do not provide the agent perfect information of the environment, this was an unfortunate limitation. this thesis introduces the reader to sound search for imperfect information games.",,2021-11-10,,['martin schmid']
2111.05901,an extensive study of user identification via eye movements across   multiple datasets,cs.cv cs.ai,"several studies have reported that biometric identification based on eye movement characteristics can be used for authentication. this paper provides an extensive study of user identification via eye movements across multiple datasets based on an improved version of method originally proposed by george and routray. we analyzed our method with respect to several factors that affect the identification accuracy, such as the type of stimulus, the ivt parameters (used for segmenting the trajectories into fixation and saccades), adding new features such as higher-order derivatives of eye movements, the inclusion of blink information, template aging, age and gender.we find that three methods namely selecting optimal ivt parameters, adding higher-order derivatives features and including an additional blink classifier have a positive impact on the identification accuracy. the improvements range from a few percentage points, up to an impressive 9 % increase on one of the datasets.",,2021-11-10,,"['sahar mahdie klim al zaidawi', 'martin h. u. prinzler', 'jonas lührs', 'sebastian maneth']"
2111.05917,recognition of patient groups with sleep related disorders using   bio-signal processing and deep learning,cs.lg cs.ai cs.et,"accurately diagnosing sleep disorders is essential for clinical assessments and treatments. polysomnography (psg) has long been used for detection of various sleep disorders. in this research, electrocardiography (ecg) and electromayography (emg) have been used for recognition of breathing and movement-related sleep disorders. bio-signal processing has been performed by extracting emg features exploiting entropy and statistical moments, in addition to developing an iterative pulse peak detection algorithm using synchrosqueezed wavelet transform (sswt) for reliable extraction of heart rate and breathing-related features from ecg. a deep learning framework has been designed to incorporate emg and ecg features. the framework has been used to classify four groups: healthy subjects, patients with obstructive sleep apnea (osa), patients with restless leg syndrome (rls) and patients with both osa and rls. the proposed deep learning framework produced a mean accuracy of 72% and weighted f1 score of 0.57 across subjects for our formulated four-class problem.",10.3390/s20092594,2021-11-10,,"['delaram jarchi', 'javier andreu-perez', 'mehrin kiani', 'oldrich vysata', 'jiri kuchynka', 'ales prochazka', 'saeid sane']"
2111.05937,recent advances in automated question answering in biomedical domain,cs.ai cs.cl cs.ir,"the objective of automated question answering (qa) systems is to provide answers to user queries in a time efficient manner. the answers are usually found in either databases (or knowledge bases) or a collection of documents commonly referred to as the corpus. in the past few decades there has been a proliferation of acquisition of knowledge and consequently there has been an exponential growth in new scientific articles in the field of biomedicine. therefore, it has become difficult to keep track of all the information in the domain, even for domain experts. with the improvements in commercial search engines, users can type in their queries and get a small set of documents most relevant for answering their query, as well as relevant snippets from the documents in some cases. however, it may be still tedious and time consuming to manually look for the required information or answers. this has necessitated the development of efficient qa systems which aim to find exact and precise answers to user provided natural language questions in the domain of biomedicine. in this paper, we introduce the basic methodologies used for developing general domain qa systems, followed by a thorough investigation of different aspects of biomedical qa systems, including benchmark datasets and several proposed approaches, both using structured databases and collection of texts. we also explore the limitations of current systems and explore potential avenues for further advancement.",,2021-11-10,,['krishanu das baksi']
2111.05941,generalizable cross-graph embedding for gnn-based congestion prediction,cs.lg cs.ai,"presently with technology node scaling, an accurate prediction model at early design stages can significantly reduce the design cycle. especially during logic synthesis, predicting cell congestion due to improper logic combination can reduce the burden of subsequent physical implementations. there have been attempts using graph neural network (gnn) techniques to tackle congestion prediction during the logic synthesis stage. however, they require informative cell features to achieve reasonable performance since the core idea of gnns is built on the message passing framework, which would be impractical at the early logic synthesis stage. to address this limitation, we propose a framework that can directly learn embeddings for the given netlist to enhance the quality of our node features. popular random-walk based embedding methods such as node2vec, line, and deepwalk suffer from the issue of cross-graph alignment and poor generalization to unseen netlist graphs, yielding inferior performance and costing significant runtime. in our framework, we introduce a superior alternative to obtain node embeddings that can generalize across netlist graphs using matrix factorization methods. we propose an efficient mini-batch training method at the sub-graph level that can guarantee parallel training and satisfy the memory restriction for large-scale netlists. we present results utilizing open-source eda tools such as dreamplace and openroad frameworks on a variety of openly available circuits. by combining the learned embedding on top of the netlist with the gnns, our method improves prediction performance, generalizes to new circuit lines, and is efficient in training, potentially saving over $90 \%$ of runtime.",,2021-11-10,,"['amur ghose', 'vincent zhang', 'yingxue zhang', 'dong li', 'wulong liu', 'mark coates']"
2111.05944,multi-objective optimization for value-sensitive and sustainable basket   recommendations,cs.ne cs.ai,"sustainable consumption aims to minimize the environmental and societal impact of the use of services and products. over-consumption of services and products leads to potential natural resource exhaustion and societal inequalities, as access to goods and services becomes more challenging. in everyday life, a person can simply achieve more sustainable purchases by drastically changing their lifestyle choices and potentially going against their personal values or wishes. conversely, achieving sustainable consumption while accounting for personal values is a more complex task, as potential trade-offs arise when trying to satisfy environmental and personal goals. this article focuses on value-sensitive design of recommender systems, which enable consumers to improve the sustainability of their purchases while respecting their personal values. value-sensitive recommendations for sustainable consumption are formalized as a multi-objective optimization problem, where each objective represents different sustainability goals and personal values. novel and existing multi-objective algorithms calculate solutions to this problem. the solutions are proposed as personalized sustainable basket recommendations to consumers. these recommendations are evaluated on a synthetic dataset, which comprises three established real-world datasets from relevant scientific and organizational reports. the synthetic dataset contains quantitative data on product prices, nutritional values and environmental impact metrics, such as greenhouse gas emissions and water footprint. the recommended baskets are highly similar to consumer purchased baskets and aligned with both sustainability goals and personal values relevant to health, expenditure and taste. even when consumers would accept only a fraction of recommendations, a considerable reduction of environmental impact is observed.",,2021-11-10,,['thomas asikis']
2111.05950,self-compression in bayesian neural networks,cs.lg cs.ai cs.cv,"machine learning models have achieved human-level performance on various tasks. this success comes at a high cost of computation and storage overhead, which makes machine learning algorithms difficult to deploy on edge devices. typically, one has to partially sacrifice accuracy in favor of an increased performance quantified in terms of reduced memory usage and energy consumption. current methods compress the networks by reducing the precision of the parameters or by eliminating redundant ones. in this paper, we propose a new insight into network compression through the bayesian framework. we show that bayesian neural networks automatically discover redundancy in model parameters, thus enabling self-compression, which is linked to the propagation of uncertainty through the layers of the network. our experimental results show that the network architecture can be successfully compressed by deleting parameters identified by the network itself while retaining the same level of accuracy.",,2021-11-10,,"['giuseppina carannante', 'dimah dera', 'ghulam rasool', 'nidhal c. bouaynaya']"
2111.05953,robust learning via ensemble density propagation in deep neural networks,cs.lg cs.ai cs.cv math.pr,"learning in uncertain, noisy, or adversarial environments is a challenging task for deep neural networks (dnns). we propose a new theoretically grounded and efficient approach for robust learning that builds upon bayesian estimation and variational inference. we formulate the problem of density propagation through layers of a dnn and solve it using an ensemble density propagation (endp) scheme. the endp approach allows us to propagate moments of the variational probability distribution across the layers of a bayesian dnn, enabling the estimation of the mean and covariance of the predictive distribution at the output of the model. our experiments using mnist and cifar-10 datasets show a significant improvement in the robustness of the trained models to random noise and adversarial attacks.",,2021-11-10,,"['giuseppina carannante', 'dimah dera', 'ghulam rasool', 'nidhal c. bouaynaya', 'lyudmila mihaylova']"
2111.05969,powergridworld: a framework for multi-agent reinforcement learning in   power systems,cs.lg cs.ai cs.ma cs.sy eess.sy,"we present the powergridworld software package to provide users with a lightweight, modular, and customizable framework for creating power-systems-focused, multi-agent gym environments that readily integrate with existing training frameworks for reinforcement learning (rl). although many frameworks exist for training multi-agent rl (marl) policies, none can rapidly prototype and develop the environments themselves, especially in the context of heterogeneous (composite, multi-device) power systems where power flow solutions are required to define grid-level variables and costs. powergridworld is an open-source software package that helps to fill this gap. to highlight powergridworld's key features, we present two case studies and demonstrate learning marl policies using both openai's multi-agent deep deterministic policy gradient (maddpg) and rllib's proximal policy optimization (ppo) algorithms. in both cases, at least some subset of agents incorporates elements of the power flow solution at each time step as part of their reward (negative cost) structures.",,2021-11-10,,"['david biagioni', 'xiangyu zhang', 'dylan wald', 'deepthi vaidhynathan', 'rohit chintala', 'jennifer king', 'ahmed s. zamzam']"
2111.05972,amazon sagemaker model parallelism: a general and flexible framework for   large model training,cs.lg cs.ai cs.dc,"with deep learning models rapidly growing in size, systems-level solutions for large-model training are required. we present amazon sagemaker model parallelism, a software library that integrates with pytorch, and enables easy training of large models using model parallelism and other memory-saving features. in contrast to existing solutions, the implementation of the sagemaker library is much more generic and flexible, in that it can automatically partition and run pipeline parallelism over arbitrary model architectures with minimal code change, and also offers a general and extensible framework for tensor parallelism, which supports a wider range of use cases, and is modular enough to be easily applied to new training scripts. the library also preserves the native pytorch user experience to a much larger degree, supporting module re-use and dynamic graphs, while giving the user full control over the details of the training step. we evaluate performance over gpt-3, roberta, bert, and neural collaborative filtering, and demonstrate competitive performance over existing solutions.",,2021-11-10,,"['can karakus', 'rahul huilgol', 'fei wu', 'anirudh subramanian', 'cade daniel', 'derya cavdar', 'teng xu', 'haohan chen', 'arash rahnama', 'luis quintela']"
2111.05973,soft sensing transformer: hundreds of sensors are worth a single word,cs.lg cs.ai,"with the rapid development of ai technology in recent years, there have been many studies with deep learning models in soft sensing area. however, the models have become more complex, yet, the data sets remain limited: researchers are fitting million-parameter models with hundreds of data samples, which is insufficient to exercise the effectiveness of their models and thus often fail to perform when implemented in industrial applications. to solve this long-lasting problem, we are providing large scale, high dimensional time series manufacturing sensor data from seagate technology to the public. we demonstrate the challenges and effectiveness of modeling industrial big data by a soft sensing transformer model on these data sets. transformer is used because, it has outperformed state-of-the-art techniques in natural language processing, and since then has also performed well in the direct application to computer vision without introduction of image-specific inductive biases. we observe the similarity of a sentence structure to the sensor readings and process the multi-variable sensor readings in a time series in a similar manner of sentences in natural language. the high-dimensional time-series data is formatted into the same shape of embedded sentences and fed into the transformer model. the results show that transformer model outperforms the benchmark models in soft sensing field based on auto-encoder and long short-term memory (lstm) models. to the best of our knowledge, we are the first team in academia or industry to benchmark the performance of original transformer model with large-scale numerical soft sensing data.",,2021-11-10,,"['chao zhang', 'jaswanth yella', 'yu huang', 'xiaoye qian', 'sergei petrov', 'andrey rzhetsky', 'sthitie bom']"
2111.05976,"classification of the chess endgame problem using logistic regression,   decision trees, and neural networks",cs.lg cs.ai,"in this study we worked on the classification of the chess endgame problem using different algorithms like logistic regression, decision trees and neural networks. our experiments indicates that the neural networks provides the best accuracy (85%) then the decision trees (79%). we did these experiments using microsoft azure machine learning as a case-study on using visual programming in classification. our experiments demonstrates that this tool is powerful and save a lot of time, also it could be improved with more features that increase the usability and reduce the learning curve. we also developed an application for dataset visualization using a new programming language called ring, our experiments demonstrates that this language have simple design like python while integrates rad tools like visual basic which is good for gui development in the open-source world",,2021-11-10,,['mahmoud s. fayed']
2111.05988,cross-language information retrieval,cs.ir cs.ai cs.cl,"two key assumptions shape the usual view of ranked retrieval: (1) that the searcher can choose words for their query that might appear in the documents that they wish to see, and (2) that ranking retrieved documents will suffice because the searcher will be able to recognize those which they wished to find. when the documents to be searched are in a language not known by the searcher, neither assumption is true. in such cases, cross-language information retrieval (clir) is needed. this chapter reviews the state of the art for cross-language information retrieval and outlines some open research questions.",,2021-11-10,,"['petra galuščáková', 'douglas w. oard', 'suraj nair']"
2111.05992,on the use and misuse of absorbing states in multi-agent reinforcement   learning,cs.lg cs.ai,"the creation and destruction of agents in cooperative multi-agent reinforcement learning (marl) is a critically under-explored area of research. current marl algorithms often assume that the number of agents within a group remains fixed throughout an experiment. however, in many practical problems, an agent may terminate before their teammates. this early termination issue presents a challenge: the terminated agent must learn from the group's success or failure which occurs beyond its own existence. we refer to propagating value from rewards earned by remaining teammates to terminated agents as the posthumous credit assignment problem. current marl methods handle this problem by placing these agents in an absorbing state until the entire group of agents reaches a termination condition. although absorbing states enable existing algorithms and apis to handle terminated agents without modification, practical training efficiency and resource use problems exist.   in this work, we first demonstrate that sample complexity increases with the quantity of absorbing states in a toy supervised learning task for a fully connected network, while attention is more robust to variable size input. then, we present a novel architecture for an existing state-of-the-art marl algorithm which uses attention instead of a fully connected layer with absorbing states. finally, we demonstrate that this novel architecture significantly outperforms the standard architecture on tasks in which agents are created or destroyed within episodes as well as standard multi-agent coordination tasks.",,2021-11-10,,"['andrew cohen', 'ervin teng', 'vincent-pierre berges', 'ruo-ping dong', 'hunter henry', 'marwan mattar', 'alexander zook', 'sujoy ganguly']"
2111.06003,detecting fake points of interest from location data,cs.lg cs.ai,"the pervasiveness of gps-enabled mobile devices and the widespread use of location-based services have resulted in the generation of massive amounts of geo-tagged data. in recent times, the data analysis now has access to more sources, including reviews, news, and images, which also raises questions about the reliability of point-of-interest (poi) data sources. while previous research attempted to detect fake poi data through various security mechanisms, the current work attempts to capture the fake poi data in a much simpler way. the proposed work is focused on supervised learning methods and their capability to find hidden patterns in location-based data. the ground truth labels are obtained through real-world data, and the fake data is generated using an api, so we get a dataset with both the real and fake labels on the location data. the objective is to predict the truth about a poi using the multi-layer perceptron (mlp) method. in the proposed work, mlp based on data classification technique is used to classify location data accurately. the proposed method is compared with traditional classification and robust and recent deep neural methods. the results show that the proposed method is better than the baseline methods.",,2021-11-10,,"['syed raza bashir', 'vojislav misic']"
2111.06005,agent spaces,cs.ai cs.lg math.oc,"exploration is one of the most important tasks in reinforcement learning, but it is not well-defined beyond finite problems in the dynamic programming paradigm (see subsection 2.4). we provide a reinterpretation of exploration which can be applied to any online learning method. we come to this definition by approaching exploration from a new direction. after finding that concepts of exploration created to solve simple markov decision processes with dynamic programming are no longer broadly applicable, we reexamine exploration. instead of extending the ends of dynamic exploration procedures, we extend their means. that is, rather than repeatedly sampling every state-action pair possible in a process, we define the act of modifying an agent to itself be explorative. the resulting definition of exploration can be applied in infinite problems and non-dynamic learning methods, which the dynamic notion of exploration cannot tolerate. to understand the way that modifications of an agent affect learning, we describe a novel structure on the set of agents: a collection of distances (see footnote 7) $d_{a} \in a$, which represent the perspectives of each agent possible in the process. using these distances, we define a topology and show that many important structures in reinforcement learning are well behaved under the topology induced by convergence in the agent space.",,2021-11-10,,"['john c. raisbeck', 'matthew w. allen', 'hakho lee']"
2111.06011,climate modeling with neural diffusion equations,cs.lg cs.ai,"owing to the remarkable development of deep learning technology, there have been a series of efforts to build deep learning-based climate models. whereas most of them utilize recurrent neural networks and/or graph neural networks, we design a novel climate model based on the two concepts, the neural ordinary differential equation (node) and the diffusion equation. many physical processes involving a brownian motion of particles can be described by the diffusion equation and as a result, it is widely used for modeling climate. on the other hand, neural ordinary differential equations (nodes) are to learn a latent governing equation of ode from data. in our presented method, we combine them into a single framework and propose a concept, called neural diffusion equation (nde). our nde, equipped with the diffusion equation and one more additional neural network to model inherent uncertainty, can learn an appropriate latent governing equation that best describes a given climate dataset. in our experiments with two real-world and one synthetic datasets and eleven baselines, our method consistently outperforms existing baselines by non-trivial margins.",,2021-11-10,,"['jeehyun hwang', 'jeongwhan choi', 'hwangyong choi', 'kookjin lee', 'dongeun lee', 'noseong park']"
2111.06014,alphagarden: learning to autonomously tend a polyculture garden,cs.ro cs.ai,"this paper presents alphagarden: an autonomous polyculture garden that prunes and irrigates living plants in a 1.5m x 3.0m physical testbed. alphagarden uses an overhead camera and sensors to track the plant distribution and soil moisture. we model individual plant growth and interplant dynamics to train a policy that chooses actions to maximize leaf coverage and diversity. for autonomous pruning, alphagarden uses two custom-designed pruning tools and a trained neural network to detect prune points. we present results for four 60-day garden cycles. results suggest alphagarden can autonomously achieve 0.96 normalized diversity with pruning shears while maintaining an average canopy coverage of 0.86 during the peak of the cycle. code, datasets, and supplemental material can be found at https://github.com/berkeleyautomation/alphagarden.",,2021-11-10,,"['mark presten', 'yahav avigal', 'mark theis', 'satvik sharma', 'rishi parikh', 'shrey aeron', 'sandeep mukherjee', 'sebastian oehme', 'simeon adebola', 'walter teitelbaum', 'varun kamat', 'ken goldberg']"
2111.06023,hmd-amp: protein language-powered hierarchical multi-label deep forest   for annotating antimicrobial peptides,cs.lg cs.ai q-bio.qm,"identifying the targets of an antimicrobial peptide is a fundamental step in studying the innate immune response and combating antibiotic resistance, and more broadly, precision medicine and public health. there have been extensive studies on the statistical and computational approaches to identify (i) whether a peptide is an antimicrobial peptide (amp) or a non-amp and (ii) which targets are these sequences effective to (gram-positive, gram-negative, etc.). despite the existing deep learning methods on this problem, most of them are unable to handle the small amp classes (anti-insect, anti-parasite, etc.). and more importantly, some amps can have multiple targets, which the previous methods fail to consider. in this study, we build a diverse and comprehensive multi-label protein sequence database by collecting and cleaning amino acids from various amp databases. to generate efficient representations and features for the small classes dataset, we take advantage of a protein language model trained on 250 million protein sequences. based on that, we develop an end-to-end hierarchical multi-label deep forest framework, hmd-amp, to annotate amp comprehensively. after identifying an amp, it further predicts what targets the amp can effectively kill from eleven available classes. extensive experiments suggest that our framework outperforms state-of-the-art models in both the binary classification task and the multi-label classification task, especially on the minor classes.the model is robust against reduced features and small perturbations and produces promising results. we believe hmd-amp contributes to both the future wet-lab investigations of the innate structural properties of different antimicrobial peptides and build promising empirical underpinnings for precise medicine with antibiotics.",,2021-11-10,,"['qinze yu', 'zhihang dong', 'xingyu fan', 'licheng zong', 'yu li']"
2111.06027,towards theoretical understanding of flexible transmitter networks via   approximation and local minima,cs.lg cs.ai,"flexible transmitter network (ftnet) is a recently proposed bio-plausible neural network and has achieved competitive performance with the state-of-the-art models when handling temporal-spatial data. however, there remains an open problem about the theoretical understanding of ftnet. this work investigates the theoretical properties of one-hidden-layer ftnet from the perspectives of approximation and local minima. under mild assumptions, we show that: i) ftnet is a universal approximator; ii) the approximation complexity of ftnet can be exponentially smaller than those of real-valued neural networks with feedforward/recurrent architectures and is of the same order in the worst case; iii) any local minimum of ftnet is the global minimum, which suggests that it is possible for local search algorithms to converge to the global minimum. our theoretical results indicate that ftnet can efficiently express target functions and has no concern about local minima, which complements the theoretical blank of ftnet and exhibits the possibility for ameliorating the ftnet.",,2021-11-10,,"['jin-hui wu', 'shao-qun zhang', 'yuan jiang', 'zhi-hua zhou']"
2111.06036,cubetr: learning to solve the rubiks cube using transformers,cs.lg cs.ai,"since its first appearance, transformers have been successfully used in wide ranging domains from computer vision to natural language processing. application of transformers in reinforcement learning by reformulating it as a sequence modelling problem was proposed only recently. compared to other commonly explored reinforcement learning problems, the rubiks cube poses a unique set of challenges. the rubiks cube has a single solved state for quintillions of possible configurations which leads to extremely sparse rewards. the proposed model cubetr attends to longer sequences of actions and addresses the problem of sparse rewards. cubetr learns how to solve the rubiks cube from arbitrary starting states without any human prior, and after move regularisation, the lengths of solutions generated by it are expected to be very close to those given by algorithms used by expert human solvers. cubetr provides insights to the generalisability of learning algorithms to higher dimensional cubes and the applicability of transformers in other relevant sparse reward scenarios.",,2021-11-10,,['mustafa ebrahim chasmai']
2111.06037,constrained stochastic submodular maximization with state-dependent   costs,cs.lg cs.ai math.oc,"in this paper, we study the constrained stochastic submodular maximization problem with state-dependent costs. the input of our problem is a set of items whose states (i.e., the marginal contribution and the cost of an item) are drawn from a known probability distribution. the only way to know the realized state of an item is to select that item. we consider two constraints, i.e., \emph{inner} and \emph{outer} constraints. recall that each item has a state-dependent cost, and the inner constraint states that the total \emph{realized} cost of all selected items must not exceed a give budget. thus, inner constraint is state-dependent. the outer constraint, one the other hand, is state-independent. it can be represented as a downward-closed family of sets of selected items regardless of their states. our objective is to maximize the objective function subject to both inner and outer constraints. under the assumption that larger cost indicates larger ""utility"", we present a constant approximate solution to this problem.",,2021-11-10,,['shaojie tang']
2111.06046,music score expansion with variable-length infilling,cs.sd cs.ai eess.as,"in this paper, we investigate using the variable-length infilling (vli) model, which is originally proposed to infill missing segments, to ""prolong"" existing musical segments at musical boundaries. specifically, as a case study, we expand 20 musical segments from 12 bars to 16 bars, and examine the degree to which the vli model preserves musical boundaries in the expanded results using a few objective metrics, including the register histogram similarity we newly propose. the results show that the vli model has the potential to address the expansion task.",,2021-11-10,,"['chih-pin tan', 'chin-jui chang', 'alvin w. y. su', 'yi-hsuan yang']"
2111.06061,edge-cloud polarization and collaboration: a comprehensive survey,cs.lg cs.ai,"influenced by the great success of deep learning via cloud computing and the rapid development of edge chips, research in artificial intelligence (ai) has shifted to both of the computing paradigms, i.e., cloud computing and edge computing. in recent years, we have witnessed significant progress in developing more advanced ai models on cloud servers that surpass traditional deep learning models owing to model innovations (e.g., transformers, pretrained families), explosion of training data and soaring computing capabilities. however, edge computing, especially edge and cloud collaborative computing, are still in its infancy to announce their success due to the resource-constrained iot scenarios with very limited algorithms deployed. in this survey, we conduct a systematic review for both cloud and edge ai. specifically, we are the first to set up the collaborative learning mechanism for cloud and edge modeling with a thorough review of the architectures that enable such mechanism. we also discuss potentials and practical experiences of some on-going advanced edge ai topics including pretraining models, graph neural networks and reinforcement learning. finally, we discuss the promising directions and challenges in this field.",,2021-11-11,2021-11-12,"['jiangchao yao', 'shengyu zhang', 'yang yao', 'feng wang', 'jianxin ma', 'jianwei zhang', 'yunfei chu', 'luo ji', 'kunyang jia', 'tao shen', 'anpeng wu', 'fengda zhang', 'ziqi tan', 'kun kuang', 'chao wu', 'fei wu', 'jingren zhou', 'hongxia yang']"
2111.06070,explainable sentence-level sentiment analysis for amazon product reviews,cs.cl cs.ai,"in this paper, we conduct a sentence level sentiment analysis on the product reviews from amazon and thorough analysis on the model interpretability. for the sentiment analysis task, we use the bilstm model with attention mechanism. for the study of interpretability, we consider the attention weights distribution of single sentence and the attention weights of main aspect terms. the model has an accuracy of up to 0.96. and we find that the aspect terms have the same or even more attention weights than the sentimental words in sentences.",,2021-11-11,,"['xuechun li', 'xueyao sun', 'zewei xu', 'yifan zhou']"
2111.06077,"a survey on hyperdimensional computing aka vector symbolic   architectures, part i: models and data transformations",cs.ai cs.lg,"this two-part comprehensive survey is devoted to a computing framework most commonly known under the names hyperdimensional computing and vector symbolic architectures (hdc/vsa). both names refer to a family of computational models that use high-dimensional distributed representations and rely on the algebraic properties of their key operations to incorporate the advantages of structured symbolic representations and vector distributed representations. notable models in the hdc/vsa family are tensor product representations, holographic reduced representations, multiply-add-permute, binary spatter codes, and sparse binary distributed representations but there are other models too. hdc/vsa is a highly interdisciplinary area with connections to computer science, electrical engineering, artificial intelligence, mathematics, and cognitive science. this fact makes it challenging to create a thorough overview of the area. however, due to a surge of new researchers joining the area in recent years, the necessity for a comprehensive survey of the area has become extremely important. therefore, amongst other aspects of the area, this part i surveys important aspects such as: known computational models of hdc/vsa and transformations of various input data types to high-dimensional distributed representations. part ii of this survey is devoted to applications, cognitive computing and architectures, as well as directions for future work. the survey is written to be useful for both newcomers and practitioners.",,2021-11-11,,"['denis kleyko', 'dmitri a. rachkovskij', 'evgeny osipov', 'abbas rahimi']"
2111.06086,a chinese multi-type complex questions answering dataset over wikidata,cs.cl cs.ai cs.db,"complex knowledge base question answering is a popular area of research in the past decade. recent public datasets have led to encouraging results in this field, but are mostly limited to english and only involve a small number of question types and relations, hindering research in more realistic settings and in languages other than english. in addition, few state-of-the-art kbqa models are trained on wikidata, one of the most popular real-world knowledge bases. we propose clc-quad, the first large scale complex chinese semantic parsing dataset over wikidata to address these challenges. together with the dataset, we present a text-to-sparql baseline model, which can effectively answer multi-type complex questions, such as factual questions, dual intent questions, boolean questions, and counting questions, with wikidata as the background knowledge. we finally analyze the performance of sota kbqa models on this dataset and identify the challenges facing chinese kbqa.",,2021-11-11,,"['jianyun zou', 'min yang', 'lichao zhang', 'yechen xu', 'qifan pan', 'fengqing jiang', 'ran qin', 'shushu wang', 'yifan he', 'songfang huang', 'zhou zhao']"
2111.06087,classification of url bitstreams using bag of bytes,cs.ni cs.ai,"protecting users from accessing malicious web sites is one of the important management tasks for network operators. there are many open-source and commercial products to control web sites users can access. the most traditional approach is blacklist-based filtering. this mechanism is simple but not scalable, though there are some enhanced approaches utilizing fuzzy matching technologies. other approaches try to use machine learning (ml) techniques by extracting features from url strings. this approach can cover a wider area of internet web sites, but finding good features requires deep knowledge of trends of web site design. recently, another approach using deep learning (dl) has appeared. the dl approach will help to extract features automatically by investigating a lot of existing sample data. using this technique, we can build a flexible filtering decision module by keep teaching the neural network module about recent trends, without any specific expert knowledge of the url domain. in this paper, we apply a mechanical approach to generate feature vectors from url strings. we implemented our approach and tested with realistic url access history data taken from a research organization and data from the famous archive site of phishing site information, phishtank.com. our approach achieved 2~3% better accuracy compared to the existing dl-based approach.",10.1109/icin.2018.8401597,2021-11-11,,"['keiichi shima', 'daisuke miyamoto', 'hiroshi abe', 'tomohiro ishihara', 'kazuya okada', 'yuji sekiya', 'hirochika asai', 'yusuke doi']"
2111.06103,towards robust knowledge graph embedding via multi-task reinforcement   learning,cs.cl cs.ai,"nowadays, knowledge graphs (kgs) have been playing a pivotal role in ai-related applications. despite the large sizes, existing kgs are far from complete and comprehensive. in order to continuously enrich kgs, automatic knowledge construction and update mechanisms are usually utilized, which inevitably bring in plenty of noise. however, most existing knowledge graph embedding (kge) methods assume that all the triple facts in kgs are correct, and project both entities and relations into a low-dimensional space without considering noise and knowledge conflicts. this will lead to low-quality and unreliable representations of kgs. to this end, in this paper, we propose a general multi-task reinforcement learning framework, which can greatly alleviate the noisy data problem. in our framework, we exploit reinforcement learning for choosing high-quality knowledge triples while filtering out the noisy ones. also, in order to take full advantage of the correlations among semantically similar relations, the triple selection processes of similar relations are trained in a collective way with multi-task learning. moreover, we extend popular kge models transe, distmult, conve and rotate with the proposed framework. finally, the experimental validation shows that our approach is able to enhance existing kge models and can provide more robust representations of kgs in noisy scenarios.",,2021-11-11,,"['zhao zhang', 'fuzhen zhuang', 'hengshu zhu', 'chao li', 'hui xiong', 'qing he', 'yongjun xu']"
2111.06175,training neural networks with synthetic electrocardiograms,cs.lg cs.ai,"we present a method for training neural networks with synthetic electrocardiograms that mimic signals produced by a wearable single lead electrocardiogram monitor. we use domain randomization where the synthetic signal properties such as the waveform shape, rr-intervals and noise are varied for every training example. models trained with synthetic data are compared to their counterparts trained with real data. detection of r-waves in electrocardiograms recorded during different physical activities and in atrial fibrillation is used to compare the models. by allowing the randomization to increase beyond what is typically observed in the real-world data the performance is on par or superseding the performance of networks trained with real data. experiments show robust performance with different seeds and training examples on different test sets without any test set specific tuning. the method makes possible to train neural networks using practically free-to-collect data with accurate labels without the need for manual annotations and it opens up the possibility of extending the use of synthetic data on cardiac disease classification when disease specific a priori information is used in the electrocardiogram generation. additionally the distribution of data can be controlled eliminating class imbalances that are typically observed in health related data and additionally the generated data is inherently private.",,2021-11-11,,"['matti kaisti', 'juho laitala', 'antti airola']"
2111.06206,"towards axiomatic, hierarchical, and symbolic explanation for deep   models",cs.lg cs.ai cs.cv,"this paper proposes a hierarchical and symbolic and-or graph (aog) to objectively explain the internal logic encoded by a well-trained deep model for inference. we first define the objectiveness of an explainer model in game theory, and we develop a rigorous representation of the and-or logic encoded by the deep model. the objectiveness and trustworthiness of the aog explainer are both theoretically guaranteed and experimentally verified. furthermore, we propose several techniques to boost the conciseness of the explanation.",,2021-11-11,,"['jie ren', 'mingjie li', 'qihan ren', 'huiqi deng', 'quanshi zhang']"
2111.06213,enhanced fast boolean matching based on sensitivity signatures pruning,cs.cc cs.ai,"boolean matching is significant to digital integrated circuits design. an exhaustive method for boolean matching is computationally expensive even for functions with only a few variables, because the time complexity of such an algorithm for an n-variable boolean function is $o(2^{n+1}n!)$. sensitivity is an important characteristic and a measure of the complexity of boolean functions. it has been used in analysis of the complexity of algorithms in different fields. this measure could be regarded as a signature of boolean functions and has great potential to help reduce the search space of boolean matching.   in this paper, we introduce boolean sensitivity into boolean matching and design several sensitivity-related signatures to enhance fast boolean matching. first, we propose some new signatures that relate sensitivity to boolean equivalence. then, we prove that these signatures are prerequisites for boolean matching, which we can use to reduce the search space of the matching problem. besides, we develop a fast sensitivity calculation method to compute and compare these signatures of two boolean functions. compared with the traditional cofactor and symmetric detection methods, sensitivity is a series of signatures of another dimension. we also show that sensitivity can be easily integrated into traditional methods and distinguish the mismatched boolean functions faster. to the best of our knowledge, this is the first work that introduces sensitivity to boolean matching. the experimental results show that sensitivity-related signatures we proposed in this paper can reduce the search space to a very large extent, and perform up to 3x speedup over the state-of-the-art boolean matching methods.",,2021-11-11,,"['jiaxi zhang', 'liwei ni', 'shenggen zheng', 'hao liu', 'xiangfu zou', 'feng wang', 'guojie luo']"
2111.06236,discovering and explaining the representation bottleneck of dnns,cs.lg cs.ai cs.cv,"this paper explores the bottleneck of feature representations of deep neural networks (dnns), from the perspective of the complexity of interactions between input variables encoded in dnns. to this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. we discover that a dnn is more likely to encode both too simple interactions and too complex interactions, but usually fails to learn interactions of intermediate complexity. such a phenomenon is widely shared by different dnns for different tasks. this phenomenon indicates a cognition gap between dnns and human beings, and we call it a representation bottleneck. we theoretically prove the underlying reason for the representation bottleneck. furthermore, we propose a loss to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities.",,2021-11-11,2021-11-18,"['huiqi deng', 'qihan ren', 'xu chen', 'hao zhang', 'jie ren', 'quanshi zhang']"
2111.06259,learning via long short-term memory (lstm) network for predicting   strains in railway bridge members under train induced vibration,cs.lg cs.ai,"bridge health monitoring using machine learning tools has become an efficient and cost-effective approach in recent times. in the present study, strains in railway bridge member, available from a previous study conducted by iit guwahati has been utilized. these strain data were collected from an existing bridge while trains were passing over the bridge. lstm is used to train the network and to predict strains in different members of the railway bridge. actual field data has been used for the purpose of predicting strain in different members using strain data from a single member, yet it has been observed that they are quite agreeable to those of ground truth values. this is in spite of the fact that a lot of noise existed in the data, thus showing the efficacy of lstm in training and predicting even from noisy field data. this may easily open up the possibility of collecting data from the bridge with a much lesser number of sensors and predicting the strain data in other members through lstm network.",,2021-11-08,,"['amartya dutta', 'kamaljyoti nath']"
2111.06266,alphadda: game artificial intelligence with dynamic difficulty   adjustment using alphazero,cs.lg cs.ai,"an artificial intelligence (ai) player has obtained superhuman skill for games like go, chess, and othello (reversi). in other words, the ai player becomes too strong as an opponent of human players. then, we will not enjoy playing board games with the ai player. in order to entertain human players, the ai player is required to balance its skill with the human player's one automatically. to address this issue, i propose alphadda, an ai player with dynamic difficulty adjustment based on alphazero. alphadda consists of a deep neural network (dnn) and monte carlo tree search like alphazero. alphadda estimates the value of the game state form only the board state using the dnn and changes its skill according to the value. alphadda can adjust alphadda's skill using only the state of a game without prior knowledge about an opponent. in this study, alphadda plays connect4, 6x6 othello, which is othello using a 6x6 size board, and othello with the other ai agents. the other ai agents are alphazero, monte carlo tree search, minimax algorithm, and a random player. this study shows that alphadda achieves to balance its skill with the other ai agents except for a random player. alphadda's dda ability is derived from the accurate estimation of the value from the state of a game. we will be able to use the approach of alphadda for any games in that the dnn can estimate the value from the state.",,2021-11-11,,['kazuhisa fujita']
2111.06268,raman spectroscopy in open world learning settings using the   objectosphere approach,cs.lg cs.ai physics.app-ph physics.bio-ph physics.comp-ph physics.med-ph,"raman spectroscopy in combination with machine learning has significant promise for applications in clinical settings as a rapid, sensitive, and label-free identification method. these approaches perform well in classifying data that contains classes that occur during the training phase. however, in practice, there are always substances whose spectra have not yet been taken or are not yet known and when the input data are far from the training set and include new classes that were not seen at the training stage, a significant number of false positives are recorded which limits the clinical relevance of these algorithms. here we show that these obstacles can be overcome by implementing recently introduced entropic open set and objectosphere loss functions. to demonstrate the efficiency of this approach, we compiled a database of raman spectra of 40 chemical classes separating them into 20 biologically relevant classes comprised of amino acids, 10 irrelevant classes comprised of bio-related chemicals, and 10 classes that the neural network has not seen before, comprised of a variety of other chemicals. we show that this approach enables the network to effectively identify the unknown classes while preserving high accuracy on the known ones, dramatically reducing the number of false positives while preserving high accuracy on the known classes, which will allow this technique to bridge the gap between laboratory experiments and clinical applications.",,2021-11-11,,"['yaroslav balytskyi', 'justin bendesky', 'tristan paul', 'guy hagen', 'kelly mcnear']"
2111.06290,"fairness, integrity, and privacy in a scalable blockchain-based   federated learning system",cs.cr cs.ai cs.dc,"federated machine learning (fl) allows to collectively train models on sensitive data as only the clients' models and not their training data need to be shared. however, despite the attention that research on fl has drawn, the concept still lacks broad adoption in practice. one of the key reasons is the great challenge to implement fl systems that simultaneously achieve fairness, integrity, and privacy preservation for all participating clients. to contribute to solving this issue, our paper suggests a fl system that incorporates blockchain technology, local differential privacy, and zero-knowledge proofs. our implementation of a proof-of-concept with multiple linear regression illustrates that these state-of-the-art technologies can be combined to a fl system that aligns economic incentives, trust, and confidentiality requirements in a scalable and transparent system.",,2021-11-11,,"['timon rückel', 'johannes sedlmeir', 'peter hofmann']"
2111.06312,implicit svd for graph representation learning,cs.lg cs.ai cs.ms cs.si,"recent improvements in the performance of state-of-the-art (sota) methods for graph representational learning (grl) have come at the cost of significant computational resource requirements for training, e.g., for calculating gradients via backprop over many data epochs. meanwhile, singular value decomposition (svd) can find closed-form solutions to convex problems, using merely a handful of epochs. in this paper, we make grl more computationally tractable for those with modest hardware. we design a framework that computes svd of \textit{implicitly} defined matrices, and apply this framework to several grl tasks. for each task, we derive linear approximation of a sota model, where we design (expensive-to-store) matrix $\mathbf{m}$ and train the model, in closed-form, via svd of $\mathbf{m}$, without calculating entries of $\mathbf{m}$. by converging to a unique point in one step, and without calculating gradients, our models show competitive empirical test performance over various graphs such as article citation and biological interaction networks. more importantly, svd can initialize a deeper model, that is architected to be non-linear almost everywhere, though behaves linearly when its parameters reside on a hyperplane, onto which svd initializes. the deeper model can then be fine-tuned within only a few epochs. overall, our procedure trains hundreds of times faster than state-of-the-art methods, while competing on empirical test performance. we open-source our implementation at: https://github.com/samihaija/isvd",,2021-11-11,,"['sami abu-el-haija', 'hesham mostafa', 'marcel nassar', 'valentino crespi', 'greg ver steeg', 'aram galstyan']"
2111.06331,towards an efficient voice identification using wav2vec2.0 and hubert   based on the quran reciters dataset,cs.sd cs.ai cs.cl cs.lg eess.as,"current authentication and trusted systems depend on classical and biometric methods to recognize or authorize users. such methods include audio speech recognitions, eye, and finger signatures. recent tools utilize deep learning and transformers to achieve better results. in this paper, we develop a deep learning constructed model for arabic speakers identification by using wav2vec2.0 and hubert audio representation learning tools. the end-to-end wav2vec2.0 paradigm acquires contextualized speech representations learnings by randomly masking a set of feature vectors, and then applies a transformer neural network. we employ an mlp classifier that is able to differentiate between invariant labeled classes. we show several experimental results that safeguard the high accuracy of the proposed model. the experiments ensure that an arbitrary wave signal for a certain speaker can be identified with 98% and 97.1% accuracies in the cases of wav2vec2.0 and hubert, respectively.",,2021-11-11,,"['aly moustafa', 'salah a. aly']"
2111.06345,poisoning knowledge graph embeddings via relation inference patterns,cs.lg cs.ai cs.cl cs.ne,"we study the problem of generating data poisoning attacks against knowledge graph embedding (kge) models for the task of link prediction in knowledge graphs. to poison kge models, we propose to exploit their inductive abilities which are captured through the relationship patterns like symmetry, inversion and composition in the knowledge graph. specifically, to degrade the model's prediction confidence on target facts, we propose to improve the model's prediction confidence on a set of decoy facts. thus, we craft adversarial additions that can improve the model's prediction confidence on decoy facts through different inference patterns. our experiments demonstrate that the proposed poisoning attacks outperform state-of-art baselines on four kge models for two publicly available datasets. we also find that the symmetry pattern based attacks generalize across all model-dataset combinations which indicates the sensitivity of kge models to this pattern.",10.18653/v1/2021.acl-long.147,2021-11-11,,"['peru bhardwaj', 'john kelleher', 'luca costabello', ""declan o'sullivan""]"
2111.06353,learning from mistakes -- a framework for neural architecture search,cs.lg cs.ai,"learning from one's mistakes is an effective human learning technique where the learners focus more on the topics where mistakes were made, so as to deepen their understanding. in this paper, we investigate if this human learning strategy can be applied in machine learning. we propose a novel machine learning method called learning from mistakes (lfm), wherein the learner improves its ability to learn by focusing more on the mistakes during revision. we formulate lfm as a three-stage optimization problem: 1) learner learns; 2) learner re-learns focusing on the mistakes, and; 3) learner validates its learning. we develop an efficient algorithm to solve the lfm problem. we apply the lfm framework to neural architecture search on cifar-10, cifar-100, and imagenet. experimental results strongly demonstrate the effectiveness of our model.",,2021-11-11,,"['bhanu garg', 'li zhang', 'pradyumna sridhara', 'ramtin hosseini', 'eric xing', 'pengtao xie']"
2111.06366,answer set programming made easy,cs.ai,"we take up an idea from the folklore of answer set programming, namely that choices, integrity constraints along with a restricted rule format is sufficient for answer set programming. we elaborate upon the foundations of this idea in the context of the logic of here-and-there and show how it can be derived from the logical principle of extension by definition. we then provide an austere form of logic programs that may serve as a normalform for logic programs similar to conjunctive normalform in classical logic. finally, we take the key ideas and propose a modeling methodology for asp beginners and illustrate how it can be used.",,2021-11-11,,"['jorge fandinno', 'seemran mishra', 'javier romero', 'torsten schaub']"
2111.06383,distilling motion planner augmented policies into visual control   policies for robot manipulation,cs.lg cs.ai cs.ro,"learning complex manipulation tasks in realistic, obstructed environments is a challenging problem due to hard exploration in the presence of obstacles and high-dimensional visual observations. prior work tackles the exploration problem by integrating motion planning and reinforcement learning. however, the motion planner augmented policy requires access to state information, which is often not available in the real-world settings. to this end, we propose to distill a state-based motion planner augmented policy to a visual control policy via (1) visual behavioral cloning to remove the motion planner dependency along with its jittery motion, and (2) vision-based reinforcement learning with the guidance of the smoothed trajectories from the behavioral cloning agent. we evaluate our method on three manipulation tasks in obstructed environments and compare it against various reinforcement learning and imitation learning baselines. the results demonstrate that our framework is highly sample-efficient and outperforms the state-of-the-art algorithms. moreover, coupled with domain randomization, our policy is capable of zero-shot transfer to unseen environment settings with distractors. code and videos are available at https://clvrai.com/mopa-pd",,2021-11-11,,"['i-chun arthur liu', 'shagun uppal', 'gaurav s. sukhatme', 'joseph j. lim', 'peter englert', 'youngwoon lee']"
2111.06387,learning signal-agnostic manifolds of neural fields,cs.lg cs.ai cs.cv stat.ml,"deep neural networks have been used widely to learn the latent structure of datasets, across modalities such as images, shapes, and audio signals. however, existing models are generally modality-dependent, requiring custom architectures and objectives to process different classes of signals. we leverage neural fields to capture the underlying structure in image, shape, audio and cross-modal audiovisual domains in a modality-independent manner. we cast our task as one of learning a manifold, where we aim to infer a low-dimensional, locally linear subspace in which our data resides. by enforcing coverage of the manifold, local linearity, and local isometry, our model -- dubbed gem -- learns to capture the underlying structure of datasets across modalities. we can then travel along linear regions of our manifold to obtain perceptually consistent interpolations between samples, and can further use gem to recover points on our manifold and glean not only diverse completions of input images, but cross-modal hallucinations of audio or image signals. finally, we show that by walking across the underlying manifold of gem, we may generate new samples in our signal domains. code and additional results are available at https://yilundu.github.io/gem/.",,2021-11-11,,"['yilun du', 'katherine m. collins', 'joshua b. tenenbaum', 'vincent sitzmann']"
2111.06389,full-body visual self-modeling of robot morphologies,cs.ro cs.ai cs.cv cs.lg cs.sy eess.sy,"internal computational models of physical bodies are fundamental to the ability of robots and animals alike to plan and control their actions. these ""self-models"" allow robots to consider outcomes of multiple possible future actions, without trying them out in physical reality. recent progress in fully data-driven self-modeling has enabled machines to learn their own forward kinematics directly from task-agnostic interaction data. however, forward-kinema\-tics models can only predict limited aspects of the morphology, such as the position of end effectors or velocity of joints and masses. a key challenge is to model the entire morphology and kinematics, without prior knowledge of what aspects of the morphology will be relevant to future tasks. here, we propose that instead of directly modeling forward-kinematics, a more useful form of self-modeling is one that could answer space occupancy queries, conditioned on the robot's state. such query-driven self models are continuous in the spatial domain, memory efficient, fully differentiable and kinematic aware. in physical experiments, we demonstrate how a visual self-model is accurate to about one percent of the workspace, enabling the robot to perform various motion planning and control tasks. visual self-modeling can also allow the robot to detect, localize and recover from real-world damage, leading to improved machine resiliency. our project website is at: https://robot-morphology.cs.columbia.edu/",,2021-11-11,,"['boyuan chen', 'robert kwiatkowski', 'carl vondrick', 'hod lipson']"
2111.06390,full characterization of adaptively strong majority voting in   crowdsourcing,stat.ap cs.ai cs.gt cs.hc,"a commonly used technique for quality control in crowdsourcing is to task the workers with examining an item and voting on whether the item is labeled correctly. to counteract possible noise in worker responses, one solution is to keep soliciting votes from more workers until the difference between the numbers of votes for the two possible outcomes exceeds a pre-specified threshold {\delta}. we show a way to model such {\delta}-margin voting consensus aggregation process using absorbing markov chains. we provide closed-form equations for the key properties of this voting process -- namely, for the quality of the results, the expected number of votes to completion, the variance of the required number of votes, and other moments of the distribution. using these results, we show further that one can adapt the value of the threshold {\delta} to achieve quality-equivalence across voting processes that employ workers of different accuracy levels. we then use this result to provide efficiency-equalizing payment rates for groups of workers characterized by different levels of response accuracy. finally, we perform a set of simulated experiments using both fully synthetic data as well as real-life crowdsourced votes. we show that our theoretical model characterizes the outcomes of the consensus aggregation process well.",,2021-11-11,,"['margarita boyarskaya', 'panos ipeirotis']"
2111.06420,explainable ai (xai): a systematic meta-survey of current challenges and   future opportunities,cs.lg cs.ai,"the past decade has seen significant progress in artificial intelligence (ai), which has resulted in algorithms being adopted for resolving a variety of problems. however, this success has been met by increasing model complexity and employing black-box ai models that lack transparency. in response to this need, explainable ai (xai) has been proposed to make ai more transparent and thus advance the adoption of ai in critical domains. although there are several reviews of xai topics in the literature that identified challenges and potential research directions in xai, these challenges and research directions are scattered. this study, hence, presents a systematic meta-survey for challenges and future research directions in xai organized in two themes: (1) general challenges and research directions in xai and (2) challenges and research directions in xai based on machine learning life cycle's phases: design, development, and deployment. we believe that our meta-survey contributes to xai literature by providing a guide for future exploration in the xai area.",,2021-11-11,,"['waddah saeed', 'christian omlin']"
2111.06440,personalized multi-faceted trust modeling to determine trust links in   social media and its potential for misinformation management,cs.si cs.ai,"in this paper, we present an approach for predicting trust links between peers in social media, one that is grounded in the artificial intelligence area of multiagent trust modeling. in particular, we propose a data-driven multi-faceted trust modeling which incorporates many distinct features for a comprehensive analysis. we focus on demonstrating how clustering of similar users enables a critical new functionality: supporting more personalized, and thus more accurate predictions for users. illustrated in a trust-aware item recommendation task, we evaluate the proposed framework in the context of a large yelp dataset. we then discuss how improving the detection of trusted relationships in social media can assist in supporting online users in their battle against the spread of misinformation and rumours, within a social networking environment which has recently exploded in popularity. we conclude with a reflection on a particularly vulnerable user base, older adults, in order to illustrate the value of reasoning about groups of users, looking to some future directions for integrating known preferences with insights gained through data analysis.",,2021-11-11,,"['alexandre parmentier', 'robin cohen', 'xueguang ma', 'gaurav sahu', 'queenie chen']"
2111.06447,observation error covariance specification in dynamical systems for data   assimilation using recurrent neural networks,cs.lg cs.ai cs.na math.na,"data assimilation techniques are widely used to predict complex dynamical systems with uncertainties, based on time-series observation data. error covariance matrices modelling is an important element in data assimilation algorithms which can considerably impact the forecasting accuracy. the estimation of these covariances, which usually relies on empirical assumptions and physical constraints, is often imprecise and computationally expensive especially for systems of large dimension. in this work, we propose a data-driven approach based on long short term memory (lstm) recurrent neural networks (rnn) to improve both the accuracy and the efficiency of observation covariance specification in data assimilation for dynamical systems. learning the covariance matrix from observed/simulated time-series data, the proposed approach does not require any knowledge or assumption about prior error distribution, unlike classical posterior tuning methods. we have compared the novel approach with two state-of-the-art covariance tuning algorithms, namely di01 and d05, first in a lorenz dynamical system and then in a 2d shallow water twin experiments framework with different covariance parameterization using ensemble assimilation. this novel method shows significant advantages in observation covariance specification, assimilation accuracy and computational efficiency.",,2021-11-11,,"['sibo cheng', 'mingming qiu']"
2111.06449,expert human-level driving in gran turismo sport using deep   reinforcement learning with image-based representation,cs.ai cs.cv,"when humans play virtual racing games, they use visual environmental information on the game screen to understand the rules within the environments. in contrast, a state-of-the-art realistic racing game ai agent that outperforms human players does not use image-based environmental information but the compact and precise measurements provided by the environment. in this paper, a vision-based control algorithm is proposed and compared with human player performances under the same conditions in realistic racing scenarios using gran turismo sport (gts), which is known as a high-fidelity realistic racing simulator. in the proposed method, the environmental information that constitutes part of the observations in conventional state-of-the-art methods is replaced with feature representations extracted from game screen images. we demonstrate that the proposed method performs expert human-level vehicle control under high-speed driving scenarios even with game screen images as high-dimensional inputs. additionally, it outperforms the built-in ai in gts in a time trial task, and its score places it among the top 10% approximately 28,000 human players.",,2021-11-11,,"['ryuji imamura', 'takuma seno', 'kenta kawamoto', 'michael spranger']"
2111.06464,catalytic role of noise and necessity of inductive biases in the   emergence of compositional communication,cs.lg cs.ai cs.cl,"communication is compositional if complex signals can be represented as a combination of simpler subparts. in this paper, we theoretically show that inductive biases on both the training framework and the data are needed to develop a compositional communication. moreover, we prove that compositionality spontaneously arises in the signaling games, where agents communicate over a noisy channel. we experimentally confirm that a range of noise levels, which depends on the model and the data, indeed promotes compositionality. finally, we provide a comprehensive study of this dependence and report results in terms of recently studied compositionality metrics: topographical similarity, conflict count, and context independence.",,2021-11-11,,"['łukasz kuciński', 'tomasz korbak', 'paweł kołodziej', 'piotr miłoś']"
2111.06467,synthbio: a case study in human-ai collaborative curation of text   datasets,cs.cl cs.ai cs.lg,"nlp researchers need more, higher-quality text datasets. human-labeled datasets are expensive to collect, while datasets collected via automatic retrieval from the web such as wikibio are noisy and can include undesired biases. moreover, data sourced from the web is often included in datasets used to pretrain models, leading to inadvertent cross-contamination of training and test sets. in this work we introduce a novel method for efficient dataset curation: we use a large language model to provide seed generations to human raters, thereby changing dataset authoring from a writing task to an editing task. we use our method to curate synthbio - a new evaluation set for wikibio - composed of structured attribute lists describing fictional individuals, mapped to natural language biographies. we show that our dataset of fictional biographies is less noisy than wikibio, and also more balanced with respect to gender and nationality.",,2021-11-11,,"['ann yuan', 'daphne ippolito', 'vitaly nikolaev', 'chris callison-burch', 'andy coenen', 'sebastian gehrmann']"
2111.06483,sequential aggregation and rematerialization: distributed full-batch   training of graph neural networks on large graphs,cs.lg cs.ai,"we present the sequential aggregation and rematerialization (sar) scheme for distributed full-batch training of graph neural networks (gnns) on large graphs. large-scale training of gnns has recently been dominated by sampling-based methods and methods based on non-learnable message passing. sar on the other hand is a distributed technique that can train any gnn type directly on an entire large graph. the key innovation in sar is the distributed sequential rematerialization scheme which sequentially re-constructs then frees pieces of the prohibitively large gnn computational graph during the backward pass. this results in excellent memory scaling behavior where the memory consumption per worker goes down linearly with the number of workers, even for densely connected graphs. using sar, we report the largest applications of full-batch gnn training to-date, and demonstrate large memory savings as the number of workers increases. we also present a general technique based on kernel fusion and attention-matrix rematerialization to optimize both the runtime and memory efficiency of attention-based models. we show that, coupled with sar, our optimized attention kernels lead to significant speedups and memory savings in attention-based gnns.",,2021-11-11,,['hesham mostafa']
2111.06486,variational auto-encoder architectures that excel at causal inference,cs.lg cs.ai stat.ml,"estimating causal effects from observational data (at either an individual -- or a population -- level) is critical for making many types of decisions. one approach to address this task is to learn decomposed representations of the underlying factors of data; this becomes significantly more challenging when there are confounding factors (which influence both the cause and the effect). in this paper, we take a generative approach that builds on the recent advances in variational auto-encoders to simultaneously learn those underlying factors as well as the causal effects. we propose a progressive sequence of models, where each improves over the previous one, culminating in the hybrid model. our empirical results demonstrate that the performance of all three proposed models are superior to both state-of-the-art discriminative as well as other generative approaches in the literature.",,2021-11-11,,"['negar hassanpour', 'russell greiner']"
2111.06494,dpll(mapf): an integration of multi-agent path finding and sat solving   technologies,cs.ai cs.ma,"in multi-agent path finding (mapf), the task is to find non-conflicting paths for multiple agents from their initial positions to given individual goal positions. mapf represents a classical artificial intelligence problem often addressed by heuristic-search. an important alternative to search-based techniques is compilation of mapf to a different formalism such as boolean satisfiability (sat). contemporary sat-based approaches to mapf regard the sat solver as an external tool whose task is to return an assignment of all decision variables of a boolean model of input mapf. we present in this short paper a novel compilation scheme called dpll(mapf) in which the consistency checking of partial assignments of decision variables with respect to the mapf rules is integrated directly into the sat solver. this scheme allows for far more automated compilation where the sat solver and the consistency checking procedure work together simultaneously to create the boolean model and to search for its satisfying assignment.",,2021-11-11,,"['martin čapek', 'pavel surynek']"
2111.06532,nonlinear tensor ring network,cs.lg cs.ai eess.iv,"the state-of-the-art deep neural networks (dnns) have been widely applied for various real-world applications, and achieved significant performance for cognitive problems. however, the increment of dnns' width and depth in architecture results in a huge amount of parameters to challenge the storage and memory cost, limiting to the usage of dnns on resource-constrained platforms, such as portable devices. by converting redundant models into compact ones, compression technique appears to be a practical solution to reducing the storage and memory consumption. in this paper, we develop a nonlinear tensor ring network (ntrn) in which both fullyconnected and convolutional layers are compressed via tensor ring decomposition. furthermore, to mitigate the accuracy loss caused by compression, a nonlinear activation function is embedded into the tensor contraction and convolution operations inside the compressed layer. experimental results demonstrate the effectiveness and superiority of the proposed ntrn for image classification using two basic neural networks, lenet-5 and vgg-11 on three datasets, viz. mnist, fashion mnist and cifar-10.",,2021-11-11,,"['xiao peng li', 'qi liu', 'hing cheung so']"
2111.06575,self-supervised gan detector,cs.cv cs.ai,"although the recent advancement in generative models brings diverse advantages to society, it can also be abused with malicious purposes, such as fraud, defamation, and fake news. to prevent such cases, vigorous research is conducted to distinguish the generated images from the real images, but challenges still remain to distinguish the unseen generated images outside of the training settings. such limitations occur due to data dependency arising from the model's overfitting issue to the training data generated by specific gans. to overcome this issue, we adopt a self-supervised scheme to propose a novel framework. our proposed method is composed of the artificial fingerprint generator reconstructing the high-quality artificial fingerprints of gan images for detailed analysis, and the gan detector distinguishing gan images by learning the reconstructed artificial fingerprints. to improve the generalization of the artificial fingerprint generator, we build multiple autoencoders with different numbers of upconvolution layers. with numerous ablation studies, the robust generalization of our method is validated by outperforming the generalization of the previous state-of-the-art algorithms, even without utilizing the gan images of the training dataset.",,2021-11-12,,"['yonghyun jeong', 'doyeon kim', 'pyounggeon kim', 'youngmin ro', 'jongwon choi']"
2111.06580,on-the-fly rectification for robust large-vocabulary topic inference,cs.cl cs.ai cs.lg,"across many data domains, co-occurrence statistics about the joint appearance of objects are powerfully informative. by transforming unsupervised learning problems into decompositions of co-occurrence statistics, spectral algorithms provide transparent and efficient algorithms for posterior inference such as latent topic analysis and community detection. as object vocabularies grow, however, it becomes rapidly more expensive to store and run inference algorithms on co-occurrence statistics. rectifying co-occurrence, the key process to uphold model assumptions, becomes increasingly more vital in the presence of rare terms, but current techniques cannot scale to large vocabularies. we propose novel methods that simultaneously compress and rectify co-occurrence statistics, scaling gracefully with the size of vocabulary and the dimension of latent space. we also present new algorithms learning latent variables from the compressed statistics, and verify that our methods perform comparably to previous approaches on both textual and non-textual data.",,2021-11-12,,"['moontae lee', 'sungjun cho', 'kun dong', 'david mimno', 'david bindel']"
2111.06599,pesto: switching point based dynamic and relative positional encoding   for code-mixed languages,cs.cl cs.ai cs.lg,"nlp applications for code-mixed (cm) or mix-lingual text have gained a significant momentum recently, the main reason being the prevalence of language mixing in social media communications in multi-lingual societies like india, mexico, europe, parts of usa etc. word embeddings are basic build-ing blocks of any nlp system today, yet, word embedding for cm languages is an unexplored territory. the major bottleneck for cm word embeddings is switching points, where the language switches. these locations lack in contextually and statistical systems fail to model this phenomena due to high variance in the seen examples. in this paper we present our initial observations on applying switching point based positional encoding techniques for cm language, specifically hinglish (hindi - english). results are only marginally better than sota, but it is evident that positional encoding could bean effective way to train position sensitive language models for cm text.",,2021-11-12,,"['mohsin ali', 'kandukuri sai teja', 'sumanth manduru', 'parth patwa', 'amitava das']"
2111.06625,a convolutional neural network based approach to recognize bangla spoken   digits from speech signal,cs.sd cs.ai cs.cl cs.lg,"speech recognition is a technique that converts human speech signals into text or words or in any form that can be easily understood by computers or other machines. there have been a few studies on bangla digit recognition systems, the majority of which used small datasets with few variations in genders, ages, dialects, and other variables. audio recordings of bangladeshi people of various genders, ages, and dialects were used to create a large speech dataset of spoken '0-9' bangla digits in this study. here, 400 noisy and noise-free samples per digit have been recorded for creating the dataset. mel frequency cepstrum coefficients (mfccs) have been utilized for extracting meaningful features from the raw speech data. then, to detect bangla numeral digits, convolutional neural networks (cnns) were utilized. the suggested technique recognizes '0-9' bangla spoken digits with 97.1% accuracy throughout the whole dataset. the efficiency of the model was also assessed using 10-fold crossvalidation, which yielded a 96.7% accuracy.",,2021-11-12,,"['ovishake sen', 'n/a al-mahmud', 'pias roy']"
2111.06638,meta-teacher for face anti-spoofing,cs.cv cs.ai,"face anti-spoofing (fas) secures face recognition from presentation attacks (pas). existing fas methods usually supervise pa detectors with handcrafted binary or pixel-wise labels. however, handcrafted labels may are not the most adequate way to supervise pa detectors learning sufficient and intrinsic spoofing cues. instead of using the handcrafted labels, we propose a novel meta-teacher fas (mt-fas) method to train a meta-teacher for supervising pa detectors more effectively. the meta-teacher is trained in a bi-level optimization manner to learn the ability to supervise the pa detectors learning rich spoofing cues. the bi-level optimization contains two key components: 1) a lower-level training in which the meta-teacher supervises the detector's learning process on the training set; and 2) a higher-level training in which the meta-teacher's teaching performance is optimized by minimizing the detector's validation loss. our meta-teacher differs significantly from existing teacher-student models because the meta-teacher is explicitly trained for better teaching the detector (student), whereas existing teachers are trained for outstanding accuracy neglecting teaching ability. extensive experiments on five fas benchmarks show that with the proposed mt-fas, the trained meta-teacher 1) provides better-suited supervision than both handcrafted labels and existing teacher-student models; and 2) significantly improves the performances of pa detectors.",,2021-11-12,,"['yunxiao qin', 'zitong yu', 'longbin yan', 'zezheng wang', 'chenxu zhao', 'zhen lei']"
2111.06639,attention guided cosine margin for overcoming class-imbalance in   few-shot road object detection,cs.cv cs.ai,"few-shot object detection (fsod) localizes and classifies objects in an image given only a few data samples. recent trends in fsod research show the adoption of metric and meta-learning techniques, which are prone to catastrophic forgetting and class confusion. to overcome these pitfalls in metric learning based fsod techniques, we introduce attention guided cosine margin (agcm) that facilitates the creation of tighter and well separated class-specific feature clusters in the classification head of the object detector. our novel attentive proposal fusion (apf) module minimizes catastrophic forgetting by reducing the intra-class variance among co-occurring classes. at the same time, the proposed cosine margin cross-entropy loss increases the angular margin between confusing classes to overcome the challenge of class confusion between already learned (base) and newly added (novel) classes. we conduct our experiments on the challenging india driving dataset (idd), which presents a real-world class-imbalanced setting alongside popular fsod benchmark pascal-voc. our method outperforms state-of-the-art (sota) approaches by up to 6.4 map points on the idd-os and up to 2.0 map points on the idd-10 splits for the 10-shot setting. on the pascal-voc dataset, we outperform existing sota approaches by up to 4.9 map points.",,2021-11-12,,"['ashutosh agarwal', 'anay majee', 'anbumani subramanian', 'chetan arora']"
2111.06679,deepstruct -- linking deep learning and graph theory,cs.lg cs.ai cs.ne,"deepstruct connects deep learning models and graph theory such that different graph structures can be imposed on neural networks or graph structures can be extracted from trained neural network models. for this, deepstruct provides deep neural network models with different restrictions which can be created based on an initial graph. further, tools to extract graph structures from trained models are available. this step of extracting graphs can be computationally expensive even for models of just a few dozen thousand parameters and poses a challenging problem.   deepstruct supports research in pruning, neural architecture search, automated network design and structure analysis of neural networks.",,2021-11-12,,"['julian stier', 'michael granitzer']"
2111.06721,causal multi-agent reinforcement learning: review and open problems,cs.lg cs.ai stat.ml,"this paper serves to introduce the reader to the field of multi-agent reinforcement learning (marl) and its intersection with methods from the study of causality. we highlight key challenges in marl and discuss these in the context of how causal methods may assist in tackling them. we promote moving toward a 'causality first' perspective on marl. specifically, we argue that causality can offer improved safety, interpretability, and robustness, while also providing strong theoretical guarantees for emergent behaviour. we discuss potential solutions for common challenges, and use this context to motivate future research directions.",,2021-11-12,,"['st john grimbly', 'jonathan shock', 'arnu pretorius']"
2111.06726,one model packs thousands of items with recurrent conditional query   learning,cs.ai cs.lg cs.ne,"recent studies have revealed that neural combinatorial optimization (nco) has advantages over conventional algorithms in many combinatorial optimization problems such as routing, but it is less efficient for more complicated optimization tasks such as packing which involves mutually conditioned action spaces. in this paper, we propose a recurrent conditional query learning (rcql) method to solve both 2d and 3d packing problems. we first embed states by a recurrent encoder, and then adopt attention with conditional queries from previous actions. the conditional query mechanism fills the information gap between learning steps, which shapes the problem as a markov decision process. benefiting from the recurrence, a single rcql model is capable of handling different sizes of packing problems. experiment results show that rcql can effectively learn strong heuristics for offline and online strip packing problems (spps), outperforming a wide range of baselines in space utilization ratio. rcql reduces the average bin gap ratio by 1.83% in offline 2d 40-box cases and 7.84% in 3d cases compared with state-of-the-art methods. meanwhile, our method also achieves 5.64% higher space utilization ratio for spps with 1000 items than the state of the art.",10.1016/j.knosys.2021.107683,2021-11-12,,"['dongda li', 'zhaoquan gu', 'yuexuan wang', 'changwei ren', 'francis c. m. lau']"
2111.06741,a quantum natural language processing approach to musical intelligence,quant-ph cs.ai,"there has been tremendous progress in artificial intelligence (ai) for music, in particular for musical composition and access to large databases for commercialisation through the internet. we are interested in further advancing this field, focusing on composition. in contrast to current black-box ai methods, we are championing an interpretable compositional outlook on generative music systems. in particular, we are importing methods from the distributional compositional categorical (discocat) modelling framework for natural language processing (nlp), motivated by musical grammars. quantum computing is a nascent technology, which is very likely to impact the music industry in time to come. thus, we are pioneering a quantum natural language processing (qnlp) approach to develop a new generation of intelligent musical systems. this work follows from previous experimental implementations of discocat linguistic models on quantum hardware. in this chapter, we present quanthoven, the first proof-of-concept ever built, which (a) demonstrates that it is possible to program a quantum computer to learn to classify music that conveys different meanings and (b) illustrates how such a capability might be leveraged to develop a system to compose meaningful pieces of music. after a discussion about our current understanding of music as a communication medium and its relationship to natural language, the chapter focuses on the techniques developed to (a) encode musical compositions as quantum circuits, and (b) design a quantum classifier. the chapter ends with demonstrations of compositions created with the system.",,2021-11-10,,"['eduardo reck miranda', 'richie yeung', 'anna pearson', 'konstantinos meichanetzidis', 'bob coecke']"
2111.06750,stfl: a temporal-spatial federated learning framework for graph neural   networks,cs.lg cs.ai,"we present a spatial-temporal federated learning framework for graph neural networks, namely stfl. the framework explores the underlying correlation of the input spatial-temporal data and transform it to both node features and adjacency matrix. the federated learning setting in the framework ensures data privacy while achieving a good model generalization. experiments results on the sleep stage dataset, isruc_s3, illustrate the effectiveness of stfl on graph prediction tasks.",,2021-11-12,,"['guannan lou', 'yuze liu', 'tiehua zhang', 'xi zheng']"
2111.06757,multiway storage modification machines,cs.ai cs.cc,"we present a parallel version of sch\""onhage's storage modification machine, the multiway storage modification machine (mwsmm). like the alternative association storage modification machine of tromp and van emde boas, mwsmms recognize in polynomial time what turing machines recognize in polynomial space. falling thus into the second machine class, the mwsmm is a parallel machine model conforming to the parallel computation thesis. we illustrate mwsmms by a simple implementation of wolfram's string substitution system.",,2021-11-12,,['j. -m. chauvet']
2111.06773,explainability and the fourth ai revolution,cs.ai cs.cy cs.hc cs.lg,"this chapter discusses ai from the prism of an automated process for the organization of data, and exemplifies the role that explainability has to play in moving from the current generation of ai systems to the next one, where the role of humans is lifted from that of data annotators working for the ai systems to that of collaborators working with the ai systems.",,2021-11-12,,['loizos michael']
2111.06780,awd3: dynamic reduction of the estimation bias,cs.lg cs.ai,"value-based deep reinforcement learning (rl) algorithms suffer from the estimation bias primarily caused by function approximation and temporal difference (td) learning. this problem induces faulty state-action value estimates and therefore harms the performance and robustness of the learning algorithms. although several techniques were proposed to tackle, learning algorithms still suffer from this bias. here, we introduce a technique that eliminates the estimation bias in off-policy continuous control algorithms using the experience replay mechanism. we adaptively learn the weighting hyper-parameter beta in the weighted twin delayed deep deterministic policy gradient algorithm. our method is named adaptive-wd3 (awd3). we show through continuous control environments of openai gym that our algorithm matches or outperforms the state-of-the-art off-policy policy gradient learning algorithms.",,2021-11-12,,"['dogan c. cicek', 'enes duran', 'baturay saglam', 'kagan kaya', 'furkan b. mutlu', 'suleyman s. kozat']"
2111.06803,two steps to risk sensitivity,cs.ai,"distributional reinforcement learning (rl) -- in which agents learn about all the possible long-term consequences of their actions, and not just the expected value -- is of great recent interest. one of the most important affordances of a distributional view is facilitating a modern, measured, approach to risk when outcomes are not completely certain. by contrast, psychological and neuroscientific investigations into decision making under risk have utilized a variety of more venerable theoretical models such as prospect theory that lack axiomatically desirable properties such as coherence. here, we consider a particularly relevant risk measure for modeling human and animal planning, called conditional value-at-risk (cvar), which quantifies worst-case outcomes (e.g., vehicle accidents or predation). we first adopt a conventional distributional approach to cvar in a sequential setting and reanalyze the choices of human decision-makers in the well-known two-step task, revealing substantial risk aversion that had been lurking under stickiness and perseveration. we then consider a further critical property of risk sensitivity, namely time consistency, showing alternatives to this form of cvar that enjoy this desirable characteristic. we use simulations to examine settings in which the various forms differ in ways that have implications for human and animal planning and behavior.",,2021-11-12,,"['chris gagne', 'peter dayan']"
2111.06804,"catastrophe, compounding & consistency in choice",cs.ai,"conditional value-at-risk (cvar) precisely characterizes the influence that rare, catastrophic events can exert over decisions. such characterizations are important for both normal decision-making and for psychiatric conditions such as anxiety disorders -- especially for sequences of decisions that might ultimately lead to disaster. cvar, like other well-founded risk measures, compounds in complex ways over such sequences -- and we recently formalized three structurally different forms in which risk either averages out or multiplies. unfortunately, existing cognitive tasks fail to discriminate these approaches well; here, we provide examples that highlight their unique characteristics, and make formal links to temporal discounting for the two of the approaches that are time consistent. these examples can ground future experiments with the broader aim of characterizing risk attitudes, especially for longer horizon problems and in psychopathological populations.",,2021-11-12,,"['chris gagne', 'peter dayan']"
2111.06827,nrc-gamma: introducing a novel large gas meter image dataset,cs.cv cs.ai cs.lg,"automatic meter reading technology is not yet widespread. gas, electricity, or water accumulation meters reading is mostly done manually on-site either by an operator or by the homeowner. in some countries, the operator takes a picture as reading proof to confirm the reading by checking offline with another operator and/or using it as evidence in case of conflicts or complaints. the whole process is time-consuming, expensive, and prone to errors. automation can optimize and facilitate such labor-intensive and human error-prone processes. with the recent advances in the fields of artificial intelligence and computer vision, automatic meter reading systems are becoming more viable than ever. motivated by the recent advances in the field of artificial intelligence and inspired by open-source open-access initiatives in the research community, we introduce a novel large benchmark dataset of real-life gas meter images, named the nrc-gamma dataset. the data were collected from an itron 400a diaphragm gas meter on january 20, 2020, between 00:05 am and 11:59 pm. we employed a systematic approach to label the images, validate the labellings, and assure the quality of the annotations. the dataset contains 28,883 images of the entire gas meter along with 57,766 cropped images of the left and the right dial displays. we hope the nrc-gamma dataset helps the research community to design and implement accurate, innovative, intelligent, and reproducible automatic gas meter reading solutions.",,2021-11-12,,"['ashkan ebadi', 'patrick paul', 'sofia auer', 'stéphane tremblay']"
2111.06852,influential papers in artificial intelligence and paediatrics: assessing   rpys by experts review,cs.dl cs.ai,"the use of artificial intelligence in paediatrics has vastly increased in the last few years. interestingly, no historical bibliometric study analysing the knowledge development in this specific paediatric field has been performed yet, thus our study aimed to close this gap. references publication years spectrography (rpys), more precisely citedreferenceexplorer (cre) software tool was employed to achieve this aim. we identified 28 influential papers and domain experts validation showed that both, the rpys method and cre tool performed adequately in the identification process.",,2021-10-27,,"['peter kokol', 'jernej završnik', 'helena blažun vošner']"
2111.06854,time in a box: advancing knowledge graph completion with temporal scopes,cs.ai,"almost all statements in knowledge bases have a temporal scope during which they are valid. hence, knowledge base completion (kbc) on temporal knowledge bases (tkb), where each statement \textit{may} be associated with a temporal scope, has attracted growing attention. prior works assume that each statement in a tkb \textit{must} be associated with a temporal scope. this ignores the fact that the scoping information is commonly missing in a kb. thus prior work is typically incapable of handling generic use cases where a tkb is composed of temporal statements with/without a known temporal scope. in order to address this issue, we establish a new knowledge base embedding framework, called time2box, that can deal with atemporal and temporal statements of different types simultaneously. our main insight is that answers to a temporal query always belong to a subset of answers to a time-agnostic counterpart. put differently, time is a filter that helps pick out answers to be correct during certain periods. we introduce boxes to represent a set of answer entities to a time-agnostic query. the filtering functionality of time is modeled by intersections over these boxes. in addition, we generalize current evaluation protocols on time interval prediction. we describe experiments on two datasets and show that the proposed method outperforms state-of-the-art (sota) methods on both link prediction and time prediction.",10.1145/3460210.3493566,2021-11-12,,"['ling cai', 'krzysztof janowic', 'bo yan', 'rui zhu', 'gengchen mai']"
2111.06902,ms-latte: a dataset of where and when to-do tasks are completed,cs.cl cs.ai,"tasks are a fundamental unit of work in the daily lives of people, who are increasingly using digital means to keep track of, organize, triage and act on them. these digital tools -- such as task management applications -- provide a unique opportunity to study and understand tasks and their connection to the real world, and through intelligent assistance, help people be more productive. by logging signals such as text, timestamp information, and social connectivity graphs, an increasingly rich and detailed picture of how tasks are created and organized, what makes them important, and who acts on them, can be progressively developed. yet the context around actual task completion remains fuzzy, due to the basic disconnect between actions taken in the real world and telemetry recorded in the digital world. thus, in this paper we compile and release a novel, real-life, large-scale dataset called ms-latte that captures two core aspects of the context surrounding task completion: location and time. we describe our annotation framework and conduct a number of analyses on the data that were collected, demonstrating that it captures intuitive contextual properties for common tasks. finally, we test the dataset on the two problems of predicting spatial and temporal task co-occurrence, concluding that predictors for co-location and co-time are both learnable, with a bert fine-tuned model outperforming several other baselines. the ms-latte dataset provides an opportunity to tackle many new modeling challenges in contextual task understanding and we hope that its release will spur future research in task intelligence more broadly.",,2021-11-12,,"['sujay kumar jauhar', 'nirupama chandrasekaran', 'michael gamon', 'ryen w. white']"
2111.06908,explainable ai for psychological profiling from digital footprints: a   case study of big five personality predictions from spending data,cs.ai,"every step we take in the digital world leaves behind a record of our behavior; a digital footprint. research has suggested that algorithms can translate these digital footprints into accurate estimates of psychological characteristics, including personality traits, mental health or intelligence. the mechanisms by which ai generates these insights, however, often remain opaque. in this paper, we show how explainable ai (xai) can help domain experts and data subjects validate, question, and improve models that classify psychological traits from digital footprints. we elaborate on two popular xai methods (rule extraction and counterfactual explanations) in the context of big five personality predictions (traits and facets) from financial transactions data (n = 6,408). first, we demonstrate how global rule extraction sheds light on the spending patterns identified by the model as most predictive for personality, and discuss how these rules can be used to explain, validate, and improve the model. second, we implement local rule extraction to show that individuals are assigned to personality classes because of their unique financial behavior, and that there exists a positive link between the model's prediction confidence and the number of features that contributed to the prediction. our experiments highlight the importance of both global and local xai methods. by better understanding how predictive models work in general as well as how they derive an outcome for a particular person, xai promotes accountability in a world in which ai impacts the lives of billions of people around the world.",,2021-11-12,,"['yanou ramon', 'sandra c. matz', 'r. a. farrokhnia', 'david martens']"
2111.06916,offense detection in dravidian languages using code-mixing index based   focal loss,cs.cl cs.ai cs.lg,"over the past decade, we have seen exponential growth in online content fueled by social media platforms. data generation of this scale comes with the caveat of insurmountable offensive content in it. the complexity of identifying offensive content is exacerbated by the usage of multiple modalities (image, language, etc.), code mixed language and more. moreover, even if we carefully sample and annotate offensive content, there will always exist significant class imbalance in offensive vs non offensive content. in this paper, we introduce a novel code-mixing index (cmi) based focal loss which circumvents two challenges (1) code mixing in languages (2) class imbalance problem for dravidian language offense detection. we also replace the conventional dot product-based classifier with the cosine-based classifier which results in a boost in performance. further, we use multilingual models that help transfer characteristics learnt across languages to work effectively with low resourced languages. it is also important to note that our model handles instances of mixed script (say usage of latin and dravidian - tamil script) as well. our model can handle offensive language detection in a low-resource, class imbalanced, multilingual and code mixed setting.",,2021-11-12,,"['debapriya tula', 'shreyas ms', 'viswanatha reddy', 'pranjal sahu', 'sumanth doddapaneni', 'prathyush potluri', 'rohan sukumaran', 'parth patwa']"
2111.06928,generalized nested rollout policy adaptation with dynamic bias for   vehicle routing,cs.ai,"in this paper we present an extension of the nested rollout policy adaptation algorithm (nrpa), namely the generalized nested rollout policy adaptation (gnrpa), as well as its use for solving some instances of the vehicle routing problem. we detail some results obtained on the solomon instances set which is a conventional benchmark for the vehicle routing problem (vrp). we show that on all instances, gnrpa performs better than nrpa. on some instances, it performs better than the google or tool module dedicated to vrp.",,2021-11-12,,"['julien sentuc', 'tristan cazenave', 'jean-yves lucas']"
2111.06929,hierarchical bayesian bandits,cs.lg cs.ai,"meta-, multi-task, and federated learning can be all viewed as solving similar tasks, drawn from an unknown distribution that reflects task similarities. in this work, we provide a unified view of all these problems, as learning to act in a hierarchical bayesian bandit. we analyze a natural hierarchical thompson sampling algorithm (hierts) that can be applied to any problem in this class. our regret bounds hold under many instances of such problems, including when the tasks are solved sequentially or in parallel; and capture the structure of the problems, such that the regret decreases with the width of the task prior. our proofs rely on novel total variance decompositions, which can be applied to other graphical model structures. finally, our theory is complemented by experiments, which show that the hierarchical structure helps with knowledge sharing among the tasks. this confirms that hierarchical bayesian bandits are a universal and statistically-efficient tool for learning to act with similar bandit tasks.",,2021-11-12,,"['joey hong', 'branislav kveton', 'manzil zaheer', 'mohammad ghavamzadeh']"
2111.06942,"predictive coding, precision and natural gradients",cs.lg cs.ai cs.ne,"there is an increasing convergence between biologically plausible computational models of inference and learning with local update rules and the global gradient-based optimization of neural network models employed in machine learning. one particularly exciting connection is the correspondence between the locally informed optimization in predictive coding networks and the error backpropagation algorithm that is used to train state-of-the-art deep artificial neural networks. here we focus on the related, but still largely under-explored connection between precision weighting in predictive coding networks and the natural gradient descent algorithm for deep neural networks. precision-weighted predictive coding is an interesting candidate for scaling up uncertainty-aware optimization -- particularly for models with large parameter spaces -- due to its distributed nature of the optimization process and the underlying local approximation of the fisher information metric, the adaptive learning rate that is central to natural gradient descent. here, we show that hierarchical predictive coding networks with learnable precision indeed are able to solve various supervised and unsupervised learning tasks with performance comparable to global backpropagation with natural gradients and outperform their classical gradient descent counterpart on tasks where high amounts of noise are embedded in data or label inputs. when applied to unsupervised auto-encoding of image inputs, the deterministic network produces hierarchically organized and disentangled embeddings, hinting at the close connections between predictive coding and hierarchical variational inference.",,2021-11-12,,"['andre ofner', 'raihan kabir ratul', 'suhita ghosh', 'sebastian stober']"
2111.06945,learning interpretation with explainable knowledge distillation,cs.lg cs.ai,"knowledge distillation (kd) has been considered as a key solution in model compression and acceleration in recent years. in kd, a small student model is generally trained from a large teacher model by minimizing the divergence between the probabilistic outputs of the two. however, as demonstrated in our experiments, existing kd methods might not transfer critical explainable knowledge of the teacher to the student, i.e. the explanations of predictions made by the two models are not consistent. in this paper, we propose a novel explainable knowledge distillation model, called xdistillation, through which both the performance the explanations' information are transferred from the teacher model to the student model. the xdistillation model leverages the idea of convolutional autoencoders to approximate the teacher explanations. our experiments shows that models trained by xdistillation outperform those trained by conventional kd methods not only in term of predictive accuracy but also faithfulness to the teacher models.",,2021-11-12,,"['raed alharbi', 'minh n. vu', 'my t. thai']"
2111.06958,computational argumentation and cognition,cs.ai cs.hc,"this paper examines the interdisciplinary research question of how to integrate computational argumentation, as studied in ai, with cognition, as can be found in cognitive science, linguistics, and philosophy. it stems from the work of the 1st workshop on computational argumentation and cognition (cognitar), which was organized as part of the 24th european conference on artificial intelligence (ecai), and took place virtually on september 8th, 2020. the paper begins with a brief presentation of the scientific motivation for the integration of computational argumentation and cognition, arguing that within the context of human-centric ai the use of theory and methods from computational argumentation for the study of cognition can be a promising avenue to pursue. a short summary of each of the workshop presentations is given showing the wide spectrum of problems where the synthesis of the theory and methods of computational argumentation with other approaches that study cognition can be applied. the paper presents the main problems and challenges in the area that would need to be addressed, both at the scientific level but also at the epistemological level, particularly in relation to the synthesis of ideas and approaches from the various disciplines involved.",,2021-11-12,,"['emmanuelle dietz', 'antonis kakas', 'loizos michael']"
2111.06968,hierarchical clustering by aggregating representatives in   sub-minimum-spanning-trees,stat.ml cs.ai cs.lg,"one of the main challenges for hierarchical clustering is how to appropriately identify the representative points in the lower level of the cluster tree, which are going to be utilized as the roots in the higher level of the cluster tree for further aggregation. however, conventional hierarchical clustering approaches have adopted some simple tricks to select the ""representative"" points which might not be as representative as enough. thus, the constructed cluster tree is less attractive in terms of its poor robustness and weak reliability. aiming at this issue, we propose a novel hierarchical clustering algorithm, in which, while building the clustering dendrogram, we can effectively detect the representative point based on scoring the reciprocal nearest data points in each sub-minimum-spanning-tree. extensive experiments on uci datasets show that the proposed algorithm is more accurate than other benchmarks. meanwhile, under our analysis, the proposed algorithm has o(nlogn) time-complexity and o(logn) space-complexity, indicating that it has the scalability in handling massive data with less time and storage consumptions.",,2021-11-11,,"['wen-bo xie', 'zhen liu', 'jaideep srivastava']"
2111.06980,grassnet: graph soft sensing neural networks,cs.lg cs.ai,"in the era of big data, data-driven based classification has become an essential method in smart manufacturing to guide production and optimize inspection. the industrial data obtained in practice is usually time-series data collected by soft sensors, which are highly nonlinear, nonstationary, imbalanced, and noisy. most existing soft-sensing machine learning models focus on capturing either intra-series temporal dependencies or pre-defined inter-series correlations, while ignoring the correlation between labels as each instance is associated with multiple labels simultaneously. in this paper, we propose a novel graph based soft-sensing neural network (grassnet) for multivariate time-series classification of noisy and highly-imbalanced soft-sensing data. the proposed grassnet is able to 1) capture the inter-series and intra-series dependencies jointly in the spectral domain; 2) exploit the label correlations by superimposing label graph that built from statistical co-occurrence information; 3) learn features with attention mechanism from both textual and numerical domain; and 4) leverage unlabeled data and mitigate data imbalance by semi-supervised learning. comparative studies with other commonly used classifiers are carried out on seagate soft sensing data, and the experimental results validate the competitive performance of our proposed method.",,2021-11-12,,"['yu huang', 'chao zhang', 'jaswanth yella', 'sergei petrov', 'xiaoye qian', 'yufei tang', 'xingquan zhu', 'sthitie bom']"
2111.06982,soft sensing model visualization: fine-tuning neural network from what   model learned,cs.lg cs.ai,"the growing availability of the data collected from smart manufacturing is changing the paradigms of production monitoring and control. the increasing complexity and content of the wafer manufacturing process in addition to the time-varying unexpected disturbances and uncertainties, make it infeasible to do the control process with model-based approaches. as a result, data-driven soft-sensing modeling has become more prevalent in wafer process diagnostics. recently, deep learning has been utilized in soft sensing system with promising performance on highly nonlinear and dynamic time-series data. despite its successes in soft-sensing systems, however, the underlying logic of the deep learning framework is hard to understand. in this paper, we propose a deep learning-based model for defective wafer detection using a highly imbalanced dataset. to understand how the proposed model works, the deep visualization approach is applied. additionally, the model is then fine-tuned guided by the deep visualization. extensive experiments are performed to validate the effectiveness of the proposed system. the results provide an interpretation of how the model works and an instructive fine-tuning method based on the interpretation.",,2021-11-12,,"['xiaoye qian', 'chao zhang', 'jaswanth yella', 'yu huang', 'ming-chun huang', 'sthitie bom']"
2111.06994,learning online for unified segmentation and tracking models,cs.cv cs.ai cs.lg,"tracking requires building a discriminative model for the target in the inference stage. an effective way to achieve this is online learning, which can comfortably outperform models that are only trained offline. recent research shows that visual tracking benefits significantly from the unification of visual tracking and segmentation due to its pixel-level discrimination. however, it imposes a great challenge to perform online learning for such a unified model. a segmentation model cannot easily learn from prior information given in the visual tracking scenario. in this paper, we propose trackmlp: a novel meta-learning method optimized to learn from only partial information to resolve the imposed challenge. our model is capable of extensively exploiting limited prior information hence possesses much stronger target-background discriminability than other online learning methods. empirically, we show that our model achieves state-of-the-art performance and tangible improvement over competing models. our model achieves improved average overlaps of66.0%,67.1%, and68.5% in vot2019, vot2018, and vot2016 datasets, which are 6.4%,7.3%, and6.4% higher than our baseline. code will be made publicly available.",10.1109/ijcnn52387.2021.9533455.,2021-11-12,,"['tianyu zhu', 'rongkai ma', 'mehrtash harandi', 'tom drummond']"
2111.07001,lomef: a framework to produce local explanations for global model time   series forecasts,cs.lg cs.ai stat.ml,"global forecasting models (gfm) that are trained across a set of multiple time series have shown superior results in many forecasting competitions and real-world applications compared with univariate forecasting approaches. one aspect of the popularity of statistical forecasting models such as ets and arima is their relative simplicity and interpretability (in terms of relevant lags, trend, seasonality, and others), while gfms typically lack interpretability, especially towards particular time series. this reduces the trust and confidence of the stakeholders when making decisions based on the forecasts without being able to understand the predictions. to mitigate this problem, in this work, we propose a novel local model-agnostic interpretability approach to explain the forecasts from gfms. we train simpler univariate surrogate models that are considered interpretable (e.g., ets) on the predictions of the gfm on samples within a neighbourhood that we obtain through bootstrapping or straightforwardly as the one-step-ahead global black-box model forecasts of the time series which needs to be explained. after, we evaluate the explanations for the forecasts of the global models in both qualitative and quantitative aspects such as accuracy, fidelity, stability and comprehensibility, and are able to show the benefits of our approach.",,2021-11-12,,"['dilini rajapaksha', 'christoph bergmeir', 'rob j hyndman']"
2111.07036,introducing variational autoencoders to high school students,cs.cy cs.ai,"generative artificial intelligence (ai) models are a compelling way to introduce k-12 students to ai education using an artistic medium, and hence have drawn attention from k-12 ai educators. previous creative ai curricula mainly focus on generative adversarial networks (gans) while paying less attention to autoregressive models, variational autoencoders (vaes), or other generative models, which have since become common in the field of generative ai. vaes' latent-space structure and interpolation ability could effectively ground the interdisciplinary learning of ai, creative arts, and philosophy. thus, we designed a lesson to teach high school students about vaes. we developed a web-based game and used plato's cave, a philosophical metaphor, to introduce how vaes work. we used a google colab notebook for students to re-train vaes with their hand-written digits to consolidate their understandings. finally, we guided the exploration of creative vae tools such as sketchrnn and musicvae to draw the connection between what they learned and real-world applications. this paper describes the lesson design and shares insights from the pilot studies with 22 students. we found that our approach was effective in teaching students about a novel ai concept.",,2021-11-12,,"['zhuoyue lyu', 'safinah ali', 'cynthia breazeal']"
2111.07037,obstacle avoidance for uas in continuous action space using deep   reinforcement learning,cs.ro cs.ai,"obstacle avoidance for small unmanned aircraft is vital for the safety of future urban air mobility (uam) and unmanned aircraft system (uas) traffic management (utm). there are many techniques for real-time robust drone guidance, but many of them solve in discretized airspace and control, which would require an additional path smoothing step to provide flexible commands for uas. to provide a safe and efficient computational guidance of operations for unmanned aircraft, we explore the use of a deep reinforcement learning algorithm based on proximal policy optimization (ppo) to guide autonomous uas to their destinations while avoiding obstacles through continuous control. the proposed scenario state representation and reward function can map the continuous state space to continuous control for both heading angle and speed. to verify the performance of the proposed learning framework, we conducted numerical experiments with static and moving obstacles. uncertainties associated with the environments and safety operation bounds are investigated in detail. results show that the proposed model can provide accurate and robust guidance and resolve conflict with a success rate of over 99%.",,2021-11-12,,"['jueming hu', 'xuxi yang', 'weichang wang', 'peng wei', 'lei ying', 'yongming liu']"
2111.07039,uet-headpose: a sensor-based top-view head pose dataset,cs.cv cs.ai cs.hc,"head pose estimation is a challenging task that aims to solve problems related to predicting three dimensions vector, that serves for many applications in human-robot interaction or customer behavior. previous researches have proposed some precise methods for collecting head pose data. but those methods require either expensive devices like depth cameras or complex laboratory environment setup. in this research, we introduce a new approach with efficient cost and easy setup to collecting head pose images, namely uet-headpose dataset, with top-view head pose data. this method uses an absolute orientation sensor instead of depth cameras to be set up quickly and small cost but still ensure good results. through experiments, our dataset has been shown the difference between its distribution and available dataset like cmu panoptic dataset \cite{cmu}. besides using the uet-headpose dataset and other head pose datasets, we also introduce the full-range model called fsanet-wide, which significantly outperforms head pose estimation results by the uet-headpose dataset, especially on top-view images. also, this model is very lightweight and takes small size images.",,2021-11-12,,"['linh nguyen viet', 'tuan nguyen dinh', 'hoang nguyen viet', 'duc tran minh', 'long tran quoc']"
2111.07074,memotion analysis through the lens of joint embedding,cs.lg cs.ai cs.cl cs.cv,"joint embedding (je) is a way to encode multi-modal data into a vector space where text remains as the grounding key and other modalities like image are to be anchored with such keys. meme is typically an image with embedded text onto it. although, memes are commonly used for fun, they could also be used to spread hate and fake information. that along with its growing ubiquity over several social platforms has caused automatic analysis of memes to become a widespread topic of research. in this paper, we report our initial experiments on memotion analysis problem through joint embeddings. results are marginally yielding sota.",,2021-11-13,2021-11-17,"['nethra gunti', 'sathyanarayanan ramamoorthy', 'parth patwa', 'amitava das']"
2111.07078,networking of internet of uavs: challenges and intelligent approaches,cs.ni cs.ai,"internet of unmanned aerial vehicle (i-uav) networks promise to accomplish sensing and transmission tasks quickly, robustly, and cost-efficiently via effective cooperation among uavs. to achieve the promising benefits, the crucial i-uav networking issue should be tackled. this article argues that i-uav networking can be classified into three categories, quality-of-service (qos) driven networking, quality-of-experience (qoe) driven networking, and situation aware networking. each category of networking poses emerging challenges which have severe effects on the safe and efficient accomplishment of i-uav missions. this article elaborately analyzes these challenges and expounds on the corresponding intelligent approaches to tackle the i-uav networking issue. besides, considering the uplifting effect of extending the scalability of i-uav networks through cooperating with high altitude platforms (haps), this article gives an overview of the integrated hap and i-uav networks and presents the corresponding networking challenges and intelligent approaches.",,2021-11-13,,"['peng yang', 'xianbin cao', 'tony q. s. quek', 'dapeng oliver wu']"
2111.07083,learning data teaching strategies via knowledge tracing,cs.lg cs.ai,"teaching plays a fundamental role in human learning. typically, a human teaching strategy would involve assessing a student's knowledge progress for tailoring the teaching materials in a way that enhances the learning progress. a human teacher would achieve this by tracing a student's knowledge over important learning concepts in a task. albeit, such teaching strategy is not well exploited yet in machine learning as current machine teaching methods tend to directly assess the progress on individual training samples without paying attention to the underlying learning concepts in a learning task. in this paper, we propose a novel method, called knowledge augmented data teaching (kadt), which can optimize a data teaching strategy for a student model by tracing its knowledge progress over multiple learning concepts in a learning task. specifically, the kadt method incorporates a knowledge tracing model to dynamically capture the knowledge progress of a student model in terms of latent learning concepts. then we develop an attention pooling mechanism to distill knowledge representations of a student model with respect to class labels, which enables to develop a data teaching strategy on critical training samples. we have evaluated the performance of the kadt method on four different machine learning tasks including knowledge tracing, sentiment analysis, movie recommendation, and image classification. the results comparing to the state-of-the-art methods empirically validate that kadt consistently outperforms others on all tasks.",,2021-11-13,,"['ghodai abdelrahman', 'qing wang']"
2111.07102,deep neural networks for automatic grain-matrix segmentation in plane   and cross-polarized sandstone photomicrographs,cs.cv cs.ai,"grain segmentation of sandstone that is partitioning the grain from its surrounding matrix/cement in the thin section is the primary step for computer-aided mineral identification and sandstone classification. the microscopic images of sandstone contain many mineral grains and their surrounding matrix/cement. the distinction between adjacent grains and the matrix is often ambiguous, making grain segmentation difficult. various solutions exist in literature to handle these problems; however, they are not robust against sandstone petrography's varied pattern. in this paper, we formulate grain segmentation as a pixel-wise two-class (i.e., grain and background) semantic segmentation task. we develop a deep learning-based end-to-end trainable framework named deep semantic grain segmentation network (dsgsn), a data-driven method, and provide a generic solution. as per the authors' knowledge, this is the first work where the deep neural network is explored to solve the grain segmentation problem. extensive experiments on microscopic images highlight that our method obtains better segmentation accuracy than various segmentation architectures with more parameters.",10.1007/s10489-021-02530-z,2021-11-13,,"['rajdeep das', 'ajoy mondal', 'tapan chakraborty', 'kuntal ghosh']"
2111.07129,visual understanding of complex table structures from document images,cs.cv cs.ai,"table structure recognition is necessary for a comprehensive understanding of documents. tables in unstructured business documents are tough to parse due to the high diversity of layouts, varying alignments of contents, and the presence of empty cells. the problem is particularly difficult because of challenges in identifying individual cells using visual or linguistic contexts or both. accurate detection of table cells (including empty cells) simplifies structure extraction and hence, it becomes the prime focus of our work. we propose a novel object-detection-based deep model that captures the inherent alignments of cells within tables and is fine-tuned for fast optimization. despite accurate detection of cells, recognizing structures for dense tables may still be challenging because of difficulties in capturing long-range row/column dependencies in presence of multi-row/column spanning cells. therefore, we also aim to improve structure recognition by deducing a novel rectilinear graph-based formulation. from a semantics perspective, we highlight the significance of empty cells in a table. to take these cells into account, we suggest an enhancement to a popular evaluation criterion. finally, we introduce a modestly sized evaluation dataset with an annotation style inspired by human cognition to encourage new approaches to the problem. our framework improves the previous state-of-the-art performance by a 2.7% average f1-score on benchmark datasets.",,2021-11-13,,"['sachin raja', 'ajoy mondal', 'c v jawahar']"
2111.07138,towards one shot search space poisoning in neural architecture search,cs.lg cs.ai cs.ne,"we evaluate the robustness of a neural architecture search (nas) algorithm known as efficient nas (enas) against data agnostic poisoning attacks on the original search space with carefully designed ineffective operations. we empirically demonstrate how our one shot search space poisoning approach exploits design flaws in the enas controller to degrade predictive performance on classification tasks. with just two poisoning operations injected into the search space, we inflate prediction error rates for child networks upto 90% on the cifar-10 dataset.",,2021-11-13,,"['nayan saxena', 'robert wu', 'rohan jain']"
2111.07145,new performance measures for object tracking under complex environments,cs.cv cs.ai,"various performance measures based on the ground truth and without ground truth exist to evaluate the quality of a developed tracking algorithm. the existing popular measures - average center location error (acle) and average tracking accuracy (ata) based on ground truth, may sometimes create confusion to quantify the quality of a developed algorithm for tracking an object under some complex environments (e.g., scaled or oriented or both scaled and oriented object). in this article, we propose three new auxiliary performance measures based on ground truth information to evaluate the quality of a developed tracking algorithm under such complex environments. moreover, one performance measure is developed by combining both two existing measures acle and ata and three new proposed measures for better quantifying the developed tracking algorithm under such complex conditions. some examples and experimental results conclude that the proposed measure is better than existing measures to quantify one developed algorithm for tracking objects under such complex environments.",10.1007/s00530-021-00775-9.pdf,2021-11-13,,['ajoy mondal']
2111.07148,socialbert -- transformers for online socialnetwork language modelling,cs.cl cs.ai cs.si,"the ubiquity of the contemporary language understanding tasks gives relevance to the development of generalized, yet highly efficient models that utilize all knowledge, provided by the data source. in this work, we present socialbert - the first model that uses knowledge about the author's position in the network during text analysis. we investigate possible models for learning social network information and successfully inject it into the baseline bert model. the evaluation shows that embedding this information maintains a good generalization, with an increase in the quality of the probabilistic model for the given author up to 7.5%. the proposed model has been trained on the majority of groups for the chosen social network, and still able to work with previously unknown groups. the obtained model, as well as the code of our experiments, is available for download and use in applied tasks.",,2021-11-13,,"['ilia karpov', 'nick kartashev']"
2111.07154,session-aware item-combination recommendation with transformer network,cs.ir cs.ai,"in this paper, we detailedly describe our solution for the ieee bigdata cup 2021: rl-based recsys (track 1: item combination prediction). we first conduct an exploratory data analysis on the dataset and then utilize the findings to design our framework. specifically, we use a two-headed transformer-based network to predict user feedback and unlocked sessions, along with the proposed session-aware reweighted loss, multi-tasking with click behavior prediction, and randomness-in-session augmentation. in the final private leaderboard on kaggle, our method ranked 2nd with a categorization accuracy of 0.39224.",,2021-11-13,,"['tzu-heng lin', 'chen gao']"
2111.07158,robust deep reinforcement learning for extractive legal summarization,cs.cl cs.ai,"automatic summarization of legal texts is an important and still a challenging task since legal documents are often long and complicated with unusual structures and styles. recent advances of deep models trained end-to-end with differentiable losses can well-summarize natural text, yet when applied to legal domain, they show limited results. in this paper, we propose to use reinforcement learning to train current deep summarization models to improve their performance on the legal domain. to this end, we adopt proximal policy optimization methods and introduce novel reward functions that encourage the generation of candidate summaries satisfying both lexical and semantic criteria. we apply our method to training different summarization backbones and observe a consistent and significant performance gain across 3 public legal datasets.",,2021-11-13,,"['duy-hung nguyen', 'bao-sinh nguyen', 'nguyen viet dung nghiem', 'dung tien le', 'mim amina khatun', 'minh-tien nguyen', 'hung le']"
2111.07224,local multi-head channel self-attention for facial expression   recognition,cs.cv cs.ai,"since the transformer architecture was introduced in 2017 there has been many attempts to bring the self-attention paradigm in the field of computer vision. in this paper we propose a novel self-attention module that can be easily integrated in virtually every convolutional neural network and that is specifically designed for computer vision, the lhc: local (multi) head channel (self-attention). lhc is based on two main ideas: first, we think that in computer vision the best way to leverage the self-attention paradigm is the channel-wise application instead of the more explored spatial attention and that convolution will not be replaced by attention modules like recurrent networks were in nlp; second, a local approach has the potential to better overcome the limitations of convolution than global attention. with lhc-net we managed to achieve a new state of the art in the famous fer2013 dataset with a significantly lower complexity and impact on the ""host"" architecture in terms of computational cost when compared with the previous sota.",,2021-11-13,2021-11-18,"['roberto pecoraro', 'valerio basile', 'viviana bono', 'sara gallo']"
2111.07228,curriculum learning for vision-and-language navigation,cs.lg cs.ai cs.cl cs.cv,"vision-and-language navigation (vln) is a task where an agent navigates in an embodied indoor environment under human instructions. previous works ignore the distribution of sample difficulty and we argue that this potentially degrade their agent performance. to tackle this issue, we propose a novel curriculum-based training paradigm for vln tasks that can balance human prior knowledge and agent learning progress about training samples. we develop the principle of curriculum design and re-arrange the benchmark room-to-room (r2r) dataset to make it suitable for curriculum training. experiments show that our method is model-agnostic and can significantly improve the performance, the generalizability, and the training efficiency of current state-of-the-art navigation agents without increasing model complexity.",,2021-11-13,,"['jiwen zhang', 'zhongyu wei', 'jianqing fan', 'jiajie peng']"
2111.07238,facos: finding api relevant contents on stack overflow with semantic and   syntactic analysis,cs.se cs.ai cs.pl,"collecting api examples, usages, and mentions relevant to a specific api method over discussions on venues such as stack overflow is not a trivial problem. it requires efforts to correctly recognize whether the discussion refers to the api method that developers/tools are searching for. the content of the thread, which consists of both text paragraphs describing the involvement of the api method in the discussion and the code snippets containing the api invocation, may refer to the given api method. leveraging this observation, we develop facos, a context-specific algorithm to capture the semantic and syntactic information of the paragraphs and code snippets in a discussion. facos combines a syntactic word-based score with a score from a predictive model fine-tuned from codebert. facos beats the state-of-the-art approach by 13.9% in terms of f1-score.",,2021-11-13,,"['kien luong', 'mohammad hadi', 'ferdian thung', 'fatemeh fard', 'david lo']"
2111.07263,"code representation learning with pr\""ufer sequences",cs.ai,"an effective and efficient encoding of the source code of a computer program is critical to the success of sequence-to-sequence deep neural network models for tasks in computer program comprehension, such as automated code summarization and documentation. a significant challenge is to find a sequential representation that captures the structural/syntactic information in a computer program and facilitates the training of the learning models.   in this paper, we propose to use the pr\""ufer sequence of the abstract syntax tree (ast) of a computer program to design a sequential representation scheme that preserves the structural information in an ast. our representation makes it possible to develop deep-learning models in which signals carried by lexical tokens in the training examples can be exploited automatically and selectively based on their syntactic role and importance. unlike other recently-proposed approaches, our representation is concise and lossless in terms of the structural information of the ast. empirical studies on real-world benchmark datasets, using a sequence-to-sequence learning model we designed for code summarization, show that our pr\""ufer-sequence-based representation is indeed highly effective and efficient, outperforming significantly all the recently-proposed deep-learning models we used as the baseline models.",,2021-11-14,,"['tenzin jinpa', 'yong gao']"
2111.07265,"linear, or non-linear, that is the question!",cs.ir cs.ai cs.lg,"there were fierce debates on whether the non-linear embedding propagation of gcns is appropriate to gcn-based recommender systems. it was recently found that the linear embedding propagation shows better accuracy than the non-linear embedding propagation. since this phenomenon was discovered especially in recommender systems, it is required that we carefully analyze the linearity and non-linearity issue. in this work, therefore, we revisit the issues of i) which of the linear or non-linear propagation is better and ii) which factors of users/items decide the linearity/non-linearity of the embedding propagation. we propose a novel hybrid method of linear and non-linear collaborative filtering method (hmlet, pronounced as hamlet). in our design, there exist both linear and non-linear propagation steps, when processing each user or item node, and our gating module chooses one of them, which results in a hybrid model of the linear and non-linear gcn-based collaborative filtering (cf). the proposed model yields the best accuracy in three public benchmark datasets. moreover, we classify users/items into the following three classes depending on our gating modules' selections: full-non-linearity (fnl), partial-non-linearity (pnl), and full-linearity (fl). we found that there exist strong correlations between nodes' centrality and their class membership, i.e., important user/item nodes exhibit more preferences towards the non-linearity during the propagation steps. to our knowledge, we are the first who designs a hybrid method and reports the correlation between the graph centrality and the linearity/non-linearity of nodes. all hmlet codes and datasets are available at: https://github.com/qbxlvnf11/hmlet.",,2021-11-14,,"['taeyong kong', 'taeri kim', 'jinsung jeon', 'jeongwhan choi', 'yeon-chang lee', 'noseong park', 'sang-wook kim']"
2111.07267,cdm: combining extraction and generation for definition modeling,cs.cl cs.ai,"definitions are essential for term understanding. recently, there is an increasing interest in extracting and generating definitions of terms automatically. however, existing approaches for this task are either extractive or abstractive - definitions are either extracted from a corpus or generated by a language generation model. in this paper, we propose to combine extraction and generation for definition modeling: first extract self- and correlative definitional information of target terms from the web and then generate the final definitions by incorporating the extracted definitional information. experiments demonstrate our framework can generate high-quality definitions for technical terms and outperform state-of-the-art models for definition modeling significantly.",,2021-11-14,,"['jie huang', 'hanyin shao', 'kevin chen-chuan chang']"
2111.07308,what should we optimize in participatory budgeting? an experimental   study,cs.ma cs.ai cs.gt,"participatory budgeting (pb) is a process in which voters decide how to allocate a common budget; most commonly it is done by ordinary people -- in particular, residents of some municipality -- to decide on a fraction of the municipal budget. from a social choice perspective, existing research on pb focuses almost exclusively on designing computationally-efficient aggregation methods that satisfy certain axiomatic properties deemed ""desirable"" by the research community. our work complements this line of research through a user study (n = 215) involving several experiments aimed at identifying what potential voters (i.e., non-experts) deem fair or desirable in simple pb settings. our results show that some modern pb aggregation techniques greatly differ from users' expectations, while other, more standard approaches, provide more aligned results. we also identify a few possible discrepancies between what non-experts consider \say{desirable} and how they perceive the notion of ""fairness"" in the pb context. taken jointly, our results can be used to help the research community identify appropriate pb aggregation methods to use in practice.",,2021-11-14,,"['ariel rosenfeld', 'nimrod talmon']"
2111.07334,relative distributed formation and obstacle avoidance with multi-agent   reinforcement learning,eess.sy cs.ai cs.lg cs.ma cs.ro cs.sy,"multi-agent formation as well as obstacle avoidance is one of the most actively studied topics in the field of multi-agent systems. although some classic controllers like model predictive control (mpc) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments. on the other hand, some reinforcement learning (rl) based approaches adopt the leader-follower structure to organize different agents' behaviors, which sacrifices the collaboration between agents thus suffering from bottlenecks in maneuverability and robustness. in this paper, we propose a distributed formation and obstacle avoidance method based on multi-agent reinforcement learning (marl). agents in our system only utilize local and relative information to make decisions and control themselves distributively. agent in the multi-agent system will reorganize themselves into a new topology quickly in case that any of them is disconnected. our method achieves better performance regarding formation error, formation convergence rate and on-par success rate of obstacle avoidance compared with baselines (both classic control methods and another rl-based method). the feasibility of our method is verified by both simulation and hardware implementation with ackermann-steering vehicles.",,2021-11-14,,"['yuzi yan', 'xiaoxiang li', 'xinyou qiu', 'jiantao qiu', 'jian wang', 'yu wang', 'yuan shen']"
2111.07369,estimation of acetabular version from anteroposterior pelvic radiograph   employing deep learning,eess.iv cs.ai cs.cv cs.lg physics.med-ph,"background and objective: the acetabular version, an essential factor in total hip arthroplasty, is measured by ct scan as the gold standard. the dose of radiation and expensiveness of ct make anterior-posterior pelvic radiograph an appropriate alternative procedure. in this study, we applied a deep learning approach on anteroposterior pelvic x-rays to measure anatomical version, eliminating the necessity of using computed tomography scan. methods: the right and left acetabular version angles of the hips of 300 patients are computed using their ct images. the proposed deep learning model, attention on pretrained-vgg16 for bone age, is applied to the ap images of the included population. the age and gender of these people are added as two other inputs to the last fully connected layer of attention mechanism. as the output, the angles of both hips are predicted. results: the angles of hips computed on ct increase as people get older with the mean values of 16.54 and 16.11 (right and left angles) for men and 20.61 and 19.55 for women in our dataset. the predicted errors in the estimation of right and left angles using the proposed method of deep learning are in the accurate region of error (<=3 degrees) which shows the ability of the proposed method in measuring anatomical version based on ap images. conclusion: the suggested algorithm, applying pre-trained vgg16 on the ap images of the pelvis of patients followed by an attention model considering age and gender of patients, can assess version accurately using only ap radiographs while obviating the need for ct scan. the applied technique of estimation of anatomical acetabular version based on ap pelvic images using dl approaches, to the best of authors' knowledge, has not been published yet.",,2021-11-14,,"['ata jodeiri', 'hadi seyedarabi', 'fatemeh shahbazi', 'seyed mohammad mahdi hashemi', 'seyyedhossein shafiei']"
2111.07386,interpretable ecg classification via a query-based latent space   traversal (qlst),cs.lg cs.ai eess.sp,"electrocardiography (ecg) is an effective and non-invasive diagnostic tool that measures the electrical activity of the heart. interpretation of ecg signals to detect various abnormalities is a challenging task that requires expertise. recently, the use of deep neural networks for ecg classification to aid medical practitioners has become popular, but their black box nature hampers clinical implementation. several saliency-based interpretability techniques have been proposed, but they only indicate the location of important features and not the actual features. we present a novel interpretability technique called qlst, a query-based latent space traversal technique that is able to provide explanations for any ecg classification model. with qlst, we train a neural network that learns to traverse in the latent space of a variational autoencoder trained on a large university hospital dataset with over 800,000 ecgs annotated for 28 diseases. we demonstrate through experiments that we can explain different black box classifiers by generating ecgs through these traversals.",,2021-11-14,,"['melle b. vessies', 'sharvaree p. vadgama', 'rutger r. van de leur', 'pieter a. doevendans', 'rutger j. hassink', 'erik bekkers', 'rené van es']"
2111.07392,edge-native intelligence for 6g communications driven by federated   learning: a survey of trends and challenges,cs.ni cs.ai,"the unprecedented surge of data volume in wireless networks empowered with artificial intelligence (ai) opens up new horizons for providing ubiquitous data-driven intelligent services. traditional cloud-centric machine learning (ml)-based services are implemented by collecting datasets and training models centrally. however, this conventional training technique encompasses two challenges: (i) high communication and energy cost due to increased data communication, (ii) threatened data privacy by allowing untrusted parties to utilise this information. recently, in light of these limitations, a new emerging technique, coined as federated learning (fl), arose to bring ml to the edge of wireless networks. fl can extract the benefits of data silos by training a global model in a distributed manner, orchestrated by the fl server. fl exploits both decentralised datasets and computing resources of participating clients to develop a generalised ml model without compromising data privacy. in this article, we introduce a comprehensive survey of the fundamentals and enabling technologies of fl. moreover, an extensive study is presented detailing various applications of fl in wireless networks and highlighting their challenges and limitations. the efficacy of fl is further explored with emerging prospective beyond fifth generation (b5g) and sixth generation (6g) communication systems. the purpose of this survey is to provide an overview of the state-of-the-art of fl applications in key wireless technologies that will serve as a foundation to establish a firm understanding of the topic. lastly, we offer a road forward for future research directions.",,2021-11-14,,"['mohammad al-quraan', 'lina mohjazi', 'lina bariah', 'anthony centeno', 'ahmed zoha', 'sami muhaidat', 'mérouane debbah', 'muhammad ali imran']"
2111.07393,deep: denoising entity pre-training for neural machine translation,cs.cl cs.ai,"it has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus. earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage. to address this limitation, we propose deep, a denoising entity pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences. besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation. experimental results on three language pairs demonstrate that \method results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 bleu and up to 9.2 entity accuracy points for english-russian translation.",,2021-11-14,,"['junjie hu', 'hiroaki hayashi', 'kyunghyun cho', 'graham neubig']"
2111.07395,"explicit explore, exploit, or escape ($e^4$): near-optimal   safety-constrained reinforcement learning in polynomial time",cs.lg cs.ai cs.ro,"in reinforcement learning (rl), an agent must explore an initially unknown environment in order to learn a desired behaviour. when rl agents are deployed in real world environments, safety is of primary concern. constrained markov decision processes (cmdps) can provide long-term safety constraints; however, the agent may violate the constraints in an effort to explore its environment. this paper proposes a model-based rl algorithm called explicit explore, exploit, or escape ($e^{4}$), which extends the explicit explore or exploit ($e^{3}$) algorithm to a robust cmdp setting. $e^4$ explicitly separates exploitation, exploration, and escape cmdps, allowing targeted policies for policy improvement across known states, discovery of unknown states, as well as safe return to known states. $e^4$ robustly optimises these policies on the worst-case cmdp from a set of cmdp models consistent with the empirical observations of the deployment environment. theoretical results show that $e^4$ finds a near-optimal constraint-satisfying policy in polynomial time whilst satisfying safety constraints throughout the learning process. we discuss robust-constrained offline optimisation algorithms as well as how to incorporate uncertainty in transition dynamics of unknown states based on empirical inference and prior knowledge.",,2021-11-14,,"['david m. bossens', 'nicholas bishop']"
2111.07402,textless speech emotion conversion using decomposed and discrete   representations,cs.cl cs.ai cs.lg cs.sd eess.as,"speech emotion conversion is the task of modifying the perceived emotion of a speech utterance while preserving the lexical content and speaker identity. in this study, we cast the problem of emotion conversion as a spoken language translation task. we decompose speech into discrete and disentangled learned representations, consisting of content units, f0, speaker, and emotion. first, we modify the speech content by translating the content units to a target emotion, and then predict the prosodic features based on these units. finally, the speech waveform is generated by feeding the predicted representations into a neural vocoder. such a paradigm allows us to go beyond spectral and parametric changes of the signal, and model non-verbal vocalizations, such as laughter insertion, yawning removal, etc. we demonstrate objectively and subjectively that the proposed method is superior to the baselines in terms of perceived emotion and audio quality. we rigorously evaluate all components of such a complex system and conclude with an extensive model analysis and ablation study to better emphasize the architectural choices, strengths and weaknesses of the proposed method. samples and code will be publicly available under the following link: https://speechbot.github.io/emotion.",,2021-11-14,,"['felix kreuk', 'adam polyak', 'jade copet', 'eugene kharitonov', 'tu-anh nguyen', 'morgane rivière', 'wei-ning hsu', 'abdelrahman mohamed', 'emmanuel dupoux', 'yossi adi']"
2111.07439,improving compound activity classification via deep transfer and   representation learning,cs.lg cs.ai q-bio.bm,"recent advances in molecular machine learning, especially deep neural networks such as graph neural networks (gnns) for predicting structure activity relationships (sar) have shown tremendous potential in computer-aided drug discovery. however, the applicability of such deep neural networks are limited by the requirement of large amounts of training data. in order to cope with limited training data for a target task, transfer learning for sar modeling has been recently adopted to leverage information from data of related tasks. in this work, in contrast to the popular parameter-based transfer learning such as pretraining, we develop novel deep transfer learning methods tac and tac-fc to leverage source domain data and transfer useful information to the target domain. tac learns to generate effective molecular features that can generalize well from one domain to another, and increase the classification performance in the target domain. additionally, tac-fc extends tac by incorporating novel components to selectively learn feature-wise and compound-wise transferability. we used the bioassay screening data from pubchem, and identified 120 pairs of bioassays such that the active compounds in each pair are more similar to each other compared to its inactive compounds. overall, tac achieves the best performance with average roc-auc of 0.801; it significantly improves roc-auc of 83% target tasks with average task-wise performance improvement of 7.102%, compared to the best baseline fcn-dmpna (dt). our experiments clearly demonstrate that tac achieves significant improvement over all baselines across a large number of target tasks. furthermore, although tac-fc achieves slightly worse roc-auc on average compared to tac (0.798 vs 0.801), tac-fc still achieves the best performance on more tasks in terms of pr-auc and f1 compared to other methods.",,2021-11-14,,"['vishal dey', 'raghu machiraju', 'xia ning']"
2111.07441,"a distributed, plug-n-play algorithm for multi-robot applications with a   priori non-computable objective functions",cs.ro cs.ai cs.ma,"this paper presents a distributed algorithm applicable to a wide range of practical multi-robot applications. in such multi-robot applications, the user-defined objectives of the mission can be cast as a general optimization problem, without explicit guidelines of the subtasks per different robot. owing to the unknown environment, unknown robot dynamics, sensor nonlinearities, etc., the analytic form of the optimization cost function is not available a priori. therefore, standard gradient-descent-like algorithms are not applicable to these problems. to tackle this, we introduce a new algorithm that carefully designs each robot's subcost function, the optimization of which can accomplish the overall team objective. upon this transformation, we propose a distributed methodology based on the cognitive-based adaptive optimization (cao) algorithm, that is able to approximate the evolution of each robot's cost function and to adequately optimize its decision variables (robot actions). the latter can be achieved by online learning only the problem-specific characteristics that affect the accomplishment of mission objectives. the overall, low-complexity algorithm can straightforwardly incorporate any kind of operational constraint, is fault tolerant, and can appropriately tackle time-varying cost functions. a cornerstone of this approach is that it shares the same convergence characteristics as those of block coordinate descent algorithms. the proposed algorithm is evaluated in three heterogeneous simulation set-ups under multiple scenarios, against both general-purpose and problem-specific algorithms. source code is available at \url{https://github.com/athakapo/a-distributed-plug-n-play-algorithm-for-multi-robot-applications}.",10.1177/0278364919845054,2021-11-14,,"['athanasios ch. kapoutsis', 'savvas a. chatzichristofis', 'elias b. kosmatopoulos']"
2111.07448,contrastive clustering: toward unsupervised bias reduction for emotion   and sentiment classification,cs.cl cs.ai,"background: when neural network emotion and sentiment classifiers are used in public health informatics studies, biases present in the classifiers could produce inadvertently misleading results.   objective: this study assesses the impact of bias on covid-19 topics, and demonstrates an automatic algorithm for reducing bias when applied to covid-19 social media texts. this could help public health informatics studies produce more timely results during crises, with a reduced risk of misleading results.   methods: emotion and sentiment classifiers were applied to covid-19 data before and after debiasing the classifiers using unsupervised contrastive clustering. contrastive clustering approximates the degree to which tokens exhibit a causal versus correlational relationship with emotion or sentiment, by contrasting the tokens' relative salience to topics versus emotions or sentiments.   results: contrastive clustering distinguishes correlation from causation for tokens with an f1 score of 0.753. masking bias prone tokens from the classifier input decreases the classifier's overall f1 score by 0.02 (anger) and 0.033 (negative sentiment), but improves the f1 score for sentences annotated as bias prone by 0.155 (anger) and 0.103 (negative sentiment). averaging across topics, debiasing reduces anger estimates by 14.4% and negative sentiment estimates by 8.0%.   conclusions: contrastive clustering reduces algorithmic bias in emotion and sentiment classification for social media text pertaining to the covid-19 pandemic. public health informatics studies should account for bias, due to its prevalence across a range of topics. further research is needed to improve bias reduction techniques and to explore the adverse impact of bias on public health informatics analyses.",,2021-11-14,,['jared mowery']
2111.07473,scrutinizing xai using linear ground-truth data with suppressor   variables,stat.ml cs.ai cs.lg,"machine learning (ml) is increasingly often used to inform high-stakes decisions. as complex ml models (e.g., deep neural networks) are often considered black boxes, a wealth of procedures has been developed to shed light on their inner workings and the ways in which their predictions come about, defining the field of 'explainable ai' (xai). saliency methods rank input features according to some measure of 'importance'. such methods are difficult to validate since a formal definition of feature importance is, thus far, lacking. it has been demonstrated that some saliency methods can highlight features that have no statistical association with the prediction target (suppressor variables). to avoid misinterpretations due to such behavior, we propose the actual presence of such an association as a necessary condition and objective preliminary definition for feature importance. we carefully crafted a ground-truth dataset in which all statistical dependencies are well-defined and linear, serving as a benchmark to study the problem of suppressor variables. we evaluate common explanation methods including lrp, dtd, patternnet, patternattribution, lime, anchors, shap, and permutation-based methods with respect to our objective definition. we show that most of these methods are unable to distinguish important features from suppressors in this setting.",,2021-11-14,,"['rick wilming', 'céline budding', 'klaus-robert müller', 'stefan haufe']"
2111.07503,measuring outcomes in healthcare economics using artificial   intelligence: with application to resource management,cs.ai cs.lg,"the quality of service in healthcare is constantly challenged by outlier events such as pandemics (i.e. covid-19) and natural disasters (such as hurricanes and earthquakes). in most cases, such events lead to critical uncertainties in decision making, as well as in multiple medical and economic aspects at a hospital. external (geographic) or internal factors (medical and managerial), lead to shifts in planning and budgeting, but most importantly, reduces confidence in conventional processes. in some cases, support from other hospitals proves necessary, which exacerbates the planning aspect. this manuscript presents three data-driven methods that provide data-driven indicators to help healthcare managers organize their economics and identify the most optimum plan for resources allocation and sharing. conventional decision-making methods fall short in recommending validated policies for managers. using reinforcement learning, genetic algorithms, traveling salesman, and clustering, we experimented with different healthcare variables and presented tools and outcomes that could be applied at health institutes. experiments are performed; the results are recorded, evaluated, and presented.",10.1017/dap.2021.29,2021-11-14,,"['chih-hao huang', 'feras a. batarseh', 'adel boueiz', 'ajay kulkarni', 'po-hsuan su', 'jahan aman']"
2111.07505,a survey on ai assurance,cs.ai cs.cy,"artificial intelligence (ai) algorithms are increasingly providing decision making and operational support across multiple domains. ai includes a wide library of algorithms for different problems. one important notion for the adoption of ai algorithms into operational decision process is the concept of assurance. the literature on assurance, unfortunately, conceals its outcomes within a tangled landscape of conflicting approaches, driven by contradicting motivations, assumptions, and intuitions. accordingly, albeit a rising and novel area, this manuscript provides a systematic review of research works that are relevant to ai assurance, between years 1985 - 2021, and aims to provide a structured alternative to the landscape. a new ai assurance definition is adopted and presented and assurance methods are contrasted and tabulated. additionally, a ten-metric scoring system is developed and introduced to evaluate and compare existing methods. lastly, in this manuscript, we provide foundational insights, discussions, future directions, a roadmap, and applicable recommendations for the development and deployment of ai assurance.",10.1186/s40537-021-00445-7,2021-11-14,,"['feras a. batarseh', 'laura freeman']"
2111.07508,public policymaking for international agricultural trade using   association rules and ensemble machine learning,cs.lg cs.ai econ.gn q-fin.ec,"international economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. the recent shocks to the free trade regime, especially trade disputes among major economies, as well as black swan events, such as trade wars and pandemics, raise the need for improved predictions to inform policy decisions. ai methods are allowing economists to solve such prediction problems in new ways. in this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. association rules (ar) analysis has been deployed successfully for economic scenarios at the consumer or store level, such as for market basket analysis. in our work however, we present analysis of imports and exports associations and their effects on commodity trade flows. moreover, ensemble machine learning methods are developed to provide improved agricultural trade predictions, outlier events' implications, and quantitative pointers to policy makers.",10.1016/j.mlwa.2021.100046,2021-11-14,,"['feras a. batarseh', 'munisamy gopinath', 'anderson monken', 'zhengrong gu']"
2111.07533,automated scholarly paper review: possibility and challenges,cs.ai cs.cl cs.dl,"peer review is a widely accepted mechanism for research evaluation, playing a pivotal role in scholarly publishing. however, criticisms have long been leveled on this mechanism, mostly because of its inefficiency and subjectivity. recent years have seen the application of artificial intelligence (ai) in assisting the peer review process. nonetheless, with the involvement of humans, such limitations remain inevitable. in this review paper, we propose the concept of automated scholarly paper review (aspr) and review the relevant literature and technologies to discuss the possibility of achieving a full-scale computerized review process. we further look into the challenges in aspr with the existing technologies. on the basis of the review and discussion, we conclude that there are already corresponding research and technologies at each stage of aspr. this verifies that aspr can be realized in the long term as the relevant technologies continue to develop. the major difficulties in its realization lie in imperfect document parsing and representation, inadequate data, defected human-computer interaction and flawed deep logical reasoning. in the foreseeable future, aspr and peer review will coexist in a reinforcing manner before aspr is able to fully undertake the reviewing workload from humans.",,2021-11-14,,"['jialiang lin', 'jiaxin song', 'zhangping zhou', 'xiaodong shi']"
2111.07545,randomized classifiers vs human decision-makers: trustworthy ai may have   to act randomly and society seems to accept this,cs.cy cs.ai cs.lg,"as \emph{artificial intelligence} (ai) systems are increasingly involved in decisions affecting our lives, ensuring that automated decision-making is fair and ethical has become a top priority. intuitively, we feel that akin to human decisions, judgments of artificial agents should necessarily be grounded in some moral principles. yet a decision-maker (whether human or artificial) can only make truly ethical (based on any ethical theory) and fair (according to any notion of fairness) decisions if full information on all the relevant factors on which the decision is based are available at the time of decision-making. this raises two problems: (1) in settings, where we rely on ai systems that are using classifiers obtained with supervised learning, some induction/generalization is present and some relevant attributes may not be present even during learning. (2) modeling such decisions as games reveals that any -- however ethical -- pure strategy is inevitably susceptible to exploitation.   moreover, in many games, a nash equilibrium can only be obtained by using mixed strategies, i.e., to achieve mathematically optimal outcomes, decisions must be randomized. in this paper, we argue that in supervised learning settings, there exist random classifiers that perform at least as well as deterministic classifiers, and may hence be the optimal choice in many circumstances. we support our theoretical results with an empirical study indicating a positive societal attitude towards randomized artificial decision-makers, and discuss some policy and implementation issues related to the use of random classifiers that relate to and are relevant for current ai policy and standardization initiatives.",,2021-11-15,,"['gábor erdélyi', 'olivia j. erdélyi', 'vladimir estivill-castro']"
2111.07555,"confucius, cyberpunk and mr. science: comparing ai ethics between china   and the eu",cs.ai cs.cy,"the exponential development and application of artificial intelligence triggered an unprecedented global concern for potential social and ethical issues. stakeholders from different industries, international foundations, governmental organisations and standards institutions quickly improvised and created various codes of ethics attempting to regulate ai. a major concern is the large homogeneity and presumed consensualism around these principles. while it is true that some ethical doctrines, such as the famous kantian deontology, aspire to universalism, they are however not universal in practice. in fact, ethical pluralism is more about differences in which relevant questions to ask rather than different answers to a common question. when people abide by different moral doctrines, they tend to disagree on the very approach to an issue. even when people from different cultures happen to agree on a set of common principles, it does not necessarily mean that they share the same understanding of these concepts and what they entail. in order to better understand the philosophical roots and cultural context underlying ethical principles in ai, we propose to analyse and compare the ethical principles endorsed by the chinese national new generation artificial intelligence governance professional committee (cnngaigpc) and those elaborated by the european high-level expert group on ai (hlegai). china and the eu have very different political systems and diverge in their cultural heritages. in our analysis, we wish to highlight that principles that seem similar a priori may actually have different meanings, derived from different approaches and reflect distinct goals.",,2021-11-15,,"['pascale fung', 'hubert etienne']"
2111.07556,high-quality real time facial capture based on single camera,cs.cv cs.ai,"we propose a real time deep learning framework for video-based facial expression capture. our process uses a high-end facial capture pipeline based on facegood to capture facial expression. we train a convolutional neural network to produce high-quality continuous blendshape weight output from video training. since this facial capture is fully automated, our system can drastically reduce the amount of labor involved in the development of modern narrative-driven video games or films involving realistic digital doubles of actors and potentially hours of animated dialogue per character. we demonstrate compelling animation inference in challenging areas such as eyes and lips.",,2021-11-15,,"['hongwei xu', 'leijia dai', 'jianxing fu', 'xiangyuan wang', 'quanwei wang']"
2111.07564,adding more data does not always help: a study in medical conversation   summarization with pegasus,cs.cl cs.ai cs.lg,"medical conversation summarization is integral in capturing information gathered during interactions between patients and physicians. summarized conversations are used to facilitate patient hand-offs between physicians, and as part of providing care in the future. summaries, however, can be time-consuming to produce and require domain expertise. modern pre-trained nlp models such as pegasus have emerged as capable alternatives to human summarization, reaching state-of-the-art performance on many summarization benchmarks. however, many downstream tasks still require at least moderately sized datasets to achieve satisfactory performance. in this work we (1) explore the effect of dataset size on transfer learning medical conversation summarization using pegasus and (2) evaluate various iterative labeling strategies in the low-data regime, following their success in the classification setting. we find that model performance saturates with increase in dataset size and that the various active-learning strategies evaluated all show equivalent performance consistent with simple dataset size increase. we also find that naive iterative pseudo-labeling is on-par or slightly worse than no pseudo-labeling. our work sheds light on the successes and challenges of translating low-data regime techniques in classification to medical conversation summarization and helps guides future work in this space. relevant code available at \url{https://github.com/curai/curai-research/tree/main/medical-summarization-ml4h-2021}.",,2021-11-15,,"['varun nair', 'namit katariya', 'xavier amatriain', 'ilya valmianski', 'anitha kannan']"
2111.07568,can graph neural networks learn to solve maxsat problem?,cs.ai,"with the rapid development of deep learning techniques, various recent work has tried to apply graph neural networks (gnns) to solve np-hard problems such as boolean satisfiability (sat), which shows the potential in bridging the gap between machine learning and symbolic reasoning. however, the quality of solutions predicted by gnns has not been well investigated in the literature. in this paper, we study the capability of gnns in learning to solve maximum satisfiability (maxsat) problem, both from theoretical and practical perspectives. we build two kinds of gnn models to learn the solution of maxsat instances from benchmarks, and show that gnns have attractive potential to solve maxsat problem through experimental evaluation. we also present a theoretical explanation of the effect that gnns can learn to solve maxsat problem to some extent for the first time, based on the algorithmic alignment theory.",,2021-11-15,,"['minghao liu', 'fuqi jia', 'pei huang', 'fan zhang', 'yuchen sun', 'shaowei cai', 'feifei ma', 'jian zhang']"
2111.07603,counterfactual temporal point processes,cs.lg cs.ai stat.ml,"machine learning models based on temporal point processes are the state of the art in a wide variety of applications involving discrete events in continuous time. however, these models lack the ability to answer counterfactual questions, which are increasingly relevant as these models are being used to inform targeted interventions. in this work, our goal is to fill this gap. to this end, we first develop a causal model of thinning for temporal point processes that builds upon the gumbel-max structural causal model. this model satisfies a desirable counterfactual monotonicity condition, which is sufficient to identify counterfactual dynamics in the process of thinning. then, given an observed realization of a temporal point process with a given intensity function, we develop a sampling algorithm that uses the above causal model of thinning and the superposition theorem to simulate counterfactual realizations of the temporal point process under a given alternative intensity function. simulation experiments using synthetic and real epidemiological data show that the counterfactual realizations provided by our algorithm may give valuable insights to enhance targeted interventions.",,2021-11-15,,"['kimia noorbakhsh', 'manuel gomez rodriguez']"
2111.07608,property inference attacks against gans,cs.cr cs.ai cs.lg stat.ml,"while machine learning (ml) has made tremendous progress during the past decade, recent research has shown that ml models are vulnerable to various security and privacy attacks. so far, most of the attacks in this field focus on discriminative models, represented by classifiers. meanwhile, little attention has been paid to the security and privacy risks of generative models, such as generative adversarial networks (gans). in this paper, we propose the first set of training dataset property inference attacks against gans. concretely, the adversary aims to infer the macro-level training dataset property, i.e., the proportion of samples used to train a target gan with respect to a certain attribute. a successful property inference attack can allow the adversary to gain extra knowledge of the target gan's training dataset, thereby directly violating the intellectual property of the target model owner. also, it can be used as a fairness auditor to check whether the target gan is trained with a biased dataset. besides, property inference can serve as a building block for other advanced attacks, such as membership inference. we propose a general attack pipeline that can be tailored to two attack scenarios, including the full black-box setting and partial black-box setting. for the latter, we introduce a novel optimization framework to increase the attack efficacy. extensive experiments over four representative gan models on five property inference tasks show that our attacks achieve strong performance. in addition, we show that our attacks can be used to enhance the performance of membership inference against gans.",,2021-11-15,,"['junhao zhou', 'yufei chen', 'chao shen', 'yang zhang']"
2111.07611,rationale production to support clinical decision-making,cs.cl cs.ai,"the development of neural networks for clinical artificial intelligence (ai) is reliant on interpretability, transparency, and performance. the need to delve into the black-box neural network and derive interpretable explanations of model output is paramount. a task of high clinical importance is predicting the likelihood of a patient being readmitted to hospital in the near future to enable efficient triage. with the increasing adoption of electronic health records (ehrs), there is great interest in applications of natural language processing (nlp) to clinical free-text contained within ehrs. in this work, we apply infocal, the current state-of-the-art model that produces extractive rationales for its predictions, to the task of predicting hospital readmission using hospital discharge notes. we compare extractive rationales produced by infocal to competitive transformer-based models pretrained on clinical text data and for which the attention mechanism can be used for interpretation. we find each presented model with selected interpretability or feature importance methods yield varying results, with clinical language domain expertise and pretraining critical to performance and subsequent interpretability.",,2021-11-15,,"['niall taylor', 'lei sha', 'dan w joyce', 'thomas lukasiewicz', 'alejo nevado-holgado', 'andrey kormilitzin']"
2111.07613,generate plane quad mesh with neural networks and tree search,cs.lg cs.ai cs.na math.na,"the quality of mesh generation has long been considered a vital aspect in providing engineers with reliable simulation results throughout the history of the finite element method (fem). the element extraction method, which is currently the most robust method, is used in business software. however, in order to speed up extraction, the approach is done by finding the next element that optimizes a target function, which can result in local mesh of bad quality after many time steps. we provide treemesh, a method that uses this method in conjunction with reinforcement learning (also possible with supervised learning) and a novel monte-carlo tree search (mcts) (coulom(2006), kocsis and szepesv\'ari(2006), browne et~al.(2012)). the algorithm is based on a previously proposed approach (pan et~al.(2021)). after making many improvements on drl (algorithm, state-action-reward setting) and adding a mcts, it outperforms the former work on the same boundary. furthermore, using tree search, our program reveals much preponderance on seed-density-changing boundaries, which is common on thin-film materials.",,2021-11-15,,"['hua tong', 'yong ni']"
2111.07631,"ai in games: techniques, challenges and opportunities",cs.ai,"with breakthrough of alphago, ai in human-computer game has become a very hot topic attracting researchers all around the world, which usually serves as an effective standard for testing artificial intelligence. various game ai systems (ais) have been developed such as libratus, openai five and alphastar, beating professional human players. in this paper, we survey recent successful game ais, covering board game ais, card game ais, first-person shooting game ais and real time strategy game ais. through this survey, we 1) compare the main difficulties among different kinds of games for the intelligent decision making field ; 2) illustrate the mainstream frameworks and techniques for developing professional level ais; 3) raise the challenges or drawbacks in the current ais for intelligent decision making; and 4) try to propose future trends in the games and intelligent decision making techniques. finally, we hope this brief review can provide an introduction for beginners, inspire insights for researchers in the filed of ai in games.",,2021-11-15,,"['qiyue yin', 'jun yang', 'wancheng ni', 'bin liang', 'kaiqi huang']"
2111.07640,animeceleb: large-scale animation celebfaces dataset via controllable 3d   synthetic models,cs.ai cs.cv,"despite remarkable success in deep learning-based face-related models, these models are still limited to the domain of real human faces. on the other hand, the domain of animation faces has been studied less intensively due to the absence of a well-organized dataset. in this paper, we present a large-scale animation celebfaces dataset (animeceleb) via controllable synthetic animation models to boost research on the animation face domain. to facilitate the data generation process, we build a semi-automatic pipeline based on an open 3d software and a developed annotation system. this leads to constructing a large-scale animation face dataset that includes multi-pose and multi-style animation faces with rich annotations. experiments suggest that our dataset is applicable to various animation-related tasks such as head reenactment and colorization.",,2021-11-15,,"['kangyeol kim', 'sunghyun park', 'jaeseong lee', 'sunghyo chung', 'junsoo lee', 'jaegul choo']"
2111.07648,the possibilistic horn non-clausal knowledge bases,cs.ai,"posibilistic logic is the most extended approach to handle uncertain and partially inconsistent information. regarding normal forms, advances in possibilistic reasoning are mostly focused on clausal form. yet, the encoding of real-world problems usually results in a non-clausal (nc) formula and nc-to-clausal translators produce severe drawbacks that heavily limit the practical performance of clausal reasoning. thus, by computing formulas in its original nc form, we propose several contributions showing that notable advances are also possible in possibilistic non-clausal reasoning.   {\em firstly,} we define the class of {\em possibilistic horn non-clausal knowledge bases,} or $\mathcal{\overline{h}}_\sigma$, which subsumes the classes: possibilistic horn and propositional horn-nc. $\mathcal{\overline{h}}_\sigma $ is shown to be a kind of nc analogous of the standard horn class.   {\em secondly}, we define {\em possibilistic non-clausal unit-resolution,} or $ \mathcal{ur}_\sigma $, and prove that $ \mathcal{ur}_\sigma $ correctly computes the inconsistency degree of $\mathcal{\overline{h}}_\sigma $members. $\mathcal{ur}_\sigma $ had not been proposed before and is formulated in a clausal-like manner, which eases its understanding, formal proofs and future extension towards non-clausal resolution.   {\em thirdly}, we prove that computing the inconsistency degree of $\mathcal{\overline{h}}_\sigma $ members takes polynomial time. although there already exist tractable classes in possibilistic logic, all of them are clausal, and thus, $\mathcal{\overline{h}}_\sigma $ turns out to be the first characterized polynomial non-clausal class within possibilistic reasoning.",,2021-11-15,,['gonzalo e. imaz']
2111.07658,calculating question similarity is enough:a new method for kbqa tasks,cs.cl cs.ai,"knowledge base question answering (kbqa) aims to answer natural language questions with the help of an external knowledge base. the core idea is to find the link between the internal knowledge behind questions and known triples of the knowledge base. the kbqa task pipeline contains several steps, including entity recognition, relationship extraction, and entity linking. this kind of pipeline method means that errors in any procedure will inevitably propagate to the final prediction. in order to solve the above problem, this paper proposes a corpus generation - retrieve method (cgrm) with pre-training language model (plm) and knowledge graph (kg). firstly, based on the mt5 model, we designed two new pre-training tasks: knowledge masked language modeling and question generation based on the paragraph to obtain the knowledge enhanced t5 (kt5) model. secondly, after preprocessing triples of knowledge graph with a series of heuristic rules, the kt5 model generates natural language qa pairs based on processed triples. finally, we directly solve the qa by retrieving the synthetic dataset. we test our method on nlpcc-iccpol 2016 kbqa dataset, and the results show that our framework improves the performance of kbqa and the out straight-forward method is competitive with the state-of-the-art.",,2021-11-15,,"['hanyu zhao', 'sha yuan', 'jiahong leng', 'xiang pan', 'guoqiang wang']"
2111.07695,joint synthesis of safety certificate and safe control policy using   constrained reinforcement learning,cs.lg cs.ai,"safety is the major consideration in controlling complex dynamical systems using reinforcement learning (rl), where the safety certificate can provide provable safety guarantee. a valid safety certificate is an energy function indicating that safe states are with low energy, and there exists a corresponding safe control policy that allows the energy function to always dissipate. the safety certificate and the safe control policy are closely related to each other and both challenging to synthesize. therefore, existing learning-based studies treat either of them as prior knowledge to learn the other, which limits their applicability with general unknown dynamics. this paper proposes a novel approach that simultaneously synthesizes the energy-function-based safety certificate and learns the safe control policy with crl. we do not rely on prior knowledge about either an available model-based controller or a perfect safety certificate. in particular, we formulate a loss function to optimize the safety certificate parameters by minimizing the occurrence of energy increases. by adding this optimization procedure as an outer loop to the lagrangian-based constrained reinforcement learning (crl), we jointly update the policy and safety certificate parameters and prove that they will converge to their respective local optima, the optimal safe policy and a valid safety certificate. we evaluate our algorithms on multiple safety-critical benchmark environments. the results show that the proposed algorithm learns provably safe policies with no constraint violation. the validity or feasibility of synthesized safety certificate is also verified numerically.",,2021-11-15,,"['haitong ma', 'changliu liu', 'shengbo eben li', 'sifa zheng', 'jianyu chen']"
2111.07734,zero-shot learning in named-entity recognition with external knowledge,cs.ai,"a significant shortcoming of current state-of-the-art (sota) named-entity recognition (ner) systems is their lack of generalization to unseen domains, which poses a major problem since obtaining labeled data for ner in a new domain is expensive and time-consuming. we propose zero, a model that performs zero-shot and few-shot learning in ner to generalize to unseen domains by incorporating pre-existing knowledge in the form of semantic word embeddings. zero first obtains contextualized word representations of input sentences using the model luke, reduces their dimensionality, and compares them directly with the embeddings of the external knowledge, allowing zero to be trained to recognize unseen output entities. we find that zero performs well on unseen ner domains with an average macro f1 score of 0.23, outperforms luke in few-shot learning, and even achieves competitive scores on an in-domain comparison. the performance across source-target domain pairs is shown to be inversely correlated with the pairs' kl divergence.",,2021-11-15,,"['nguyen van hoang', 'soeren hougaard mulvad', 'dexter neo yuan rong', 'yang yue']"
2111.07736,continual learning via local module composition,cs.lg cs.ai,"modularity is a compelling solution to continual learning (cl), the problem of modeling sequences of related tasks. learning and then composing modules to solve different tasks provides an abstraction to address the principal challenges of cl including catastrophic forgetting, backward and forward transfer across tasks, and sub-linear model growth. we introduce local module composition (lmc), an approach to modular cl where each module is provided a local structural component that estimates a module's relevance to the input. dynamic module composition is performed layer-wise based on local relevance scores. we demonstrate that agnosticity to task identities (ids) arises from (local) structural learning that is module-specific as opposed to the task- and/or model-specific as in previous works, making lmc applicable to more cl settings compared to previous works. in addition, lmc also tracks statistics about the input distribution and adds new modules when outlier samples are detected. in the first set of experiments, lmc performs favorably compared to existing methods on the recent continual transfer-learning benchmark without requiring task identities. in another study, we show that the locality of structural learning allows lmc to interpolate to related but unseen tasks (ood), as well as to compose modular networks trained independently on different task sequences into a third modular network without any fine-tuning. finally, in search for limitations of lmc we study it on more challenging sequences of 30 and 100 tasks, demonstrating that local module selection becomes much more challenging in presence of a large number of candidate modules. in this setting best performing lmc spawns much fewer modules compared to an oracle based baseline, however, it reaches a lower overall accuracy. the codebase is available under https://github.com/oleksost/lmc.",,2021-11-15,,"['oleksiy ostapenko', 'pau rodriguez', 'massimo caccia', 'laurent charlin']"
2111.07765,an argument for the impossibility of machine intelligence,cs.ai,"since the noun phrase `artificial intelligence' (ai) was coined, it has been debated whether humans are able to create intelligence using technology. we shed new light on this question from the point of view of themodynamics and mathematics. first, we define what it is to be an agent (device) that could be the bearer of ai. then we show that the mainstream definitions of `intelligence' proposed by hutter and others and still accepted by the ai community are too weak even to capture what is involved when we ascribe intelligence to an insect. we then summarise the highly useful definition of basic (arthropod) intelligence proposed by rodney brooks, and we identify the properties that an ai agent would need to possess in order to be the bearer of intelligence by this definition. finally, we show that, from the perspective of the disciplines needed to create such an agent, namely mathematics and physics, these properties are realisable by neither implicit nor explicit mathematical design nor by setting up an environment in which an ai could evolve spontaneously.",,2021-10-20,,"['jobst landgrebe', 'barry smith']"
2111.07775,learning representations for pixel-based control: what matters and why?,cs.lg cs.ai cs.cv,"learning representations for pixel-based control has garnered significant attention recently in reinforcement learning. a wide range of methods have been proposed to enable efficient learning, leading to sample complexities similar to those in the full state setting. however, moving beyond carefully curated pixel data sets (centered crop, appropriate lighting, clear background, etc.) remains challenging. in this paper, we adopt a more difficult setting, incorporating background distractors, as a first step towards addressing this challenge. we present a simple baseline approach that can learn meaningful representations with no metric-based learning, no data augmentations, no world-model learning, and no contrastive learning. we then analyze when and why previously proposed methods are likely to fail or reduce to the same performance as the baseline in this harder setting and why we should think carefully about extending such methods beyond the well curated environments. our results show that finer categorization of benchmarks on the basis of characteristics like density of reward, planning horizon of the problem, presence of task-irrelevant components, etc., is crucial in evaluating algorithms. based on these observations, we propose different metrics to consider when evaluating an algorithm on benchmark tasks. we hope such a data-centric view can motivate researchers to rethink representation learning when investigating how to best apply rl to real-world tasks.",,2021-11-15,,"['manan tomar', 'utkarsh a. mishra', 'amy zhang', 'matthew e. taylor']"
2111.07779,overcoming digital gravity when using ai in public health decisions,cs.ai,"in popular usage, data gravity refers to the ability of a body of data to attract applications, services and other data. in this work we introduce a broader concept, ""digital gravity"" which includes not just data, but other elements of the ai/ml workflow. this concept is born out of our recent experiences in developing and deploying an ai-based decision support platform intended for use in a public health context. in addition to data, examples of additional considerations are compute (infrastructure and software), devsecops (personnel and practices), algorithms/programs, control planes, middleware (considered separately from programs), and even companies/service providers. we discuss the impact of digital gravity on the pathway to adoption and suggest preliminary approaches to conceptualize and mitigate the friction caused by it.",,2021-11-04,,"['sekou l remy', 'aisha walcott-bryant', 'nelson k bore', 'charles m wachira', 'julian kuenhert']"
2111.07786,independent se(3)-equivariant models for end-to-end rigid protein   docking,cs.ai cs.lg,"protein complex formation is a central problem in biology, being involved in most of the cell's processes, and essential for applications, e.g. drug design or protein engineering. we tackle rigid body protein-protein docking, i.e., computationally predicting the 3d structure of a protein-protein complex from the individual unbound structures, assuming no conformational change within the proteins happens during binding. we design a novel pairwise-independent se(3)-equivariant graph matching network to predict the rotation and translation to place one of the proteins at the right docked position relative to the second protein. we mathematically guarantee a basic principle: the predicted complex is always identical regardless of the initial locations and orientations of the two structures. our model, named equidock, approximates the binding pockets and predicts the docking poses using keypoint matching and alignment, achieved through optimal transport and a differentiable kabsch algorithm. empirically, we achieve significant running time improvements and often outperform existing docking software despite not relying on heavy candidate sampling, structure refinement, or templates.",,2021-11-15,,"['octavian-eugen ganea', 'xinyuan huang', 'charlotte bunne', 'yatao bian', 'regina barzilay', 'tommi jaakkola', 'andreas krause']"
2111.07819,testing the generalization of neural language models for covid-19   misinformation detection,cs.cl cs.ai cs.lg,"a drastic rise in potentially life-threatening misinformation has been a by-product of the covid-19 pandemic. computational support to identify false information within the massive body of data on the topic is crucial to prevent harm. researchers proposed many methods for flagging online misinformation related to covid-19. however, these methods predominantly target specific content types (e.g., news) or platforms (e.g., twitter). the methods' capabilities to generalize were largely unclear so far. we evaluate fifteen transformer-based models on five covid-19 misinformation datasets that include social media posts, news articles, and scientific papers to fill this gap. we show tokenizers and models tailored to covid-19 data do not provide a significant advantage over general-purpose ones. our study provides a realistic assessment of models for detecting covid-19 misinformation. we expect that evaluating a broad spectrum of datasets and models will benefit future research in developing misinformation detection systems.",,2021-11-15,,"['jan philip wahle', 'nischal ashok', 'terry ruas', 'norman meuschke', 'tirthankar ghosal', 'bela gipp']"
2111.07876,winning solution of the aicrowd sbb flatland challenge 2019-2020,cs.ai,"this report describes the main ideas of the solution which won the aicrowd sbb flatland challenge 2019-2020, with a score of 99% (meaning that, on average, 99% of the agents were routed to their destinations within the allotted time steps). the details of the task can be found on the competition's website. the solution consists of 2 major components: 1) a component which (re-)generates paths over a time-expanded graph for each agent 2) a component which updates the agent paths after a malfunction occurs, in order to try to preserve the same agent ordering of entering each cell as before the malfunction. the goal of this component is twofold: a) to (try to) avoid deadlocks b) to bring the system back to a consistent state (where each agent has a feasible path over the time-expanded graph). i am discussing both of these components, as well as a series of potentially promising, but unexplored ideas, below.",,2021-11-11,,['mugurel-ionut andreica']
2111.07898,category-orthogonal object features guide information processing in   recurrent neural networks trained for object categorization,cs.cv cs.ai cs.lg,"recurrent neural networks (rnns) have been shown to perform better than feedforward architectures in visual object categorization tasks, especially in challenging conditions such as cluttered images. however, little is known about the exact computational role of recurrent information flow in these conditions. here we test rnns trained for object categorization on the hypothesis that recurrence iteratively aids object categorization via the communication of category-orthogonal auxiliary variables (the location, orientation, and scale of the object). using diagnostic linear readouts, we find that: (a) information about auxiliary variables increases across time in all network layers, (b) this information is indeed present in the recurrent information flow, and (c) its manipulation significantly affects task performance. these observations confirm the hypothesis that category-orthogonal auxiliary variable information is conveyed through recurrent connectivity and is used to optimize category inference in cluttered environments.",,2021-11-15,,"['sushrut thorat', 'giacomo aldegheri', 'tim c. kietzmann']"
2111.07902,deep semantic manipulation of facial videos,cs.cv cs.ai,"editing and manipulating facial features in videos is an interesting and important field of research with a plethora of applications, ranging from movie post-production and visual effects to realistic avatars for video games and virtual assistants. to the best of our knowledge, this paper proposes the first method to perform photorealistic manipulation of facial expressions in videos. our method supports semantic video manipulation based on neural rendering and 3d-based facial expression modelling. we focus on interactive manipulation of the videos by altering and controlling the facial expressions, achieving promising photorealistic results. the proposed method is based on a disentangled representation and estimation of the 3d facial shape and activity, providing the user with intuitive and easy-to-use control of the facial expressions in the input video. we also introduce a user-friendly, interactive ai tool that processes human-readable semantic labels about the desired emotion manipulations in specific parts of the input video and synthesizes photorealistic manipulated videos. we achieve that by mapping the emotion labels to valence-arousal (va) values, which in turn are mapped to disentangled 3d facial expressions through an especially designed and trained expression decoder network. the paper presents detailed qualitative and quantitative experiments, which demonstrate the effectiveness of our system and the promising results it achieves. additional results and videos can be found at the supplementary material (https://github.com/girish-03/deepsemmanipulation).",,2021-11-15,,"['girish kumar solanki', 'anastasios roussos']"
2111.07908,learning to execute: efficient learning of universal plan-conditioned   policies in robotics,cs.ai cs.ro,"applications of reinforcement learning (rl) in robotics are often limited by high data demand. on the other hand, approximate models are readily available in many robotics scenarios, making model-based approaches like planning a data-efficient alternative. still, the performance of these methods suffers if the model is imprecise or wrong. in this sense, the respective strengths and weaknesses of rl and model-based planners are. in the present work, we investigate how both approaches can be integrated into one framework that combines their strengths. we introduce learning to execute (l2e), which leverages information contained in approximate plans to learn universal policies that are conditioned on plans. in our robotic manipulation experiments, l2e exhibits increased performance when compared to pure rl, pure planning, or baseline methods combining learning and planning.",,2021-11-15,,"['ingmar schubert', 'danny driess', 'ozgur s. oguz', 'marc toussaint']"
2111.07928,target layer regularization for continual learning using cramer-wold   generator,cs.lg cs.ai cs.cv,"we propose an effective regularization strategy (cw-talar) for solving continual learning problems. it uses a penalizing term expressed by the cramer-wold distance between two probability distributions defined on a target layer of an underlying neural network that is shared by all tasks, and the simple architecture of the cramer-wold generator for modeling output data representation. our strategy preserves target layer distribution while learning a new task but does not require remembering previous tasks' datasets. we perform experiments involving several common supervised frameworks, which prove the competitiveness of the cw-talar method in comparison to a few existing state-of-the-art continual learning models.",,2021-11-15,,"['marcin mazur', 'łukasz pustelnik', 'szymon knop', 'patryk pagacz', 'przemysław spurek']"
2111.07970,triggerless backdoor attack for nlp tasks with clean labels,cs.cl cs.ai,"backdoor attacks pose a new threat to nlp models. a standard strategy to construct poisoned data in backdoor attacks is to insert triggers (e.g., rare words) into selected sentences and alter the original label to a target label. this strategy comes with a severe flaw of being easily detected from both the trigger and the label perspectives: the trigger injected, which is usually a rare word, leads to an abnormal natural language expression, and thus can be easily detected by a defense model; the changed target label leads the example to be mistakenly labeled and thus can be easily detected by manual inspections. to deal with this issue, in this paper, we propose a new strategy to perform textual backdoor attacks which do not require an external trigger, and the poisoned samples are correctly labeled. the core idea of the proposed strategy is to construct clean-labeled examples, whose labels are correct but can lead to test label changes when fused with the training set. to generate poisoned clean-labeled examples, we propose a sentence generation model based on the genetic algorithm to cater to the non-differentiable characteristic of text data. extensive experiments demonstrate that the proposed attacking strategy is not only effective, but more importantly, hard to defend due to its triggerless and clean-labeled nature. our work marks the first step towards developing triggerless attacking strategies in nlp.",,2021-11-15,,"['leilei gan', 'jiwei li', 'tianwei zhang', 'xiaoya li', 'yuxian meng', 'fei wu', 'shangwei guo', 'chun fan']"
2111.07971,towards optimal strategies for training self-driving perception models   in simulation,cs.cv cs.ai cs.lg,"autonomous driving relies on a huge volume of real-world data to be labeled to high precision. alternative solutions seek to exploit driving simulators that can generate large amounts of labeled data with a plethora of content variations. however, the domain gap between the synthetic and real data remains, raising the following important question: what are the best ways to utilize a self-driving simulator for perception tasks? in this work, we build on top of recent advances in domain-adaptation theory, and from this perspective, propose ways to minimize the reality gap. we primarily focus on the use of labels in the synthetic domain alone. our approach introduces both a principled way to learn neural-invariant representations and a theoretically inspired view on how to sample the data from the simulator. our method is easy to implement in practice as it is agnostic of the network architecture and the choice of the simulator. we showcase our approach on the bird's-eye-view vehicle segmentation task with multi-sensor data (cameras, lidar) using an open-source simulator (carla), and evaluate the entire framework on a real-world dataset (nuscenes). last but not least, we show what types of variations (e.g. weather conditions, number of assets, map design, and color diversity) matter to perception networks when trained with driving simulators, and which ones can be compensated for with our domain adaptation technique.",,2021-11-15,,"['david acuna', 'jonah philion', 'sanja fidler']"
2111.07979,metric-based multimodal meta-learning for human movement identification   via footstep recognition,cs.sd cs.ai cs.lg cs.sy eess.as eess.sy q-bio.nc,"we describe a novel metric-based learning approach that introduces a multimodal framework and uses deep audio and geophone encoders in siamese configuration to design an adaptable and lightweight supervised model. this framework eliminates the need for expensive data labeling procedures and learns general-purpose representations from low multisensory data obtained from omnipresent sensing systems. these sensing systems provide numerous applications and various use cases in activity recognition tasks. here, we intend to explore the human footstep movements from indoor environments and analyze representations from a small self-collected dataset of acoustic and vibration-based sensors. the core idea is to learn plausible similarities between two sensory traits and combining representations from audio and geophone signals. we present a generalized framework to learn embeddings from temporal and spatial features extracted from audio and geophone signals. we then extract the representations in a shared space to maximize the learning of a compatibility function between acoustic and geophone features. this, in turn, can be used effectively to carry out a classification task from the learned model, as demonstrated by assigning high similarity to the pairs with a human footstep movement and lower similarity to pairs containing no footstep movement. performance analyses show that our proposed multimodal framework achieves a 19.99\% accuracy increase (in absolute terms) and avoided overfitting on the evaluation set when the training samples were increased from 200 pairs to just 500 pairs while satisfactorily learning the audio and geophone representations. our results employ a metric-based contrastive learning approach for multi-sensor data to mitigate the impact of data scarcity and perform human movement identification with limited data size.",,2021-11-15,,"['muhammad shakeel', 'katsutoshi itoyama', 'kenji nishida', 'kazuhiro nakadai']"
2111.07999,adversarial skill chaining for long-horizon robot manipulation via   terminal state regularization,cs.lg cs.ai cs.ro,"skill chaining is a promising approach for synthesizing complex behaviors by sequentially combining previously learned skills. yet, a naive composition of skills fails when a policy encounters a starting state never seen during its training. for successful skill chaining, prior approaches attempt to widen the policy's starting state distribution. however, these approaches require larger state distributions to be covered as more policies are sequenced, and thus are limited to short skill sequences. in this paper, we propose to chain multiple policies without excessively large initial state distributions by regularizing the terminal state distributions in an adversarial learning framework. we evaluate our approach on two complex long-horizon manipulation tasks of furniture assembly. our results have shown that our method establishes the first model-free reinforcement learning algorithm to solve these tasks; whereas prior skill chaining approaches fail. the code and videos are available at https://clvrai.com/skill-chaining",,2021-11-15,,"['youngwoon lee', 'joseph j. lim', 'anima anandkumar', 'yuke zhu']"
2111.08001,metagenome2vec: building contextualized representations for scalable   metagenome analysis,q-bio.gn cs.ai cs.lg,"advances in next-generation metagenome sequencing have the potential to revolutionize the point-of-care diagnosis of novel pathogen infections, which could help prevent potential widespread transmission of diseases. given the high volume of metagenome sequences, there is a need for scalable frameworks to analyze and segment metagenome sequences from clinical samples, which can be highly imbalanced. there is an increased need for learning robust representations from metagenome reads since pathogens within a family can have highly similar genome structures (some more than 90%) and hence enable the segmentation and identification of novel pathogen sequences with limited labeled data. in this work, we propose metagenome2vec - a contextualized representation that captures the global structural properties inherent in metagenome data and local contextualized properties through self-supervised representation learning. we show that the learned representations can help detect six (6) related pathogens from clinical samples with less than 100 labeled sequences. extensive experiments on simulated and clinical metagenome data show that the proposed representation encodes compositional properties that can generalize beyond annotations to segment novel pathogens in an unsupervised setting.",,2021-11-09,,"['sathyanarayanan n. aakur', 'vineela indla', 'vennela indla', 'sai narayanan', 'arunkumar bagavathi', 'vishalini laguduva ramnath', 'akhilesh ramachandran']"
2111.08010,modular networks prevent catastrophic interference in model-based   multi-task reinforcement learning,cs.lg cs.ai,"in a multi-task reinforcement learning setting, the learner commonly benefits from training on multiple related tasks by exploiting similarities among them. at the same time, the trained agent is able to solve a wider range of different problems. while this effect is well documented for model-free multi-task methods, we demonstrate a detrimental effect when using a single learned dynamics model for multiple tasks. thus, we address the fundamental question of whether model-based multi-task reinforcement learning benefits from shared dynamics models in a similar way model-free methods do from shared policy networks. using a single dynamics model, we see clear evidence of task confusion and reduced performance. as a remedy, enforcing an internal structure for the learned dynamics model by training isolated sub-networks for each task notably improves performance while using the same amount of parameters. we illustrate our findings by comparing both methods on a simple gridworld and a more complex vizdoom multi-task experiment.",,2021-11-15,,"['robin schiewer', 'laurenz wiskott']"
2111.08054,revisiting c.s.peirce's experiment: 150 years later,econ.em cs.ai stat.me,"an iconoclastic philosopher and polymath, charles sanders peirce (1837-1914) is among the greatest of american minds. in 1872, peirce conducted a series of experiments to determine the distribution of response times to an auditory stimulus, which is widely regarded as one of the most significant statistical investigations in the history of nineteenth-century american mathematical research (stigler, 1978). on the 150th anniversary of this historic experiment, we look back at peirce's view on empirical modeling through a modern statistical lens.",,2021-11-15,,['deep mukhopadhyay']
2111.08073,learning robust scheduling with search and attention,cs.ni cs.ai cs.lg eess.sp,"allocating physical layer resources to users based on channel quality, buffer size, requirements and constraints represents one of the central optimization problems in the management of radio resources. the solution space grows combinatorially with the cardinality of each dimension making it hard to find optimal solutions using an exhaustive search or even classical optimization algorithms given the stringent time requirements. this problem is even more pronounced in mu-mimo scheduling where the scheduler can assign multiple users to the same time-frequency physical resources. traditional approaches thus resort to designing heuristics that trade optimality in favor of feasibility of execution. in this work we treat the mu-mimo scheduling problem as a tree-structured combinatorial problem and, borrowing from the recent successes of alphago zero, we investigate the feasibility of searching for the best performing solutions using a combination of monte carlo tree search and reinforcement learning. to cater to the nature of the problem at hand, like the lack of an intrinsic ordering of the users as well as the importance of dependencies between combinations of users, we make fundamental modifications to the neural network architecture by introducing the self-attention mechanism. we then demonstrate that the resulting approach is not only feasible but vastly outperforms state-of-the-art heuristic-based scheduling approaches in the presence of measurement uncertainties and finite buffers.",,2021-11-15,,"['david sandberg', 'tor kvernvik', 'francesco davide calabrese']"
2111.08082,learning graph neural networks for multivariate time series anomaly   detection,cs.lg cs.ai,"in this work, we propose glue (graph deviation network with local uncertainty estimation), building on the recently proposed graph deviation network (gdn). glue not only automatically learns complex dependencies between variables and uses them to better identify anomalous behavior, but also quantifies its predictive uncertainty, allowing us to account for the variation in the data as well to have more interpretable anomaly detection thresholds. results on two real world datasets tell us that optimizing the negative gaussian log likelihood is reasonable because glue's forecasting results are at par with gdn and in fact better than the vector autoregressor baseline, which is significant given that gdn directly optimizes the mse loss. in summary, our experiments demonstrate that glue is competitive with gdn at anomaly detection, with the added benefit of uncertainty estimations. we also show that glue learns meaningful sensor embeddings which clusters similar sensors together.",,2021-11-15,,"['saswati ray', 'sana lakdawala', 'mononito goswami', 'chufan gao']"
2111.08096,visualenv: visual gym environments with blender,cs.lg cs.ai,"in this paper visualenv, a new tool for creating visual environment for reinforcement learning is introduced. it is the product of an integration of an open-source modelling and rendering software, blender, and a python module used to generate environment model for simulation, openai gym. visualenv allows the user to create custom environments with photorealistic rendering capabilities and full integration with python. the framework is described and tested on a series of example problems that showcase its features for training reinforcement learning agents.",,2021-11-15,,"['andrea scorsoglio', 'roberto furfaro']"
2111.08102,the partially observable history process,cs.ai cs.gt,"we introduce the partially observable history process (pohp) formalism for reinforcement learning. pohp centers around the actions and observations of a single agent and abstracts away the presence of other players without reducing them to stochastic processes. our formalism provides a streamlined interface for designing algorithms that defy categorization as exclusively single or multi-agent, and for developing theory that applies across these domains. we show how the pohp formalism unifies traditional models including the markov decision process, the markov game, the extensive-form game, and their partially observable extensions, without introducing burdensome technical machinery or violating the philosophical underpinnings of reinforcement learning. we illustrate the utility of our formalism by concisely exploring observable sequential rationality, re-deriving the extensive-form regret minimization (efr) algorithm, and examining efr's theoretical properties in greater generality.",,2021-11-15,,"['dustin morrill', 'amy r. greenwald', 'michael bowling']"
2111.08108,learning optimal control with stochastic models of hamiltonian dynamics,math.oc cs.ai,"optimal control problems can be solved by first applying the pontryagin maximum principle, followed by computing a solution of the corresponding unconstrained hamiltonian dynamical system. in this paper, and to achieve a balance between robustness and efficiency, we learn a reduced hamiltonian of the unconstrained hamiltonian. this reduced hamiltonian is learned by going backward in time and by minimizing the loss function resulting from application of the pontryagin maximum principle conditions. the robustness of our learning process is then further improved by progressively learning a posterior distribution of reduced hamiltonians. this leads to a more efficient sampling of the generalized coordinates (position, velocity) of our phase space. our solution framework applies to not only optimal control problems with finite-dimensional phase (state) spaces but also the infinite dimensional case.",,2021-11-15,,"['chandrajit bajaj', 'minh nguyen']"
2111.08156,improving learning from demonstrations by learning from experience,cs.ai,"how to make imitation learning more general when demonstrations are relatively limited has been a persistent problem in reinforcement learning (rl). poor demonstrations lead to narrow and biased date distribution, non-markovian human expert demonstration makes it difficult for the agent to learn, and over-reliance on sub-optimal trajectories can make it hard for the agent to improve its performance. to solve these problems we propose a new algorithm named td3fg that can smoothly transition from learning from experts to learning from experience. our algorithm achieves good performance in the mujoco environment with limited and sub-optimal demonstrations. we use behavior cloning to train the network as a reference action generator and utilize it in terms of both loss function and exploration noise. this innovation can help agents extract a priori knowledge from demonstrations while reducing the detrimental effects of the poor markovian properties of the demonstrations. it has a better performance compared to the bc+ fine-tuning and ddpgfd approach, especially when the demonstrations are relatively limited. we call our method td3fg meaning td3 from a generator.",,2021-11-15,,"['haofeng liu', 'yiwen chen', 'jiayi tan', 'marcelo h ang']"
2111.08168,explaining medical ai performance disparities across sites with   confounder shapley value analysis,cs.lg cs.ai,"medical ai algorithms can often experience degraded performance when evaluated on previously unseen sites. addressing cross-site performance disparities is key to ensuring that ai is equitable and effective when deployed on diverse patient populations. multi-site evaluations are key to diagnosing such disparities as they can test algorithms across a broader range of potential biases such as patient demographics, equipment types, and technical parameters. however, such tests do not explain why the model performs worse. our framework provides a method for quantifying the marginal and cumulative effect of each type of bias on the overall performance difference when a model is evaluated on external data. we demonstrate its usefulness in a case study of a deep learning model trained to detect the presence of pneumothorax, where our framework can help explain up to 60% of the discrepancy in performance across different sites with known biases like disease comorbidities and imaging parameters.",,2021-11-12,,"['eric wu', 'kevin wu', 'james zou']"
2111.08171,solving linear algebra by program synthesis,cs.lg cs.ai cs.cl,"we solve mit's linear algebra 18.06 course and columbia university's computational linear algebra coms3251 courses with perfect accuracy by interactive program synthesis. this surprisingly strong result is achieved by turning the course questions into programming tasks and then running the programs to produce the correct answers. we use openai codex with zero-shot learning, without providing any examples in the prompts, to synthesize code from questions. we quantify the difference between the original question text and the transformed question text that yields a correct answer. since all coms3251 questions are not available online the model is not overfitting. we go beyond just generating code for questions with numerical answers by interactively generating code that also results visually pleasing plots as output. finally, we automatically generate new questions given a few sample questions which may be used as new course content. this work is a significant step forward in solving quantitative math problems and opens the door for solving many university level stem courses by machine.",,2021-11-15,,"['iddo drori', 'nakul verma']"
2111.08206,jmsnas: joint model split and neural architecture search for learning   over mobile edge networks,cs.ai cs.dc,"the main challenge to deploy deep neural network (dnn) over a mobile edge network is how to split the dnn model so as to match the network architecture as well as all the nodes' computation and communication capacity. this essentially involves two highly coupled procedures: model generating and model splitting. in this paper, a joint model split and neural architecture search (jmsnas) framework is proposed to automatically generate and deploy a dnn model over a mobile edge network. considering both the computing and communication resource constraints, a computational graph search problem is formulated to find the multi-split points of the dnn model, and then the model is trained to meet some accuracy requirements. moreover, the trade-off between model accuracy and completion latency is achieved through the proper design of the objective function. the experiment results confirm the superiority of the proposed framework over the state-of-the-art split machine learning design methods.",,2021-11-15,,"['yuqing tian', 'zhaoyang zhang', 'zhaohui yang', 'qianqian yang']"
2111.08222,will we trust what we don't understand? impact of model interpretability   and outcome feedback on trust in ai,cs.ai cs.hc,"despite ai's superhuman performance in a variety of domains, humans are often unwilling to adopt ai systems. the lack of interpretability inherent in many modern ai techniques is believed to be hurting their adoption, as users may not trust systems whose decision processes they do not understand. we investigate this proposition with a novel experiment in which we use an interactive prediction task to analyze the impact of interpretability and outcome feedback on trust in ai and on human performance in ai-assisted prediction tasks. we find that interpretability led to no robust improvements in trust, while outcome feedback had a significantly greater and more reliable effect. however, both factors had modest effects on participants' task performance. our findings suggest that (1) factors receiving significant attention, such as interpretability, may be less effective at increasing trust than factors like outcome feedback, and (2) augmenting human performance via ai systems may not be a simple matter of increasing trust in ai, as increased trust is not always associated with equally sizable improvements in performance. these findings invite the research community to focus not only on methods for generating interpretations but also on techniques for ensuring that interpretations impact trust and performance in practice.",,2021-11-15,,"['daehwan ahn', 'abdullah almaatouq', 'monisha gulabani', 'kartik hosanagar']"
2111.08232,online self-evolving anomaly detection in cloud computing environments,cs.dc cs.ai,"modern cloud computing systems contain hundreds to thousands of computing and storage servers. such a scale, combined with ever-growing system complexity, is causing a key challenge to failure and resource management for dependable cloud computing. autonomic failure detection is a crucial technique for understanding emergent, cloud-wide phenomena and self-managing cloud resources for system-level dependability assurance. to detect failures, we need to monitor the cloud execution and collect runtime performance data. these data are usually unlabeled, and thus a prior failure history is not always available in production clouds. in this paper, we present a \emph{self-evolving anomaly detection} (sead) framework for cloud dependability assurance. our framework self-evolves by recursively exploring newly verified anomaly records and continuously updating the anomaly detector online. as a distinct advantage of our framework, cloud system administrators only need to check a small number of detected anomalies, and their decisions are leveraged to update the detector. thus, the detector evolves following the upgrade of system hardware, update of the software stack, and change of user workloads. moreover, we design two types of detectors, one for general anomaly detection and the other for type-specific anomaly detection. with the help of self-evolving techniques, our detectors can achieve 88.94\% in sensitivity and 94.60\% in specificity on average, which makes them suitable for real-world deployment.",,2021-11-16,,"['haili wang', 'jingda guo', 'xu ma', 'song fu', 'qing yang', 'yunzhong xu']"
2111.08246,self-encoding barnacle mating optimizer algorithm for manpower   scheduling in flow shop,cs.ai,"flow shop scheduling (fss) has been widely researched due to its application in many types of fields, while the human participant brings great challenges to this problem. manpower scheduling captures attention for assigning workers with diverse proficiency to the appropriate stages, which is of great significance to production efficiency.   in this paper, we present a novel algorithm called self-encoding barnacle mating optimizer (sbmo), which solves the fss problem considering worker proficiency, defined as a new problem, flow shop manpower scheduling problem (fsmsp). the highlight of the sbmo algorithm is the combination with the encoding method, crossover and mutation operators. moreover, in order to solve the local optimum problem, we design a neighborhood search scheme. finally, the extensive comparison simulations are conducted to demonstrate the superiority of the proposed sbmo. the results indicate the effectiveness of sbmo in approximate ratio, powerful stability, and execution time, compared with the classic and popular counterparts.",,2021-11-16,,"['shuyun luo', 'wushuang wang', 'mengyuan fang', 'weiqiang xu']"
2111.08259,pose recognition in the wild: animal pose estimation using agglomerative   clustering and contrastive learning,cs.cv cs.ai,"animal pose estimation has recently come into the limelight due to its application in biology, zoology, and aquaculture. deep learning methods have effectively been applied to human pose estimation. however, the major bottleneck to the application of these methods to animal pose estimation is the unavailability of sufficient quantities of labeled data. though there are ample quantities of unlabelled data publicly available, it is economically impractical to label large quantities of data for each animal. in addition, due to the wide variety of body shapes in the animal kingdom, the transfer of knowledge across domains is ineffective. given the fact that the human brain is able to recognize animal pose without requiring large amounts of labeled data, it is only reasonable that we exploit unsupervised learning to tackle the problem of animal pose recognition from the available, unlabelled data. in this paper, we introduce a novel architecture that is able to recognize the pose of multiple animals fromunlabelled data. we do this by (1) removing background information from each image and employing an edge detection algorithm on the body of the animal, (2) tracking motion of the edge pixels and performing agglomerative clustering to segment body parts, (3) employing contrastive learning to discourage grouping of distant body parts together. hence we are able to distinguish between body parts of the animal, based on their visual behavior, instead of the underlying anatomy. thus, we are able to achieve a more effective classification of the data than their human-labeled counterparts. we test our model on the tigdog and wld (wildlife documentary) datasets, where we outperform state-of-the-art approaches by a significant margin. we also study the performance of our model on other public data to demonstrate the generalization ability of our model.",,2021-11-16,,"['samayan bhattacharya', 'sk shahnawaz']"
2111.08267,solving probability and statistics problems by program synthesis,cs.lg cs.ai cs.cl cs.pl,"we solve university level probability and statistics questions by program synthesis using openai's codex, a transformer trained on text and fine-tuned on code. we transform course problems from mit's 18.05 introduction to probability and statistics and harvard's stat110 probability into programming tasks. we then execute the generated code to get a solution. since these course questions are grounded in probability, we often aim to have codex generate probabilistic programs that simulate a large number of probabilistic dependencies to compute its solution. our approach requires prompt engineering to transform the question from its original form to an explicit, tractable form that results in a correct program and solution. to estimate the amount of work needed to translate an original question into its tractable form, we measure the similarity between original and transformed questions. our work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models.",,2021-11-16,,"['leonard tang', 'elizabeth ke', 'nikhil singh', 'nakul verma', 'iddo drori']"
2111.08274,hadfl: heterogeneity-aware decentralized federated learning framework,cs.lg cs.ai,"federated learning (fl) supports training models on geographically distributed devices. however, traditional fl systems adopt a centralized synchronous strategy, putting high communication pressure and model generalization challenge. existing optimizations on fl either fail to speedup training on heterogeneous devices or suffer from poor communication efficiency. in this paper, we propose hadfl, a framework that supports decentralized asynchronous training on heterogeneous devices. the devices train model locally with heterogeneity-aware local steps using local data. in each aggregation cycle, they are selected based on probability to perform model synchronization and aggregation. compared with the traditional fl system, hadfl can relieve the central server's communication pressure, efficiently utilize heterogeneous computing power, and can achieve a maximum speedup of 3.15x than decentralized-fedavg and 4.68x than pytorch distributed training scheme, respectively, with almost no loss of convergence accuracy.",,2021-11-16,,"['jing cao', 'zirui lian', 'weihong liu', 'zongwei zhu', 'cheng ji']"
2111.08291,switching recurrent kalman networks,cs.lg cs.ai eess.sp,"forecasting driving behavior or other sensor measurements is an essential component of autonomous driving systems. often real-world multivariate time series data is hard to model because the underlying dynamics are nonlinear and the observations are noisy. in addition, driving data can often be multimodal in distribution, meaning that there are distinct predictions that are likely, but averaging can hurt model performance. to address this, we propose the switching recurrent kalman network (srkn) for efficient inference and prediction on nonlinear and multi-modal time-series data. the model switches among several kalman filters that model different aspects of the dynamics in a factorized latent state. we empirically test the resulting scalable and interpretable deep state-space model on toy data sets and real driving data from taxis in porto. in all cases, the model can capture the multimodal nature of the dynamics in the data.",,2021-11-16,,"['giao nguyen-quynh', 'philipp becker', 'chen qiu', 'maja rudolph', 'gerhard neumann']"
2111.08299,accounting for gaussian process imprecision in bayesian optimization,cs.ai stat.me,"bayesian optimization (bo) with gaussian processes (gp) as surrogate models is widely used to optimize analytically unknown and expensive-to-evaluate functions. in this paper, we propose prior-mean-robust bayesian optimization (probo) that outperforms classical bo on specific problems. first, we study the effect of the gaussian processes' prior specifications on classical bo's convergence. we find the prior's mean parameters to have the highest influence on convergence among all prior components. in response to this result, we introduce probo as a generalization of bo that aims at rendering the method more robust towards prior mean parameter misspecification. this is achieved by explicitly accounting for gp imprecision via a prior near-ignorance model. at the heart of this is a novel acquisition function, the generalized lower confidence bound (glcb). we test our approach against classical bo on a real-world problem from material science and observe probo to converge faster. further experiments on multimodal and wiggly target functions confirm the superiority of our method.",,2021-11-16,,"['julian rodemann', 'thomas augustin']"
2111.08322,an empirical study of finding similar exercises,cs.ai,"education artificial intelligence aims to profit tasks in the education domain such as intelligent test paper generation and consolidation exercises where the main technique behind is how to match the exercises, known as the finding similar exercises(fse) problem. most of these approaches emphasized their model abilities to represent the exercise, unfortunately there are still many challenges such as the scarcity of data, insufficient understanding of exercises and high label noises. we release a chinese education pre-trained language model bert$_{edu}$ for the label-scarce dataset and introduce the exercise normalization to overcome the diversity of mathematical formulas and terms in exercise. we discover new auxiliary tasks in an innovative way depends on problem-solving ideas and propose a very effective moe enhanced multi-task model for fse task to attain better understanding of exercises. in addition, confidence learning was utilized to prune train-set and overcome high noises in labeling data. experiments show that these methods proposed in this paper are very effective.",,2021-11-16,,"['tongwen huang', 'xihua li']"
2111.08357,a first approach to closeness distributions,cs.ai math.st stat.ml stat.th,"probabilistic graphical models allow us to encode a large probability distribution as a composition of smaller ones. it is oftentimes the case that we are interested in incorporating in the model the idea that some of these smaller distributions are likely to be similar to one another. in this paper we provide an information geometric approach on how to incorporate this information, and see that it allows us to reinterpret some already existing models.",,2021-11-16,,['jesus cerquides']
2111.08361,from convolutions towards spikes: the environmental metric that the   community currently misses,cs.ai,"today, the ai community is obsessed with 'state-of-the-art' scores (80% papers in neurips) as the major performance metrics, due to which an important parameter, i.e., the environmental metric, remains unreported. computational capabilities were a limiting factor a decade ago; however, in foreseeable future circumstances, the challenge will be to develop environment-friendly and power-efficient algorithms. the human brain, which has been optimizing itself for almost a million years, consumes the same amount of power as a typical laptop. therefore, developing nature-inspired algorithms is one solution to it. in this study, we show that currently used anns are not what we find in nature, and why, although having lower performance, spiking neural networks, which mirror the mammalian visual cortex, have attracted much interest. we further highlight the hardware gaps restricting the researchers from using spike-based computation for developing neuromorphic energy-efficient microchips on a large scale. using neuromorphic processors instead of traditional gpus might be more environment friendly and efficient. these processors will turn snns into an ideal solution for the problem. this paper presents in-depth attention highlighting the current gaps, the lack of comparative research, while proposing new research directions at the intersection of two fields -- neuroscience and deep learning. further, we define a new evaluation metric 'nature' for reporting the carbon footprint of ai models.",,2021-11-16,,"['aviral chharia', 'shivu chauhan', 'rahul upadhyay', 'vinay kumar']"
2111.08374,literature-augmented clinical outcome prediction,cs.cl cs.ai cs.ir,"predictive models for medical outcomes hold great promise for enhancing clinical decision-making. these models are trained on rich patient data such as clinical notes, aggregating many patient signals into an outcome prediction. however, ai-based clinical models have typically been developed in isolation from the prominent paradigm of evidence based medicine (ebm), in which medical decisions are based on explicit evidence from existing literature. in this work, we introduce techniques to help bridge this gap between ebm and ai-based clinical models, and show that these methods can improve predictive accuracy. we propose a novel system that automatically retrieves patient-specific literature based on intensive care (icu) patient information, aggregates relevant papers and fuses them with internal admission notes to form outcome predictions. our model is able to substantially boost predictive accuracy on three challenging tasks in comparison to strong recent baselines; for in-hospital mortality, we are able to boost top-10% precision by a large margin of over 25%.",,2021-11-16,,"['aakanksha naik', 'sravanthi parasa', 'sergey feldman', 'lucy lu wang', 'tom hope']"
2111.08386,towards generating real-world time series data,cs.lg cs.ai,"time series data generation has drawn increasing attention in recent years. several generative adversarial network (gan) based methods have been proposed to tackle the problem usually with the assumption that the targeted time series data are well-formatted and complete. however, real-world time series (rts) data are far away from this utopia, e.g., long sequences with variable lengths and informative missing data raise intractable challenges for designing powerful generation algorithms. in this paper, we propose a novel generative framework for rts data - rtsgan to tackle the aforementioned challenges. rtsgan first learns an encoder-decoder module which provides a mapping between a time series instance and a fixed-dimension latent vector and then learns a generation module to generate vectors in the same latent space. by combining the generator and the decoder, rtsgan is able to generate rts which respect the original feature distributions and the temporal dynamics. to generate time series with missing values, we further equip rtsgan with an observation embedding layer and a decide-and-generate decoder to better utilize the informative missing patterns. experiments on the four rts datasets show that the proposed framework outperforms the previous generation methods in terms of synthetic data utility for downstream classification and prediction tasks.",,2021-11-16,,"['hengzhi pei', 'kan ren', 'yuqing yang', 'chang liu', 'tao qin', 'dongsheng li']"
2111.08408,stamp 4 nlp -- an agile framework for rapid quality-driven nlp   applications development,cs.cl cs.ai,"the progress in natural language processing (nlp) research over the last years, offers novel business opportunities for companies, as automated user interaction or improved data analysis. building sophisticated nlp applications requires dealing with modern machine learning (ml) technologies, which impedes enterprises from establishing successful nlp projects. our experience in applied nlp research projects shows that the continuous integration of research prototypes in production-like environments with quality assurance builds trust in the software and shows convenience and usefulness regarding the business goal. we introduce stamp 4 nlp as an iterative and incremental process model for developing nlp applications. with stamp 4 nlp, we merge software engineering principles with best practices from data science. instantiating our process model allows efficiently creating prototypes by utilizing templates, conventions, and implementations, enabling developers and data scientists to focus on the business goals. due to our iterative-incremental approach, businesses can deploy an enhanced version of the prototype to their software environment after every iteration, maximizing potential business value and trust early and avoiding the cost of successful yet never deployed experiments.",10.1007/978-3-030-85347-1_12,2021-11-16,,"['philipp kohl', 'oliver schmidts', 'lars klöser', 'henri werth', 'bodo kraft', 'albert zündorf']"
2111.08415,causal policy ranking,cs.ai cs.lg,"policies trained via reinforcement learning (rl) are often very complex even for simple tasks. in an episode with $n$ time steps, a policy will make $n$ decisions on actions to take, many of which may appear non-intuitive to the observer. moreover, it is not clear which of these decisions directly contribute towards achieving the reward and how significant is their contribution. given a trained policy, we propose a black-box method based on counterfactual reasoning that estimates the causal effect that these decisions have on reward attainment and ranks the decisions according to this estimate. in this preliminary work, we compare our measure against an alternative, non-causal, ranking procedure, highlight the benefits of causality-based policy ranking, and discuss potential future work integrating causal algorithms into the interpretation of rl agent policies.",,2021-11-16,,"['daniel mcnamee', 'hana chockler']"
2111.08435,free will belief as a consequence of model-based reinforcement learning,cs.lg cs.ai,"the debate on whether or not humans have free will has been raging for centuries. although there are good arguments based on our current understanding of the laws of nature for the view that it is not possible for humans to have free will, most people believe they do. this discrepancy begs for an explanation. if we accept that we do not have free will, we are faced with two problems: (1) while freedom is a very commonly used concept that everyone intuitively understands, what are we actually referring to when we say that an action or choice is ""free"" or not? and, (2) why is the belief in free will so common? where does this belief come from, and what is its purpose, if any? in this paper, we examine these questions from the perspective of reinforcement learning (rl). rl is a framework originally developed for training artificial intelligence agents. however, it can also be used as a computational model of human decision making and learning, and by doing so, we propose that the first problem can be answered by observing that people's common sense understanding of freedom is closely related to the information entropy of an rl agent's normalized action values, while the second can be explained by the necessity for agents to model themselves as if they could have taken decisions other than those they actually took, when dealing with the temporal credit assignment problem. put simply, we suggest that by applying the rl framework as a model for human learning it becomes evident that in order for us to learn efficiently and be intelligent we need to view ourselves as if we have free will.",,2021-11-14,,['erik m. rehn']
2111.08441,use of machine learning in geriatric clinical care for chronic diseases:   a systematic literature review,eess.sp cs.ai cs.lg,"objectives-geriatric clinical care is a multidisciplinary assessment designed to evaluate older patients (age 65 years and above) functional ability, physical health, and cognitive wellbeing. the majority of these patients suffer from multiple chronic conditions and require special attention. recently, hospitals utilize various artificial intelligence (ai) systems to improve care for elderly patients. the purpose of this systematic literature review is to understand the current use of ai systems, particularly machine learning (ml), in geriatric clinical care for chronic diseases. materials and methods-we restricted our search to eight databases, namely pubmed, worldcat, medline, proquest, sciencedirect, springerlink, wiley, and eric, to analyze research articles published in english between january 2010 and june 2019. we focused on studies that used ml algorithms in the care of geriatrics patients with chronic conditions. results-we identified 35 eligible studies and classified in three groups-psychological disorder (n=22), eye diseases (n=6), and others (n=7). this review identified the lack of standardized ml evaluation metrics and the need for data governance specific to health care applications. conclusion- more studies and ml standardization tailored to health care applications are required to confirm whether ml could aid in improving geriatric clinical care.",10.1093/jamiaopen/ooaa034,2021-10-30,,"['avishek choudhury', 'emily renjilian', 'onur asan']"
2111.08446,"automatic sleep staging: recent development, challenges, and future   directions",eess.sp cs.ai cs.lg,"modern deep learning holds a great potential to transform clinical practice on human sleep. teaching a machine to carry out routine tasks would be a tremendous reduction in workload for clinicians. sleep staging, a fundamental step in sleep practice, is a suitable task for this and will be the focus in this article. recently, automatic sleep staging systems have been trained to mimic manual scoring, leading to similar performance to human sleep experts, at least on scoring of healthy subjects. despite tremendous progress, we have not seen automatic sleep scoring adopted widely in clinical environments. this review aims to give a shared view of the authors on the most recent state-of-the-art development in automatic sleep staging, the challenges that still need to be addressed, and the future directions for automatic sleep scoring to achieve clinical value.",,2021-11-03,,"['huy phan', 'kaare mikkelsen']"
2111.08451,which is making the contribution: modulating unimodal and cross-modal   dynamics for multimodal sentiment analysis,cs.lg cs.ai,"multimodal sentiment analysis (msa) draws increasing attention with the availability of multimodal data. the boost in performance of msa models is mainly hindered by two problems. on the one hand, recent msa works mostly focus on learning cross-modal dynamics, but neglect to explore an optimal solution for unimodal networks, which determines the lower limit of msa models. on the other hand, noisy information hidden in each modality interferes the learning of correct cross-modal dynamics. to address the above-mentioned problems, we propose a novel msa framework \textbf{m}odulation \textbf{m}odel for \textbf{m}ultimodal \textbf{s}entiment \textbf{a}nalysis ({$ m^3sa $}) to identify the contribution of modalities and reduce the impact of noisy information, so as to better learn unimodal and cross-modal dynamics. specifically, modulation loss is designed to modulate the loss contribution based on the confidence of individual modalities in each utterance, so as to explore an optimal update solution for each unimodal network. besides, contrary to most existing works which fail to explicitly filter out noisy information, we devise a modality filter module to identify and filter out modality noise for the learning of correct cross-modal embedding. extensive experiments on publicly datasets demonstrate that our approach achieves state-of-the-art performance.",,2021-11-09,,"['ying zeng', 'sijie mai', 'haifeng hu']"
2111.08452,on minimizers and convolutional filters: a partial justification for the   unreasonable effectiveness of cnns in categorical sequence analysis,cs.lg cs.ai q-bio.gn,"minimizers and convolutional neural networks (cnns) are two quite distinct popular techniques that have both been employed to analyze biological sequences. at face value, the methods seem entirely dissimilar. minimizers use min-wise hashing on a rolling window to extract a single important k-mer feature per window. cnns start with a wide array of randomly initialized convolutional filters, paired with a pooling operation, and then multiple additional neural layers to learn both the filters themselves and how those filters can be used to classify the sequence. in this manuscript, i demonstrate through a careful mathematical analysis of hash function properties that there are deep theoretical connections between minimizers and convolutional filters -- in short, for sequences over a categorical alphabet, random gaussian initialization of convolutional filters with max-pooling is equivalent to choosing minimizers from a random hash function biased towards more distinct k-mers. this provides a partial explanation for the unreasonable effectiveness of cnns in categorical sequence analysis.",,2021-11-09,,['yun william yu']
2111.08456,trustworthy multimodal regression with mixture of normal-inverse gamma   distributions,cs.lg cs.ai,"multimodal regression is a fundamental task, which integrates the information from different sources to improve the performance of follow-up applications. however, existing methods mainly focus on improving the performance and often ignore the confidence of prediction for diverse situations. in this study, we are devoted to trustworthy multimodal regression which is critical in cost-sensitive domains. to this end, we introduce a novel mixture of normal-inverse gamma distributions (monig) algorithm, which efficiently estimates uncertainty in principle for adaptive integration of different modalities and produces a trustworthy regression result. our model can be dynamically aware of uncertainty for each modality, and also robust for corrupted modalities. furthermore, the proposed monig ensures explicitly representation of (modality-specific/global) epistemic and aleatoric uncertainties, respectively. experimental results on both synthetic and different real-world data demonstrate the effectiveness and trustworthiness of our method on various multimodal regression tasks (e.g., temperature prediction for superconductivity, relative location prediction for ct slices, and multimodal sentiment analysis).",,2021-11-11,,"['huan ma', 'zongbo han', 'changqing zhang', 'huazhu fu', 'joey tianyi zhou', 'qinghua hu']"
2111.08458,lifelong learning from event-based data,cs.lg cs.ai,"lifelong learning is a long-standing aim for artificial agents that act in dynamic environments, in which an agent needs to accumulate knowledge incrementally without forgetting previously learned representations. we investigate methods for learning from data produced by event cameras and compare techniques to mitigate forgetting while learning incrementally. we propose a model that is composed of both, feature extraction and continuous learning. furthermore, we introduce a habituation-based method to mitigate forgetting. our experimental results show that the combination of different techniques can help to avoid catastrophic forgetting while learning incrementally from the features provided by the extraction module.",,2021-11-11,,"['vadym gryshchuk', 'cornelius weber', 'chu kiong loo', 'stefan wermter']"
2111.08466,interpretable and fair boolean rule sets via column generation,cs.lg cs.ai math.oc,"this paper considers the learning of boolean rules in either disjunctive normal form (dnf, or-of-ands, equivalent to decision rule sets) or conjunctive normal form (cnf, and-of-ors) as an interpretable model for classification. an integer program is formulated to optimally trade classification accuracy for rule simplicity. we also consider the fairness setting and extend the formulation to include explicit constraints on two different measures of classification parity: equality of opportunity and equalized odds. column generation (cg) is used to efficiently search over an exponential number of candidate clauses (conjunctions or disjunctions) without the need for heuristic rule mining. this approach also bounds the gap between the selected rule set and the best possible rule set on the training data. to handle large datasets, we propose an approximate cg algorithm using randomization. compared to three recently proposed alternatives, the cg algorithm dominates the accuracy-simplicity trade-off in 8 out of 16 datasets. when maximized for accuracy, cg is competitive with rule learners designed for this purpose, sometimes finding significantly simpler solutions that are no less accurate. compared to other fair and interpretable classifiers, our method is able to find rule sets that meet stricter notions of fairness with a modest trade-off in accuracy.",,2021-11-16,,"['connor lawless', 'sanjeeb dash', 'oktay gunluk', 'dennis wei']"
2111.08468,point detection through multi-instance deep heatmap regression for   sutures in endoscopy,cs.cv cs.ai,"purpose: mitral valve repair is a complex minimally invasive surgery of the heart valve. in this context, suture detection from endoscopic images is a highly relevant task that provides quantitative information to analyse suturing patterns, assess prosthetic configurations and produce augmented reality visualisations. facial or anatomical landmark detection tasks typically contain a fixed number of landmarks, and use regression or fixed heatmap-based approaches to localize the landmarks. however in endoscopy, there are a varying number of sutures in every image, and the sutures may occur at any location in the annulus, as they are not semantically unique. method: in this work, we formulate the suture detection task as a multi-instance deep heatmap regression problem, to identify entry and exit points of sutures. we extend our previous work, and introduce the novel use of a 2d gaussian layer followed by a differentiable 2d spatial soft-argmax layer to function as a local non-maximum suppression. results: we present extensive experiments with multiple heatmap distribution functions and two variants of the proposed model. in the intra-operative domain, variant 1 showed a mean f1 of +0.0422 over the baseline. similarly, in the simulator domain, variant 1 showed a mean f1 of +0.0865 over the baseline. conclusion: the proposed model shows an improvement over the baseline in the intra-operative and the simulator domains. the data is made publicly available within the scope of the miccai adaptor2021 challenge https://adaptor2021.github.io/, and the code at https://github.com/cardio-ai/suture-detection-pytorch/. doi:10.1007/s11548-021-02523-w. the link to the open access article can be found here: https://link.springer.com/article/10.1007%2fs11548-021-02523-w",10.1007/s11548-021-02523-w,2021-11-16,,"['lalith sharan', 'gabriele romano', 'julian brand', 'halvar kelm', 'matthias karck', 'raffaele de simone', 'sandy engelhardt']"
2111.08486,neural class expression synthesis,cs.ai,"class expression learning is a branch of explainable supervised machine learning of increasing importance. most existing approaches for class expression learning in description logics are search algorithms or hard-rule-based. in particular, approaches based on refinement operators suffer from scalability issues as they rely on heuristic functions to explore a large search space for each learning problem. we propose a new family of approaches, which we dub synthesis approaches. instances of this family compute class expressions directly from the examples provided. consequently, they are not subject to the runtime limitations of search-based approaches nor the lack of flexibility of hard-rule-based approaches. we study three instances of this novel family of approaches that use lightweight neural network architectures to synthesize class expressions from sets of positive examples. the results of their evaluation on four benchmark datasets suggest that they can effectively synthesize high-quality class expressions with respect to the input examples in under a second on average. moreover, a comparison with the state-of-the-art approaches celoe and eltl suggests that we achieve significantly better f-measures on large ontologies. for reproducibility purposes, we provide our implementation as well as pre-trained models in the public github repository at https://github.com/conceptlengthlearner/nces",,2021-11-16,2021-11-18,"[""n'dah jean kouagou"", 'stefan heindorf', 'caglar demir', 'axel-cyrille ngonga ngomo']"
2111.08500,patent data for engineering design: a review,cs.dl cs.ai,"patent data have been utilized for engineering design research for long because it contains massive amount of design information. recent advances in artificial intelligence and data science present unprecedented opportunities to mine, analyse and make sense of patent data to develop design theory and methodology. herein, we survey the patent-for-design literature by their contributions to design theories, methods, tools, and strategies, as well as different forms of patent data and various methods. our review sheds light on promising future research directions for the field.",,2021-11-15,,"['shuo jiang', 'serhad sarica', 'binyang song', 'jie hu', 'jianxi luo']"
2111.08502,human-error-potential estimation based on wearable biometric sensors,eess.sp cs.ai cs.cv cs.lg cs.mm stat.ap,"this study tackles on a new problem of estimating human-error potential on a shop floor on the basis of wearable sensors. unlike existing studies that utilize biometric sensing technology to estimate people's internal state such as fatigue and mental stress, we attempt to estimate the human-error potential in a situation where a target person does not stay calm, which is much more difficult as sensor noise significantly increases. we propose a novel formulation, in which the human-error-potential estimation problem is reduced to a classification problem, and introduce a new method that can be used for solving the classification problem even with noisy sensing data. the key ideas are to model the process of calculating biometric indices probabilistically so that the prior knowledge on the biometric indices can be integrated, and to utilize the features that represent the movement of target persons in combination with biometric features. the experimental analysis showed that our method effectively estimates the human-error potential.",10.5220/0010642400003064,2021-11-14,,"['hiroki ohashi', 'hiroto nagayoshi']"
2111.08510,cvss-bert: explainable natural language processing to determine the   severity of a computer security vulnerability from its description,cs.cl cs.ai cs.lg,"when a new computer security vulnerability is publicly disclosed, only a textual description of it is available. cybersecurity experts later provide an analysis of the severity of the vulnerability using the common vulnerability scoring system (cvss). specifically, the different characteristics of the vulnerability are summarized into a vector (consisting of a set of metrics), from which a severity score is computed. however, because of the high number of vulnerabilities disclosed everyday this process requires lot of manpower, and several days may pass before a vulnerability is analyzed. we propose to leverage recent advances in the field of natural language processing (nlp) to determine the cvss vector and the associated severity score of a vulnerability from its textual description in an explainable manner. to this purpose, we trained multiple bert classifiers, one for each metric composing the cvss vector. experimental results show that our trained classifiers are able to determine the value of the metrics of the cvss vector with high accuracy. the severity score computed from the predicted cvss vector is also very close to the real severity score attributed by a human expert. for explainability purpose, gradient-based input saliency method was used to determine the most relevant input words for a given prediction made by our classifiers. often, the top relevant words include terms in agreement with the rationales of a human cybersecurity expert, making the explanation comprehensible for end-users.",,2021-11-16,,"['mustafizur shahid', 'hervé debar']"
2111.08529,improving the robustness and accuracy of biomedical language models   through adversarial training,cs.cl cs.ai,"deep transformer neural network models have improved the predictive accuracy of intelligent text processing systems in the biomedical domain. they have obtained state-of-the-art performance scores on a wide variety of biomedical and clinical natural language processing (nlp) benchmarks. however, the robustness and reliability of these models has been less explored so far. neural nlp models can be easily fooled by adversarial samples, i.e. minor changes to input that preserve the meaning and understandability of the text but force the nlp system to make erroneous decisions. this raises serious concerns about the security and trust-worthiness of biomedical nlp systems, especially when they are intended to be deployed in real-world use cases. we investigated the robustness of several transformer neural language models, i.e. biobert, scibert, biomed-roberta, and bio-clinicalbert, on a wide range of biomedical and clinical text processing tasks. we implemented various adversarial attack methods to test the nlp systems in different attack scenarios. experimental results showed that the biomedical nlp models are sensitive to adversarial samples; their performance dropped in average by 21 and 18.9 absolute percent on character-level and word-level adversarial noise, respectively. conducting extensive adversarial training experiments, we fine-tuned the nlp models on a mixture of clean samples and adversarial inputs. results showed that adversarial training is an effective defense mechanism against adversarial noise; the models robustness improved in average by 11.3 absolute percent. in addition, the models performance on clean data increased in average by 2.4 absolute present, demonstrating that adversarial training can boost generalization abilities of biomedical nlp systems.",,2021-11-16,,"['milad moradi', 'matthias samwald']"
2111.08531,language bias in visual question answering: a survey and taxonomy,cs.cv cs.ai,"visual question answering (vqa) is a challenging task, which has attracted more and more attention in the field of computer vision and natural language processing. however, the current visual question answering has the problem of language bias, which reduces the robustness of the model and has an adverse impact on the practical application of visual question answering. in this paper, we conduct a comprehensive review and analysis of this field for the first time, and classify the existing methods according to three categories, including enhancing visual information, weakening language priors, data enhancement and training strategies. at the same time, the relevant representative methods are introduced, summarized and analyzed in turn. the causes of language bias are revealed and classified. secondly, this paper introduces the datasets mainly used for testing, and reports the experimental results of various existing methods. finally, we discuss the possible future research directions in this field.",,2021-11-16,,['desen yuan']
2111.08550,on effective scheduling of model-based reinforcement learning,cs.lg cs.ai stat.ml,"model-based reinforcement learning has attracted wide attention due to its superior sample efficiency. despite its impressive success so far, it is still unclear how to appropriately schedule the important hyperparameters to achieve adequate performance, such as the real data ratio for policy optimization in dyna-style model-based algorithms. in this paper, we first theoretically analyze the role of real data in policy training, which suggests that gradually increasing the ratio of real data yields better performance. inspired by the analysis, we propose a framework named autombpo to automatically schedule the real data ratio as well as other hyperparameters in training model-based policy optimization (mbpo) algorithm, a representative running case of model-based methods. on several continuous control tasks, the mbpo instance trained with hyperparameters scheduled by autombpo can significantly surpass the original one, and the real data ratio schedule found by autombpo shows consistency with our theoretical analysis.",,2021-11-16,,"['hang lai', 'jian shen', 'weinan zhang', 'yimin huang', 'xing zhang', 'ruiming tang', 'yong yu', 'zhenguo li']"
2111.08557,rethinking keypoint representations: modeling keypoints and poses as   objects for multi-person human pose estimation,cs.cv cs.ai,"in keypoint estimation tasks such as human pose estimation, heatmap-based regression is the dominant approach despite possessing notable drawbacks: heatmaps intrinsically suffer from quantization error and require excessive computation to generate and post-process. motivated to find a more efficient solution, we propose a new heatmap-free keypoint estimation method in which individual keypoints and sets of spatially related keypoints (i.e., poses) are modeled as objects within a dense single-stage anchor-based detection framework. hence, we call our method kapao (pronounced ""ka-pow!"") for keypoints and poses as objects. we apply kapao to the problem of single-stage multi-person human pose estimation by simultaneously detecting human pose objects and keypoint objects and fusing the detections to exploit the strengths of both object representations. in experiments, we observe that kapao is significantly faster and more accurate than previous methods, which suffer greatly from heatmap post-processing. moreover, the accuracy-speed trade-off is especially favourable in the practical setting when not using test-time augmentation. our large model, kapao-l, achieves an ap of 70.6 on the microsoft coco keypoints validation set without test-time augmentation while being 2.5x faster than the next best single-stage model, whose accuracy is 4.0 ap less. furthermore, kapao excels in the presence of heavy occlusion. on the crowdpose test set, kapao-l achieves new state-of-the-art accuracy for a single-stage method with an ap of 68.9.",,2021-11-16,2021-11-17,"['william mcnally', 'kanav vats', 'alexander wong', 'john mcphee']"
2111.08564,doxastic extensions of \l ukasiewicz logic,cs.lo cs.ai math.lo,"we propose two new doxastic extensions of fuzzy \l ukasiewicz logic in which their semantics are kripke-based with both fuzzy atomic propositions and fuzzy accessibility relations. a class of these extensions is equipped with uninformed belief operator, and the other class is based on a new notion of skeptical belief. we model a fuzzy version of muddy children problem and a cpa-security experiment using uniformed belief and skeptical belief, respectively. moreover, we prove soundness and completeness for both of these belief extensions.",,2021-11-04,,"['doratossadat dastgheib', 'hadi farahani']"
2111.08566,spann: highly-efficient billion-scale approximate nearest neighbor   search,cs.db cs.ai cs.cv cs.ir cs.lg,"the in-memory algorithms for approximate nearest neighbor search (anns) have achieved great success for fast high-recall search, but are extremely expensive when handling very large scale database. thus, there is an increasing request for the hybrid anns solutions with small memory and inexpensive solid-state drive (ssd). in this paper, we present a simple but efficient memory-disk hybrid indexing and search system, named spann, that follows the inverted index methodology. it stores the centroid points of the posting lists in the memory and the large posting lists in the disk. we guarantee both disk-access efficiency (low latency) and high recall by effectively reducing the disk-access number and retrieving high-quality posting lists. in the index-building stage, we adopt a hierarchical balanced clustering algorithm to balance the length of posting lists and augment the posting list by adding the points in the closure of the corresponding clusters. in the search stage, we use a query-aware scheme to dynamically prune the access of unnecessary posting lists. experiment results demonstrate that spann is 2$\times$ faster than the state-of-the-art anns solution diskann to reach the same recall quality $90\%$ with same memory cost in three billion-scale datasets. it can reach $90\%$ recall@1 and recall@10 in just around one millisecond with only 32gb memory cost. code is available at: {\footnotesize\color{blue}{\url{https://github.com/microsoft/sptag}}}.",,2021-11-05,,"['qi chen', 'bing zhao', 'haidong wang', 'mingqin li', 'chuanjie liu', 'zengzhong li', 'mao yang', 'jingdong wang']"
2111.08581,words of wisdom: representational harms in learning from ai   communication,cs.hc cs.ai cs.cl cs.cy,"many educational technologies use artificial intelligence (ai) that presents generated or produced language to the learner. we contend that all language, including all ai communication, encodes information about the identity of the human or humans who contributed to crafting the language. with ai communication, however, the user may index identity information that does not match the source. this can lead to representational harms if language associated with one cultural group is presented as ""standard"" or ""neutral"", if the language advantages one group over another, or if the language reinforces negative stereotypes. in this work, we discuss a case study using a visual question generation (vqg) task involving gathering crowdsourced data from targeted demographic groups. generated questions will be presented to human evaluators to understand how they index the identity behind the language, whether and how they perceive any representational harms, and how they would ideally address any such harms caused by ai communication. we reflect on the educational applications of this work as well as the implications for equality, diversity, and inclusion (edi).",,2021-11-16,,"['amanda buddemeyer', 'erin walker', 'malihe alikhani']"
2111.08587,offline contextual bandits for wireless network optimization,cs.ai,"the explosion in mobile data traffic together with the ever-increasing expectations for higher quality of service call for the development of ai algorithms for wireless network optimization. in this paper, we investigate how to learn policies that can automatically adjust the configuration parameters of every cell in the network in response to the changes in the user demand. our solution combines existent methods for offline learning and adapts them in a principled way to overcome crucial challenges arising in this context. empirical results suggest that our proposed method will achieve important performance gains when deployed in the real network while satisfying practical constrains on computational efficiency.",,2021-11-11,,"['miguel suau', 'alexandros agapitos', 'david lynch', 'derek farrell', 'mingqi zhou', 'aleksandar milenovic']"
2111.08597,a layer-stress learning framework universally augments deep neural   network tasks,eess.iv cs.ai cs.cv,"deep neural networks (dnn) such as multi-layer perception (mlp) and convolutional neural networks (cnn) represent one of the most established deep learning algorithms. given the tremendous effects of the number of hidden layers on network architecture and performance, it is very important to choose the number of hidden layers but still a serious challenge. more importantly, the current network architectures can only process the information from the last layer of the feature extractor, which greatly limited us to further improve its performance. here we presented a layer-stress deep learning framework (x-nn) which implemented automatic and wise depth decision on shallow or deep feature map in a deep network through firstly designing enough number of layers and then trading off them by multi-head attention block. the x-nn can make use of features from various depth layers through attention allocation and then help to make final decision as well. as a result, x-nn showed outstanding prediction ability in the alzheimer's disease classification technique challenge prcv 2021, in which it won the top laurel and outperformed all other ai models. moreover, the performance of x-nn was verified by one more ad neuroimaging dataset and other ai tasks.",,2021-11-14,,"['shihao shao', 'yong liu', 'qinghua cui']"
2111.08625,uncertainty-aware multiple instance learning fromlarge-scale long time   series data,cs.ai,"we propose a novel framework to classify large-scale time series data with long duration. long time seriesclassification (l-tsc) is a challenging problem because the dataoften contains a large amount of irrelevant information to theclassification target. the irrelevant period degrades the classifica-tion performance while the relevance is unknown to the system.this paper proposes an uncertainty-aware multiple instancelearning (mil) framework to identify the most relevant periodautomatically. the predictive uncertainty enables designing anattention mechanism that forces the mil model to learn from thepossibly discriminant period. moreover, the predicted uncertaintyyields a principled estimator to identify whether a prediction istrustworthy or not. we further incorporate another modality toaccommodate unreliable predictions by training a separate modelbased on its availability and conduct uncertainty aware fusion toproduce the final prediction. systematic evaluation is conductedon the automatic identification system (ais) data, which is col-lected to identify and track real-world vessels. empirical resultsdemonstrate that the proposed method can effectively detect thetypes of vessels based on the trajectory and the uncertainty-awarefusion with other available data modality (synthetic-apertureradar or sar imagery is used in our experiments) can furtherimprove the detection accuracy.",,2021-11-16,2021-11-17,"['yuansheng zhu', 'weishi shi', 'deep shankar pandey', 'yang liu', 'xiaofan que', 'daniel e. krutz', 'qi yu']"
2111.08667,machine learning and ensemble approach onto predicting heart disease,cs.lg cs.ai,"the four essential chambers of one's heart that lie in the thoracic cavity are crucial for one's survival, yet ironically prove to be the most vulnerable. cardiovascular disease (cvd) also commonly referred to as heart disease has steadily grown to the leading cause of death amongst humans over the past few decades. taking this concerning statistic into consideration, it is evident that patients suffering from cvds need a quick and correct diagnosis in order to facilitate early treatment to lessen the chances of fatality. this paper attempts to utilize the data provided to train classification models such as logistic regression, k nearest neighbors, support vector machine, decision tree, gaussian naive bayes, random forest, and multi-layer perceptron (artificial neural network) and eventually using a soft voting ensemble technique in order to attain as many correct diagnoses as possible.",,2021-11-16,,['aaditya surya']
2111.08679,automatically detecting anomalous exoplanet transits,cs.lg astro-ph.im cs.ai cs.ne,"raw light curve data from exoplanet transits is too complex to naively apply traditional outlier detection methods. we propose an architecture which estimates a latent representation of both the main transit and residual deviations with a pair of variational autoencoders. we show, using two fabricated datasets, that our latent representations of anomalous transit residuals are significantly more amenable to outlier detection than raw data or the latent representation of a traditional variational autoencoder. we then apply our method to real exoplanet transit data. our study is the first which automatically identifies anomalous exoplanet transit light curves. we additionally release three first-of-their-kind datasets to enable further research.",,2021-11-16,,"['christoph j. hönes', 'benjamin kurt miller', 'ana m. heras', 'bernard h. foing']"
2111.08687,intern: a new learning paradigm towards general vision,cs.cv cs.ai cs.lg,"enormous waves of technological innovations over the past several years, marked by the advances in ai technologies, are profoundly reshaping the industry and the society. however, down the road, a key challenge awaits us, that is, our capability of meeting rapidly-growing scenario-specific demands is severely limited by the cost of acquiring a commensurate amount of training data. this difficult situation is in essence due to limitations of the mainstream learning paradigm: we need to train a new model for each new scenario, based on a large quantity of well-annotated data and commonly from scratch. in tackling this fundamental problem, we move beyond and develop a new learning paradigm named intern. by learning with supervisory signals from multiple sources in multiple stages, the model being trained will develop strong generalizability. we evaluate our model on 26 well-known datasets that cover four categories of tasks in computer vision. in most cases, our models, adapted with only 10% of the training data in the target domain, outperform the counterparts trained with the full set of data, often by a significant margin. this is an important step towards a promising prospect where such a model with general vision capability can dramatically reduce our reliance on data, thus expediting the adoption of ai technologies. furthermore, revolving around our new paradigm, we also introduce a new data system, a new architecture, and a new benchmark, which, together, form a general vision ecosystem to support its future development in an open and inclusive manner.",,2021-11-16,,"['jing shao', 'siyu chen', 'yangguang li', 'kun wang', 'zhenfei yin', 'yinan he', 'jianing teng', 'qinghong sun', 'mengya gao', 'jihao liu', 'gengshi huang', 'guanglu song', 'yichao wu', 'yuming huang', 'fenggang liu', 'huan peng', 'shuo qin', 'chengyu wang', 'yujie wang', 'conghui he', 'ding liang', 'yu liu', 'fengwei yu', 'junjie yan', 'dahua lin', 'xiaogang wang', 'yu qiao']"
2111.08723,who decides if ai is fair? the labels problem in algorithmic auditing,cs.cl cs.ai cs.hc cs.lg,"labelled ""ground truth"" datasets are routinely used to evaluate and audit ai algorithms applied in high-stakes settings. however, there do not exist widely accepted benchmarks for the quality of labels in these datasets. we provide empirical evidence that quality of labels can significantly distort the results of algorithmic audits in real-world settings. using data annotators typically hired by ai firms in india, we show that fidelity of the ground truth data can lead to spurious differences in performance of asrs between urban and rural populations. after a rigorous, albeit expensive, label cleaning process, these disparities between groups disappear. our findings highlight how trade-offs between label quality and data annotation costs can complicate algorithmic audits in practice. they also emphasize the need for development of consensus-driven, widely accepted benchmarks for label quality.",,2021-11-16,,"['abhilash mishra', 'yash gorana']"
2111.08738,synthesis-guided feature learning for cross-spectral periocular   recognition,cs.cv cs.ai,"a common yet challenging scenario in periocular biometrics is cross-spectral matching - in particular, the matching of visible wavelength against near-infrared (nir) periocular images. we propose a novel approach to cross-spectral periocular verification that primarily focuses on learning a mapping from visible and nir periocular images to a shared latent representational subspace, and supports this effort by simultaneously learning intra-spectral image reconstruction. we show the auxiliary image reconstruction task (and in particular the reconstruction of high-level, semantic features) results in learning a more discriminative, domain-invariant subspace compared to the baseline while incurring no additional computational or memory costs at test-time. the proposed coupled conditional generative adversarial network (cogan) architecture uses paired generator networks (one operating on visible images and the other on nir) composed of u-nets with resnet-18 encoders trained for feature learning via contrastive loss and for intra-spectral image reconstruction with adversarial, pixel-based, and perceptual reconstruction losses. moreover, the proposed cogan model beats the current state-of-art (sota) in cross-spectral periocular recognition. on the hong kong polyu benchmark dataset, we achieve 98.65% auc and 5.14% eer compared to the sota eer of 8.02%. on the cross-eyed dataset, we achieve 99.31% auc and 3.99% eer versus sota eer of 4.39%.",,2021-11-16,,"['domenick poster', 'nasser nasrabadi']"
2111.08749,smace: a new method for the interpretability of composite decision   systems,cs.lg cs.ai,"interpretability is a pressing issue for decision systems. many post hoc methods have been proposed to explain the predictions of any machine learning model. however, business processes and decision systems are rarely centered around a single, standalone model. these systems combine multiple models that produce key predictions, and then apply decision rules to generate the final decision. to explain such decision, we present smace, semi-model-agnostic contextual explainer, a novel interpretability method that combines a geometric approach for decision rules with existing post hoc solutions for machine learning models to generate an intuitive feature ranking tailored to the end user. we show that established model-agnostic approaches produce poor results in this framework.",,2021-11-16,,"['gianluigi lopardo', 'damien garreau', 'frederic precioso', 'greger ottosson']"
2111.08755,learning scene dynamics from point cloud sequences,cs.cv cs.ai,"understanding 3d scenes is a critical prerequisite for autonomous agents. recently, lidar and other sensors have made large amounts of data available in the form of temporal sequences of point cloud frames. in this work, we propose a novel problem -- sequential scene flow estimation (ssfe) -- that aims to predict 3d scene flow for all pairs of point clouds in a given sequence. this is unlike the previously studied problem of scene flow estimation which focuses on two frames.   we introduce the spcm-net architecture, which solves this problem by computing multi-scale spatiotemporal correlations between neighboring point clouds and then aggregating the correlation across time with an order-invariant recurrent unit. our experimental evaluation confirms that recurrent processing of point cloud sequences results in significantly better ssfe compared to using only two frames. additionally, we demonstrate that this approach can be effectively modified for sequential point cloud forecasting (spf), a related problem that demands forecasting future point cloud frames.   our experimental results are evaluated using a new benchmark for both ssfe and spf consisting of synthetic and real datasets. previously, datasets for scene flow estimation have been limited to two frames. we provide non-trivial extensions to these datasets for multi-frame estimation and prediction. due to the difficulty of obtaining ground truth motion for real-world datasets, we use self-supervised training and evaluation metrics. we believe that this benchmark will be pivotal to future research in this area. all code for benchmark and models will be made accessible.",,2021-11-16,,"['pan he', 'patrick emami', 'sanjay ranka', 'anand rangarajan']"
2111.08792,predprop: bidirectional stochastic optimization with precision weighted   predictive coding,cs.lg cs.ai cs.ne,"we present predprop, a method for bidirectional, parallel and local optimisation of weights, activities and precision in neural networks. predprop jointly addresses inference and learning, scales learning rates dynamically and weights gradients by the curvature of the loss function by optimizing prediction error precision. predprop optimizes network parameters with stochastic gradient descent and error forward propagation based strictly on prediction errors and variables locally available to each layer. neighboring layers optimise shared activity variables so that prediction errors can propagate forward in the network, while predictions propagate backwards. this process minimises the negative free energy, or evidence lower bound of the entire network. we show that networks trained with predprop resemble gradient based predictive coding when the number of weights between neighboring activity variables is one. in contrast to related work, predprop generalizes towards backward connections of arbitrary depth and optimizes precision for any deep network architecture. due to the analogy between prediction error precision and the fisher information for each layer, predprop implements a form of natural gradient descent. when optimizing dnn models, layer-wise predprop renders the model a bidirectional predictive coding network. alternatively dnns can parameterize the weights between two activity variables. we evaluate predprop for dense dnns on simple inference, learning and combined tasks. we show that, without an explicit sampling step in the network, predprop implements a form of variational inference that allows to learn disentangled embeddings from low amounts of data and leave evaluation on more complex tasks and datasets to future work.",,2021-11-16,,"['andré ofner', 'sebastian stober']"
2111.08817,compressive features in offline reinforcement learning for recommender   systems,cs.ai,"in this paper, we develop a recommender system for a game that suggests potential items to players based on their interactive behaviors to maximize revenue for the game provider. our approach is built on a reinforcement learning-based technique and is trained on an offline data set that is publicly available on an ieee big data cup challenge. the limitation of the offline data set and the curse of high dimensionality pose significant obstacles to solving this problem. our proposed method focuses on improving the total rewards and performance by tackling these main difficulties. more specifically, we utilized sparse pca to extract important features of user behaviors. our q-learning-based system is then trained from the processed offline data set. to exploit all possible information from the provided data set, we cluster user features to different groups and build an independent q-table for each group. furthermore, to tackle the challenge of unknown formula for evaluation metrics, we design a metric to self-evaluate our system's performance based on the potential value the game provider might achieve and a small collection of actual evaluation metrics that we obtain from the live scoring environment. our experiments show that our proposed metric is consistent with the results published by the challenge organizers. we have implemented the proposed training pipeline, and the results show that our method outperforms current state-of-the-art methods in terms of both total rewards and training speed. by addressing the main challenges and leveraging the state-of-the-art techniques, we have achieved the best public leaderboard result in the challenge. furthermore, our proposed method achieved an estimated score of approximately 20% better and can be trained faster by 30 times than the best of the current state-of-the-art methods.",,2021-11-16,,"['hung nguyen', 'minh nguyen', 'long pham', 'jennifer adorno nieves']"
2111.08823,meta-auto-decoder for solving parametric partial differential equations,cs.lg cs.ai physics.comp-ph,"partial differential equations (pdes) are ubiquitous in many disciplines of science and engineering and notoriously difficult to solve. in general, closed-form solutions of pdes are unavailable and numerical approximation methods are computationally expensive. the parameters of pdes are variable in many applications, such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. in these applications, our goal is to solve parametric pdes rather than one instance of them. our proposed approach, called meta-auto-decoder (mad), treats solving parametric pdes as a meta-learning problem and utilizes the auto-decoder structure in \cite{park2019deepsdf} to deal with different tasks/pdes. physics-informed losses induced from the pde governing equations and boundary conditions is used as the training losses for different tasks. the goal of mad is to learn a good model initialization that can generalize across different tasks, and eventually enables the unseen task to be learned faster. the inspiration of mad comes from (conjectured) low-dimensional structure of parametric pde solutions and we explain our approach from the perspective of manifold learning. finally, we demonstrate the power of mad though extensive numerical studies, including burgers' equation, laplace's equation and time-domain maxwell's equations. mad exhibits faster convergence speed without losing the accuracy compared with other deep learning methods.",,2021-11-14,,"['xiang huang', 'zhanhong ye', 'hongsheng liu', 'beiji shi', 'zidong wang', 'kang yang', 'yang li', 'bingya weng', 'min wang', 'haotian chu', 'jing zhou', 'fan yu', 'bei hua', 'lei chen', 'bin dong']"
2111.08826,a benchmark for modeling violation-of-expectation in physical reasoning   across event categories,cs.cv cs.ai,"recent work in computer vision and cognitive reasoning has given rise to an increasing adoption of the violation-of-expectation (voe) paradigm in synthetic datasets. inspired by infant psychology, researchers are now evaluating a model's ability to label scenes as either expected or surprising with knowledge of only expected scenes. however, existing voe-based 3d datasets in physical reasoning provide mainly vision data with little to no heuristics or inductive biases. cognitive models of physical reasoning reveal infants create high-level abstract representations of objects and interactions. capitalizing on this knowledge, we established a benchmark to study physical reasoning by curating a novel large-scale synthetic 3d voe dataset armed with ground-truth heuristic labels of causally relevant features and rules. to validate our dataset in five event categories of physical reasoning, we benchmarked and analyzed human performance. we also proposed the object file physical reasoning network (ofpr-net) which exploits the dataset's novel heuristics to outperform our baseline and ablation models. the ofpr-net is also flexible in learning an alternate physical reality, showcasing its ability to learn universal causal relationships in physical reasoning to create systems with better interpretability.",,2021-11-16,,"['arijit dasgupta', 'jiafei duan', 'marcelo h. ang', 'yi lin', 'su-hua wang', 'renée baillargeon', 'cheston tan']"
2111.08840,online advertising revenue forecasting: an interpretable deep learning   approach,cs.lg cs.ai,"online advertising revenues account for an increasing share of publishers' revenue streams, especially for small and medium-sized publishers who depend on the advertisement networks of tech companies such as google and facebook. thus publishers may benefit significantly from accurate online advertising revenue forecasts to better manage their website monetization strategies. however, publishers who only have access to their own revenue data lack a holistic view of the total ad market of publishers, which in turn limits their ability to generate insights into their own future online advertising revenues. to address this business issue, we leverage a proprietary database encompassing google adsense revenues from a large collection of publishers in diverse areas. we adopt the temporal fusion transformer (tft) model, a novel attention-based architecture to predict publishers' advertising revenues. we leverage multiple covariates, including not only the publisher's own characteristics but also other publishers' advertising revenues. our prediction results outperform several benchmark deep-learning time-series forecast models over multiple time horizons. moreover, we interpret the results by analyzing variable importance weights to identify significant features and self-attention weights to reveal persistent temporal patterns.",,2021-11-16,,"['max würfel', 'qiwei han', 'maximilian kaiser']"
2111.08857,seihai: a sample-efficient hierarchical ai for the minerl competition,cs.lg cs.ai cs.ma cs.ro cs.sy eess.sy,"the minerl competition is designed for the development of reinforcement learning and imitation learning algorithms that can efficiently leverage human demonstrations to drastically reduce the number of environment interactions needed to solve the complex \emph{obtaindiamond} task with sparse rewards. to address the challenge, in this paper, we present \textbf{seihai}, a \textbf{s}ample-\textbf{e}ff\textbf{i}cient \textbf{h}ierarchical \textbf{ai}, that fully takes advantage of the human demonstrations and the task structure. specifically, we split the task into several sequentially dependent subtasks, and train a suitable agent for each subtask using reinforcement learning and imitation learning. we further design a scheduler to select different agents for different subtasks automatically. seihai takes the first place in the preliminary and final of the neurips-2020 minerl competition.",,2021-11-16,,"['hangyu mao', 'chao wang', 'xiaotian hao', 'yihuan mao', 'yiming lu', 'chengjie wu', 'jianye hao', 'dong li', 'pingzhong tang']"
2111.08858,a normative and biologically plausible algorithm for independent   component analysis,cs.ne cs.ai q-bio.nc,"the brain effortlessly solves blind source separation (bss) problems, but the algorithm it uses remains elusive. in signal processing, linear bss problems are often solved by independent component analysis (ica). to serve as a model of a biological circuit, the ica neural network (nn) must satisfy at least the following requirements: 1. the algorithm must operate in the online setting where data samples are streamed one at a time, and the nn computes the sources on the fly without storing any significant fraction of the data in memory. 2. the synaptic weight update is local, i.e., it depends only on the biophysical variables present in the vicinity of a synapse. here, we propose a novel objective function for ica from which we derive a biologically plausible nn, including both the neural architecture and the synaptic learning rules. interestingly, our algorithm relies on modulating synaptic plasticity by the total activity of the output neurons. in the brain, this could be accomplished by neuromodulators, extracellular calcium, local field potential, or nitric oxide.",,2021-11-16,,"['yanis bahroun', 'dmitri b chklovskii', 'anirvan m sengupta']"
2111.08897,arkitscenes -- a diverse real-world dataset for 3d indoor scene   understanding using mobile rgb-d data,cs.cv cs.ai,"scene understanding is an active research area. commercial depth sensors, such as kinect, have enabled the release of several rgb-d datasets over the past few years which spawned novel methods in 3d scene understanding. more recently with the launch of the lidar sensor in apple's ipads and iphones, high quality rgb-d data is accessible to millions of people on a device they commonly use. this opens a whole new era in scene understanding for the computer vision community as well as app developers. the fundamental research in scene understanding together with the advances in machine learning can now impact people's everyday experiences. however, transforming these scene understanding methods to real-world experiences requires additional innovation and development. in this paper we introduce arkitscenes. it is not only the first rgb-d dataset that is captured with a now widely available depth sensor, but to our best knowledge, it also is the largest indoor scene understanding data released. in addition to the raw and processed data from the mobile device, arkitscenes includes high resolution depth maps captured using a stationary laser scanner, as well as manually labeled 3d oriented bounding boxes for a large taxonomy of furniture. we further analyze the usefulness of the data for two downstream tasks: 3d object detection and color-guided depth upsampling. we demonstrate that our dataset can help push the boundaries of existing state-of-the-art methods and it introduces new challenges that better represent real-world scenarios.",,2021-11-16,,"['gilad baruch', 'zhuoyuan chen', 'afshin dehghan', 'tal dimry', 'yuri feigin', 'peter fu', 'thomas gebauer', 'brandon joffe', 'daniel kurz', 'arik schwartz', 'elad shulman']"
2111.08951,exploring student representation for neural cognitive diagnosis,cs.ai,"cognitive diagnosis, the goal of which is to obtain the proficiency level of students on specific knowledge concepts, is an fundamental task in smart educational systems. previous works usually represent each student as a trainable knowledge proficiency vector, which cannot capture the relations of concepts and the basic profile(e.g. memory or comprehension) of students. in this paper, we propose a method of student representation with the exploration of the hierarchical relations of knowledge concepts and student embedding. specifically, since the proficiency on parent knowledge concepts reflects the correlation between knowledge concepts, we get the first knowledge proficiency with a parent-child concepts projection layer. in addition, a low-dimension dense vector is adopted as the embedding of each student, and obtain the second knowledge proficiency with a full connection layer. then, we combine the two proficiency vector above to get the final representation of students. experiments show the effectiveness of proposed representation method.",,2021-11-17,,"['hengyao bao', 'xihua li', 'xuemin zhao', 'yunbo cao']"
2111.08960,compositional transformers for scene generation,cs.cv cs.ai cs.lg,"we introduce the ganformer2 model, an iterative object-oriented transformer, explored for the task of generative modeling. the network incorporates strong and explicit structural priors, to reflect the compositional nature of visual scenes, and synthesizes images through a sequential process. it operates in two stages: a fast and lightweight planning phase, where we draft a high-level scene layout, followed by an attention-based execution phase, where the layout is being refined, evolving into a rich and detailed picture. our model moves away from conventional black-box gan architectures that feature a flat and monolithic latent space towards a transparent design that encourages efficiency, controllability and interpretability. we demonstrate ganformer2's strengths and qualities through a careful evaluation over a range of datasets, from multi-object clevr scenes to the challenging coco images, showing it successfully achieves state-of-the-art performance in terms of visual quality, diversity and consistency. further experiments demonstrate the model's disentanglement and provide a deeper insight into its generative process, as it proceeds step-by-step from a rough initial sketch, to a detailed layout that accounts for objects' depths and dependencies, and up to the final high-resolution depiction of vibrant and intricate real-world scenes. see https://github.com/dorarad/gansformer for model implementation.",,2021-11-17,,"['drew a. hudson', 'c. lawrence zitnick']"
2111.08995,self-learning tuning for post-silicon validation,cs.lg cs.ai,"increasing complexity of modern chips makes design validation more difficult. existing approaches are not able anymore to cope with the complexity of tasks such as robust performance tuning in post-silicon validation. therefore, we propose a novel approach based on learn-to-optimize and reinforcement learning in order to solve complex and mixed-type tuning tasks in a efficient and robust way.",,2021-11-17,2021-11-18,"['peter domanski', 'dirk pflüger', 'jochen rivoir', 'raphaël latty']"
2111.09035,multi-attribute relation extraction (mare) -- simplifying the   application of relation extraction,cs.cl cs.ai cs.ir cs.lg,"natural language understanding's relation extraction makes innovative and encouraging novel business concepts possible and facilitates new digitilized decision-making processes. current approaches allow the extraction of relations with a fixed number of entities as attributes. extracting relations with an arbitrary amount of attributes requires complex systems and costly relation-trigger annotations to assist these systems. we introduce multi-attribute relation extraction (mare) as an assumption-less problem formulation with two approaches, facilitating an explicit mapping from business use cases to the data annotations. avoiding elaborated annotation constraints simplifies the application of relation extraction approaches. the evaluation compares our models to current state-of-the-art event extraction and binary relation extraction methods. our approaches show improvement compared to these on the extraction of general multi-attribute relations.",10.5220/0010559201480156,2021-11-17,,"['lars klöser', 'philipp kohl', 'bodo kraft', 'albert zündorf']"
2111.09078,green cws: extreme distillation and efficient decode method towards   industrial application,cs.ai,"benefiting from the strong ability of the pre-trained model, the research on chinese word segmentation (cws) has made great progress in recent years. however, due to massive computation, large and complex models are incapable of empowering their ability for industrial use. on the other hand, for low-resource scenarios, the prevalent decode method, such as conditional random field (crf), fails to exploit the full information of the training data. this work proposes a fast and accurate cws framework that incorporates a light-weighted model and an upgraded decode method (pcrf) towards industrially low-resource cws scenarios. first, we distill a transformer-based student model as an encoder, which not only accelerates the inference speed but also combines open knowledge and domain-specific knowledge. second, the perplexity score to evaluate the language model is fused into the crf module to better identify the word boundaries. experiments show that our work obtains relatively high performance on multiple datasets with as low as 14\% of time consumption compared with the original bert-based model. moreover, under the low-resource setting, we get superior results in comparison with the traditional decoding methods.",,2021-11-17,,"['yulan hu', 'yong liu']"
2111.09084,a graph-based imputation method for sparse medical records,cs.ai,"electronic medical records (ehr) are extremely sparse. only a small proportion of events (symptoms, diagnoses, and treatments) are observed in the lifetime of an individual. the high degree of missingness of ehr can be attributed to a large number of factors, including device failure, privacy concerns, or other unexpected reasons. unfortunately, many traditional imputation methods are not well suited for highly sparse data and scale poorly to high dimensional datasets. in this paper, we propose a graph-based imputation method that is both robust to sparsity and to unreliable unmeasured events. our approach compares favourably to several standard and state-of-the-art imputation methods in terms of performance and runtime. moreover, results indicate that the model learns to embed different event types in a clinically meaningful way. our work can facilitate the diagnosis of novel diseases based on the clinical history of past events, with the potential to increase our understanding of the landscape of comorbidities.",,2021-11-17,,"['ramon vinas', 'xu zheng', 'jer hayes']"
2111.09085,network generation with differential privacy,cs.lg cs.ai cs.cr cs.si,"we consider the problem of generating private synthetic versions of real-world graphs containing private information while maintaining the utility of generated graphs. differential privacy is a gold standard for data privacy, and the introduction of the differentially private stochastic gradient descent (dp-sgd) algorithm has facilitated the training of private neural models in a number of domains. recent advances in graph generation via deep generative networks have produced several high performing models. we evaluate and compare state-of-the-art models including adjacency matrix based models and edge based models, and show a practical implementation that favours the edge-list approach utilizing the gaussian noise mechanism when evaluated on commonly used graph datasets. based on our findings, we propose a generative model that can reproduce the properties of real-world networks while maintaining edge-differential privacy. the proposed model is based on a stochastic neural network that generates discrete edge-list samples and is trained using the wasserstein gan objective with the dp-sgd optimizer. being the first approach to combine these beneficial properties, our model contributes to further research on graph data privacy.",,2021-11-17,,"['xu zheng', 'nicholas mccarthy', 'jer hayes']"
2111.09093,the faulty gps problem: shortest time paths in networks with unreliable   directions,cs.ai,"this paper optimizes motion planning when there is a known risk that the road choice suggested by a satnav (gps) is not on a shortest path. at every branch node of a network q, a satnav (gps) points to the arc leading to the destination, or home node, h - but only with a high known probability p. always trusting the satnav's suggestion may lead to an infinite cycle. if one wishes to reach h in least expected time, with what probability q=q(q,p) should one trust the pointer (if not, one chooses randomly among the other arcs)? we call this the faulty satnav (gps) problem. we also consider versions where the trust probability q can depend on the degree of the current node and a `treasure hunt' where two searchers try to reach h first. the agent searching for h need not be a car, that is just a familiar example -- it could equally be a uav receiving unreliable gps information. this problem has its origin not in driver frustration but in the work of fonio et al (2017) on ant navigation, where the pointers correspond to pheromone markers pointing to the nest. neither the driver or ant will know the exact process by which a choice (arc) is suggested, which puts the problem into the domain of how much to trust an option suggested by ai.",,2021-11-17,,['steve alpern']
2111.09111,forecasting crude oil price using event extraction,cs.lg cs.ai cs.cl econ.gn q-fin.ec stat.ap,"research on crude oil price forecasting has attracted tremendous attention from scholars and policymakers due to its significant effect on the global economy. besides supply and demand, crude oil prices are largely influenced by various factors, such as economic development, financial markets, conflicts, wars, and political events. most previous research treats crude oil price forecasting as a time series or econometric variable prediction problem. although recently there have been researches considering the effects of real-time news events, most of these works mainly use raw news headlines or topic models to extract text features without profoundly exploring the event information. in this study, a novel crude oil price forecasting framework, agesl, is proposed to deal with this problem. in our approach, an open domain event extraction algorithm is utilized to extract underlying related events, and a text sentiment analysis algorithm is used to extract sentiment from massive news. then a deep neural network integrating the news event features, sentimental features, and historical price features is built to predict future crude oil prices. empirical experiments are performed on west texas intermediate (wti) crude oil price data, and the results show that our approach obtains superior performance compared with several benchmark methods.",10.1109/access.2021.3124802,2021-11-14,,"['jiangwei liu', 'xiaohong huang']"
2111.09121,uncertainty quantification of surrogate explanations: an ordinal   consensus approach,cs.lg cs.ai stat.ml,"explainability of black-box machine learning models is crucial, in particular when deployed in critical applications such as medicine or autonomous cars. existing approaches produce explanations for the predictions of models, however, how to assess the quality and reliability of such explanations remains an open question. in this paper we take a step further in order to provide the practitioner with tools to judge the trustworthiness of an explanation. to this end, we produce estimates of the uncertainty of a given explanation by measuring the ordinal consensus amongst a set of diverse bootstrapped surrogate explainers. while we encourage diversity by using ensemble techniques, we propose and analyse metrics to aggregate the information contained within the set of explainers through a rating scheme. we empirically illustrate the properties of this approach through experiments on state-of-the-art convolutional neural network ensembles. furthermore, through tailored visualisations, we show specific examples of situations where uncertainty estimates offer concrete actionable insights to the user beyond those arising from standard surrogate explainers.",,2021-11-17,,"['jonas schulz', 'rafael poyiadzi', 'raul santos-rodriguez']"
2111.09124,route optimization via environment-aware deep network and reinforcement   learning,cs.lg cs.ai,"vehicle mobility optimization in urban areas is a long-standing problem in smart city and spatial data analysis. given the complex urban scenario and unpredictable social events, our work focuses on developing a mobile sequential recommendation system to maximize the profitability of vehicle service providers (e.g., taxi drivers). in particular, we treat the dynamic route optimization problem as a long-term sequential decision-making task. a reinforcement-learning framework is proposed to tackle this problem, by integrating a self-check mechanism and a deep neural network for customer pick-up point monitoring. to account for unexpected situations (e.g., the covid-19 outbreak), our method is designed to be capable of handling related environment changes with a self-adaptive parameter determination mechanism. based on the yellow taxi data in new york city and vicinity before and after the covid-19 outbreak, we have conducted comprehensive experiments to evaluate the effectiveness of our method. the results show consistently excellent performance, from hourly to weekly measures, to support the superiority of our method over the state-of-the-art methods (i.e., with more than 98% improvement in terms of the profitability for taxi drivers).",,2021-11-15,,"['pengzhan guo', 'keli xiao', 'zeyang ye', 'wei zhu']"
2111.09139,airport taxi time prediction and alerting: a convolutional neural   network approach,cs.lg cs.ai,"this paper proposes a novel approach to predict and determine whether the average taxi- out time at an airport will exceed a pre-defined threshold within the next hour of operations. prior work in this domain has focused exclusively on predicting taxi-out times on a flight-by-flight basis, which requires significant efforts and data on modeling taxiing activities from gates to runways. learning directly from surface radar information with minimal processing, a computer vision-based model is proposed that incorporates airport surface data in such a way that adaptation-specific information (e.g., runway configuration, the state of aircraft in the taxiing process) is inferred implicitly and automatically by artificial intelligence (ai).",,2021-11-17,,"['erik vargo', 'alex tien', 'arian jafari']"
2111.09152,improved cooperation by balancing exploration and exploitation in   intertemporal social dilemma tasks,cs.ma cs.ai cs.cy,"when an individual's behavior has rational characteristics, this may lead to irrational collective actions for the group. a wide range of organisms from animals to humans often evolve the social attribute of cooperation to meet this challenge. therefore, cooperation among individuals is of great significance for allowing social organisms to adapt to changes in the natural environment. based on multi-agent reinforcement learning, we propose a new learning strategy for achieving coordination by incorporating a learning rate that can balance exploration and exploitation. we demonstrate that agents that use the simple strategy improve a relatively collective return in a decision task called the intertemporal social dilemma, where the conflict between the individual and the group is particularly sharp. we also explore the effects of the diversity of learning rates on the population of reinforcement learning agents and show that agents trained in heterogeneous populations develop particularly coordinated policies relative to those trained in homogeneous populations.",,2021-10-19,,"['zhenbo cheng', 'xingguang liu', 'leilei zhang', 'hangcheng meng', 'qin li', 'xiao gang']"
2111.09159,aggressive q-learning with ensembles: achieving both high sample   efficiency and high asymptotic performance,cs.lg cs.ai,"recently, truncated quantile critics (tqc), using distributional representation of critics, was shown to provide state-of-the-art asymptotic training performance on all environments from the mujoco continuous control benchmark suite. also recently, randomized ensemble double q-learning (redq), using a high update-to-data ratio and target randomization, was shown to achieve high sample efficiency that is competitive with state-of-the-art model-based methods. in this paper, we propose a novel model-free algorithm, aggressive q-learning with ensembles (aqe), which improves the sample-efficiency performance of redq and the asymptotic performance of tqc, thereby providing overall state-of-the-art performance during all stages of training. moreover, aqe is very simple, requiring neither distributional representation of critics nor target randomization.",,2021-11-17,,"['yanqiu wu', 'xinyue chen', 'che wang', 'yiming zhang', 'zijian zhou', 'keith w. ross']"
2111.09189,tom2c: target-oriented multi-agent communication and cooperation with   theory of mind,cs.ma cs.ai cs.lg,"being able to predict the mental states of others is a key factor to effective social interaction. it is also crucial for distributed multi-agent systems, where agents are required to communicate and cooperate. in this paper, we introduce such an important social-cognitive skill, i.e. theory of mind (tom), to build socially intelligent agents who are able to communicate and cooperate effectively to accomplish challenging tasks. with tom, each agent is capable of inferring the mental states and intentions of others according to its (local) observation. based on the inferred states, the agents decide ""when"" and with ""whom"" to share their intentions. with the information observed, inferred, and received, the agents decide their sub-goals and reach a consensus among the team. in the end, the low-level executors independently take primitive actions to accomplish the sub-goals. we demonstrate the idea in two typical target-oriented multi-agent tasks: cooperative navigation and multi-sensor target coverage. the experiments show that the proposed model not only outperforms the state-of-the-art methods on reward and communication efficiency, but also shows good generalization across different scales of the environment.",,2021-10-15,,"['yuanfei wang', 'fangwei zhong', 'jing xu', 'yizhou wang']"
2111.09190,understanding and testing generalization of deep networks on   out-of-distribution data,cs.lg cs.ai,"deep network models perform excellently on in-distribution (id) data, but can significantly fail on out-of-distribution (ood) data. while developing methods focus on improving ood generalization, few attention has been paid to evaluating the capability of models to handle ood data. this study is devoted to analyzing the problem of experimental id test and designing ood test paradigm to accurately evaluate the practical performance. our analysis is based on an introduced categorization of three types of distribution shifts to generate ood data. main observations include: (1) id test fails in neither reflecting the actual performance of a single model nor comparing between different models under ood data. (2) the id test failure can be ascribed to the learned marginal and conditional spurious correlations resulted from the corresponding distribution shifts. based on this, we propose novel ood test paradigms to evaluate the generalization capacity of models to unseen data, and discuss how to use ood test results to find bugs of models to guide model debugging.",,2021-11-17,,"['rui hu', 'jitao sang', 'jinqiang wang', 'rui hu', 'chaoquan jiang']"
2111.09194,iv-gnn : interval valued data handling using graph neural network,cs.lg cs.ai,"graph neural network (gnn) is a powerful tool to perform standard machine learning on graphs. to have a euclidean representation of every node in the non-euclidean graph-like data, gnn follows neighbourhood aggregation and combination of information recursively along the edges of the graph. despite having many gnn variants in the literature, no model can deal with graphs having nodes with interval-valued features. this article proposes an interval-valuedgraph neural network, a novel gnn model where, for the first time, we relax the restriction of the feature space being countable. our model is much more general than existing models as any countable set is always a subset of the universal set $r^{n}$, which is uncountable. here, to deal with interval-valued feature vectors, we propose a new aggregation scheme of intervals and show its expressive power to capture different interval structures. we validate our theoretical findings about our model for graph classification tasks by comparing its performance with those of the state-of-the-art models on several benchmark network and synthetic datasets.",,2021-11-17,,"['sucheta dawn', 'sanghamitra bandyopadhyay']"
2111.09248,secure federated learning for residential short term load forecasting,cs.lg cs.ai cs.sy eess.sy,"the inclusion of intermittent and renewable energy sources has increased the importance of demand forecasting in power systems. smart meters can play a critical role in demand forecasting due to the measurement granularity they provide. consumers' privacy concerns, reluctance of utilities and vendors to share data with competitors or third parties, and regulatory constraints are some constraints smart meter forecasting faces. this paper examines a collaborative machine learning method for short-term demand forecasting using smart meter data as a solution to the previous constraints. privacy preserving techniques and federated learning enable to ensure consumers' confidentiality concerning both, their data, the models generated using it (differential privacy), and the communication mean (secure aggregation). the methods evaluated take into account several scenarios that explore how traditional centralized approaches could be projected in the direction of a decentralized, collaborative and private system. the results obtained over the evaluations provided almost perfect privacy budgets (1.39,$10e^{-5}$) and (2.01,$10e^{-5}$) with a negligible performance compromise.",,2021-11-17,,"['joaquin delgado fernandez', 'sergio potenciano menci', 'charles lee', 'gilbert fridgen']"
2111.09259,acquisition of chess knowledge in alphazero,cs.ai stat.ml,"what is being learned by superhuman neural network agents such as alphazero? this question is of both scientific and practical interest. if the representations of strong neural networks bear no resemblance to human concepts, our ability to understand faithful explanations of their decisions will be restricted, ultimately limiting what we can achieve with neural network interpretability. in this work we provide evidence that human knowledge is acquired by the alphazero neural network as it trains on the game of chess. by probing for a broad range of human chess concepts we show when and where these concepts are represented in the alphazero network. we also provide a behavioural analysis focusing on opening play, including qualitative analysis from chess grandmaster vladimir kramnik. finally, we carry out a preliminary investigation looking at the low-level details of alphazero's representations, and make the resulting behavioural and representational analyses available online.",,2021-11-17,,"['thomas mcgrath', 'andrei kapishnikov', 'nenad tomašev', 'adam pearce', 'demis hassabis', 'been kim', 'ulrich paquet', 'vladimir kramnik']"
2111.09266,gflownet foundations,cs.lg cs.ai stat.ml,"generative flow networks (gflownets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. in this paper, we show a number of additional theoretical properties of gflownets. they can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. gflownets amortize the work typically done by computationally expensive mcmc methods in a single but trained generative pass. they could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). we introduce variations enabling the estimation of entropy and mutual information, sampling from a pareto frontier, connections to reward-maximizing policies, and extensions to stochastic environments, continuous actions and modular energy functions.",,2021-11-17,,"['yoshua bengio', 'tristan deleu', 'edward j. hu', 'salem lahlou', 'mo tiwari', 'emmanuel bengio']"
2111.09267,divergan: an efficient and effective single-stage framework for diverse   text-to-image generation,cs.cv cs.ai,"in this paper, we present an efficient and effective single-stage framework (divergan) to generate diverse, plausible and semantically consistent images according to a natural-language description. divergan adopts two novel word-level attention modules, i.e., a channel-attention module (cam) and a pixel-attention module (pam), which model the importance of each word in the given sentence while allowing the network to assign larger weights to the significant channels and pixels semantically aligning with the salient words. after that, conditional adaptive instance-layer normalization (cadailn) is introduced to enable the linguistic cues from the sentence embedding to flexibly manipulate the amount of change in shape and texture, further improving visual-semantic representation and helping stabilize the training. also, a dual-residual structure is developed to preserve more original visual features while allowing for deeper networks, resulting in faster convergence speed and more vivid details. furthermore, we propose to plug a fully-connected layer into the pipeline to address the lack-of-diversity problem, since we observe that a dense layer will remarkably enhance the generative capability of the network, balancing the trade-off between a low-dimensional random latent code contributing to variants and modulation modules that use high-dimensional and textual contexts to strength feature maps. inserting a linear layer after the second residual block achieves the best variety and quality. both qualitative and quantitative results on benchmark data sets demonstrate the superiority of our divergan for realizing diversity, without harming quality and semantic consistency.",,2021-11-17,,"['zhenxing zhang', 'lambert schomaker']"
2111.09277,smoothmix: training confidence-calibrated smoothed classifiers for   certified robustness,cs.lg cs.ai,"randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against $\ell_2$-adversarial perturbations. under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. this motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of a smoothed classifier. in this paper, we propose a simple training scheme, coined smoothmix, to control the robustness of smoothed classifiers via self-mixup: it trains on convex combinations of samples along the direction of adversarial perturbation for each input. the proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. our experimental results demonstrate that the proposed method can significantly improve the certified $\ell_2$-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.",,2021-11-17,,"['jongheon jeong', 'sejun park', 'minkyu kim', 'heung-chang lee', 'doguk kim', 'jinwoo shin']"
2111.09297,learning to compose visual relations,cs.cv cs.ai cs.lg cs.ro stat.ml,"the visual world around us can be described as a structured set of objects and their associated relations. an image of a room may be conjured given only the description of the underlying objects and their associated relations. while there has been significant work on designing deep neural networks which may compose individual objects together, less work has been done on composing the individual relations between objects. a principal difficulty is that while the placement of objects is mutually independent, their relations are entangled and dependent on each other. to circumvent this issue, existing works primarily compose relations by utilizing a holistic encoder, in the form of text or graphs. in this work, we instead propose to represent each relation as an unnormalized density (an energy-based model), enabling us to compose separate relations in a factorized manner. we show that such a factorized decomposition allows the model to both generate and edit scenes that have multiple sets of relations more faithfully. we further show that decomposition enables our model to effectively understand the underlying relational scene structure. project page at: https://composevisualrelations.github.io/.",,2021-11-17,,"['nan liu', 'shuang li', 'yilun du', 'joshua b. tenenbaum', 'antonio torralba']"
2111.09301,learning to align sequential actions in the wild,cs.cv cs.ai,"state-of-the-art methods for self-supervised sequential action alignment rely on deep networks that find correspondences across videos in time. they either learn frame-to-frame mapping across sequences, which does not leverage temporal information, or assume monotonic alignment between each video pair, which ignores variations in the order of actions. as such, these methods are not able to deal with common real-world scenarios that involve background frames or videos that contain non-monotonic sequence of actions.   in this paper, we propose an approach to align sequential actions in the wild that involve diverse temporal variations. to this end, we propose an approach to enforce temporal priors on the optimal transport matrix, which leverages temporal consistency, while allowing for variations in the order of actions. our model accounts for both monotonic and non-monotonic sequences and handles background frames that should not be aligned. we demonstrate that our approach consistently outperforms the state-of-the-art in self-supervised sequential action representation learning on four different benchmark datasets.",,2021-11-17,,"['weizhe liu', 'bugra tekin', 'huseyin coskun', 'vibhav vineet', 'pascal fua', 'marc pollefeys']"
2111.09381,"medcod: a medically-accurate, emotive, diverse, and controllable dialog   system",cs.cl cs.ai cs.lg,"we present medcod, a medically-accurate, emotive, diverse, and controllable dialog system with a unique approach to the natural language generator module. medcod has been developed and evaluated specifically for the history taking task. it integrates the advantage of a traditional modular approach to incorporate (medical) domain knowledge with modern deep learning techniques to generate flexible, human-like natural language expressions. two key aspects of medcod's natural language output are described in detail. first, the generated sentences are emotive and empathetic, similar to how a doctor would communicate to the patient. second, the generated sentence structures and phrasings are varied and diverse while maintaining medical consistency with the desired medical concept (provided by the dialogue manager module of medcod). experimental results demonstrate the effectiveness of our approach in creating a human-like medical dialogue system. relevant code is available at https://github.com/curai/curai-research/tree/main/medcod",,2021-11-17,,"['rhys compton', 'ilya valmianski', 'li deng', 'costa huang', 'namit katariya', 'xavier amatriain', 'anitha kannan']"
2111.09388,minimum bayes risk decoding with neural metrics of translation quality,cs.cl cs.ai cs.lg,"this work applies minimum bayes risk (mbr) decoding to optimize diverse automated metrics of translation quality. automatic metrics in machine translation have made tremendous progress recently. in particular, neural metrics, fine-tuned on human ratings (e.g. bleurt, or comet) are outperforming surface metrics in terms of correlations to human judgements. our experiments show that the combination of a neural translation model with a neural reference-based metric, bleurt, results in significant improvement in automatic and human evaluations. this improvement is obtained with translations different from classical beam-search output: these translations have much lower likelihood and are less favored by surface metrics like bleu.",,2021-11-17,,"['markus freitag', 'david grangier', 'qijun tan', 'bowen liang']"
2111.09412,meta-reinforcement learning via buffering graph signatures for live   video streaming events,cs.ni cs.ai cs.lg,"in this study, we present a meta-learning model to adapt the predictions of the network's capacity between viewers who participate in a live video streaming event. we propose the melanie model, where an event is formulated as a markov decision process, performing meta-learning on reinforcement learning tasks. by considering a new event as a task, we design an actor-critic learning scheme to compute the optimal policy on estimating the viewers' high-bandwidth connections. to ensure fast adaptation to new connections or changes among viewers during an event, we implement a prioritized replay memory buffer based on the kullback-leibler divergence of the reward/throughput of the viewers' connections. moreover, we adopt a model-agnostic meta-learning framework to generate a global model from past events. as viewers scarcely participate in several events, the challenge resides on how to account for the low structural similarity of different events. to combat this issue, we design a graph signature buffer to calculate the structural similarities of several streaming events and adjust the training of the global model accordingly. we evaluate the proposed model on the link weight prediction task on three real-world datasets of live video streaming events. our experiments demonstrate the effectiveness of our proposed model, with an average relative gain of 25% against state-of-the-art strategies. for reproduction purposes, our evaluation datasets and implementation are publicly available at https://github.com/stefanosantaris/melanie",,2021-10-03,,"['stefanos antaris', 'dimitrios rafailidis', 'sarunas girdzijauskas']"
2111.09415,automated pii extraction from social media for raising privacy   awareness: a deep transfer learning approach,cs.si cs.ai cs.lg,"internet users have been exposing an increasing amount of personally identifiable information (pii) on social media. such exposed pii can cause severe losses to the users, and informing users of their pii exposure is crucial to raise their privacy awareness and encourage them to take protective measures. to this end, advanced automatic techniques are needed. while information extraction (ie) techniques can be used to extract the pii automatically, deep learning (dl)-based ie models alleviate the need for feature engineering and further improve the efficiency. however, dl-based ie models often require large-scale labeled data for training, but pii-labeled social media posts are difficult to obtain due to privacy concerns. also, these models rely heavily on pre-trained word embeddings, while pii in social media often varies in forms and thus has no fixed representations in pre-trained word embeddings. in this study, we propose the deep transfer learning for pii extraction (dtl-piie) framework to address these two limitations. dtl-piie transfers knowledge learned from publicly available pii data to social media to address the problem of rare pii-labeled data. moreover, our framework leverages graph convolutional networks (gcns) to incorporate syntactic patterns to guide piie without relying on pre-trained word embeddings. evaluation against benchmark ie models indicates that our approach outperforms state-of-the-art dl-based ie models. our framework can facilitate various applications, such as pii misuse prediction and privacy risk assessment, protecting the privacy of internet users.",,2021-11-11,,"['yizhi liu', 'fang yu lin', 'mohammadreza ebrahimi', 'weifeng li', 'hsinchun chen']"
2111.09437,sustainable artificial intelligence through continual learning,cs.ai cs.lg,"the increasing attention on artificial intelligence (ai) regulation has led to the definition of a set of ethical principles grouped into the sustainable ai framework. in this article, we identify continual learning, an active area of ai research, as a promising approach towards the design of systems compliant with the sustainable ai principles. while sustainable ai outlines general desiderata for ethical applications, continual learning provides means to put such desiderata into practice.",,2021-11-17,,"['andrea cossu', 'marta ziosi', 'vincenzo lomonaco']"
2111.09461,advancing covid-19 diagnosis with privacy-preserving collaboration in   artificial intelligence,cs.ai cs.cr,"artificial intelligence (ai) provides a promising substitution for streamlining covid-19 diagnoses. however, concerns surrounding security and trustworthiness impede the collection of large-scale representative medical data, posing a considerable challenge for training a well-generalised model in clinical practices. to address this, we launch the unified ct-covid ai diagnostic initiative (ucadi), where the ai model can be distributedly trained and independently executed at each host institution under a federated learning framework (fl) without data sharing. here we show that our fl model outperformed all the local models by a large yield (test sensitivity /specificity in china: 0.973/0.951, in the uk: 0.730/0.942), achieving comparable performance with a panel of professional radiologists. we further evaluated the model on the hold-out (collected from another two hospitals leaving out the fl) and heterogeneous (acquired with contrast materials) data, provided visual explanations for decisions made by the model, and analysed the trade-offs between the model performance and the communication costs in the federated training process. our study is based on 9,573 chest computed tomography scans (cts) from 3,336 patients collected from 23 hospitals located in china and the uk. collectively, our work advanced the prospects of utilising federated learning for privacy-preserving ai in digital health.",,2021-11-17,,"['xiang bai', 'hanchen wang', 'liya ma', 'yongchao xu', 'jiefeng gan', 'ziwei fan', 'fan yang', 'ke ma', 'jiehua yang', 'song bai', 'chang shu', 'xinyu zou', 'renhao huang', 'changzheng zhang', 'xiaowu liu', 'dandan tu', 'chuou xu', 'wenqing zhang', 'xi wang', 'anguo chen', 'yu zeng', 'dehua yang', 'ming-wei wang', 'nagaraj holalkere', 'neil j. halin', 'ihab r. kamel', 'jia wu', 'xuehua peng', 'xiang wang', 'jianbo shao', 'pattanasak mongkolwat', 'jianjun zhang', 'weiyang liu', 'michael roberts', 'zhongzhao teng', 'lucian beer', 'lorena escudero sanchez', 'evis sala', 'daniel rubin', 'adrian weller', 'joan lasenby', 'chuangsheng zheng', 'jianming wang', 'zhen li', 'carola-bibiane schönlieb', 'tian xia']"
2111.09475,lifelong reinforcement learning with temporal logic formulas and reward   machines,cs.ai,"continuously learning new tasks using high-level ideas or knowledge is a key capability of humans. in this paper, we propose lifelong reinforcement learning with sequential linear temporal logic formulas and reward machines (lsrm), which enables an agent to leverage previously learned knowledge to fasten learning of logically specified tasks. for the sake of more flexible specification of tasks, we first introduce sequential linear temporal logic (sltl), which is a supplement to the existing linear temporal logic (ltl) formal language. we then utilize reward machines (rm) to exploit structural reward functions for tasks encoded with high-level events, and propose automatic extension of rm and efficient knowledge transfer over tasks for continuous learning in lifetime. experimental results show that lsrm outperforms the methods that learn the target tasks from scratch by taking advantage of the task decomposition using sltl and knowledge transfer over rm during the lifelong learning process.",,2021-11-17,,"['xuejing zheng', 'chao yu', 'chen chen', 'jianye hao', 'hankz hankui zhuo']"
2111.09478,software engineering for responsible ai: an empirical study and   operationalised patterns,cs.ai cs.se,"although artificial intelligence (ai) is solving real-world challenges and transforming industries, there are serious concerns about its ability to behave and make decisions in a responsible way. many ai ethics principles and guidelines for responsible ai have been recently issued by governments, organisations, and enterprises. however, these ai ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to design and develop responsible ai systems. to address this shortcoming, we first present an empirical study where we interviewed 21 scientists and engineers to understand the practitioners' perceptions on ai ethics principles and their implementation. we then propose a template that enables ai ethics principles to be operationalised in the form of concrete patterns and suggest a list of patterns using the newly created template. these patterns provide concrete, operationalised guidance that facilitate the development of responsible ai systems.",,2021-11-17,,"['qinghua lu', 'liming zhu', 'xiwei xu', 'jon whittle', 'david douglas', 'conrad sanderson']"
2111.09502,docking-based virtual screening with multi-task learning,cs.lg cs.ai q-bio.bm,"machine learning shows great potential in virtual screening for drug discovery. current efforts on accelerating docking-based virtual screening do not consider using existing data of other previously developed targets. to make use of the knowledge of the other targets and take advantage of the existing data, in this work, we apply multi-task learning to the problem of docking-based virtual screening. with two large docking datasets, the results of extensive experiments show that multi-task learning can achieve better performances on docking score prediction. by learning knowledge across multiple targets, the model trained by multi-task learning shows a better ability to adapt to a new target. additional empirical study shows that other problems in drug discovery, such as the experimental drug-target affinity prediction, may also benefit from multi-task learning. our results demonstrate that multi-task learning is a promising machine learning approach for docking-based virtual screening and accelerating the process of drug discovery.",,2021-11-17,,"['zijing liu', 'xianbin ye', 'xiaoming fang', 'fan wang', 'hua wu', 'haifeng wang']"
2111.09533,deepguard: a framework for safeguarding autonomous driving systems from   inconsistent behavior,cs.lg cs.ai,"the deep neural networks (dnns)based autonomous driving systems (adss) are expected to reduce road accidents and improve safety in the transportation domain as it removes the factor of human error from driving tasks. the dnn based ads sometimes may exhibit erroneous or unexpected behaviors due to unexpected driving conditions which may cause accidents. it is not possible to generalize the dnn model performance for all driving conditions. therefore, the driving conditions that were not considered during the training of the ads may lead to unpredictable consequences for the safety of autonomous vehicles. this study proposes an autoencoder and time series analysis based anomaly detection system to prevent the safety critical inconsistent behavior of autonomous vehicles at runtime. our approach called deepguard consists of two components. the first component, the inconsistent behavior predictor, is based on an autoencoder and time series analysis to reconstruct the driving scenarios. based on reconstruction error and threshold it determines the normal and unexpected driving scenarios and predicts potential inconsistent behavior. the second component provides on the fly safety guards, that is, it automatically activates healing strategies to prevent inconsistencies in the behavior. we evaluated the performance of deepguard in predicting the injected anomalous driving scenarios using already available open sourced dnn based adss in the udacity simulator. our simulation results show that the best variant of deepguard can predict up to 93 percent on the chauffeur ads, 83 percent on dave2 ads, and 80 percent of inconsistent behavior on the epoch ads model, outperforming selforacle and deeproad. overall, deepguard can prevent up to 89 percent of all predicted inconsistent behaviors of ads by executing predefined safety guards.",,2021-11-18,,"['manzoor hussain', 'nazakat ali', 'jang-eui hong']"
2111.09537,the prominence of artificial intelligence in covid-19,cs.lg cs.ai,"in december 2019, a novel virus called covid-19 had caused an enormous number of causalities to date. the battle with the novel coronavirus is baffling and horrifying after the spanish flu 2019. while the front-line doctors and medical researchers have made significant progress in controlling the spread of the highly contiguous virus, technology has also proved its significance in the battle. moreover, artificial intelligence has been adopted in many medical applications to diagnose many diseases, even baffling experienced doctors. therefore, this survey paper explores the methodologies proposed that can aid doctors and researchers in early and inexpensive methods of diagnosis of the disease. most developing countries have difficulties carrying out tests using the conventional manner, but a significant way can be adopted with machine and deep learning. on the other hand, the access to different types of medical images has motivated the researchers. as a result, a mammoth number of techniques are proposed. this paper first details the background knowledge of the conventional methods in the artificial intelligence domain. following that, we gather the commonly used datasets and their use cases to date. in addition, we also show the percentage of researchers adopting machine learning over deep learning. thus we provide a thorough analysis of this scenario. lastly, in the research challenges, we elaborate on the problems faced in covid-19 research, and we address the issues with our understanding to build a bright and healthy environment.",,2021-11-18,,"['md abdullah al nasim', 'aditi dhali', 'faria afrin', 'noshin tasnim zaman', 'nazmul karim']"
2111.09562,comet: a novel memory-efficient deep learning training framework by   using error-bounded lossy compression,cs.ai cs.dc,"training wide and deep neural networks (dnns) require large amounts of storage resources such as memory because the intermediate activation data must be saved in the memory during forward propagation and then restored for backward propagation. however, state-of-the-art accelerators such as gpus are only equipped with very limited memory capacities due to hardware design constraints, which significantly limits the maximum batch size and hence performance speedup when training large-scale dnns. traditional memory saving techniques either suffer from performance overhead or are constrained by limited interconnect bandwidth or specific interconnect technology. in this paper, we propose a novel memory-efficient cnn training framework (called comet) that leverages error-bounded lossy compression to significantly reduce the memory requirement for training, to allow training larger models or to accelerate training. different from the state-of-the-art solutions that adopt image-based lossy compressors (such as jpeg) to compress the activation data, our framework purposely adopts error-bounded lossy compression with a strict error-controlling mechanism. specifically, we perform a theoretical analysis on the compression error propagation from the altered activation data to the gradients, and empirically investigate the impact of altered gradients over the training process. based on these analyses, we optimize the error-bounded lossy compression and propose an adaptive error-bound control scheme for activation data compression. we evaluate our design against state-of-the-art solutions with five widely-adopted cnns and imagenet dataset. experiments demonstrate that our proposed framework can significantly reduce the training memory consumption by up to 13.5x over the baseline training and 1.8x over another state-of-the-art compression-based framework, respectively, with little or no accuracy loss.",,2021-11-18,,"['sian jin', 'chengming zhang', 'xintong jiang', 'yunhe feng', 'hui guan', 'guanpeng li', 'shuaiwen leon song', 'dingwen tao']"
2111.09613,improving transferability of representations via augmentation-aware   self-supervision,cs.lg cs.ai cs.cv,"recent unsupervised representation learning methods have shown to be effective in a range of vision tasks by learning representations invariant to data augmentations such as random cropping and color jittering. however, such invariance could be harmful to downstream tasks if they rely on the characteristics of the data augmentations, e.g., location- or color-sensitive. this is not an issue just for unsupervised learning; we found that this occurs even in supervised learning because it also learns to predict the same label for all augmented samples of an instance. to avoid such failures and obtain more generalizable representations, we suggest to optimize an auxiliary self-supervised loss, coined augself, that learns the difference of augmentation parameters (e.g., cropping positions, color adjustment intensities) between two randomly augmented samples. our intuition is that augself encourages to preserve augmentation-aware information in learned representations, which could be beneficial for their transferability. furthermore, augself can easily be incorporated into recent state-of-the-art representation learning methods with a negligible additional training cost. extensive experiments demonstrate that our simple idea consistently improves the transferability of representations learned by supervised and unsupervised methods in various transfer learning scenarios. the code is available at https://github.com/hankook/augself.",,2021-11-18,,"['hankook lee', 'kibok lee', 'kimin lee', 'honglak lee', 'jinwoo shin']"
2111.09618,to augment or not to augment? a comparative study on text augmentation   techniques for low-resource nlp,cs.cl cs.ai,"data-hungry deep neural networks have established themselves as the standard for many nlp tasks including the traditional sequence tagging ones. despite their state-of-the-art performance on high-resource languages, they still fall behind of their statistical counter-parts in low-resource scenarios. one methodology to counter attack this problem is text augmentation, i.e., generating new synthetic training data points from existing data. although nlp has recently witnessed a load of textual augmentation techniques, the field still lacks a systematic performance analysis on a diverse set of languages and sequence tagging tasks. to fill this gap, we investigate three categories of text augmentation methodologies which perform changes on the syntax (e.g., cropping sub-sentences), token (e.g., random word insertion) and character (e.g., character swapping) levels. we systematically compare them on part-of-speech tagging, dependency parsing and semantic role labeling for a diverse set of language families using various models including the architectures that rely on pretrained multilingual contextualized language models such as mbert. augmentation most significantly improves dependency parsing, followed by part-of-speech tagging and semantic role labeling. we find the experimented techniques to be effective on morphologically rich languages in general rather than analytic languages such as vietnamese. our results suggest that the augmentation techniques can further improve over strong baselines based on mbert. we identify the character-level methods as the most consistent performers, while synonym replacement and syntactic augmenters provide inconsistent improvements. finally, we discuss that the results most heavily depend on the task, language pair, and the model type.",,2021-11-18,,['gözde gül şahin']
2111.09656,clmb: deep contrastive learning for robust metagenomic binning,cs.lg cs.ai q-bio.gn q-bio.qm,"the reconstruction of microbial genomes from large metagenomic datasets is a critical procedure for finding uncultivated microbial populations and defining their microbial functional roles. to achieve that, we need to perform metagenomic binning, clustering the assembled contigs into draft genomes. despite the existing computational tools, most of them neglect one important property of the metagenomic data, that is, the noise. to further improve the metagenomic binning step and reconstruct better metagenomes, we propose a deep contrastive learning framework for metagenome binning (clmb), which can efficiently eliminate the disturbance of noise and produce more stable and robust results. essentially, instead of denoising the data explicitly, we add simulated noise to the training data and force the deep learning model to produce similar and stable representations for both the noise-free data and the distorted data. consequently, the trained model will be robust to noise and handle it implicitly during usage. clmb outperforms the previous state-of-the-art binning methods significantly, recovering the most near-complete genomes on almost all the benchmarking datasets (up to 17\% more reconstructed genomes compared to the second-best method). it also improves the performance of bin refinement, reconstructing 8-22 more high-quality genomes and 15-32 more middle-quality genomes than the second-best result. impressively, in addition to being compatible with the binning refiner, single clmb even recovers on average 15 more hq genomes than the refiner of vamb and maxbin on the benchmarking datasets. clmb is open-source and available at https://github.com/zpf0117b/clmb/.",,2021-11-18,,"['pengfei zhang', 'zhengyuan jiang', 'yixuan wang', 'yu li']"
2111.09701,visual design intuition: predicting dynamic properties of beams from raw   cross-section images,eess.iv cs.ai cs.cv,"in this work we aim to mimic the human ability to acquire the intuition to estimate the performance of a design from visual inspection and experience alone. we study the ability of convolutional neural networks to predict static and dynamic properties of cantilever beams directly from their raw cross-section images. using pixels as the only input, the resulting models learn to predict beam properties such as volume maximum deflection and eigenfrequencies with 4.54% and 1.43% mean average percentage error (mape) respectively, compared to the finite element analysis (fea) approach. training these models doesn't require prior knowledge of theory or relevant geometric properties, but rather relies solely on simulated or empirical data, thereby making predictions based on ""experience"" as opposed to theoretical knowledge. since this approach is over 1000 times faster than fea, it can be adopted to create surrogate models that could speed up the preliminary optimization studies where numerous consecutive evaluations of similar geometries are required. we suggest that this modeling approach would aid in addressing challenging optimization problems involving complex structures and physical phenomena for which theoretical models are unavailable.",,2021-11-13,,"['philippe m. wyder', 'hod lipson']"
2111.09739,learning ultrasound scanning skills from human demonstrations,cs.ai cs.ro,"recently, the robotic ultrasound system has become an emerging topic owing to the widespread use of medical ultrasound. however, it is still a challenging task to model and to transfer the ultrasound skill from an ultrasound physician. in this paper, we propose a learning-based framework to acquire ultrasound scanning skills from human demonstrations. first, the ultrasound scanning skills are encapsulated into a high-dimensional multi-modal model in terms of interactions among ultrasound images, the probe pose and the contact force. the parameters of the model are learned using the data collected from skilled sonographers' demonstrations. second, a sampling-based strategy is proposed with the learned model to adjust the extracorporeal ultrasound scanning process to guide a newbie sonographer or a robot arm. finally, the robustness of the proposed framework is validated with the experiments on real data from sonographers.",,2021-11-09,,"['xutian deng', 'ziwei lei', 'yi wang', 'miao li']"
2111.09744,covered information disentanglement: model transparency via unbiased   permutation importance,cs.lg cs.ai,"model transparency is a prerequisite in many domains and an increasingly popular area in machine learning research. in the medical domain, for instance, unveiling the mechanisms behind a disease often has higher priority than the diagnostic itself since it might dictate or guide potential treatments and research directions. one of the most popular approaches to explain model global predictions is the permutation importance where the performance on permuted data is benchmarked against the baseline. however, this method and other related approaches will undervalue the importance of a feature in the presence of covariates since these cover part of its provided information. to address this issue, we propose covered information disentanglement (cid), a method that considers all feature information overlap to correct the values provided by permutation importance. we further show how to compute cid efficiently when coupled with markov random fields. we demonstrate its efficacy in adjusting permutation importance first on a controlled toy dataset and discuss its effect on real-world medical data.",,2021-11-18,,"['joão pereira', 'erik s. g. stroes', 'aeilko h. zwinderman', 'evgeni levin']"
2111.09762,hybrid super intelligence and polymetric analysis,cs.ai cs.cc,the problem of possible applications polymetric analysis for the resolution problems of artificial intelligence is discussed. as example the hybrid super intelligence system by n. moiseev type was selected. the bond between polymetric analysis and hybrid super intelligence system was shown. in operational sense polymetric analysis is more general system. therefore main principles of moiseev concept may be unify with the help of polymetric analysis. main peculiarities of this unification are analyzed.,,2021-11-18,,"['vladislav dorofeev', 'petro trokhimchuk']"
2111.09794,a survey of generalisation in deep reinforcement learning,cs.lg cs.ai,"the study of generalisation in deep reinforcement learning (rl) aims to produce rl algorithms whose policies generalise well to novel unseen situations at deployment time, avoiding overfitting to their training environments. tackling this is vital if we are to deploy reinforcement learning algorithms in real world scenarios, where the environment will be diverse, dynamic and unpredictable. this survey is an overview of this nascent field. we provide a unifying formalism and terminology for discussing different generalisation problems, building upon previous works. we go on to categorise existing benchmarks for generalisation, as well as current methods for tackling the generalisation problem. finally, we provide a critical discussion of the current state of the field, including recommendations for future work. among other conclusions, we argue that taking a purely procedural content generation approach to benchmark design is not conducive to progress in generalisation, we suggest fast online adaptation and tackling rl-specific problems as some areas for future work on methods for generalisation, and we recommend building benchmarks in underexplored problem settings such as offline rl generalisation and reward-function variation.",,2021-11-18,,"['robert kirk', 'amy zhang', 'edward grefenstette', 'tim rocktäschel']"
2111.09800,reinforcement learning on human decision models for uniquely   collaborative ai teammates,cs.ai cs.lg,"in 2021 the johns hopkins university applied physics laboratory held an internal challenge to develop artificially intelligent (ai) agents that could excel at the collaborative card game hanabi. agents were evaluated on their ability to play with human players whom the agents had never previously encountered. this study details the development of the agent that won the challenge by achieving a human-play average score of 16.5, outperforming the current state-of-the-art for human-bot hanabi scores. the winning agent's development consisted of observing and accurately modeling the author's decision making in hanabi, then training with a behavioral clone of the author. notably, the agent discovered a human-complementary play style by first mimicking human decision making, then exploring variations to the human-like strategy that led to higher simulated human-bot scores. this work examines in detail the design and implementation of this human compatible hanabi teammate, as well as the existence and implications of human-complementary strategies and how they may be explored for more successful applications of ai in human machine teams.",,2021-11-18,,['nicholas kantack']
2111.09851,the effects of learning in morphologically evolving robot systems,cs.ro cs.ai,"simultaneously evolving morphologies (bodies) and controllers (brains) of robots can cause a mismatch between the inherited body and brain in the offspring. to mitigate this problem, the addition of an infant learning period by the so-called triangle of life framework has been proposed relatively long ago. however, an empirical assessment is still lacking to-date. in this paper we investigate the effects of such a learning mechanism from different perspectives. using extensive simulations we show that learning can greatly increase task performance and reduce the number of generations required to reach a certain fitness level compared to the purely evolutionary approach. furthermore, although learning only directly affects the controllers, we demonstrate that the evolved morphologies will be also different. this provides a quantitative demonstration that changes in the brain can induce changes in the body. finally, we examine the concept of morphological intelligence quantified by the ability of a given body to learn. we observe that the learning delta, the performance difference between the inherited and the learned brain, is growing throughout the evolutionary process. this shows that evolution is producing robots with an increasing plasticity, that is, consecutive generations are becoming better and better learners which in turn makes them better and better at the given task. all in all, our results demonstrate that the triangle of life is not only a concept of theoretical interest, but a system architecture with practical benefits.",,2021-11-18,,"['jie luo', 'aart stuurman', 'jakub m. tomczak', 'jacintha ellers', 'agoston e. eiben']"
2111.09858,successor feature landmarks for long-horizon goal-conditioned   reinforcement learning,cs.lg cs.ai cs.cv cs.ro,"operating in the real-world often requires agents to learn about a complex environment and apply this understanding to achieve a breadth of goals. this problem, known as goal-conditioned reinforcement learning (gcrl), becomes especially challenging for long-horizon goals. current methods have tackled this problem by augmenting goal-conditioned policies with graph-based planning algorithms. however, they struggle to scale to large, high-dimensional state spaces and assume access to exploration mechanisms for efficiently collecting training data. in this work, we introduce successor feature landmarks (sfl), a framework for exploring large, high-dimensional environments so as to obtain a policy that is proficient for any goal. sfl leverages the ability of successor features (sf) to capture transition dynamics, using it to drive exploration by estimating state-novelty and to enable high-level planning by abstracting the state-space as a non-parametric landmark-based graph. we further exploit sf to directly compute a goal-conditioned policy for inter-landmark traversal, which we use to execute plans to ""frontier"" landmarks at the edge of the explored state space. we show in our experiments on minigrid and vizdoom that sfl enables efficient exploration of large, high-dimensional state spaces and outperforms state-of-the-art baselines on long-horizon gcrl tasks.",,2021-11-18,,"['christopher hoang', 'sungryull sohn', 'jongwook choi', 'wilka carvalho', 'honglak lee']"
2111.09863,a secure experimentation sandbox for the design and execution of trusted   and secure analytics in the aviation domain,cs.cr cs.ai cs.lg,"the aviation industry as well as the industries that benefit and are linked to it are ripe for innovation in the form of big data analytics. the number of available big data technologies is constantly growing, while at the same time the existing ones are rapidly evolving and empowered with new features. however, the big data era imposes the crucial challenge of how to effectively handle information security while managing massive and rapidly evolving data from heterogeneous data sources. while multiple technologies have emerged, there is a need to find a balance between multiple security requirements, privacy obligations, system performance and rapid dynamic analysis on large datasets. the current paper aims to introduce the icarus secure experimentation sandbox of the icarus platform. the icarus platform aims to provide a big data-enabled platform that aspires to become an 'one-stop shop' for aviation data and intelligence marketplace that provides a trusted and secure 'sandboxed' analytics workspace, allowing the exploration, integration and deep analysis of original and derivative data in a trusted and fair manner. towards this end, a secure experimentation sandbox has been designed and integrated in the icarus platform offering, that enables the provisioning of a sophisticated environment that can completely guarantee the safety and confidentiality of data, allowing to any interested party to utilise the platform to conduct analytical experiments in closed-lab conditions.",10.1007/978-3-030-66922-5_8,2021-11-18,,"['dimitrios miltiadou', 'stamatis pitsios', 'dimitrios spyropoulos', 'dimitrios alexandrou', 'fenareti lampathaki', 'domenico messina', 'konstantinos perakis']"
2111.09872,a big data intelligence marketplace and secure analytics experimentation   platform for the aviation industry,cs.cr cs.ai cs.lg,"the unprecedented volume, diversity and richness of aviation data that can be acquired, generated, stored, and managed provides unique capabilities for the aviation-related industries and pertains value that remains to be unlocked with the adoption of the innovative big data analytics technologies. despite the large efforts and investments on research and innovation, the big data technologies introduce a number of challenges to its adopters. besides the effective storage and access to the underlying big data, efficient data integration and data interoperability should be considered, while at the same time multiple data sources should be effectively combined by performing data exchange and data sharing between the different stakeholders. however, this reveals additional challenges for the crucial preservation of the information security of the collected data, the trusted and secure data exchange and data sharing, as well as the robust data access control. the current paper aims to introduce the icarus big data-enabled platform that aims provide a multi-sided platform that offers a novel aviation data and intelligence marketplace accompanied by a trusted and secure analytics workspace. it holistically handles the complete big data lifecycle from the data collection, data curation and data exploration to the data integration and data analysis of data originating from heterogeneous data sources with different velocity, variety and volume in a trusted and secure manner.",10.1007/978-3-030-72802-1_4,2021-11-18,,"['dimitrios miltiadou', 'stamatis pitsios', 'dimitrios spyropoulos', 'dimitrios alexandrou', 'fenareti lampathaki', 'domenico messina', 'konstantinos perakis']"
2111.09884,assisted robust reward design,cs.ro cs.ai cs.lg,"real-world robotic tasks require complex reward functions. when we define the problem the robot needs to solve, we pretend that a designer specifies this complex reward exactly, and it is set in stone from then on. in practice, however, reward design is an iterative process: the designer chooses a reward, eventually encounters an ""edge-case"" environment where the reward incentivizes the wrong behavior, revises the reward, and repeats. what would it mean to rethink robotics problems to formally account for this iterative nature of reward design? we propose that the robot not take the specified reward for granted, but rather have uncertainty about it, and account for the future design iterations as future evidence. we contribute an assisted reward design method that speeds up the design process by anticipating and influencing this future evidence: rather than letting the designer eventually encounter failure cases and revise the reward then, the method actively exposes the designer to such environments during the development phase. we test this method in a simplified autonomous driving task and find that it more quickly improves the car's behavior in held-out environments by proposing environments that are ""edge cases"" for the current reward.",,2021-11-18,,"['jerry zhi-yang he', 'anca d. dragan']"
